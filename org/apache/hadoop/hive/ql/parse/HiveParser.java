// $ANTLR 3.4 /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g 2014-09-16 00:26:59

package org.apache.hadoop.hive.ql.parse;

import java.util.Collection;
import java.util.HashMap;


import org.antlr.runtime.*;
import java.util.Stack;
import java.util.List;
import java.util.ArrayList;

import org.antlr.runtime.tree.*;


/**
   Licensed to the Apache Software Foundation (ASF) under one or more 
   contributor license agreements.  See the NOTICE file distributed with 
   this work for additional information regarding copyright ownership.
   The ASF licenses this file to You under the Apache License, Version 2.0
   (the "License"); you may not use this file except in compliance with 
   the License.  You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
*/
@SuppressWarnings({"all", "warnings", "unchecked"})
public class HiveParser extends Parser {
    public static final String[] tokenNames = new String[] {
        "<invalid>", "<EOR>", "<DOWN>", "<UP>", "AMPERSAND", "BITWISEOR", "BITWISEXOR", "BigintLiteral", "ByteLengthLiteral", "COLON", "COMMA", "COMMENT", "CharSetLiteral", "CharSetName", "DIV", "DIVIDE", "DOLLAR", "DOT", "DecimalLiteral", "Digit", "EQUAL", "EQUAL_NS", "Exponent", "GREATERTHAN", "GREATERTHANOREQUALTO", "HexDigit", "Identifier", "KW_ADD", "KW_AFTER", "KW_ALL", "KW_ALTER", "KW_ANALYZE", "KW_AND", "KW_ARCHIVE", "KW_ARRAY", "KW_AS", "KW_ASC", "KW_BEFORE", "KW_BETWEEN", "KW_BIGINT", "KW_BINARY", "KW_BOOLEAN", "KW_BOTH", "KW_BUCKET", "KW_BUCKETS", "KW_BY", "KW_CASCADE", "KW_CASE", "KW_CAST", "KW_CHANGE", "KW_CLUSTER", "KW_CLUSTERED", "KW_CLUSTERSTATUS", "KW_COLLECTION", "KW_COLUMN", "KW_COLUMNS", "KW_COMMENT", "KW_COMPUTE", "KW_CONCATENATE", "KW_CONTINUE", "KW_CREATE", "KW_CROSS", "KW_CUBE", "KW_CURRENT", "KW_CURSOR", "KW_DATA", "KW_DATABASE", "KW_DATABASES", "KW_DATE", "KW_DATETIME", "KW_DBPROPERTIES", "KW_DECIMAL", "KW_DEFERRED", "KW_DELETE", "KW_DELIMITED", "KW_DEPENDENCY", "KW_DESC", "KW_DESCRIBE", "KW_DIRECTORIES", "KW_DIRECTORY", "KW_DISABLE", "KW_DISTINCT", "KW_DISTRIBUTE", "KW_DOUBLE", "KW_DROP", "KW_ELEM_TYPE", "KW_ELSE", "KW_ENABLE", "KW_END", "KW_ESCAPED", "KW_EXCHANGE", "KW_EXCLUSIVE", "KW_EXISTS", "KW_EXPLAIN", "KW_EXPORT", "KW_EXTENDED", "KW_EXTERNAL", "KW_FALSE", "KW_FETCH", "KW_FIELDS", "KW_FILEFORMAT", "KW_FIRST", "KW_FLOAT", "KW_FOLLOWING", "KW_FOR", "KW_FORMAT", "KW_FORMATTED", "KW_FROM", "KW_FULL", "KW_FUNCTION", "KW_FUNCTIONS", "KW_GRANT", "KW_GROUP", "KW_GROUPING", "KW_HAVING", "KW_HOLD_DDLTIME", "KW_IDXPROPERTIES", "KW_IF", "KW_IGNORE", "KW_IMPORT", "KW_IN", "KW_INDEX", "KW_INDEXES", "KW_INNER", "KW_INPATH", "KW_INPUTDRIVER", "KW_INPUTFORMAT", "KW_INSERT", "KW_INT", "KW_INTERSECT", "KW_INTO", "KW_IS", "KW_ITEMS", "KW_JOIN", "KW_KEYS", "KW_KEY_TYPE", "KW_LATERAL", "KW_LEFT", "KW_LESS", "KW_LIKE", "KW_LIMIT", "KW_LINES", "KW_LOAD", "KW_LOCAL", "KW_LOCATION", "KW_LOCK", "KW_LOCKS", "KW_LOGICAL", "KW_LONG", "KW_MACRO", "KW_MAP", "KW_MAPJOIN", "KW_MATERIALIZED", "KW_MINUS", "KW_MORE", "KW_MSCK", "KW_NOSCAN", "KW_NOT", "KW_NO_DROP", "KW_NULL", "KW_OF", "KW_OFFLINE", "KW_ON", "KW_OPTION", "KW_OR", "KW_ORCFILE", "KW_ORDER", "KW_OUT", "KW_OUTER", "KW_OUTPUTDRIVER", "KW_OUTPUTFORMAT", "KW_OVER", "KW_OVERWRITE", "KW_PARTIALSCAN", "KW_PARTITION", "KW_PARTITIONED", "KW_PARTITIONS", "KW_PERCENT", "KW_PLUS", "KW_PRECEDING", "KW_PRESERVE", "KW_PRETTY", "KW_PROCEDURE", "KW_PROTECTION", "KW_PURGE", "KW_RANGE", "KW_RCFILE", "KW_READ", "KW_READONLY", "KW_READS", "KW_REBUILD", "KW_RECORDREADER", "KW_RECORDWRITER", "KW_REDUCE", "KW_REGEXP", "KW_RENAME", "KW_REPAIR", "KW_REPLACE", "KW_RESTRICT", "KW_REVOKE", "KW_RIGHT", "KW_RLIKE", "KW_ROLE", "KW_ROLLUP", "KW_ROW", "KW_ROWS", "KW_SCHEMA", "KW_SCHEMAS", "KW_SELECT", "KW_SEMI", "KW_SEQUENCEFILE", "KW_SERDE", "KW_SERDEPROPERTIES", "KW_SET", "KW_SETS", "KW_SHARED", "KW_SHOW", "KW_SHOW_DATABASE", "KW_SKEWED", "KW_SMALLINT", "KW_SORT", "KW_SORTED", "KW_SSL", "KW_STATISTICS", "KW_STORED", "KW_STREAMTABLE", "KW_STRING", "KW_STRUCT", "KW_TABLE", "KW_TABLES", "KW_TABLESAMPLE", "KW_TBLPROPERTIES", "KW_TEMPORARY", "KW_TERMINATED", "KW_TEXTFILE", "KW_THEN", "KW_TIMESTAMP", "KW_TINYINT", "KW_TO", "KW_TOUCH", "KW_TRANSFORM", "KW_TRIGGER", "KW_TRUE", "KW_TRUNCATE", "KW_UNARCHIVE", "KW_UNBOUNDED", "KW_UNDO", "KW_UNION", "KW_UNIONTYPE", "KW_UNIQUEJOIN", "KW_UNLOCK", "KW_UNSET", "KW_UNSIGNED", "KW_UPDATE", "KW_USE", "KW_USER", "KW_USING", "KW_UTC", "KW_UTCTIMESTAMP", "KW_VALUE_TYPE", "KW_VARCHAR", "KW_VIEW", "KW_WHEN", "KW_WHERE", "KW_WHILE", "KW_WINDOW", "KW_WITH", "LCURLY", "LESSTHAN", "LESSTHANOREQUALTO", "LPAREN", "LSQUARE", "Letter", "MINUS", "MOD", "NOTEQUAL", "Number", "PLUS", "QUESTION", "RCURLY", "RPAREN", "RSQUARE", "RegexComponent", "SEMICOLON", "STAR", "SmallintLiteral", "StringLiteral", "TILDE", "TinyintLiteral", "WS", "TOK_ALIASLIST", "TOK_ALLCOLREF", "TOK_ALTERDATABASE_PROPERTIES", "TOK_ALTERINDEX_PROPERTIES", "TOK_ALTERINDEX_REBUILD", "TOK_ALTERTABLE_ADDCOLS", "TOK_ALTERTABLE_ADDPARTS", "TOK_ALTERTABLE_ALTERPARTS", "TOK_ALTERTABLE_ALTERPARTS_MERGEFILES", "TOK_ALTERTABLE_ALTERPARTS_PROTECTMODE", "TOK_ALTERTABLE_ARCHIVE", "TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION", "TOK_ALTERTABLE_CLUSTER_SORT", "TOK_ALTERTABLE_DROPPARTS", "TOK_ALTERTABLE_FILEFORMAT", "TOK_ALTERTABLE_LOCATION", "TOK_ALTERTABLE_PARTITION", "TOK_ALTERTABLE_PROPERTIES", "TOK_ALTERTABLE_RENAME", "TOK_ALTERTABLE_RENAMECOL", "TOK_ALTERTABLE_RENAMEPART", "TOK_ALTERTABLE_REPLACECOLS", "TOK_ALTERTABLE_SERDEPROPERTIES", "TOK_ALTERTABLE_SERIALIZER", "TOK_ALTERTABLE_SKEWED", "TOK_ALTERTABLE_TOUCH", "TOK_ALTERTABLE_UNARCHIVE", "TOK_ALTERTBLPART_SKEWED_LOCATION", "TOK_ALTERVIEW_ADDPARTS", "TOK_ALTERVIEW_AS", "TOK_ALTERVIEW_DROPPARTS", "TOK_ALTERVIEW_PROPERTIES", "TOK_ALTERVIEW_RENAME", "TOK_ANALYZE", "TOK_BIGINT", "TOK_BINARY", "TOK_BOOLEAN", "TOK_CASCADE", "TOK_CHARSETLITERAL", "TOK_CLUSTERBY", "TOK_COLTYPELIST", "TOK_CREATEDATABASE", "TOK_CREATEFUNCTION", "TOK_CREATEINDEX", "TOK_CREATEINDEX_INDEXTBLNAME", "TOK_CREATEMACRO", "TOK_CREATEROLE", "TOK_CREATETABLE", "TOK_CREATEVIEW", "TOK_CROSSJOIN", "TOK_CUBE_GROUPBY", "TOK_DATABASECOMMENT", "TOK_DATABASELOCATION", "TOK_DATABASEPROPERTIES", "TOK_DATE", "TOK_DATELITERAL", "TOK_DATETIME", "TOK_DBPROPLIST", "TOK_DECIMAL", "TOK_DEFERRED_REBUILDINDEX", "TOK_DESCDATABASE", "TOK_DESCFUNCTION", "TOK_DESCTABLE", "TOK_DESTINATION", "TOK_DIR", "TOK_DISABLE", "TOK_DISTRIBUTEBY", "TOK_DOUBLE", "TOK_DROPDATABASE", "TOK_DROPFUNCTION", "TOK_DROPINDEX", "TOK_DROPMACRO", "TOK_DROPROLE", "TOK_DROPTABLE", "TOK_DROPTABLE_PROPERTIES", "TOK_DROPVIEW", "TOK_DROPVIEW_PROPERTIES", "TOK_ENABLE", "TOK_EXCHANGEPARTITION", "TOK_EXPLAIN", "TOK_EXPLIST", "TOK_EXPORT", "TOK_FALSE", "TOK_FILEFORMAT_GENERIC", "TOK_FLOAT", "TOK_FROM", "TOK_FULLOUTERJOIN", "TOK_FUNCTION", "TOK_FUNCTIONDI", "TOK_FUNCTIONSTAR", "TOK_GRANT", "TOK_GRANT_ROLE", "TOK_GRANT_WITH_OPTION", "TOK_GROUP", "TOK_GROUPBY", "TOK_GROUPING_SETS", "TOK_GROUPING_SETS_EXPRESSION", "TOK_HAVING", "TOK_HINT", "TOK_HINTARGLIST", "TOK_HINTLIST", "TOK_HOLD_DDLTIME", "TOK_IFEXISTS", "TOK_IFNOTEXISTS", "TOK_IGNOREPROTECTION", "TOK_IMPORT", "TOK_INDEXCOMMENT", "TOK_INDEXPROPERTIES", "TOK_INDEXPROPLIST", "TOK_INSERT", "TOK_INSERT_INTO", "TOK_INT", "TOK_ISNOTNULL", "TOK_ISNULL", "TOK_JOIN", "TOK_LATERAL_VIEW", "TOK_LATERAL_VIEW_OUTER", "TOK_LEFTOUTERJOIN", "TOK_LEFTSEMIJOIN", "TOK_LENGTH", "TOK_LIKETABLE", "TOK_LIMIT", "TOK_LIST", "TOK_LOAD", "TOK_LOCAL_DIR", "TOK_LOCKTABLE", "TOK_MAP", "TOK_MAPJOIN", "TOK_MSCK", "TOK_NOT_CLUSTERED", "TOK_NOT_SORTED", "TOK_NO_DROP", "TOK_NULL", "TOK_OFFLINE", "TOK_OP_ADD", "TOK_OP_AND", "TOK_OP_BITAND", "TOK_OP_BITNOT", "TOK_OP_BITOR", "TOK_OP_BITXOR", "TOK_OP_DIV", "TOK_OP_EQ", "TOK_OP_GE", "TOK_OP_GT", "TOK_OP_LE", "TOK_OP_LIKE", "TOK_OP_LT", "TOK_OP_MOD", "TOK_OP_MUL", "TOK_OP_NE", "TOK_OP_NOT", "TOK_OP_OR", "TOK_OP_SUB", "TOK_ORDERBY", "TOK_ORREPLACE", "TOK_PARTITIONINGSPEC", "TOK_PARTITIONLOCATION", "TOK_PARTSPEC", "TOK_PARTVAL", "TOK_PERCENT", "TOK_PRINCIPAL_NAME", "TOK_PRIVILEGE", "TOK_PRIVILEGE_LIST", "TOK_PRIV_ALL", "TOK_PRIV_ALTER_DATA", "TOK_PRIV_ALTER_METADATA", "TOK_PRIV_CREATE", "TOK_PRIV_DROP", "TOK_PRIV_INDEX", "TOK_PRIV_LOCK", "TOK_PRIV_OBJECT", "TOK_PRIV_OBJECT_COL", "TOK_PRIV_SELECT", "TOK_PRIV_SHOW_DATABASE", "TOK_PTBLFUNCTION", "TOK_QUERY", "TOK_READONLY", "TOK_RECORDREADER", "TOK_RECORDWRITER", "TOK_RESTRICT", "TOK_REVOKE", "TOK_REVOKE_ROLE", "TOK_RIGHTOUTERJOIN", "TOK_ROLE", "TOK_ROLLUP_GROUPBY", "TOK_ROWCOUNT", "TOK_SELECT", "TOK_SELECTDI", "TOK_SELEXPR", "TOK_SERDE", "TOK_SERDENAME", "TOK_SERDEPROPS", "TOK_SHOWCOLUMNS", "TOK_SHOWDATABASES", "TOK_SHOWFUNCTIONS", "TOK_SHOWINDEXES", "TOK_SHOWLOCKS", "TOK_SHOWPARTITIONS", "TOK_SHOWTABLES", "TOK_SHOW_CREATETABLE", "TOK_SHOW_GRANT", "TOK_SHOW_ROLE_GRANT", "TOK_SHOW_TABLESTATUS", "TOK_SHOW_TBLPROPERTIES", "TOK_SKEWED_LOCATIONS", "TOK_SKEWED_LOCATION_LIST", "TOK_SKEWED_LOCATION_MAP", "TOK_SMALLINT", "TOK_SORTBY", "TOK_STORAGEHANDLER", "TOK_STOREDASDIRS", "TOK_STREAMTABLE", "TOK_STRING", "TOK_STRINGLITERALSEQUENCE", "TOK_STRUCT", "TOK_SUBQUERY", "TOK_SWITCHDATABASE", "TOK_TAB", "TOK_TABALIAS", "TOK_TABCOL", "TOK_TABCOLLIST", "TOK_TABCOLNAME", "TOK_TABCOLVALUE", "TOK_TABCOLVALUES", "TOK_TABCOLVALUE_PAIR", "TOK_TABLEBUCKETS", "TOK_TABLEBUCKETSAMPLE", "TOK_TABLECOMMENT", "TOK_TABLEFILEFORMAT", "TOK_TABLELOCATION", "TOK_TABLEPARTCOLS", "TOK_TABLEPROPERTIES", "TOK_TABLEPROPERTY", "TOK_TABLEPROPLIST", "TOK_TABLEROWFORMAT", "TOK_TABLEROWFORMATCOLLITEMS", "TOK_TABLEROWFORMATFIELD", "TOK_TABLEROWFORMATLINES", "TOK_TABLEROWFORMATMAPKEYS", "TOK_TABLESERIALIZER", "TOK_TABLESKEWED", "TOK_TABLESPLITSAMPLE", "TOK_TABLE_OR_COL", "TOK_TABLE_PARTITION", "TOK_TABNAME", "TOK_TABREF", "TOK_TABSORTCOLNAMEASC", "TOK_TABSORTCOLNAMEDESC", "TOK_TABSRC", "TOK_TABTYPE", "TOK_TBLORCFILE", "TOK_TBLRCFILE", "TOK_TBLSEQUENCEFILE", "TOK_TBLTEXTFILE", "TOK_TIMESTAMP", "TOK_TINYINT", "TOK_TMP_FILE", "TOK_TRANSFORM", "TOK_TRUE", "TOK_TRUNCATETABLE", "TOK_UNION", "TOK_UNIONTYPE", "TOK_UNIQUEJOIN", "TOK_UNLOCKTABLE", "TOK_USER", "TOK_USERSCRIPTCOLNAMES", "TOK_USERSCRIPTCOLSCHEMA", "TOK_VARCHAR", "TOK_VIEWPARTCOLS", "TOK_WHERE", "TOK_WINDOWDEF", "TOK_WINDOWRANGE", "TOK_WINDOWSPEC", "TOK_WINDOWVALUES", "826"
    };

    public static final int EOF=-1;
    public static final int AMPERSAND=4;
    public static final int BITWISEOR=5;
    public static final int BITWISEXOR=6;
    public static final int BigintLiteral=7;
    public static final int ByteLengthLiteral=8;
    public static final int COLON=9;
    public static final int COMMA=10;
    public static final int COMMENT=11;
    public static final int CharSetLiteral=12;
    public static final int CharSetName=13;
    public static final int DIV=14;
    public static final int DIVIDE=15;
    public static final int DOLLAR=16;
    public static final int DOT=17;
    public static final int DecimalLiteral=18;
    public static final int Digit=19;
    public static final int EQUAL=20;
    public static final int EQUAL_NS=21;
    public static final int Exponent=22;
    public static final int GREATERTHAN=23;
    public static final int GREATERTHANOREQUALTO=24;
    public static final int HexDigit=25;
    public static final int Identifier=26;
    public static final int KW_ADD=27;
    public static final int KW_AFTER=28;
    public static final int KW_ALL=29;
    public static final int KW_ALTER=30;
    public static final int KW_ANALYZE=31;
    public static final int KW_AND=32;
    public static final int KW_ARCHIVE=33;
    public static final int KW_ARRAY=34;
    public static final int KW_AS=35;
    public static final int KW_ASC=36;
    public static final int KW_BEFORE=37;
    public static final int KW_BETWEEN=38;
    public static final int KW_BIGINT=39;
    public static final int KW_BINARY=40;
    public static final int KW_BOOLEAN=41;
    public static final int KW_BOTH=42;
    public static final int KW_BUCKET=43;
    public static final int KW_BUCKETS=44;
    public static final int KW_BY=45;
    public static final int KW_CASCADE=46;
    public static final int KW_CASE=47;
    public static final int KW_CAST=48;
    public static final int KW_CHANGE=49;
    public static final int KW_CLUSTER=50;
    public static final int KW_CLUSTERED=51;
    public static final int KW_CLUSTERSTATUS=52;
    public static final int KW_COLLECTION=53;
    public static final int KW_COLUMN=54;
    public static final int KW_COLUMNS=55;
    public static final int KW_COMMENT=56;
    public static final int KW_COMPUTE=57;
    public static final int KW_CONCATENATE=58;
    public static final int KW_CONTINUE=59;
    public static final int KW_CREATE=60;
    public static final int KW_CROSS=61;
    public static final int KW_CUBE=62;
    public static final int KW_CURRENT=63;
    public static final int KW_CURSOR=64;
    public static final int KW_DATA=65;
    public static final int KW_DATABASE=66;
    public static final int KW_DATABASES=67;
    public static final int KW_DATE=68;
    public static final int KW_DATETIME=69;
    public static final int KW_DBPROPERTIES=70;
    public static final int KW_DECIMAL=71;
    public static final int KW_DEFERRED=72;
    public static final int KW_DELETE=73;
    public static final int KW_DELIMITED=74;
    public static final int KW_DEPENDENCY=75;
    public static final int KW_DESC=76;
    public static final int KW_DESCRIBE=77;
    public static final int KW_DIRECTORIES=78;
    public static final int KW_DIRECTORY=79;
    public static final int KW_DISABLE=80;
    public static final int KW_DISTINCT=81;
    public static final int KW_DISTRIBUTE=82;
    public static final int KW_DOUBLE=83;
    public static final int KW_DROP=84;
    public static final int KW_ELEM_TYPE=85;
    public static final int KW_ELSE=86;
    public static final int KW_ENABLE=87;
    public static final int KW_END=88;
    public static final int KW_ESCAPED=89;
    public static final int KW_EXCHANGE=90;
    public static final int KW_EXCLUSIVE=91;
    public static final int KW_EXISTS=92;
    public static final int KW_EXPLAIN=93;
    public static final int KW_EXPORT=94;
    public static final int KW_EXTENDED=95;
    public static final int KW_EXTERNAL=96;
    public static final int KW_FALSE=97;
    public static final int KW_FETCH=98;
    public static final int KW_FIELDS=99;
    public static final int KW_FILEFORMAT=100;
    public static final int KW_FIRST=101;
    public static final int KW_FLOAT=102;
    public static final int KW_FOLLOWING=103;
    public static final int KW_FOR=104;
    public static final int KW_FORMAT=105;
    public static final int KW_FORMATTED=106;
    public static final int KW_FROM=107;
    public static final int KW_FULL=108;
    public static final int KW_FUNCTION=109;
    public static final int KW_FUNCTIONS=110;
    public static final int KW_GRANT=111;
    public static final int KW_GROUP=112;
    public static final int KW_GROUPING=113;
    public static final int KW_HAVING=114;
    public static final int KW_HOLD_DDLTIME=115;
    public static final int KW_IDXPROPERTIES=116;
    public static final int KW_IF=117;
    public static final int KW_IGNORE=118;
    public static final int KW_IMPORT=119;
    public static final int KW_IN=120;
    public static final int KW_INDEX=121;
    public static final int KW_INDEXES=122;
    public static final int KW_INNER=123;
    public static final int KW_INPATH=124;
    public static final int KW_INPUTDRIVER=125;
    public static final int KW_INPUTFORMAT=126;
    public static final int KW_INSERT=127;
    public static final int KW_INT=128;
    public static final int KW_INTERSECT=129;
    public static final int KW_INTO=130;
    public static final int KW_IS=131;
    public static final int KW_ITEMS=132;
    public static final int KW_JOIN=133;
    public static final int KW_KEYS=134;
    public static final int KW_KEY_TYPE=135;
    public static final int KW_LATERAL=136;
    public static final int KW_LEFT=137;
    public static final int KW_LESS=138;
    public static final int KW_LIKE=139;
    public static final int KW_LIMIT=140;
    public static final int KW_LINES=141;
    public static final int KW_LOAD=142;
    public static final int KW_LOCAL=143;
    public static final int KW_LOCATION=144;
    public static final int KW_LOCK=145;
    public static final int KW_LOCKS=146;
    public static final int KW_LOGICAL=147;
    public static final int KW_LONG=148;
    public static final int KW_MACRO=149;
    public static final int KW_MAP=150;
    public static final int KW_MAPJOIN=151;
    public static final int KW_MATERIALIZED=152;
    public static final int KW_MINUS=153;
    public static final int KW_MORE=154;
    public static final int KW_MSCK=155;
    public static final int KW_NOSCAN=156;
    public static final int KW_NOT=157;
    public static final int KW_NO_DROP=158;
    public static final int KW_NULL=159;
    public static final int KW_OF=160;
    public static final int KW_OFFLINE=161;
    public static final int KW_ON=162;
    public static final int KW_OPTION=163;
    public static final int KW_OR=164;
    public static final int KW_ORCFILE=165;
    public static final int KW_ORDER=166;
    public static final int KW_OUT=167;
    public static final int KW_OUTER=168;
    public static final int KW_OUTPUTDRIVER=169;
    public static final int KW_OUTPUTFORMAT=170;
    public static final int KW_OVER=171;
    public static final int KW_OVERWRITE=172;
    public static final int KW_PARTIALSCAN=173;
    public static final int KW_PARTITION=174;
    public static final int KW_PARTITIONED=175;
    public static final int KW_PARTITIONS=176;
    public static final int KW_PERCENT=177;
    public static final int KW_PLUS=178;
    public static final int KW_PRECEDING=179;
    public static final int KW_PRESERVE=180;
    public static final int KW_PRETTY=181;
    public static final int KW_PROCEDURE=182;
    public static final int KW_PROTECTION=183;
    public static final int KW_PURGE=184;
    public static final int KW_RANGE=185;
    public static final int KW_RCFILE=186;
    public static final int KW_READ=187;
    public static final int KW_READONLY=188;
    public static final int KW_READS=189;
    public static final int KW_REBUILD=190;
    public static final int KW_RECORDREADER=191;
    public static final int KW_RECORDWRITER=192;
    public static final int KW_REDUCE=193;
    public static final int KW_REGEXP=194;
    public static final int KW_RENAME=195;
    public static final int KW_REPAIR=196;
    public static final int KW_REPLACE=197;
    public static final int KW_RESTRICT=198;
    public static final int KW_REVOKE=199;
    public static final int KW_RIGHT=200;
    public static final int KW_RLIKE=201;
    public static final int KW_ROLE=202;
    public static final int KW_ROLLUP=203;
    public static final int KW_ROW=204;
    public static final int KW_ROWS=205;
    public static final int KW_SCHEMA=206;
    public static final int KW_SCHEMAS=207;
    public static final int KW_SELECT=208;
    public static final int KW_SEMI=209;
    public static final int KW_SEQUENCEFILE=210;
    public static final int KW_SERDE=211;
    public static final int KW_SERDEPROPERTIES=212;
    public static final int KW_SET=213;
    public static final int KW_SETS=214;
    public static final int KW_SHARED=215;
    public static final int KW_SHOW=216;
    public static final int KW_SHOW_DATABASE=217;
    public static final int KW_SKEWED=218;
    public static final int KW_SMALLINT=219;
    public static final int KW_SORT=220;
    public static final int KW_SORTED=221;
    public static final int KW_SSL=222;
    public static final int KW_STATISTICS=223;
    public static final int KW_STORED=224;
    public static final int KW_STREAMTABLE=225;
    public static final int KW_STRING=226;
    public static final int KW_STRUCT=227;
    public static final int KW_TABLE=228;
    public static final int KW_TABLES=229;
    public static final int KW_TABLESAMPLE=230;
    public static final int KW_TBLPROPERTIES=231;
    public static final int KW_TEMPORARY=232;
    public static final int KW_TERMINATED=233;
    public static final int KW_TEXTFILE=234;
    public static final int KW_THEN=235;
    public static final int KW_TIMESTAMP=236;
    public static final int KW_TINYINT=237;
    public static final int KW_TO=238;
    public static final int KW_TOUCH=239;
    public static final int KW_TRANSFORM=240;
    public static final int KW_TRIGGER=241;
    public static final int KW_TRUE=242;
    public static final int KW_TRUNCATE=243;
    public static final int KW_UNARCHIVE=244;
    public static final int KW_UNBOUNDED=245;
    public static final int KW_UNDO=246;
    public static final int KW_UNION=247;
    public static final int KW_UNIONTYPE=248;
    public static final int KW_UNIQUEJOIN=249;
    public static final int KW_UNLOCK=250;
    public static final int KW_UNSET=251;
    public static final int KW_UNSIGNED=252;
    public static final int KW_UPDATE=253;
    public static final int KW_USE=254;
    public static final int KW_USER=255;
    public static final int KW_USING=256;
    public static final int KW_UTC=257;
    public static final int KW_UTCTIMESTAMP=258;
    public static final int KW_VALUE_TYPE=259;
    public static final int KW_VARCHAR=260;
    public static final int KW_VIEW=261;
    public static final int KW_WHEN=262;
    public static final int KW_WHERE=263;
    public static final int KW_WHILE=264;
    public static final int KW_WINDOW=265;
    public static final int KW_WITH=266;
    public static final int LCURLY=267;
    public static final int LESSTHAN=268;
    public static final int LESSTHANOREQUALTO=269;
    public static final int LPAREN=270;
    public static final int LSQUARE=271;
    public static final int Letter=272;
    public static final int MINUS=273;
    public static final int MOD=274;
    public static final int NOTEQUAL=275;
    public static final int Number=276;
    public static final int PLUS=277;
    public static final int QUESTION=278;
    public static final int RCURLY=279;
    public static final int RPAREN=280;
    public static final int RSQUARE=281;
    public static final int RegexComponent=282;
    public static final int SEMICOLON=283;
    public static final int STAR=284;
    public static final int SmallintLiteral=285;
    public static final int StringLiteral=286;
    public static final int TILDE=287;
    public static final int TinyintLiteral=288;
    public static final int WS=289;
    public static final int TOK_ALIASLIST=552;
    public static final int TOK_ALLCOLREF=553;
    public static final int TOK_ALTERDATABASE_PROPERTIES=554;
    public static final int TOK_ALTERINDEX_PROPERTIES=555;
    public static final int TOK_ALTERINDEX_REBUILD=556;
    public static final int TOK_ALTERTABLE_ADDCOLS=557;
    public static final int TOK_ALTERTABLE_ADDPARTS=558;
    public static final int TOK_ALTERTABLE_ALTERPARTS=559;
    public static final int TOK_ALTERTABLE_ALTERPARTS_MERGEFILES=560;
    public static final int TOK_ALTERTABLE_ALTERPARTS_PROTECTMODE=561;
    public static final int TOK_ALTERTABLE_ARCHIVE=562;
    public static final int TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION=563;
    public static final int TOK_ALTERTABLE_CLUSTER_SORT=564;
    public static final int TOK_ALTERTABLE_DROPPARTS=565;
    public static final int TOK_ALTERTABLE_FILEFORMAT=566;
    public static final int TOK_ALTERTABLE_LOCATION=567;
    public static final int TOK_ALTERTABLE_PARTITION=568;
    public static final int TOK_ALTERTABLE_PROPERTIES=569;
    public static final int TOK_ALTERTABLE_RENAME=570;
    public static final int TOK_ALTERTABLE_RENAMECOL=571;
    public static final int TOK_ALTERTABLE_RENAMEPART=572;
    public static final int TOK_ALTERTABLE_REPLACECOLS=573;
    public static final int TOK_ALTERTABLE_SERDEPROPERTIES=574;
    public static final int TOK_ALTERTABLE_SERIALIZER=575;
    public static final int TOK_ALTERTABLE_SKEWED=576;
    public static final int TOK_ALTERTABLE_TOUCH=577;
    public static final int TOK_ALTERTABLE_UNARCHIVE=578;
    public static final int TOK_ALTERTBLPART_SKEWED_LOCATION=579;
    public static final int TOK_ALTERVIEW_ADDPARTS=580;
    public static final int TOK_ALTERVIEW_AS=581;
    public static final int TOK_ALTERVIEW_DROPPARTS=582;
    public static final int TOK_ALTERVIEW_PROPERTIES=583;
    public static final int TOK_ALTERVIEW_RENAME=584;
    public static final int TOK_ANALYZE=585;
    public static final int TOK_BIGINT=586;
    public static final int TOK_BINARY=587;
    public static final int TOK_BOOLEAN=588;
    public static final int TOK_CASCADE=589;
    public static final int TOK_CHARSETLITERAL=590;
    public static final int TOK_CLUSTERBY=591;
    public static final int TOK_COLTYPELIST=592;
    public static final int TOK_CREATEDATABASE=593;
    public static final int TOK_CREATEFUNCTION=594;
    public static final int TOK_CREATEINDEX=595;
    public static final int TOK_CREATEINDEX_INDEXTBLNAME=596;
    public static final int TOK_CREATEMACRO=597;
    public static final int TOK_CREATEROLE=598;
    public static final int TOK_CREATETABLE=599;
    public static final int TOK_CREATEVIEW=600;
    public static final int TOK_CROSSJOIN=601;
    public static final int TOK_CUBE_GROUPBY=602;
    public static final int TOK_DATABASECOMMENT=603;
    public static final int TOK_DATABASELOCATION=604;
    public static final int TOK_DATABASEPROPERTIES=605;
    public static final int TOK_DATE=606;
    public static final int TOK_DATELITERAL=607;
    public static final int TOK_DATETIME=608;
    public static final int TOK_DBPROPLIST=609;
    public static final int TOK_DECIMAL=610;
    public static final int TOK_DEFERRED_REBUILDINDEX=611;
    public static final int TOK_DESCDATABASE=612;
    public static final int TOK_DESCFUNCTION=613;
    public static final int TOK_DESCTABLE=614;
    public static final int TOK_DESTINATION=615;
    public static final int TOK_DIR=616;
    public static final int TOK_DISABLE=617;
    public static final int TOK_DISTRIBUTEBY=618;
    public static final int TOK_DOUBLE=619;
    public static final int TOK_DROPDATABASE=620;
    public static final int TOK_DROPFUNCTION=621;
    public static final int TOK_DROPINDEX=622;
    public static final int TOK_DROPMACRO=623;
    public static final int TOK_DROPROLE=624;
    public static final int TOK_DROPTABLE=625;
    public static final int TOK_DROPTABLE_PROPERTIES=626;
    public static final int TOK_DROPVIEW=627;
    public static final int TOK_DROPVIEW_PROPERTIES=628;
    public static final int TOK_ENABLE=629;
    public static final int TOK_EXCHANGEPARTITION=630;
    public static final int TOK_EXPLAIN=631;
    public static final int TOK_EXPLIST=632;
    public static final int TOK_EXPORT=633;
    public static final int TOK_FALSE=634;
    public static final int TOK_FILEFORMAT_GENERIC=635;
    public static final int TOK_FLOAT=636;
    public static final int TOK_FROM=637;
    public static final int TOK_FULLOUTERJOIN=638;
    public static final int TOK_FUNCTION=639;
    public static final int TOK_FUNCTIONDI=640;
    public static final int TOK_FUNCTIONSTAR=641;
    public static final int TOK_GRANT=642;
    public static final int TOK_GRANT_ROLE=643;
    public static final int TOK_GRANT_WITH_OPTION=644;
    public static final int TOK_GROUP=645;
    public static final int TOK_GROUPBY=646;
    public static final int TOK_GROUPING_SETS=647;
    public static final int TOK_GROUPING_SETS_EXPRESSION=648;
    public static final int TOK_HAVING=649;
    public static final int TOK_HINT=650;
    public static final int TOK_HINTARGLIST=651;
    public static final int TOK_HINTLIST=652;
    public static final int TOK_HOLD_DDLTIME=653;
    public static final int TOK_IFEXISTS=654;
    public static final int TOK_IFNOTEXISTS=655;
    public static final int TOK_IGNOREPROTECTION=656;
    public static final int TOK_IMPORT=657;
    public static final int TOK_INDEXCOMMENT=658;
    public static final int TOK_INDEXPROPERTIES=659;
    public static final int TOK_INDEXPROPLIST=660;
    public static final int TOK_INSERT=661;
    public static final int TOK_INSERT_INTO=662;
    public static final int TOK_INT=663;
    public static final int TOK_ISNOTNULL=664;
    public static final int TOK_ISNULL=665;
    public static final int TOK_JOIN=666;
    public static final int TOK_LATERAL_VIEW=667;
    public static final int TOK_LATERAL_VIEW_OUTER=668;
    public static final int TOK_LEFTOUTERJOIN=669;
    public static final int TOK_LEFTSEMIJOIN=670;
    public static final int TOK_LENGTH=671;
    public static final int TOK_LIKETABLE=672;
    public static final int TOK_LIMIT=673;
    public static final int TOK_LIST=674;
    public static final int TOK_LOAD=675;
    public static final int TOK_LOCAL_DIR=676;
    public static final int TOK_LOCKTABLE=677;
    public static final int TOK_MAP=678;
    public static final int TOK_MAPJOIN=679;
    public static final int TOK_MSCK=680;
    public static final int TOK_NOT_CLUSTERED=681;
    public static final int TOK_NOT_SORTED=682;
    public static final int TOK_NO_DROP=683;
    public static final int TOK_NULL=684;
    public static final int TOK_OFFLINE=685;
    public static final int TOK_OP_ADD=686;
    public static final int TOK_OP_AND=687;
    public static final int TOK_OP_BITAND=688;
    public static final int TOK_OP_BITNOT=689;
    public static final int TOK_OP_BITOR=690;
    public static final int TOK_OP_BITXOR=691;
    public static final int TOK_OP_DIV=692;
    public static final int TOK_OP_EQ=693;
    public static final int TOK_OP_GE=694;
    public static final int TOK_OP_GT=695;
    public static final int TOK_OP_LE=696;
    public static final int TOK_OP_LIKE=697;
    public static final int TOK_OP_LT=698;
    public static final int TOK_OP_MOD=699;
    public static final int TOK_OP_MUL=700;
    public static final int TOK_OP_NE=701;
    public static final int TOK_OP_NOT=702;
    public static final int TOK_OP_OR=703;
    public static final int TOK_OP_SUB=704;
    public static final int TOK_ORDERBY=705;
    public static final int TOK_ORREPLACE=706;
    public static final int TOK_PARTITIONINGSPEC=707;
    public static final int TOK_PARTITIONLOCATION=708;
    public static final int TOK_PARTSPEC=709;
    public static final int TOK_PARTVAL=710;
    public static final int TOK_PERCENT=711;
    public static final int TOK_PRINCIPAL_NAME=712;
    public static final int TOK_PRIVILEGE=713;
    public static final int TOK_PRIVILEGE_LIST=714;
    public static final int TOK_PRIV_ALL=715;
    public static final int TOK_PRIV_ALTER_DATA=716;
    public static final int TOK_PRIV_ALTER_METADATA=717;
    public static final int TOK_PRIV_CREATE=718;
    public static final int TOK_PRIV_DROP=719;
    public static final int TOK_PRIV_INDEX=720;
    public static final int TOK_PRIV_LOCK=721;
    public static final int TOK_PRIV_OBJECT=722;
    public static final int TOK_PRIV_OBJECT_COL=723;
    public static final int TOK_PRIV_SELECT=724;
    public static final int TOK_PRIV_SHOW_DATABASE=725;
    public static final int TOK_PTBLFUNCTION=726;
    public static final int TOK_QUERY=727;
    public static final int TOK_READONLY=728;
    public static final int TOK_RECORDREADER=729;
    public static final int TOK_RECORDWRITER=730;
    public static final int TOK_RESTRICT=731;
    public static final int TOK_REVOKE=732;
    public static final int TOK_REVOKE_ROLE=733;
    public static final int TOK_RIGHTOUTERJOIN=734;
    public static final int TOK_ROLE=735;
    public static final int TOK_ROLLUP_GROUPBY=736;
    public static final int TOK_ROWCOUNT=737;
    public static final int TOK_SELECT=738;
    public static final int TOK_SELECTDI=739;
    public static final int TOK_SELEXPR=740;
    public static final int TOK_SERDE=741;
    public static final int TOK_SERDENAME=742;
    public static final int TOK_SERDEPROPS=743;
    public static final int TOK_SHOWCOLUMNS=744;
    public static final int TOK_SHOWDATABASES=745;
    public static final int TOK_SHOWFUNCTIONS=746;
    public static final int TOK_SHOWINDEXES=747;
    public static final int TOK_SHOWLOCKS=748;
    public static final int TOK_SHOWPARTITIONS=749;
    public static final int TOK_SHOWTABLES=750;
    public static final int TOK_SHOW_CREATETABLE=751;
    public static final int TOK_SHOW_GRANT=752;
    public static final int TOK_SHOW_ROLE_GRANT=753;
    public static final int TOK_SHOW_TABLESTATUS=754;
    public static final int TOK_SHOW_TBLPROPERTIES=755;
    public static final int TOK_SKEWED_LOCATIONS=756;
    public static final int TOK_SKEWED_LOCATION_LIST=757;
    public static final int TOK_SKEWED_LOCATION_MAP=758;
    public static final int TOK_SMALLINT=759;
    public static final int TOK_SORTBY=760;
    public static final int TOK_STORAGEHANDLER=761;
    public static final int TOK_STOREDASDIRS=762;
    public static final int TOK_STREAMTABLE=763;
    public static final int TOK_STRING=764;
    public static final int TOK_STRINGLITERALSEQUENCE=765;
    public static final int TOK_STRUCT=766;
    public static final int TOK_SUBQUERY=767;
    public static final int TOK_SWITCHDATABASE=768;
    public static final int TOK_TAB=769;
    public static final int TOK_TABALIAS=770;
    public static final int TOK_TABCOL=771;
    public static final int TOK_TABCOLLIST=772;
    public static final int TOK_TABCOLNAME=773;
    public static final int TOK_TABCOLVALUE=774;
    public static final int TOK_TABCOLVALUES=775;
    public static final int TOK_TABCOLVALUE_PAIR=776;
    public static final int TOK_TABLEBUCKETS=777;
    public static final int TOK_TABLEBUCKETSAMPLE=778;
    public static final int TOK_TABLECOMMENT=779;
    public static final int TOK_TABLEFILEFORMAT=780;
    public static final int TOK_TABLELOCATION=781;
    public static final int TOK_TABLEPARTCOLS=782;
    public static final int TOK_TABLEPROPERTIES=783;
    public static final int TOK_TABLEPROPERTY=784;
    public static final int TOK_TABLEPROPLIST=785;
    public static final int TOK_TABLEROWFORMAT=786;
    public static final int TOK_TABLEROWFORMATCOLLITEMS=787;
    public static final int TOK_TABLEROWFORMATFIELD=788;
    public static final int TOK_TABLEROWFORMATLINES=789;
    public static final int TOK_TABLEROWFORMATMAPKEYS=790;
    public static final int TOK_TABLESERIALIZER=791;
    public static final int TOK_TABLESKEWED=792;
    public static final int TOK_TABLESPLITSAMPLE=793;
    public static final int TOK_TABLE_OR_COL=794;
    public static final int TOK_TABLE_PARTITION=795;
    public static final int TOK_TABNAME=796;
    public static final int TOK_TABREF=797;
    public static final int TOK_TABSORTCOLNAMEASC=798;
    public static final int TOK_TABSORTCOLNAMEDESC=799;
    public static final int TOK_TABSRC=800;
    public static final int TOK_TABTYPE=801;
    public static final int TOK_TBLORCFILE=802;
    public static final int TOK_TBLRCFILE=803;
    public static final int TOK_TBLSEQUENCEFILE=804;
    public static final int TOK_TBLTEXTFILE=805;
    public static final int TOK_TIMESTAMP=806;
    public static final int TOK_TINYINT=807;
    public static final int TOK_TMP_FILE=808;
    public static final int TOK_TRANSFORM=809;
    public static final int TOK_TRUE=810;
    public static final int TOK_TRUNCATETABLE=811;
    public static final int TOK_UNION=812;
    public static final int TOK_UNIONTYPE=813;
    public static final int TOK_UNIQUEJOIN=814;
    public static final int TOK_UNLOCKTABLE=815;
    public static final int TOK_USER=816;
    public static final int TOK_USERSCRIPTCOLNAMES=817;
    public static final int TOK_USERSCRIPTCOLSCHEMA=818;
    public static final int TOK_VARCHAR=819;
    public static final int TOK_VIEWPARTCOLS=820;
    public static final int TOK_WHERE=821;
    public static final int TOK_WINDOWDEF=822;
    public static final int TOK_WINDOWRANGE=823;
    public static final int TOK_WINDOWSPEC=824;
    public static final int TOK_WINDOWVALUES=825;

    // delegates
    public HiveParser_SelectClauseParser gSelectClauseParser;
    public HiveParser_FromClauseParser gFromClauseParser;
    public HiveParser_IdentifiersParser gIdentifiersParser;
    public Parser[] getDelegates() {
        return new Parser[] {gSelectClauseParser, gFromClauseParser, gIdentifiersParser};
    }

    // delegators


    public HiveParser(TokenStream input) {
        this(input, new RecognizerSharedState());
    }
    public HiveParser(TokenStream input, RecognizerSharedState state) {
        super(input, state);
        gSelectClauseParser = new HiveParser_SelectClauseParser(input, state, this);
        gFromClauseParser = new HiveParser_FromClauseParser(input, state, this);
        gIdentifiersParser = new HiveParser_IdentifiersParser(input, state, this);
    }

protected TreeAdaptor adaptor = new CommonTreeAdaptor();

public void setTreeAdaptor(TreeAdaptor adaptor) {
    this.adaptor = adaptor;
    gSelectClauseParser.setTreeAdaptor(this.adaptor);gFromClauseParser.setTreeAdaptor(this.adaptor);gIdentifiersParser.setTreeAdaptor(this.adaptor);
}
public TreeAdaptor getTreeAdaptor() {
    return adaptor;
}
    public String[] getTokenNames() { return HiveParser.tokenNames; }
    public String getGrammarFileName() { return "/root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g"; }


      ArrayList<ParseError> errors = new ArrayList<ParseError>();
      Stack msgs = new Stack<String>();

      private static HashMap<String, String> xlateMap;
      static {
        xlateMap = new HashMap<String, String>();

        // Keywords
        xlateMap.put("KW_TRUE", "TRUE");
        xlateMap.put("KW_FALSE", "FALSE");
        xlateMap.put("KW_ALL", "ALL");
        xlateMap.put("KW_AND", "AND");
        xlateMap.put("KW_OR", "OR");
        xlateMap.put("KW_NOT", "NOT");
        xlateMap.put("KW_LIKE", "LIKE");

        xlateMap.put("KW_ASC", "ASC");
        xlateMap.put("KW_DESC", "DESC");
        xlateMap.put("KW_ORDER", "ORDER");
        xlateMap.put("KW_BY", "BY");
        xlateMap.put("KW_GROUP", "GROUP");
        xlateMap.put("KW_WHERE", "WHERE");
        xlateMap.put("KW_FROM", "FROM");
        xlateMap.put("KW_AS", "AS");
        xlateMap.put("KW_SELECT", "SELECT");
        xlateMap.put("KW_DISTINCT", "DISTINCT");
        xlateMap.put("KW_INSERT", "INSERT");
        xlateMap.put("KW_OVERWRITE", "OVERWRITE");
        xlateMap.put("KW_OUTER", "OUTER");
        xlateMap.put("KW_JOIN", "JOIN");
        xlateMap.put("KW_LEFT", "LEFT");
        xlateMap.put("KW_RIGHT", "RIGHT");
        xlateMap.put("KW_FULL", "FULL");
        xlateMap.put("KW_ON", "ON");
        xlateMap.put("KW_PARTITION", "PARTITION");
        xlateMap.put("KW_PARTITIONS", "PARTITIONS");
        xlateMap.put("KW_TABLE", "TABLE");
        xlateMap.put("KW_TABLES", "TABLES");
        xlateMap.put("KW_TBLPROPERTIES", "TBLPROPERTIES");
        xlateMap.put("KW_SHOW", "SHOW");
        xlateMap.put("KW_MSCK", "MSCK");
        xlateMap.put("KW_DIRECTORY", "DIRECTORY");
        xlateMap.put("KW_LOCAL", "LOCAL");
        xlateMap.put("KW_TRANSFORM", "TRANSFORM");
        xlateMap.put("KW_USING", "USING");
        xlateMap.put("KW_CLUSTER", "CLUSTER");
        xlateMap.put("KW_DISTRIBUTE", "DISTRIBUTE");
        xlateMap.put("KW_SORT", "SORT");
        xlateMap.put("KW_UNION", "UNION");
        xlateMap.put("KW_LOAD", "LOAD");
        xlateMap.put("KW_DATA", "DATA");
        xlateMap.put("KW_INPATH", "INPATH");
        xlateMap.put("KW_IS", "IS");
        xlateMap.put("KW_NULL", "NULL");
        xlateMap.put("KW_CREATE", "CREATE");
        xlateMap.put("KW_EXTERNAL", "EXTERNAL");
        xlateMap.put("KW_ALTER", "ALTER");
        xlateMap.put("KW_DESCRIBE", "DESCRIBE");
        xlateMap.put("KW_DROP", "DROP");
        xlateMap.put("KW_REANME", "REANME");
        xlateMap.put("KW_TO", "TO");
        xlateMap.put("KW_COMMENT", "COMMENT");
        xlateMap.put("KW_BOOLEAN", "BOOLEAN");
        xlateMap.put("KW_TINYINT", "TINYINT");
        xlateMap.put("KW_SMALLINT", "SMALLINT");
        xlateMap.put("KW_INT", "INT");
        xlateMap.put("KW_BIGINT", "BIGINT");
        xlateMap.put("KW_FLOAT", "FLOAT");
        xlateMap.put("KW_DOUBLE", "DOUBLE");
        xlateMap.put("KW_DATE", "DATE");
        xlateMap.put("KW_DATETIME", "DATETIME");
        xlateMap.put("KW_TIMESTAMP", "TIMESTAMP");
        xlateMap.put("KW_STRING", "STRING");
        xlateMap.put("KW_BINARY", "BINARY");
        xlateMap.put("KW_ARRAY", "ARRAY");
        xlateMap.put("KW_MAP", "MAP");
        xlateMap.put("KW_REDUCE", "REDUCE");
        xlateMap.put("KW_PARTITIONED", "PARTITIONED");
        xlateMap.put("KW_CLUSTERED", "CLUSTERED");
        xlateMap.put("KW_SORTED", "SORTED");
        xlateMap.put("KW_INTO", "INTO");
        xlateMap.put("KW_BUCKETS", "BUCKETS");
        xlateMap.put("KW_ROW", "ROW");
        xlateMap.put("KW_FORMAT", "FORMAT");
        xlateMap.put("KW_DELIMITED", "DELIMITED");
        xlateMap.put("KW_FIELDS", "FIELDS");
        xlateMap.put("KW_TERMINATED", "TERMINATED");
        xlateMap.put("KW_COLLECTION", "COLLECTION");
        xlateMap.put("KW_ITEMS", "ITEMS");
        xlateMap.put("KW_KEYS", "KEYS");
        xlateMap.put("KW_KEY_TYPE", "$KEY$");
        xlateMap.put("KW_LINES", "LINES");
        xlateMap.put("KW_STORED", "STORED");
        xlateMap.put("KW_SEQUENCEFILE", "SEQUENCEFILE");
        xlateMap.put("KW_TEXTFILE", "TEXTFILE");
        xlateMap.put("KW_INPUTFORMAT", "INPUTFORMAT");
        xlateMap.put("KW_OUTPUTFORMAT", "OUTPUTFORMAT");
        xlateMap.put("KW_LOCATION", "LOCATION");
        xlateMap.put("KW_TABLESAMPLE", "TABLESAMPLE");
        xlateMap.put("KW_BUCKET", "BUCKET");
        xlateMap.put("KW_OUT", "OUT");
        xlateMap.put("KW_OF", "OF");
        xlateMap.put("KW_CAST", "CAST");
        xlateMap.put("KW_ADD", "ADD");
        xlateMap.put("KW_REPLACE", "REPLACE");
        xlateMap.put("KW_COLUMNS", "COLUMNS");
        xlateMap.put("KW_RLIKE", "RLIKE");
        xlateMap.put("KW_REGEXP", "REGEXP");
        xlateMap.put("KW_TEMPORARY", "TEMPORARY");
        xlateMap.put("KW_FUNCTION", "FUNCTION");
        xlateMap.put("KW_EXPLAIN", "EXPLAIN");
        xlateMap.put("KW_EXTENDED", "EXTENDED");
        xlateMap.put("KW_SERDE", "SERDE");
        xlateMap.put("KW_WITH", "WITH");
        xlateMap.put("KW_SERDEPROPERTIES", "SERDEPROPERTIES");
        xlateMap.put("KW_LIMIT", "LIMIT");
        xlateMap.put("KW_SET", "SET");
        xlateMap.put("KW_PROPERTIES", "TBLPROPERTIES");
        xlateMap.put("KW_VALUE_TYPE", "$VALUE$");
        xlateMap.put("KW_ELEM_TYPE", "$ELEM$");

        // Operators
        xlateMap.put("DOT", ".");
        xlateMap.put("COLON", ":");
        xlateMap.put("COMMA", ",");
        xlateMap.put("SEMICOLON", ");");

        xlateMap.put("LPAREN", "(");
        xlateMap.put("RPAREN", ")");
        xlateMap.put("LSQUARE", "[");
        xlateMap.put("RSQUARE", "]");

        xlateMap.put("EQUAL", "=");
        xlateMap.put("NOTEQUAL", "<>");
        xlateMap.put("EQUAL_NS", "<=>");
        xlateMap.put("LESSTHANOREQUALTO", "<=");
        xlateMap.put("LESSTHAN", "<");
        xlateMap.put("GREATERTHANOREQUALTO", ">=");
        xlateMap.put("GREATERTHAN", ">");

        xlateMap.put("DIVIDE", "/");
        xlateMap.put("PLUS", "+");
        xlateMap.put("MINUS", "-");
        xlateMap.put("STAR", "*");
        xlateMap.put("MOD", "%");

        xlateMap.put("AMPERSAND", "&");
        xlateMap.put("TILDE", "~");
        xlateMap.put("BITWISEOR", "|");
        xlateMap.put("BITWISEXOR", "^");
        xlateMap.put("CharSetLiteral", "\\'");
      }

      public static Collection<String> getKeywords() {
        return xlateMap.values();
      }

      private static String xlate(String name) {

        String ret = xlateMap.get(name);
        if (ret == null) {
          ret = name;
        }

        return ret;
      }

      @Override
      public Object recoverFromMismatchedSet(IntStream input,
          RecognitionException re, BitSet follow) throws RecognitionException {
        throw re;
      }

      @Override
      public void displayRecognitionError(String[] tokenNames,
          RecognitionException e) {
        errors.add(new ParseError(this, e, tokenNames));
      }

      @Override
      public String getErrorHeader(RecognitionException e) {
        String header = null;
        if (e.charPositionInLine < 0 && input.LT(-1) != null) {
          Token t = input.LT(-1);
          header = "line " + t.getLine() + ":" + t.getCharPositionInLine();
        } else {
          header = super.getErrorHeader(e);
        }

        return header;
      }
      
      @Override
      public String getErrorMessage(RecognitionException e, String[] tokenNames) {
        String msg = null;

        // Translate the token names to something that the user can understand
        String[] xlateNames = new String[tokenNames.length];
        for (int i = 0; i < tokenNames.length; ++i) {
          xlateNames[i] = HiveParser.xlate(tokenNames[i]);
        }

        if (e instanceof NoViableAltException) {
          @SuppressWarnings("unused")
          NoViableAltException nvae = (NoViableAltException) e;
          // for development, can add
          // "decision=<<"+nvae.grammarDecisionDescription+">>"
          // and "(decision="+nvae.decisionNumber+") and
          // "state "+nvae.stateNumber
          msg = "cannot recognize input near"
                  + (input.LT(1) != null ? " " + getTokenErrorDisplay(input.LT(1)) : "")
                  + (input.LT(2) != null ? " " + getTokenErrorDisplay(input.LT(2)) : "")
                  + (input.LT(3) != null ? " " + getTokenErrorDisplay(input.LT(3)) : "");
        } else if (e instanceof MismatchedTokenException) {
          MismatchedTokenException mte = (MismatchedTokenException) e;
          msg = super.getErrorMessage(e, xlateNames) + (input.LT(-1) == null ? "":" near '" + input.LT(-1).getText()) + "'";
        } else if (e instanceof FailedPredicateException) {
          FailedPredicateException fpe = (FailedPredicateException) e;
          msg = "Failed to recognize predicate '" + fpe.token.getText() + "'. Failed rule: '" + fpe.ruleName + "'";
        } else {
          msg = super.getErrorMessage(e, xlateNames);
        }

        if (msgs.size() > 0) {
          msg = msg + " in " + msgs.peek();
        }
        return msg;
      }


    public static class statement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "statement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:555:1: statement : ( explainStatement EOF | execStatement EOF );
    public final HiveParser.statement_return statement() throws RecognitionException {
        HiveParser.statement_return retval = new HiveParser.statement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token EOF2=null;
        Token EOF4=null;
        HiveParser.explainStatement_return explainStatement1 =null;

        HiveParser.execStatement_return execStatement3 =null;


        CommonTree EOF2_tree=null;
        CommonTree EOF4_tree=null;

        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:556:2: ( explainStatement EOF | execStatement EOF )
            int alt1=2;
            int LA1_0 = input.LA(1);

            if ( (LA1_0==KW_EXPLAIN) ) {
                alt1=1;
            }
            else if ( ((LA1_0 >= KW_ALTER && LA1_0 <= KW_ANALYZE)||LA1_0==KW_CREATE||(LA1_0 >= KW_DESC && LA1_0 <= KW_DESCRIBE)||LA1_0==KW_DROP||LA1_0==KW_EXPORT||LA1_0==KW_FROM||LA1_0==KW_GRANT||LA1_0==KW_IMPORT||LA1_0==KW_INSERT||LA1_0==KW_LOAD||LA1_0==KW_LOCK||LA1_0==KW_MAP||LA1_0==KW_MSCK||LA1_0==KW_REDUCE||LA1_0==KW_REVOKE||LA1_0==KW_SELECT||LA1_0==KW_SHOW||LA1_0==KW_TRUNCATE||LA1_0==KW_UNLOCK||LA1_0==KW_USE) ) {
                alt1=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 1, 0, input);

                throw nvae;

            }
            switch (alt1) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:556:4: explainStatement EOF
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_explainStatement_in_statement905);
                    explainStatement1=explainStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, explainStatement1.getTree());

                    EOF2=(Token)match(input,EOF,FOLLOW_EOF_in_statement907); 
                    EOF2_tree = 
                    (CommonTree)adaptor.create(EOF2)
                    ;
                    adaptor.addChild(root_0, EOF2_tree);


                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:557:4: execStatement EOF
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_execStatement_in_statement912);
                    execStatement3=execStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, execStatement3.getTree());

                    EOF4=(Token)match(input,EOF,FOLLOW_EOF_in_statement914); 
                    EOF4_tree = 
                    (CommonTree)adaptor.create(EOF4)
                    ;
                    adaptor.addChild(root_0, EOF4_tree);


                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "statement"


    public static class explainStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "explainStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:560:1: explainStatement : KW_EXPLAIN (explainOptions= KW_EXTENDED |explainOptions= KW_FORMATTED |explainOptions= KW_DEPENDENCY |explainOptions= KW_LOGICAL )? execStatement -> ^( TOK_EXPLAIN execStatement ( $explainOptions)? ) ;
    public final HiveParser.explainStatement_return explainStatement() throws RecognitionException {
        HiveParser.explainStatement_return retval = new HiveParser.explainStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token explainOptions=null;
        Token KW_EXPLAIN5=null;
        HiveParser.execStatement_return execStatement6 =null;


        CommonTree explainOptions_tree=null;
        CommonTree KW_EXPLAIN5_tree=null;
        RewriteRuleTokenStream stream_KW_FORMATTED=new RewriteRuleTokenStream(adaptor,"token KW_FORMATTED");
        RewriteRuleTokenStream stream_KW_DEPENDENCY=new RewriteRuleTokenStream(adaptor,"token KW_DEPENDENCY");
        RewriteRuleTokenStream stream_KW_EXTENDED=new RewriteRuleTokenStream(adaptor,"token KW_EXTENDED");
        RewriteRuleTokenStream stream_KW_EXPLAIN=new RewriteRuleTokenStream(adaptor,"token KW_EXPLAIN");
        RewriteRuleTokenStream stream_KW_LOGICAL=new RewriteRuleTokenStream(adaptor,"token KW_LOGICAL");
        RewriteRuleSubtreeStream stream_execStatement=new RewriteRuleSubtreeStream(adaptor,"rule execStatement");
         msgs.push("explain statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:563:2: ( KW_EXPLAIN (explainOptions= KW_EXTENDED |explainOptions= KW_FORMATTED |explainOptions= KW_DEPENDENCY |explainOptions= KW_LOGICAL )? execStatement -> ^( TOK_EXPLAIN execStatement ( $explainOptions)? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:563:4: KW_EXPLAIN (explainOptions= KW_EXTENDED |explainOptions= KW_FORMATTED |explainOptions= KW_DEPENDENCY |explainOptions= KW_LOGICAL )? execStatement
            {
            KW_EXPLAIN5=(Token)match(input,KW_EXPLAIN,FOLLOW_KW_EXPLAIN_in_explainStatement935);  
            stream_KW_EXPLAIN.add(KW_EXPLAIN5);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:563:15: (explainOptions= KW_EXTENDED |explainOptions= KW_FORMATTED |explainOptions= KW_DEPENDENCY |explainOptions= KW_LOGICAL )?
            int alt2=5;
            switch ( input.LA(1) ) {
                case KW_EXTENDED:
                    {
                    alt2=1;
                    }
                    break;
                case KW_FORMATTED:
                    {
                    alt2=2;
                    }
                    break;
                case KW_DEPENDENCY:
                    {
                    alt2=3;
                    }
                    break;
                case KW_LOGICAL:
                    {
                    alt2=4;
                    }
                    break;
            }

            switch (alt2) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:563:16: explainOptions= KW_EXTENDED
                    {
                    explainOptions=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_explainStatement940);  
                    stream_KW_EXTENDED.add(explainOptions);


                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:563:43: explainOptions= KW_FORMATTED
                    {
                    explainOptions=(Token)match(input,KW_FORMATTED,FOLLOW_KW_FORMATTED_in_explainStatement944);  
                    stream_KW_FORMATTED.add(explainOptions);


                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:563:71: explainOptions= KW_DEPENDENCY
                    {
                    explainOptions=(Token)match(input,KW_DEPENDENCY,FOLLOW_KW_DEPENDENCY_in_explainStatement948);  
                    stream_KW_DEPENDENCY.add(explainOptions);


                    }
                    break;
                case 4 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:563:100: explainOptions= KW_LOGICAL
                    {
                    explainOptions=(Token)match(input,KW_LOGICAL,FOLLOW_KW_LOGICAL_in_explainStatement952);  
                    stream_KW_LOGICAL.add(explainOptions);


                    }
                    break;

            }


            pushFollow(FOLLOW_execStatement_in_explainStatement956);
            execStatement6=execStatement();

            state._fsp--;

            stream_execStatement.add(execStatement6.getTree());

            // AST REWRITE
            // elements: explainOptions, execStatement
            // token labels: explainOptions
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_explainOptions=new RewriteRuleTokenStream(adaptor,"token explainOptions",explainOptions);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 564:7: -> ^( TOK_EXPLAIN execStatement ( $explainOptions)? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:564:10: ^( TOK_EXPLAIN execStatement ( $explainOptions)? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_EXPLAIN, "TOK_EXPLAIN")
                , root_1);

                adaptor.addChild(root_1, stream_execStatement.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:564:39: ( $explainOptions)?
                if ( stream_explainOptions.hasNext() ) {
                    adaptor.addChild(root_1, stream_explainOptions.nextNode());

                }
                stream_explainOptions.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "explainStatement"


    public static class execStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "execStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:567:1: execStatement : ( queryStatementExpression | loadStatement | exportStatement | importStatement | ddlStatement );
    public final HiveParser.execStatement_return execStatement() throws RecognitionException {
        HiveParser.execStatement_return retval = new HiveParser.execStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser.queryStatementExpression_return queryStatementExpression7 =null;

        HiveParser.loadStatement_return loadStatement8 =null;

        HiveParser.exportStatement_return exportStatement9 =null;

        HiveParser.importStatement_return importStatement10 =null;

        HiveParser.ddlStatement_return ddlStatement11 =null;



         msgs.push("statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:570:5: ( queryStatementExpression | loadStatement | exportStatement | importStatement | ddlStatement )
            int alt3=5;
            switch ( input.LA(1) ) {
            case KW_FROM:
            case KW_INSERT:
            case KW_MAP:
            case KW_REDUCE:
            case KW_SELECT:
                {
                alt3=1;
                }
                break;
            case KW_LOAD:
                {
                alt3=2;
                }
                break;
            case KW_EXPORT:
                {
                alt3=3;
                }
                break;
            case KW_IMPORT:
                {
                alt3=4;
                }
                break;
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_CREATE:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DROP:
            case KW_GRANT:
            case KW_LOCK:
            case KW_MSCK:
            case KW_REVOKE:
            case KW_SHOW:
            case KW_TRUNCATE:
            case KW_UNLOCK:
            case KW_USE:
                {
                alt3=5;
                }
                break;
            default:
                NoViableAltException nvae =
                    new NoViableAltException("", 3, 0, input);

                throw nvae;

            }

            switch (alt3) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:570:7: queryStatementExpression
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_queryStatementExpression_in_execStatement998);
                    queryStatementExpression7=queryStatementExpression();

                    state._fsp--;

                    adaptor.addChild(root_0, queryStatementExpression7.getTree());

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:571:7: loadStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_loadStatement_in_execStatement1006);
                    loadStatement8=loadStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, loadStatement8.getTree());

                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:572:7: exportStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_exportStatement_in_execStatement1014);
                    exportStatement9=exportStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, exportStatement9.getTree());

                    }
                    break;
                case 4 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:573:7: importStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_importStatement_in_execStatement1022);
                    importStatement10=importStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, importStatement10.getTree());

                    }
                    break;
                case 5 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:574:7: ddlStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_ddlStatement_in_execStatement1030);
                    ddlStatement11=ddlStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, ddlStatement11.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "execStatement"


    public static class loadStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "loadStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:577:1: loadStatement : KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition ) -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ) ;
    public final HiveParser.loadStatement_return loadStatement() throws RecognitionException {
        HiveParser.loadStatement_return retval = new HiveParser.loadStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token islocal=null;
        Token path=null;
        Token isoverwrite=null;
        Token KW_LOAD12=null;
        Token KW_DATA13=null;
        Token KW_INPATH14=null;
        Token KW_INTO15=null;
        Token KW_TABLE16=null;
        HiveParser_IdentifiersParser.tableOrPartition_return tab =null;


        CommonTree islocal_tree=null;
        CommonTree path_tree=null;
        CommonTree isoverwrite_tree=null;
        CommonTree KW_LOAD12_tree=null;
        CommonTree KW_DATA13_tree=null;
        CommonTree KW_INPATH14_tree=null;
        CommonTree KW_INTO15_tree=null;
        CommonTree KW_TABLE16_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_INPATH=new RewriteRuleTokenStream(adaptor,"token KW_INPATH");
        RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
        RewriteRuleTokenStream stream_KW_LOCAL=new RewriteRuleTokenStream(adaptor,"token KW_LOCAL");
        RewriteRuleTokenStream stream_KW_OVERWRITE=new RewriteRuleTokenStream(adaptor,"token KW_OVERWRITE");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_KW_LOAD=new RewriteRuleTokenStream(adaptor,"token KW_LOAD");
        RewriteRuleTokenStream stream_KW_DATA=new RewriteRuleTokenStream(adaptor,"token KW_DATA");
        RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
         msgs.push("load statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:580:5: ( KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition ) -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:580:7: KW_LOAD KW_DATA (islocal= KW_LOCAL )? KW_INPATH (path= StringLiteral ) (isoverwrite= KW_OVERWRITE )? KW_INTO KW_TABLE (tab= tableOrPartition )
            {
            KW_LOAD12=(Token)match(input,KW_LOAD,FOLLOW_KW_LOAD_in_loadStatement1057);  
            stream_KW_LOAD.add(KW_LOAD12);


            KW_DATA13=(Token)match(input,KW_DATA,FOLLOW_KW_DATA_in_loadStatement1059);  
            stream_KW_DATA.add(KW_DATA13);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:580:23: (islocal= KW_LOCAL )?
            int alt4=2;
            int LA4_0 = input.LA(1);

            if ( (LA4_0==KW_LOCAL) ) {
                alt4=1;
            }
            switch (alt4) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:580:24: islocal= KW_LOCAL
                    {
                    islocal=(Token)match(input,KW_LOCAL,FOLLOW_KW_LOCAL_in_loadStatement1064);  
                    stream_KW_LOCAL.add(islocal);


                    }
                    break;

            }


            KW_INPATH14=(Token)match(input,KW_INPATH,FOLLOW_KW_INPATH_in_loadStatement1068);  
            stream_KW_INPATH.add(KW_INPATH14);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:580:53: (path= StringLiteral )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:580:54: path= StringLiteral
            {
            path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_loadStatement1073);  
            stream_StringLiteral.add(path);


            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:580:74: (isoverwrite= KW_OVERWRITE )?
            int alt5=2;
            int LA5_0 = input.LA(1);

            if ( (LA5_0==KW_OVERWRITE) ) {
                alt5=1;
            }
            switch (alt5) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:580:75: isoverwrite= KW_OVERWRITE
                    {
                    isoverwrite=(Token)match(input,KW_OVERWRITE,FOLLOW_KW_OVERWRITE_in_loadStatement1079);  
                    stream_KW_OVERWRITE.add(isoverwrite);


                    }
                    break;

            }


            KW_INTO15=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_loadStatement1083);  
            stream_KW_INTO.add(KW_INTO15);


            KW_TABLE16=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_loadStatement1085);  
            stream_KW_TABLE.add(KW_TABLE16);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:580:119: (tab= tableOrPartition )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:580:120: tab= tableOrPartition
            {
            pushFollow(FOLLOW_tableOrPartition_in_loadStatement1090);
            tab=tableOrPartition();

            state._fsp--;

            stream_tableOrPartition.add(tab.getTree());

            }


            // AST REWRITE
            // elements: path, isoverwrite, tab, islocal
            // token labels: islocal, isoverwrite, path
            // rule labels: retval, tab
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_islocal=new RewriteRuleTokenStream(adaptor,"token islocal",islocal);
            RewriteRuleTokenStream stream_isoverwrite=new RewriteRuleTokenStream(adaptor,"token isoverwrite",isoverwrite);
            RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_tab=new RewriteRuleSubtreeStream(adaptor,"rule tab",tab!=null?tab.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 581:5: -> ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:581:8: ^( TOK_LOAD $path $tab ( $islocal)? ( $isoverwrite)? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_LOAD, "TOK_LOAD")
                , root_1);

                adaptor.addChild(root_1, stream_path.nextNode());

                adaptor.addChild(root_1, stream_tab.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:581:31: ( $islocal)?
                if ( stream_islocal.hasNext() ) {
                    adaptor.addChild(root_1, stream_islocal.nextNode());

                }
                stream_islocal.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:581:41: ( $isoverwrite)?
                if ( stream_isoverwrite.hasNext() ) {
                    adaptor.addChild(root_1, stream_isoverwrite.nextNode());

                }
                stream_isoverwrite.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "loadStatement"


    public static class exportStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "exportStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:584:1: exportStatement : KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) -> ^( TOK_EXPORT $tab $path) ;
    public final HiveParser.exportStatement_return exportStatement() throws RecognitionException {
        HiveParser.exportStatement_return retval = new HiveParser.exportStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token path=null;
        Token KW_EXPORT17=null;
        Token KW_TABLE18=null;
        Token KW_TO19=null;
        HiveParser_IdentifiersParser.tableOrPartition_return tab =null;


        CommonTree path_tree=null;
        CommonTree KW_EXPORT17_tree=null;
        CommonTree KW_TABLE18_tree=null;
        CommonTree KW_TO19_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_EXPORT=new RewriteRuleTokenStream(adaptor,"token KW_EXPORT");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
        RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
         msgs.push("export statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:587:5: ( KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral ) -> ^( TOK_EXPORT $tab $path) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:587:7: KW_EXPORT KW_TABLE (tab= tableOrPartition ) KW_TO (path= StringLiteral )
            {
            KW_EXPORT17=(Token)match(input,KW_EXPORT,FOLLOW_KW_EXPORT_in_exportStatement1142);  
            stream_KW_EXPORT.add(KW_EXPORT17);


            KW_TABLE18=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_exportStatement1144);  
            stream_KW_TABLE.add(KW_TABLE18);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:587:26: (tab= tableOrPartition )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:587:27: tab= tableOrPartition
            {
            pushFollow(FOLLOW_tableOrPartition_in_exportStatement1149);
            tab=tableOrPartition();

            state._fsp--;

            stream_tableOrPartition.add(tab.getTree());

            }


            KW_TO19=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_exportStatement1152);  
            stream_KW_TO.add(KW_TO19);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:587:55: (path= StringLiteral )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:587:56: path= StringLiteral
            {
            path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_exportStatement1157);  
            stream_StringLiteral.add(path);


            }


            // AST REWRITE
            // elements: path, tab
            // token labels: path
            // rule labels: retval, tab
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_tab=new RewriteRuleSubtreeStream(adaptor,"rule tab",tab!=null?tab.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 588:5: -> ^( TOK_EXPORT $tab $path)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:588:8: ^( TOK_EXPORT $tab $path)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_EXPORT, "TOK_EXPORT")
                , root_1);

                adaptor.addChild(root_1, stream_tab.nextTree());

                adaptor.addChild(root_1, stream_path.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "exportStatement"


    public static class importStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "importStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:591:1: importStatement : KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( tableLocation )? -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? ) ;
    public final HiveParser.importStatement_return importStatement() throws RecognitionException {
        HiveParser.importStatement_return retval = new HiveParser.importStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token ext=null;
        Token path=null;
        Token KW_IMPORT20=null;
        Token KW_TABLE21=null;
        Token KW_FROM22=null;
        HiveParser_IdentifiersParser.tableOrPartition_return tab =null;

        HiveParser.tableLocation_return tableLocation23 =null;


        CommonTree ext_tree=null;
        CommonTree path_tree=null;
        CommonTree KW_IMPORT20_tree=null;
        CommonTree KW_TABLE21_tree=null;
        CommonTree KW_FROM22_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_IMPORT=new RewriteRuleTokenStream(adaptor,"token KW_IMPORT");
        RewriteRuleTokenStream stream_KW_EXTERNAL=new RewriteRuleTokenStream(adaptor,"token KW_EXTERNAL");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
        RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
        RewriteRuleSubtreeStream stream_tableLocation=new RewriteRuleSubtreeStream(adaptor,"rule tableLocation");
         msgs.push("import statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:594:2: ( KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( tableLocation )? -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:594:4: KW_IMPORT ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )? KW_FROM (path= StringLiteral ) ( tableLocation )?
            {
            KW_IMPORT20=(Token)match(input,KW_IMPORT,FOLLOW_KW_IMPORT_in_importStatement1198);  
            stream_KW_IMPORT.add(KW_IMPORT20);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:594:14: ( (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition ) )?
            int alt7=2;
            int LA7_0 = input.LA(1);

            if ( (LA7_0==KW_EXTERNAL||LA7_0==KW_TABLE) ) {
                alt7=1;
            }
            switch (alt7) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:594:15: (ext= KW_EXTERNAL )? KW_TABLE (tab= tableOrPartition )
                    {
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:594:15: (ext= KW_EXTERNAL )?
                    int alt6=2;
                    int LA6_0 = input.LA(1);

                    if ( (LA6_0==KW_EXTERNAL) ) {
                        alt6=1;
                    }
                    switch (alt6) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:594:16: ext= KW_EXTERNAL
                            {
                            ext=(Token)match(input,KW_EXTERNAL,FOLLOW_KW_EXTERNAL_in_importStatement1204);  
                            stream_KW_EXTERNAL.add(ext);


                            }
                            break;

                    }


                    KW_TABLE21=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_importStatement1208);  
                    stream_KW_TABLE.add(KW_TABLE21);


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:594:43: (tab= tableOrPartition )
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:594:44: tab= tableOrPartition
                    {
                    pushFollow(FOLLOW_tableOrPartition_in_importStatement1213);
                    tab=tableOrPartition();

                    state._fsp--;

                    stream_tableOrPartition.add(tab.getTree());

                    }


                    }
                    break;

            }


            KW_FROM22=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_importStatement1218);  
            stream_KW_FROM.add(KW_FROM22);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:594:76: (path= StringLiteral )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:594:77: path= StringLiteral
            {
            path=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_importStatement1223);  
            stream_StringLiteral.add(path);


            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:594:97: ( tableLocation )?
            int alt8=2;
            int LA8_0 = input.LA(1);

            if ( (LA8_0==KW_LOCATION) ) {
                alt8=1;
            }
            switch (alt8) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:594:97: tableLocation
                    {
                    pushFollow(FOLLOW_tableLocation_in_importStatement1226);
                    tableLocation23=tableLocation();

                    state._fsp--;

                    stream_tableLocation.add(tableLocation23.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: tab, ext, path, tableLocation
            // token labels: path, ext
            // rule labels: retval, tab
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_path=new RewriteRuleTokenStream(adaptor,"token path",path);
            RewriteRuleTokenStream stream_ext=new RewriteRuleTokenStream(adaptor,"token ext",ext);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_tab=new RewriteRuleSubtreeStream(adaptor,"rule tab",tab!=null?tab.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 595:5: -> ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:595:8: ^( TOK_IMPORT $path ( $tab)? ( $ext)? ( tableLocation )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_IMPORT, "TOK_IMPORT")
                , root_1);

                adaptor.addChild(root_1, stream_path.nextNode());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:595:28: ( $tab)?
                if ( stream_tab.hasNext() ) {
                    adaptor.addChild(root_1, stream_tab.nextTree());

                }
                stream_tab.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:595:34: ( $ext)?
                if ( stream_ext.hasNext() ) {
                    adaptor.addChild(root_1, stream_ext.nextNode());

                }
                stream_ext.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:595:39: ( tableLocation )?
                if ( stream_tableLocation.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableLocation.nextTree());

                }
                stream_tableLocation.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "importStatement"


    public static class ddlStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "ddlStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:598:1: ddlStatement : ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | dropViewStatement | createFunctionStatement | createMacroStatement | createIndexStatement | dropIndexStatement | dropFunctionStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | createRoleStatement | dropRoleStatement | grantPrivileges | revokePrivileges | showGrants | showRoleGrants | grantRole | revokeRole );
    public final HiveParser.ddlStatement_return ddlStatement() throws RecognitionException {
        HiveParser.ddlStatement_return retval = new HiveParser.ddlStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser.createDatabaseStatement_return createDatabaseStatement24 =null;

        HiveParser.switchDatabaseStatement_return switchDatabaseStatement25 =null;

        HiveParser.dropDatabaseStatement_return dropDatabaseStatement26 =null;

        HiveParser.createTableStatement_return createTableStatement27 =null;

        HiveParser.dropTableStatement_return dropTableStatement28 =null;

        HiveParser.truncateTableStatement_return truncateTableStatement29 =null;

        HiveParser.alterStatement_return alterStatement30 =null;

        HiveParser.descStatement_return descStatement31 =null;

        HiveParser.showStatement_return showStatement32 =null;

        HiveParser.metastoreCheck_return metastoreCheck33 =null;

        HiveParser.createViewStatement_return createViewStatement34 =null;

        HiveParser.dropViewStatement_return dropViewStatement35 =null;

        HiveParser.createFunctionStatement_return createFunctionStatement36 =null;

        HiveParser.createMacroStatement_return createMacroStatement37 =null;

        HiveParser.createIndexStatement_return createIndexStatement38 =null;

        HiveParser.dropIndexStatement_return dropIndexStatement39 =null;

        HiveParser.dropFunctionStatement_return dropFunctionStatement40 =null;

        HiveParser.dropMacroStatement_return dropMacroStatement41 =null;

        HiveParser.analyzeStatement_return analyzeStatement42 =null;

        HiveParser.lockStatement_return lockStatement43 =null;

        HiveParser.unlockStatement_return unlockStatement44 =null;

        HiveParser.createRoleStatement_return createRoleStatement45 =null;

        HiveParser.dropRoleStatement_return dropRoleStatement46 =null;

        HiveParser.grantPrivileges_return grantPrivileges47 =null;

        HiveParser.revokePrivileges_return revokePrivileges48 =null;

        HiveParser.showGrants_return showGrants49 =null;

        HiveParser.showRoleGrants_return showRoleGrants50 =null;

        HiveParser.grantRole_return grantRole51 =null;

        HiveParser.revokeRole_return revokeRole52 =null;



         msgs.push("ddl statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:601:5: ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | dropViewStatement | createFunctionStatement | createMacroStatement | createIndexStatement | dropIndexStatement | dropFunctionStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | createRoleStatement | dropRoleStatement | grantPrivileges | revokePrivileges | showGrants | showRoleGrants | grantRole | revokeRole )
            int alt9=29;
            alt9 = dfa9.predict(input);
            switch (alt9) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:601:7: createDatabaseStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_createDatabaseStatement_in_ddlStatement1278);
                    createDatabaseStatement24=createDatabaseStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, createDatabaseStatement24.getTree());

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:602:7: switchDatabaseStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_switchDatabaseStatement_in_ddlStatement1286);
                    switchDatabaseStatement25=switchDatabaseStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, switchDatabaseStatement25.getTree());

                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:603:7: dropDatabaseStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_dropDatabaseStatement_in_ddlStatement1294);
                    dropDatabaseStatement26=dropDatabaseStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, dropDatabaseStatement26.getTree());

                    }
                    break;
                case 4 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:604:7: createTableStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_createTableStatement_in_ddlStatement1302);
                    createTableStatement27=createTableStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, createTableStatement27.getTree());

                    }
                    break;
                case 5 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:605:7: dropTableStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_dropTableStatement_in_ddlStatement1310);
                    dropTableStatement28=dropTableStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, dropTableStatement28.getTree());

                    }
                    break;
                case 6 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:606:7: truncateTableStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_truncateTableStatement_in_ddlStatement1318);
                    truncateTableStatement29=truncateTableStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, truncateTableStatement29.getTree());

                    }
                    break;
                case 7 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:607:7: alterStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatement_in_ddlStatement1326);
                    alterStatement30=alterStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatement30.getTree());

                    }
                    break;
                case 8 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:608:7: descStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_descStatement_in_ddlStatement1334);
                    descStatement31=descStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, descStatement31.getTree());

                    }
                    break;
                case 9 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:609:7: showStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_showStatement_in_ddlStatement1342);
                    showStatement32=showStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, showStatement32.getTree());

                    }
                    break;
                case 10 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:610:7: metastoreCheck
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_metastoreCheck_in_ddlStatement1350);
                    metastoreCheck33=metastoreCheck();

                    state._fsp--;

                    adaptor.addChild(root_0, metastoreCheck33.getTree());

                    }
                    break;
                case 11 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:611:7: createViewStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_createViewStatement_in_ddlStatement1358);
                    createViewStatement34=createViewStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, createViewStatement34.getTree());

                    }
                    break;
                case 12 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:612:7: dropViewStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_dropViewStatement_in_ddlStatement1366);
                    dropViewStatement35=dropViewStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, dropViewStatement35.getTree());

                    }
                    break;
                case 13 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:613:7: createFunctionStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_createFunctionStatement_in_ddlStatement1374);
                    createFunctionStatement36=createFunctionStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, createFunctionStatement36.getTree());

                    }
                    break;
                case 14 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:614:7: createMacroStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_createMacroStatement_in_ddlStatement1382);
                    createMacroStatement37=createMacroStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, createMacroStatement37.getTree());

                    }
                    break;
                case 15 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:615:7: createIndexStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_createIndexStatement_in_ddlStatement1390);
                    createIndexStatement38=createIndexStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, createIndexStatement38.getTree());

                    }
                    break;
                case 16 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:616:7: dropIndexStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_dropIndexStatement_in_ddlStatement1398);
                    dropIndexStatement39=dropIndexStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, dropIndexStatement39.getTree());

                    }
                    break;
                case 17 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:617:7: dropFunctionStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_dropFunctionStatement_in_ddlStatement1406);
                    dropFunctionStatement40=dropFunctionStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, dropFunctionStatement40.getTree());

                    }
                    break;
                case 18 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:618:7: dropMacroStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_dropMacroStatement_in_ddlStatement1414);
                    dropMacroStatement41=dropMacroStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, dropMacroStatement41.getTree());

                    }
                    break;
                case 19 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:619:7: analyzeStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_analyzeStatement_in_ddlStatement1422);
                    analyzeStatement42=analyzeStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, analyzeStatement42.getTree());

                    }
                    break;
                case 20 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:620:7: lockStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_lockStatement_in_ddlStatement1430);
                    lockStatement43=lockStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, lockStatement43.getTree());

                    }
                    break;
                case 21 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:621:7: unlockStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_unlockStatement_in_ddlStatement1438);
                    unlockStatement44=unlockStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, unlockStatement44.getTree());

                    }
                    break;
                case 22 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:622:7: createRoleStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_createRoleStatement_in_ddlStatement1446);
                    createRoleStatement45=createRoleStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, createRoleStatement45.getTree());

                    }
                    break;
                case 23 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:623:7: dropRoleStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_dropRoleStatement_in_ddlStatement1454);
                    dropRoleStatement46=dropRoleStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, dropRoleStatement46.getTree());

                    }
                    break;
                case 24 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:624:7: grantPrivileges
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_grantPrivileges_in_ddlStatement1462);
                    grantPrivileges47=grantPrivileges();

                    state._fsp--;

                    adaptor.addChild(root_0, grantPrivileges47.getTree());

                    }
                    break;
                case 25 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:625:7: revokePrivileges
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_revokePrivileges_in_ddlStatement1470);
                    revokePrivileges48=revokePrivileges();

                    state._fsp--;

                    adaptor.addChild(root_0, revokePrivileges48.getTree());

                    }
                    break;
                case 26 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:626:7: showGrants
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_showGrants_in_ddlStatement1478);
                    showGrants49=showGrants();

                    state._fsp--;

                    adaptor.addChild(root_0, showGrants49.getTree());

                    }
                    break;
                case 27 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:627:7: showRoleGrants
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_showRoleGrants_in_ddlStatement1486);
                    showRoleGrants50=showRoleGrants();

                    state._fsp--;

                    adaptor.addChild(root_0, showRoleGrants50.getTree());

                    }
                    break;
                case 28 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:628:7: grantRole
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_grantRole_in_ddlStatement1494);
                    grantRole51=grantRole();

                    state._fsp--;

                    adaptor.addChild(root_0, grantRole51.getTree());

                    }
                    break;
                case 29 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:629:7: revokeRole
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_revokeRole_in_ddlStatement1502);
                    revokeRole52=revokeRole();

                    state._fsp--;

                    adaptor.addChild(root_0, revokeRole52.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "ddlStatement"


    public static class ifExists_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "ifExists"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:632:1: ifExists : KW_IF KW_EXISTS -> ^( TOK_IFEXISTS ) ;
    public final HiveParser.ifExists_return ifExists() throws RecognitionException {
        HiveParser.ifExists_return retval = new HiveParser.ifExists_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_IF53=null;
        Token KW_EXISTS54=null;

        CommonTree KW_IF53_tree=null;
        CommonTree KW_EXISTS54_tree=null;
        RewriteRuleTokenStream stream_KW_IF=new RewriteRuleTokenStream(adaptor,"token KW_IF");
        RewriteRuleTokenStream stream_KW_EXISTS=new RewriteRuleTokenStream(adaptor,"token KW_EXISTS");

         msgs.push("if exists clause"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:635:5: ( KW_IF KW_EXISTS -> ^( TOK_IFEXISTS ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:635:7: KW_IF KW_EXISTS
            {
            KW_IF53=(Token)match(input,KW_IF,FOLLOW_KW_IF_in_ifExists1529);  
            stream_KW_IF.add(KW_IF53);


            KW_EXISTS54=(Token)match(input,KW_EXISTS,FOLLOW_KW_EXISTS_in_ifExists1531);  
            stream_KW_EXISTS.add(KW_EXISTS54);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 636:5: -> ^( TOK_IFEXISTS )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:636:8: ^( TOK_IFEXISTS )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_IFEXISTS, "TOK_IFEXISTS")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "ifExists"


    public static class restrictOrCascade_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "restrictOrCascade"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:639:1: restrictOrCascade : ( KW_RESTRICT -> ^( TOK_RESTRICT ) | KW_CASCADE -> ^( TOK_CASCADE ) );
    public final HiveParser.restrictOrCascade_return restrictOrCascade() throws RecognitionException {
        HiveParser.restrictOrCascade_return retval = new HiveParser.restrictOrCascade_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_RESTRICT55=null;
        Token KW_CASCADE56=null;

        CommonTree KW_RESTRICT55_tree=null;
        CommonTree KW_CASCADE56_tree=null;
        RewriteRuleTokenStream stream_KW_CASCADE=new RewriteRuleTokenStream(adaptor,"token KW_CASCADE");
        RewriteRuleTokenStream stream_KW_RESTRICT=new RewriteRuleTokenStream(adaptor,"token KW_RESTRICT");

         msgs.push("restrict or cascade clause"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:642:5: ( KW_RESTRICT -> ^( TOK_RESTRICT ) | KW_CASCADE -> ^( TOK_CASCADE ) )
            int alt10=2;
            int LA10_0 = input.LA(1);

            if ( (LA10_0==KW_RESTRICT) ) {
                alt10=1;
            }
            else if ( (LA10_0==KW_CASCADE) ) {
                alt10=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 10, 0, input);

                throw nvae;

            }
            switch (alt10) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:642:7: KW_RESTRICT
                    {
                    KW_RESTRICT55=(Token)match(input,KW_RESTRICT,FOLLOW_KW_RESTRICT_in_restrictOrCascade1568);  
                    stream_KW_RESTRICT.add(KW_RESTRICT55);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 643:5: -> ^( TOK_RESTRICT )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:643:8: ^( TOK_RESTRICT )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_RESTRICT, "TOK_RESTRICT")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:644:7: KW_CASCADE
                    {
                    KW_CASCADE56=(Token)match(input,KW_CASCADE,FOLLOW_KW_CASCADE_in_restrictOrCascade1586);  
                    stream_KW_CASCADE.add(KW_CASCADE56);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 645:5: -> ^( TOK_CASCADE )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:645:8: ^( TOK_CASCADE )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_CASCADE, "TOK_CASCADE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "restrictOrCascade"


    public static class ifNotExists_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "ifNotExists"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:648:1: ifNotExists : KW_IF KW_NOT KW_EXISTS -> ^( TOK_IFNOTEXISTS ) ;
    public final HiveParser.ifNotExists_return ifNotExists() throws RecognitionException {
        HiveParser.ifNotExists_return retval = new HiveParser.ifNotExists_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_IF57=null;
        Token KW_NOT58=null;
        Token KW_EXISTS59=null;

        CommonTree KW_IF57_tree=null;
        CommonTree KW_NOT58_tree=null;
        CommonTree KW_EXISTS59_tree=null;
        RewriteRuleTokenStream stream_KW_IF=new RewriteRuleTokenStream(adaptor,"token KW_IF");
        RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
        RewriteRuleTokenStream stream_KW_EXISTS=new RewriteRuleTokenStream(adaptor,"token KW_EXISTS");

         msgs.push("if not exists clause"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:651:5: ( KW_IF KW_NOT KW_EXISTS -> ^( TOK_IFNOTEXISTS ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:651:7: KW_IF KW_NOT KW_EXISTS
            {
            KW_IF57=(Token)match(input,KW_IF,FOLLOW_KW_IF_in_ifNotExists1623);  
            stream_KW_IF.add(KW_IF57);


            KW_NOT58=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_ifNotExists1625);  
            stream_KW_NOT.add(KW_NOT58);


            KW_EXISTS59=(Token)match(input,KW_EXISTS,FOLLOW_KW_EXISTS_in_ifNotExists1627);  
            stream_KW_EXISTS.add(KW_EXISTS59);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 652:5: -> ^( TOK_IFNOTEXISTS )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:652:8: ^( TOK_IFNOTEXISTS )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_IFNOTEXISTS, "TOK_IFNOTEXISTS")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "ifNotExists"


    public static class storedAsDirs_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "storedAsDirs"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:655:1: storedAsDirs : KW_STORED KW_AS KW_DIRECTORIES -> ^( TOK_STOREDASDIRS ) ;
    public final HiveParser.storedAsDirs_return storedAsDirs() throws RecognitionException {
        HiveParser.storedAsDirs_return retval = new HiveParser.storedAsDirs_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_STORED60=null;
        Token KW_AS61=null;
        Token KW_DIRECTORIES62=null;

        CommonTree KW_STORED60_tree=null;
        CommonTree KW_AS61_tree=null;
        CommonTree KW_DIRECTORIES62_tree=null;
        RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
        RewriteRuleTokenStream stream_KW_STORED=new RewriteRuleTokenStream(adaptor,"token KW_STORED");
        RewriteRuleTokenStream stream_KW_DIRECTORIES=new RewriteRuleTokenStream(adaptor,"token KW_DIRECTORIES");

         msgs.push("stored as directories"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:658:5: ( KW_STORED KW_AS KW_DIRECTORIES -> ^( TOK_STOREDASDIRS ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:658:7: KW_STORED KW_AS KW_DIRECTORIES
            {
            KW_STORED60=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_storedAsDirs1664);  
            stream_KW_STORED.add(KW_STORED60);


            KW_AS61=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_storedAsDirs1666);  
            stream_KW_AS.add(KW_AS61);


            KW_DIRECTORIES62=(Token)match(input,KW_DIRECTORIES,FOLLOW_KW_DIRECTORIES_in_storedAsDirs1668);  
            stream_KW_DIRECTORIES.add(KW_DIRECTORIES62);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 659:5: -> ^( TOK_STOREDASDIRS )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:659:8: ^( TOK_STOREDASDIRS )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_STOREDASDIRS, "TOK_STOREDASDIRS")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "storedAsDirs"


    public static class orReplace_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "orReplace"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:662:1: orReplace : KW_OR KW_REPLACE -> ^( TOK_ORREPLACE ) ;
    public final HiveParser.orReplace_return orReplace() throws RecognitionException {
        HiveParser.orReplace_return retval = new HiveParser.orReplace_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_OR63=null;
        Token KW_REPLACE64=null;

        CommonTree KW_OR63_tree=null;
        CommonTree KW_REPLACE64_tree=null;
        RewriteRuleTokenStream stream_KW_REPLACE=new RewriteRuleTokenStream(adaptor,"token KW_REPLACE");
        RewriteRuleTokenStream stream_KW_OR=new RewriteRuleTokenStream(adaptor,"token KW_OR");

         msgs.push("or replace clause"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:665:5: ( KW_OR KW_REPLACE -> ^( TOK_ORREPLACE ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:665:7: KW_OR KW_REPLACE
            {
            KW_OR63=(Token)match(input,KW_OR,FOLLOW_KW_OR_in_orReplace1705);  
            stream_KW_OR.add(KW_OR63);


            KW_REPLACE64=(Token)match(input,KW_REPLACE,FOLLOW_KW_REPLACE_in_orReplace1707);  
            stream_KW_REPLACE.add(KW_REPLACE64);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 666:5: -> ^( TOK_ORREPLACE )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:666:8: ^( TOK_ORREPLACE )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_ORREPLACE, "TOK_ORREPLACE")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "orReplace"


    public static class ignoreProtection_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "ignoreProtection"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:669:1: ignoreProtection : KW_IGNORE KW_PROTECTION -> ^( TOK_IGNOREPROTECTION ) ;
    public final HiveParser.ignoreProtection_return ignoreProtection() throws RecognitionException {
        HiveParser.ignoreProtection_return retval = new HiveParser.ignoreProtection_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_IGNORE65=null;
        Token KW_PROTECTION66=null;

        CommonTree KW_IGNORE65_tree=null;
        CommonTree KW_PROTECTION66_tree=null;
        RewriteRuleTokenStream stream_KW_PROTECTION=new RewriteRuleTokenStream(adaptor,"token KW_PROTECTION");
        RewriteRuleTokenStream stream_KW_IGNORE=new RewriteRuleTokenStream(adaptor,"token KW_IGNORE");

         msgs.push("ignore protection clause"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:672:9: ( KW_IGNORE KW_PROTECTION -> ^( TOK_IGNOREPROTECTION ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:672:11: KW_IGNORE KW_PROTECTION
            {
            KW_IGNORE65=(Token)match(input,KW_IGNORE,FOLLOW_KW_IGNORE_in_ignoreProtection1748);  
            stream_KW_IGNORE.add(KW_IGNORE65);


            KW_PROTECTION66=(Token)match(input,KW_PROTECTION,FOLLOW_KW_PROTECTION_in_ignoreProtection1750);  
            stream_KW_PROTECTION.add(KW_PROTECTION66);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 673:9: -> ^( TOK_IGNOREPROTECTION )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:673:12: ^( TOK_IGNOREPROTECTION )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_IGNOREPROTECTION, "TOK_IGNOREPROTECTION")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "ignoreProtection"


    public static class createDatabaseStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "createDatabaseStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:676:1: createDatabaseStatement : KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( dbLocation )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )? -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( databaseComment )? ( $dbprops)? ) ;
    public final HiveParser.createDatabaseStatement_return createDatabaseStatement() throws RecognitionException {
        HiveParser.createDatabaseStatement_return retval = new HiveParser.createDatabaseStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_CREATE67=null;
        Token KW_DATABASE68=null;
        Token KW_SCHEMA69=null;
        Token KW_WITH73=null;
        Token KW_DBPROPERTIES74=null;
        HiveParser_IdentifiersParser.identifier_return name =null;

        HiveParser.dbProperties_return dbprops =null;

        HiveParser.ifNotExists_return ifNotExists70 =null;

        HiveParser.databaseComment_return databaseComment71 =null;

        HiveParser.dbLocation_return dbLocation72 =null;


        CommonTree KW_CREATE67_tree=null;
        CommonTree KW_DATABASE68_tree=null;
        CommonTree KW_SCHEMA69_tree=null;
        CommonTree KW_WITH73_tree=null;
        CommonTree KW_DBPROPERTIES74_tree=null;
        RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
        RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
        RewriteRuleTokenStream stream_KW_DBPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_DBPROPERTIES");
        RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
        RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
        RewriteRuleSubtreeStream stream_dbProperties=new RewriteRuleSubtreeStream(adaptor,"rule dbProperties");
        RewriteRuleSubtreeStream stream_dbLocation=new RewriteRuleSubtreeStream(adaptor,"rule dbLocation");
        RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
        RewriteRuleSubtreeStream stream_databaseComment=new RewriteRuleSubtreeStream(adaptor,"rule databaseComment");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("create database statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:679:5: ( KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( dbLocation )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )? -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( databaseComment )? ( $dbprops)? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:679:7: KW_CREATE ( KW_DATABASE | KW_SCHEMA ) ( ifNotExists )? name= identifier ( databaseComment )? ( dbLocation )? ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )?
            {
            KW_CREATE67=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createDatabaseStatement1795);  
            stream_KW_CREATE.add(KW_CREATE67);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:679:17: ( KW_DATABASE | KW_SCHEMA )
            int alt11=2;
            int LA11_0 = input.LA(1);

            if ( (LA11_0==KW_DATABASE) ) {
                alt11=1;
            }
            else if ( (LA11_0==KW_SCHEMA) ) {
                alt11=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 11, 0, input);

                throw nvae;

            }
            switch (alt11) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:679:18: KW_DATABASE
                    {
                    KW_DATABASE68=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_createDatabaseStatement1798);  
                    stream_KW_DATABASE.add(KW_DATABASE68);


                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:679:30: KW_SCHEMA
                    {
                    KW_SCHEMA69=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_createDatabaseStatement1800);  
                    stream_KW_SCHEMA.add(KW_SCHEMA69);


                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:680:9: ( ifNotExists )?
            int alt12=2;
            int LA12_0 = input.LA(1);

            if ( (LA12_0==KW_IF) ) {
                alt12=1;
            }
            switch (alt12) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:680:9: ifNotExists
                    {
                    pushFollow(FOLLOW_ifNotExists_in_createDatabaseStatement1811);
                    ifNotExists70=ifNotExists();

                    state._fsp--;

                    stream_ifNotExists.add(ifNotExists70.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_identifier_in_createDatabaseStatement1824);
            name=identifier();

            state._fsp--;

            stream_identifier.add(name.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:682:9: ( databaseComment )?
            int alt13=2;
            int LA13_0 = input.LA(1);

            if ( (LA13_0==KW_COMMENT) ) {
                alt13=1;
            }
            switch (alt13) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:682:9: databaseComment
                    {
                    pushFollow(FOLLOW_databaseComment_in_createDatabaseStatement1834);
                    databaseComment71=databaseComment();

                    state._fsp--;

                    stream_databaseComment.add(databaseComment71.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:683:9: ( dbLocation )?
            int alt14=2;
            int LA14_0 = input.LA(1);

            if ( (LA14_0==KW_LOCATION) ) {
                alt14=1;
            }
            switch (alt14) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:683:9: dbLocation
                    {
                    pushFollow(FOLLOW_dbLocation_in_createDatabaseStatement1845);
                    dbLocation72=dbLocation();

                    state._fsp--;

                    stream_dbLocation.add(dbLocation72.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:684:9: ( KW_WITH KW_DBPROPERTIES dbprops= dbProperties )?
            int alt15=2;
            int LA15_0 = input.LA(1);

            if ( (LA15_0==KW_WITH) ) {
                alt15=1;
            }
            switch (alt15) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:684:10: KW_WITH KW_DBPROPERTIES dbprops= dbProperties
                    {
                    KW_WITH73=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_createDatabaseStatement1857);  
                    stream_KW_WITH.add(KW_WITH73);


                    KW_DBPROPERTIES74=(Token)match(input,KW_DBPROPERTIES,FOLLOW_KW_DBPROPERTIES_in_createDatabaseStatement1859);  
                    stream_KW_DBPROPERTIES.add(KW_DBPROPERTIES74);


                    pushFollow(FOLLOW_dbProperties_in_createDatabaseStatement1863);
                    dbprops=dbProperties();

                    state._fsp--;

                    stream_dbProperties.add(dbprops.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: databaseComment, dbLocation, ifNotExists, dbprops, name
            // token labels: 
            // rule labels: retval, name, dbprops
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);
            RewriteRuleSubtreeStream stream_dbprops=new RewriteRuleSubtreeStream(adaptor,"rule dbprops",dbprops!=null?dbprops.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 685:5: -> ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( databaseComment )? ( $dbprops)? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:685:8: ^( TOK_CREATEDATABASE $name ( ifNotExists )? ( dbLocation )? ( databaseComment )? ( $dbprops)? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_CREATEDATABASE, "TOK_CREATEDATABASE")
                , root_1);

                adaptor.addChild(root_1, stream_name.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:685:35: ( ifNotExists )?
                if ( stream_ifNotExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifNotExists.nextTree());

                }
                stream_ifNotExists.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:685:48: ( dbLocation )?
                if ( stream_dbLocation.hasNext() ) {
                    adaptor.addChild(root_1, stream_dbLocation.nextTree());

                }
                stream_dbLocation.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:685:60: ( databaseComment )?
                if ( stream_databaseComment.hasNext() ) {
                    adaptor.addChild(root_1, stream_databaseComment.nextTree());

                }
                stream_databaseComment.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:685:78: ( $dbprops)?
                if ( stream_dbprops.hasNext() ) {
                    adaptor.addChild(root_1, stream_dbprops.nextTree());

                }
                stream_dbprops.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "createDatabaseStatement"


    public static class dbLocation_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dbLocation"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:688:1: dbLocation : KW_LOCATION locn= StringLiteral -> ^( TOK_DATABASELOCATION $locn) ;
    public final HiveParser.dbLocation_return dbLocation() throws RecognitionException {
        HiveParser.dbLocation_return retval = new HiveParser.dbLocation_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token locn=null;
        Token KW_LOCATION75=null;

        CommonTree locn_tree=null;
        CommonTree KW_LOCATION75_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");

         msgs.push("database location specification"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:691:5: ( KW_LOCATION locn= StringLiteral -> ^( TOK_DATABASELOCATION $locn) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:692:7: KW_LOCATION locn= StringLiteral
            {
            KW_LOCATION75=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_dbLocation1924);  
            stream_KW_LOCATION.add(KW_LOCATION75);


            locn=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_dbLocation1928);  
            stream_StringLiteral.add(locn);


            // AST REWRITE
            // elements: locn
            // token labels: locn
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_locn=new RewriteRuleTokenStream(adaptor,"token locn",locn);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 692:38: -> ^( TOK_DATABASELOCATION $locn)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:692:41: ^( TOK_DATABASELOCATION $locn)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_DATABASELOCATION, "TOK_DATABASELOCATION")
                , root_1);

                adaptor.addChild(root_1, stream_locn.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dbLocation"


    public static class dbProperties_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dbProperties"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:695:1: dbProperties : LPAREN dbPropertiesList RPAREN -> ^( TOK_DATABASEPROPERTIES dbPropertiesList ) ;
    public final HiveParser.dbProperties_return dbProperties() throws RecognitionException {
        HiveParser.dbProperties_return retval = new HiveParser.dbProperties_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token LPAREN76=null;
        Token RPAREN78=null;
        HiveParser.dbPropertiesList_return dbPropertiesList77 =null;


        CommonTree LPAREN76_tree=null;
        CommonTree RPAREN78_tree=null;
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleSubtreeStream stream_dbPropertiesList=new RewriteRuleSubtreeStream(adaptor,"rule dbPropertiesList");
         msgs.push("dbproperties"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:698:5: ( LPAREN dbPropertiesList RPAREN -> ^( TOK_DATABASEPROPERTIES dbPropertiesList ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:699:7: LPAREN dbPropertiesList RPAREN
            {
            LPAREN76=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_dbProperties1970);  
            stream_LPAREN.add(LPAREN76);


            pushFollow(FOLLOW_dbPropertiesList_in_dbProperties1972);
            dbPropertiesList77=dbPropertiesList();

            state._fsp--;

            stream_dbPropertiesList.add(dbPropertiesList77.getTree());

            RPAREN78=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_dbProperties1974);  
            stream_RPAREN.add(RPAREN78);


            // AST REWRITE
            // elements: dbPropertiesList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 699:38: -> ^( TOK_DATABASEPROPERTIES dbPropertiesList )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:699:41: ^( TOK_DATABASEPROPERTIES dbPropertiesList )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_DATABASEPROPERTIES, "TOK_DATABASEPROPERTIES")
                , root_1);

                adaptor.addChild(root_1, stream_dbPropertiesList.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dbProperties"


    public static class dbPropertiesList_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dbPropertiesList"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:702:1: dbPropertiesList : keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_DBPROPLIST ( keyValueProperty )+ ) ;
    public final HiveParser.dbPropertiesList_return dbPropertiesList() throws RecognitionException {
        HiveParser.dbPropertiesList_return retval = new HiveParser.dbPropertiesList_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token COMMA80=null;
        HiveParser.keyValueProperty_return keyValueProperty79 =null;

        HiveParser.keyValueProperty_return keyValueProperty81 =null;


        CommonTree COMMA80_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_keyValueProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyValueProperty");
         msgs.push("database properties list"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:705:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_DBPROPLIST ( keyValueProperty )+ ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:706:7: keyValueProperty ( COMMA keyValueProperty )*
            {
            pushFollow(FOLLOW_keyValueProperty_in_dbPropertiesList2015);
            keyValueProperty79=keyValueProperty();

            state._fsp--;

            stream_keyValueProperty.add(keyValueProperty79.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:706:24: ( COMMA keyValueProperty )*
            loop16:
            do {
                int alt16=2;
                int LA16_0 = input.LA(1);

                if ( (LA16_0==COMMA) ) {
                    alt16=1;
                }


                switch (alt16) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:706:25: COMMA keyValueProperty
            	    {
            	    COMMA80=(Token)match(input,COMMA,FOLLOW_COMMA_in_dbPropertiesList2018);  
            	    stream_COMMA.add(COMMA80);


            	    pushFollow(FOLLOW_keyValueProperty_in_dbPropertiesList2020);
            	    keyValueProperty81=keyValueProperty();

            	    state._fsp--;

            	    stream_keyValueProperty.add(keyValueProperty81.getTree());

            	    }
            	    break;

            	default :
            	    break loop16;
                }
            } while (true);


            // AST REWRITE
            // elements: keyValueProperty
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 706:50: -> ^( TOK_DBPROPLIST ( keyValueProperty )+ )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:706:53: ^( TOK_DBPROPLIST ( keyValueProperty )+ )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_DBPROPLIST, "TOK_DBPROPLIST")
                , root_1);

                if ( !(stream_keyValueProperty.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_keyValueProperty.hasNext() ) {
                    adaptor.addChild(root_1, stream_keyValueProperty.nextTree());

                }
                stream_keyValueProperty.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dbPropertiesList"


    public static class switchDatabaseStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "switchDatabaseStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:710:1: switchDatabaseStatement : KW_USE identifier -> ^( TOK_SWITCHDATABASE identifier ) ;
    public final HiveParser.switchDatabaseStatement_return switchDatabaseStatement() throws RecognitionException {
        HiveParser.switchDatabaseStatement_return retval = new HiveParser.switchDatabaseStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_USE82=null;
        HiveParser_IdentifiersParser.identifier_return identifier83 =null;


        CommonTree KW_USE82_tree=null;
        RewriteRuleTokenStream stream_KW_USE=new RewriteRuleTokenStream(adaptor,"token KW_USE");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("switch database statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:713:5: ( KW_USE identifier -> ^( TOK_SWITCHDATABASE identifier ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:713:7: KW_USE identifier
            {
            KW_USE82=(Token)match(input,KW_USE,FOLLOW_KW_USE_in_switchDatabaseStatement2059);  
            stream_KW_USE.add(KW_USE82);


            pushFollow(FOLLOW_identifier_in_switchDatabaseStatement2061);
            identifier83=identifier();

            state._fsp--;

            stream_identifier.add(identifier83.getTree());

            // AST REWRITE
            // elements: identifier
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 714:5: -> ^( TOK_SWITCHDATABASE identifier )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:714:8: ^( TOK_SWITCHDATABASE identifier )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_SWITCHDATABASE, "TOK_SWITCHDATABASE")
                , root_1);

                adaptor.addChild(root_1, stream_identifier.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "switchDatabaseStatement"


    public static class dropDatabaseStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dropDatabaseStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:717:1: dropDatabaseStatement : KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )? -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? ) ;
    public final HiveParser.dropDatabaseStatement_return dropDatabaseStatement() throws RecognitionException {
        HiveParser.dropDatabaseStatement_return retval = new HiveParser.dropDatabaseStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_DROP84=null;
        Token KW_DATABASE85=null;
        Token KW_SCHEMA86=null;
        HiveParser.ifExists_return ifExists87 =null;

        HiveParser_IdentifiersParser.identifier_return identifier88 =null;

        HiveParser.restrictOrCascade_return restrictOrCascade89 =null;


        CommonTree KW_DROP84_tree=null;
        CommonTree KW_DATABASE85_tree=null;
        CommonTree KW_SCHEMA86_tree=null;
        RewriteRuleTokenStream stream_KW_SCHEMA=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMA");
        RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
        RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
        RewriteRuleSubtreeStream stream_restrictOrCascade=new RewriteRuleSubtreeStream(adaptor,"rule restrictOrCascade");
        RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("drop database statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:720:5: ( KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )? -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:720:7: KW_DROP ( KW_DATABASE | KW_SCHEMA ) ( ifExists )? identifier ( restrictOrCascade )?
            {
            KW_DROP84=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropDatabaseStatement2100);  
            stream_KW_DROP.add(KW_DROP84);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:720:15: ( KW_DATABASE | KW_SCHEMA )
            int alt17=2;
            int LA17_0 = input.LA(1);

            if ( (LA17_0==KW_DATABASE) ) {
                alt17=1;
            }
            else if ( (LA17_0==KW_SCHEMA) ) {
                alt17=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 17, 0, input);

                throw nvae;

            }
            switch (alt17) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:720:16: KW_DATABASE
                    {
                    KW_DATABASE85=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_dropDatabaseStatement2103);  
                    stream_KW_DATABASE.add(KW_DATABASE85);


                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:720:28: KW_SCHEMA
                    {
                    KW_SCHEMA86=(Token)match(input,KW_SCHEMA,FOLLOW_KW_SCHEMA_in_dropDatabaseStatement2105);  
                    stream_KW_SCHEMA.add(KW_SCHEMA86);


                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:720:39: ( ifExists )?
            int alt18=2;
            int LA18_0 = input.LA(1);

            if ( (LA18_0==KW_IF) ) {
                alt18=1;
            }
            switch (alt18) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:720:39: ifExists
                    {
                    pushFollow(FOLLOW_ifExists_in_dropDatabaseStatement2108);
                    ifExists87=ifExists();

                    state._fsp--;

                    stream_ifExists.add(ifExists87.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_identifier_in_dropDatabaseStatement2111);
            identifier88=identifier();

            state._fsp--;

            stream_identifier.add(identifier88.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:720:60: ( restrictOrCascade )?
            int alt19=2;
            int LA19_0 = input.LA(1);

            if ( (LA19_0==KW_CASCADE||LA19_0==KW_RESTRICT) ) {
                alt19=1;
            }
            switch (alt19) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:720:60: restrictOrCascade
                    {
                    pushFollow(FOLLOW_restrictOrCascade_in_dropDatabaseStatement2113);
                    restrictOrCascade89=restrictOrCascade();

                    state._fsp--;

                    stream_restrictOrCascade.add(restrictOrCascade89.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: restrictOrCascade, identifier, ifExists
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 721:5: -> ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:721:8: ^( TOK_DROPDATABASE identifier ( ifExists )? ( restrictOrCascade )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_DROPDATABASE, "TOK_DROPDATABASE")
                , root_1);

                adaptor.addChild(root_1, stream_identifier.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:721:38: ( ifExists )?
                if ( stream_ifExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifExists.nextTree());

                }
                stream_ifExists.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:721:48: ( restrictOrCascade )?
                if ( stream_restrictOrCascade.hasNext() ) {
                    adaptor.addChild(root_1, stream_restrictOrCascade.nextTree());

                }
                stream_restrictOrCascade.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dropDatabaseStatement"


    public static class databaseComment_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "databaseComment"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:724:1: databaseComment : KW_COMMENT comment= StringLiteral -> ^( TOK_DATABASECOMMENT $comment) ;
    public final HiveParser.databaseComment_return databaseComment() throws RecognitionException {
        HiveParser.databaseComment_return retval = new HiveParser.databaseComment_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token comment=null;
        Token KW_COMMENT90=null;

        CommonTree comment_tree=null;
        CommonTree KW_COMMENT90_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");

         msgs.push("database's comment"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:727:5: ( KW_COMMENT comment= StringLiteral -> ^( TOK_DATABASECOMMENT $comment) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:727:7: KW_COMMENT comment= StringLiteral
            {
            KW_COMMENT90=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_databaseComment2159);  
            stream_KW_COMMENT.add(KW_COMMENT90);


            comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_databaseComment2163);  
            stream_StringLiteral.add(comment);


            // AST REWRITE
            // elements: comment
            // token labels: comment
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 728:5: -> ^( TOK_DATABASECOMMENT $comment)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:728:8: ^( TOK_DATABASECOMMENT $comment)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_DATABASECOMMENT, "TOK_DATABASECOMMENT")
                , root_1);

                adaptor.addChild(root_1, stream_comment.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "databaseComment"


    public static class createTableStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "createTableStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:731:1: createTableStatement : KW_CREATE (ext= KW_EXTERNAL )? KW_TABLE ( ifNotExists )? name= tableName (like= KW_LIKE likeName= tableName ( tableLocation )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatement )? ) -> ^( TOK_CREATETABLE $name ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeList )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( selectStatement )? ) ;
    public final HiveParser.createTableStatement_return createTableStatement() throws RecognitionException {
        HiveParser.createTableStatement_return retval = new HiveParser.createTableStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token ext=null;
        Token like=null;
        Token KW_CREATE91=null;
        Token KW_TABLE92=null;
        Token LPAREN96=null;
        Token RPAREN98=null;
        Token KW_AS107=null;
        HiveParser_FromClauseParser.tableName_return name =null;

        HiveParser_FromClauseParser.tableName_return likeName =null;

        HiveParser.ifNotExists_return ifNotExists93 =null;

        HiveParser.tableLocation_return tableLocation94 =null;

        HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed95 =null;

        HiveParser.columnNameTypeList_return columnNameTypeList97 =null;

        HiveParser.tableComment_return tableComment99 =null;

        HiveParser.tablePartition_return tablePartition100 =null;

        HiveParser.tableBuckets_return tableBuckets101 =null;

        HiveParser.tableSkewed_return tableSkewed102 =null;

        HiveParser.tableRowFormat_return tableRowFormat103 =null;

        HiveParser.tableFileFormat_return tableFileFormat104 =null;

        HiveParser.tableLocation_return tableLocation105 =null;

        HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed106 =null;

        HiveParser.selectStatement_return selectStatement108 =null;


        CommonTree ext_tree=null;
        CommonTree like_tree=null;
        CommonTree KW_CREATE91_tree=null;
        CommonTree KW_TABLE92_tree=null;
        CommonTree LPAREN96_tree=null;
        CommonTree RPAREN98_tree=null;
        CommonTree KW_AS107_tree=null;
        RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
        RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_LIKE=new RewriteRuleTokenStream(adaptor,"token KW_LIKE");
        RewriteRuleTokenStream stream_KW_EXTERNAL=new RewriteRuleTokenStream(adaptor,"token KW_EXTERNAL");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleSubtreeStream stream_selectStatement=new RewriteRuleSubtreeStream(adaptor,"rule selectStatement");
        RewriteRuleSubtreeStream stream_columnNameTypeList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeList");
        RewriteRuleSubtreeStream stream_tableBuckets=new RewriteRuleSubtreeStream(adaptor,"rule tableBuckets");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
        RewriteRuleSubtreeStream stream_tablePartition=new RewriteRuleSubtreeStream(adaptor,"rule tablePartition");
        RewriteRuleSubtreeStream stream_tablePropertiesPrefixed=new RewriteRuleSubtreeStream(adaptor,"rule tablePropertiesPrefixed");
        RewriteRuleSubtreeStream stream_tableComment=new RewriteRuleSubtreeStream(adaptor,"rule tableComment");
        RewriteRuleSubtreeStream stream_tableRowFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormat");
        RewriteRuleSubtreeStream stream_tableFileFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableFileFormat");
        RewriteRuleSubtreeStream stream_tableLocation=new RewriteRuleSubtreeStream(adaptor,"rule tableLocation");
        RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
        RewriteRuleSubtreeStream stream_tableSkewed=new RewriteRuleSubtreeStream(adaptor,"rule tableSkewed");
         msgs.push("create table statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:734:5: ( KW_CREATE (ext= KW_EXTERNAL )? KW_TABLE ( ifNotExists )? name= tableName (like= KW_LIKE likeName= tableName ( tableLocation )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatement )? ) -> ^( TOK_CREATETABLE $name ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeList )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( selectStatement )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:734:7: KW_CREATE (ext= KW_EXTERNAL )? KW_TABLE ( ifNotExists )? name= tableName (like= KW_LIKE likeName= tableName ( tableLocation )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatement )? )
            {
            KW_CREATE91=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createTableStatement2203);  
            stream_KW_CREATE.add(KW_CREATE91);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:734:17: (ext= KW_EXTERNAL )?
            int alt20=2;
            int LA20_0 = input.LA(1);

            if ( (LA20_0==KW_EXTERNAL) ) {
                alt20=1;
            }
            switch (alt20) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:734:18: ext= KW_EXTERNAL
                    {
                    ext=(Token)match(input,KW_EXTERNAL,FOLLOW_KW_EXTERNAL_in_createTableStatement2208);  
                    stream_KW_EXTERNAL.add(ext);


                    }
                    break;

            }


            KW_TABLE92=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_createTableStatement2212);  
            stream_KW_TABLE.add(KW_TABLE92);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:734:45: ( ifNotExists )?
            int alt21=2;
            int LA21_0 = input.LA(1);

            if ( (LA21_0==KW_IF) ) {
                alt21=1;
            }
            switch (alt21) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:734:45: ifNotExists
                    {
                    pushFollow(FOLLOW_ifNotExists_in_createTableStatement2214);
                    ifNotExists93=ifNotExists();

                    state._fsp--;

                    stream_ifNotExists.add(ifNotExists93.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_tableName_in_createTableStatement2219);
            name=tableName();

            state._fsp--;

            stream_tableName.add(name.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:735:7: (like= KW_LIKE likeName= tableName ( tableLocation )? ( tablePropertiesPrefixed )? | ( LPAREN columnNameTypeList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatement )? )
            int alt34=2;
            int LA34_0 = input.LA(1);

            if ( (LA34_0==KW_LIKE) ) {
                alt34=1;
            }
            else if ( (LA34_0==EOF||LA34_0==KW_AS||LA34_0==KW_CLUSTERED||LA34_0==KW_COMMENT||LA34_0==KW_LOCATION||LA34_0==KW_PARTITIONED||LA34_0==KW_ROW||LA34_0==KW_SKEWED||LA34_0==KW_STORED||LA34_0==KW_TBLPROPERTIES||LA34_0==LPAREN) ) {
                alt34=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 34, 0, input);

                throw nvae;

            }
            switch (alt34) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:735:10: like= KW_LIKE likeName= tableName ( tableLocation )? ( tablePropertiesPrefixed )?
                    {
                    like=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_createTableStatement2232);  
                    stream_KW_LIKE.add(like);


                    pushFollow(FOLLOW_tableName_in_createTableStatement2236);
                    likeName=tableName();

                    state._fsp--;

                    stream_tableName.add(likeName.getTree());

                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:736:10: ( tableLocation )?
                    int alt22=2;
                    int LA22_0 = input.LA(1);

                    if ( (LA22_0==KW_LOCATION) ) {
                        alt22=1;
                    }
                    switch (alt22) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:736:10: tableLocation
                            {
                            pushFollow(FOLLOW_tableLocation_in_createTableStatement2247);
                            tableLocation94=tableLocation();

                            state._fsp--;

                            stream_tableLocation.add(tableLocation94.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:737:10: ( tablePropertiesPrefixed )?
                    int alt23=2;
                    int LA23_0 = input.LA(1);

                    if ( (LA23_0==KW_TBLPROPERTIES) ) {
                        alt23=1;
                    }
                    switch (alt23) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:737:10: tablePropertiesPrefixed
                            {
                            pushFollow(FOLLOW_tablePropertiesPrefixed_in_createTableStatement2259);
                            tablePropertiesPrefixed95=tablePropertiesPrefixed();

                            state._fsp--;

                            stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed95.getTree());

                            }
                            break;

                    }


                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:738:10: ( LPAREN columnNameTypeList RPAREN )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( KW_AS selectStatement )?
                    {
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:738:10: ( LPAREN columnNameTypeList RPAREN )?
                    int alt24=2;
                    int LA24_0 = input.LA(1);

                    if ( (LA24_0==LPAREN) ) {
                        alt24=1;
                    }
                    switch (alt24) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:738:11: LPAREN columnNameTypeList RPAREN
                            {
                            LPAREN96=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createTableStatement2272);  
                            stream_LPAREN.add(LPAREN96);


                            pushFollow(FOLLOW_columnNameTypeList_in_createTableStatement2274);
                            columnNameTypeList97=columnNameTypeList();

                            state._fsp--;

                            stream_columnNameTypeList.add(columnNameTypeList97.getTree());

                            RPAREN98=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createTableStatement2276);  
                            stream_RPAREN.add(RPAREN98);


                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:739:10: ( tableComment )?
                    int alt25=2;
                    int LA25_0 = input.LA(1);

                    if ( (LA25_0==KW_COMMENT) ) {
                        alt25=1;
                    }
                    switch (alt25) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:739:10: tableComment
                            {
                            pushFollow(FOLLOW_tableComment_in_createTableStatement2289);
                            tableComment99=tableComment();

                            state._fsp--;

                            stream_tableComment.add(tableComment99.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:740:10: ( tablePartition )?
                    int alt26=2;
                    int LA26_0 = input.LA(1);

                    if ( (LA26_0==KW_PARTITIONED) ) {
                        alt26=1;
                    }
                    switch (alt26) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:740:10: tablePartition
                            {
                            pushFollow(FOLLOW_tablePartition_in_createTableStatement2301);
                            tablePartition100=tablePartition();

                            state._fsp--;

                            stream_tablePartition.add(tablePartition100.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:741:10: ( tableBuckets )?
                    int alt27=2;
                    int LA27_0 = input.LA(1);

                    if ( (LA27_0==KW_CLUSTERED) ) {
                        alt27=1;
                    }
                    switch (alt27) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:741:10: tableBuckets
                            {
                            pushFollow(FOLLOW_tableBuckets_in_createTableStatement2313);
                            tableBuckets101=tableBuckets();

                            state._fsp--;

                            stream_tableBuckets.add(tableBuckets101.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:742:10: ( tableSkewed )?
                    int alt28=2;
                    int LA28_0 = input.LA(1);

                    if ( (LA28_0==KW_SKEWED) ) {
                        alt28=1;
                    }
                    switch (alt28) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:742:10: tableSkewed
                            {
                            pushFollow(FOLLOW_tableSkewed_in_createTableStatement2325);
                            tableSkewed102=tableSkewed();

                            state._fsp--;

                            stream_tableSkewed.add(tableSkewed102.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:743:10: ( tableRowFormat )?
                    int alt29=2;
                    int LA29_0 = input.LA(1);

                    if ( (LA29_0==KW_ROW) ) {
                        alt29=1;
                    }
                    switch (alt29) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:743:10: tableRowFormat
                            {
                            pushFollow(FOLLOW_tableRowFormat_in_createTableStatement2337);
                            tableRowFormat103=tableRowFormat();

                            state._fsp--;

                            stream_tableRowFormat.add(tableRowFormat103.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:744:10: ( tableFileFormat )?
                    int alt30=2;
                    int LA30_0 = input.LA(1);

                    if ( (LA30_0==KW_STORED) ) {
                        alt30=1;
                    }
                    switch (alt30) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:744:10: tableFileFormat
                            {
                            pushFollow(FOLLOW_tableFileFormat_in_createTableStatement2349);
                            tableFileFormat104=tableFileFormat();

                            state._fsp--;

                            stream_tableFileFormat.add(tableFileFormat104.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:745:10: ( tableLocation )?
                    int alt31=2;
                    int LA31_0 = input.LA(1);

                    if ( (LA31_0==KW_LOCATION) ) {
                        alt31=1;
                    }
                    switch (alt31) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:745:10: tableLocation
                            {
                            pushFollow(FOLLOW_tableLocation_in_createTableStatement2361);
                            tableLocation105=tableLocation();

                            state._fsp--;

                            stream_tableLocation.add(tableLocation105.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:746:10: ( tablePropertiesPrefixed )?
                    int alt32=2;
                    int LA32_0 = input.LA(1);

                    if ( (LA32_0==KW_TBLPROPERTIES) ) {
                        alt32=1;
                    }
                    switch (alt32) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:746:10: tablePropertiesPrefixed
                            {
                            pushFollow(FOLLOW_tablePropertiesPrefixed_in_createTableStatement2373);
                            tablePropertiesPrefixed106=tablePropertiesPrefixed();

                            state._fsp--;

                            stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed106.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:747:10: ( KW_AS selectStatement )?
                    int alt33=2;
                    int LA33_0 = input.LA(1);

                    if ( (LA33_0==KW_AS) ) {
                        alt33=1;
                    }
                    switch (alt33) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:747:11: KW_AS selectStatement
                            {
                            KW_AS107=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_createTableStatement2386);  
                            stream_KW_AS.add(KW_AS107);


                            pushFollow(FOLLOW_selectStatement_in_createTableStatement2388);
                            selectStatement108=selectStatement();

                            state._fsp--;

                            stream_selectStatement.add(selectStatement108.getTree());

                            }
                            break;

                    }


                    }
                    break;

            }


            // AST REWRITE
            // elements: tableComment, tablePropertiesPrefixed, tableFileFormat, ext, name, tableBuckets, tableSkewed, likeName, ifNotExists, selectStatement, tablePartition, columnNameTypeList, tableLocation, tableRowFormat
            // token labels: ext
            // rule labels: retval, likeName, name
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_ext=new RewriteRuleTokenStream(adaptor,"token ext",ext);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_likeName=new RewriteRuleSubtreeStream(adaptor,"rule likeName",likeName!=null?likeName.tree:null);
            RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 749:5: -> ^( TOK_CREATETABLE $name ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeList )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( selectStatement )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:749:8: ^( TOK_CREATETABLE $name ( $ext)? ( ifNotExists )? ^( TOK_LIKETABLE ( $likeName)? ) ( columnNameTypeList )? ( tableComment )? ( tablePartition )? ( tableBuckets )? ( tableSkewed )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( selectStatement )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_CREATETABLE, "TOK_CREATETABLE")
                , root_1);

                adaptor.addChild(root_1, stream_name.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:749:33: ( $ext)?
                if ( stream_ext.hasNext() ) {
                    adaptor.addChild(root_1, stream_ext.nextNode());

                }
                stream_ext.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:749:38: ( ifNotExists )?
                if ( stream_ifNotExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifNotExists.nextTree());

                }
                stream_ifNotExists.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:750:10: ^( TOK_LIKETABLE ( $likeName)? )
                {
                CommonTree root_2 = (CommonTree)adaptor.nil();
                root_2 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_LIKETABLE, "TOK_LIKETABLE")
                , root_2);

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:750:27: ( $likeName)?
                if ( stream_likeName.hasNext() ) {
                    adaptor.addChild(root_2, stream_likeName.nextTree());

                }
                stream_likeName.reset();

                adaptor.addChild(root_1, root_2);
                }

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:751:10: ( columnNameTypeList )?
                if ( stream_columnNameTypeList.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());

                }
                stream_columnNameTypeList.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:752:10: ( tableComment )?
                if ( stream_tableComment.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableComment.nextTree());

                }
                stream_tableComment.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:753:10: ( tablePartition )?
                if ( stream_tablePartition.hasNext() ) {
                    adaptor.addChild(root_1, stream_tablePartition.nextTree());

                }
                stream_tablePartition.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:754:10: ( tableBuckets )?
                if ( stream_tableBuckets.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableBuckets.nextTree());

                }
                stream_tableBuckets.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:755:10: ( tableSkewed )?
                if ( stream_tableSkewed.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableSkewed.nextTree());

                }
                stream_tableSkewed.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:756:10: ( tableRowFormat )?
                if ( stream_tableRowFormat.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableRowFormat.nextTree());

                }
                stream_tableRowFormat.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:757:10: ( tableFileFormat )?
                if ( stream_tableFileFormat.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableFileFormat.nextTree());

                }
                stream_tableFileFormat.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:758:10: ( tableLocation )?
                if ( stream_tableLocation.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableLocation.nextTree());

                }
                stream_tableLocation.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:759:10: ( tablePropertiesPrefixed )?
                if ( stream_tablePropertiesPrefixed.hasNext() ) {
                    adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());

                }
                stream_tablePropertiesPrefixed.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:760:10: ( selectStatement )?
                if ( stream_selectStatement.hasNext() ) {
                    adaptor.addChild(root_1, stream_selectStatement.nextTree());

                }
                stream_selectStatement.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "createTableStatement"


    public static class truncateTableStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "truncateTableStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:764:1: truncateTableStatement : KW_TRUNCATE KW_TABLE tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )? -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ) ;
    public final HiveParser.truncateTableStatement_return truncateTableStatement() throws RecognitionException {
        HiveParser.truncateTableStatement_return retval = new HiveParser.truncateTableStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_TRUNCATE109=null;
        Token KW_TABLE110=null;
        Token KW_COLUMNS112=null;
        Token LPAREN113=null;
        Token RPAREN115=null;
        HiveParser.tablePartitionPrefix_return tablePartitionPrefix111 =null;

        HiveParser.columnNameList_return columnNameList114 =null;


        CommonTree KW_TRUNCATE109_tree=null;
        CommonTree KW_TABLE110_tree=null;
        CommonTree KW_COLUMNS112_tree=null;
        CommonTree LPAREN113_tree=null;
        CommonTree RPAREN115_tree=null;
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_KW_TRUNCATE=new RewriteRuleTokenStream(adaptor,"token KW_TRUNCATE");
        RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
        RewriteRuleSubtreeStream stream_tablePartitionPrefix=new RewriteRuleSubtreeStream(adaptor,"rule tablePartitionPrefix");
         msgs.push("truncate table statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:767:5: ( KW_TRUNCATE KW_TABLE tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )? -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:767:7: KW_TRUNCATE KW_TABLE tablePartitionPrefix ( KW_COLUMNS LPAREN columnNameList RPAREN )?
            {
            KW_TRUNCATE109=(Token)match(input,KW_TRUNCATE,FOLLOW_KW_TRUNCATE_in_truncateTableStatement2591);  
            stream_KW_TRUNCATE.add(KW_TRUNCATE109);


            KW_TABLE110=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_truncateTableStatement2593);  
            stream_KW_TABLE.add(KW_TABLE110);


            pushFollow(FOLLOW_tablePartitionPrefix_in_truncateTableStatement2595);
            tablePartitionPrefix111=tablePartitionPrefix();

            state._fsp--;

            stream_tablePartitionPrefix.add(tablePartitionPrefix111.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:767:49: ( KW_COLUMNS LPAREN columnNameList RPAREN )?
            int alt35=2;
            int LA35_0 = input.LA(1);

            if ( (LA35_0==KW_COLUMNS) ) {
                alt35=1;
            }
            switch (alt35) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:767:50: KW_COLUMNS LPAREN columnNameList RPAREN
                    {
                    KW_COLUMNS112=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_truncateTableStatement2598);  
                    stream_KW_COLUMNS.add(KW_COLUMNS112);


                    LPAREN113=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_truncateTableStatement2600);  
                    stream_LPAREN.add(LPAREN113);


                    pushFollow(FOLLOW_columnNameList_in_truncateTableStatement2602);
                    columnNameList114=columnNameList();

                    state._fsp--;

                    stream_columnNameList.add(columnNameList114.getTree());

                    RPAREN115=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_truncateTableStatement2604);  
                    stream_RPAREN.add(RPAREN115);


                    }
                    break;

            }


            // AST REWRITE
            // elements: columnNameList, tablePartitionPrefix
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 767:92: -> ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:767:95: ^( TOK_TRUNCATETABLE tablePartitionPrefix ( columnNameList )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TRUNCATETABLE, "TOK_TRUNCATETABLE")
                , root_1);

                adaptor.addChild(root_1, stream_tablePartitionPrefix.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:767:136: ( columnNameList )?
                if ( stream_columnNameList.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnNameList.nextTree());

                }
                stream_columnNameList.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "truncateTableStatement"


    public static class createIndexStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "createIndexStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:769:1: createIndexStatement : KW_CREATE KW_INDEX indexName= identifier KW_ON KW_TABLE tab= tableName LPAREN indexedCols= columnNameList RPAREN KW_AS typeName= StringLiteral ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( indexComment )? -> ^( TOK_CREATEINDEX $indexName $typeName $tab $indexedCols ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( indexComment )? ) ;
    public final HiveParser.createIndexStatement_return createIndexStatement() throws RecognitionException {
        HiveParser.createIndexStatement_return retval = new HiveParser.createIndexStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token typeName=null;
        Token KW_CREATE116=null;
        Token KW_INDEX117=null;
        Token KW_ON118=null;
        Token KW_TABLE119=null;
        Token LPAREN120=null;
        Token RPAREN121=null;
        Token KW_AS122=null;
        HiveParser_IdentifiersParser.identifier_return indexName =null;

        HiveParser_FromClauseParser.tableName_return tab =null;

        HiveParser.columnNameList_return indexedCols =null;

        HiveParser.autoRebuild_return autoRebuild123 =null;

        HiveParser.indexPropertiesPrefixed_return indexPropertiesPrefixed124 =null;

        HiveParser.indexTblName_return indexTblName125 =null;

        HiveParser.tableRowFormat_return tableRowFormat126 =null;

        HiveParser.tableFileFormat_return tableFileFormat127 =null;

        HiveParser.tableLocation_return tableLocation128 =null;

        HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed129 =null;

        HiveParser.indexComment_return indexComment130 =null;


        CommonTree typeName_tree=null;
        CommonTree KW_CREATE116_tree=null;
        CommonTree KW_INDEX117_tree=null;
        CommonTree KW_ON118_tree=null;
        CommonTree KW_TABLE119_tree=null;
        CommonTree LPAREN120_tree=null;
        CommonTree RPAREN121_tree=null;
        CommonTree KW_AS122_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
        RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_INDEX=new RewriteRuleTokenStream(adaptor,"token KW_INDEX");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
        RewriteRuleSubtreeStream stream_indexPropertiesPrefixed=new RewriteRuleSubtreeStream(adaptor,"rule indexPropertiesPrefixed");
        RewriteRuleSubtreeStream stream_tableRowFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormat");
        RewriteRuleSubtreeStream stream_tableFileFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableFileFormat");
        RewriteRuleSubtreeStream stream_tablePropertiesPrefixed=new RewriteRuleSubtreeStream(adaptor,"rule tablePropertiesPrefixed");
        RewriteRuleSubtreeStream stream_autoRebuild=new RewriteRuleSubtreeStream(adaptor,"rule autoRebuild");
        RewriteRuleSubtreeStream stream_tableLocation=new RewriteRuleSubtreeStream(adaptor,"rule tableLocation");
        RewriteRuleSubtreeStream stream_indexTblName=new RewriteRuleSubtreeStream(adaptor,"rule indexTblName");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_indexComment=new RewriteRuleSubtreeStream(adaptor,"rule indexComment");
         msgs.push("create index statement");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:772:5: ( KW_CREATE KW_INDEX indexName= identifier KW_ON KW_TABLE tab= tableName LPAREN indexedCols= columnNameList RPAREN KW_AS typeName= StringLiteral ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( indexComment )? -> ^( TOK_CREATEINDEX $indexName $typeName $tab $indexedCols ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( indexComment )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:772:7: KW_CREATE KW_INDEX indexName= identifier KW_ON KW_TABLE tab= tableName LPAREN indexedCols= columnNameList RPAREN KW_AS typeName= StringLiteral ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( indexComment )?
            {
            KW_CREATE116=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createIndexStatement2639);  
            stream_KW_CREATE.add(KW_CREATE116);


            KW_INDEX117=(Token)match(input,KW_INDEX,FOLLOW_KW_INDEX_in_createIndexStatement2641);  
            stream_KW_INDEX.add(KW_INDEX117);


            pushFollow(FOLLOW_identifier_in_createIndexStatement2645);
            indexName=identifier();

            state._fsp--;

            stream_identifier.add(indexName.getTree());

            KW_ON118=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_createIndexStatement2653);  
            stream_KW_ON.add(KW_ON118);


            KW_TABLE119=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_createIndexStatement2655);  
            stream_KW_TABLE.add(KW_TABLE119);


            pushFollow(FOLLOW_tableName_in_createIndexStatement2659);
            tab=tableName();

            state._fsp--;

            stream_tableName.add(tab.getTree());

            LPAREN120=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createIndexStatement2661);  
            stream_LPAREN.add(LPAREN120);


            pushFollow(FOLLOW_columnNameList_in_createIndexStatement2665);
            indexedCols=columnNameList();

            state._fsp--;

            stream_columnNameList.add(indexedCols.getTree());

            RPAREN121=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createIndexStatement2667);  
            stream_RPAREN.add(RPAREN121);


            KW_AS122=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_createIndexStatement2675);  
            stream_KW_AS.add(KW_AS122);


            typeName=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_createIndexStatement2679);  
            stream_StringLiteral.add(typeName);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:775:7: ( autoRebuild )?
            int alt36=2;
            int LA36_0 = input.LA(1);

            if ( (LA36_0==KW_WITH) ) {
                alt36=1;
            }
            switch (alt36) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:775:7: autoRebuild
                    {
                    pushFollow(FOLLOW_autoRebuild_in_createIndexStatement2687);
                    autoRebuild123=autoRebuild();

                    state._fsp--;

                    stream_autoRebuild.add(autoRebuild123.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:776:7: ( indexPropertiesPrefixed )?
            int alt37=2;
            int LA37_0 = input.LA(1);

            if ( (LA37_0==KW_IDXPROPERTIES) ) {
                alt37=1;
            }
            switch (alt37) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:776:7: indexPropertiesPrefixed
                    {
                    pushFollow(FOLLOW_indexPropertiesPrefixed_in_createIndexStatement2696);
                    indexPropertiesPrefixed124=indexPropertiesPrefixed();

                    state._fsp--;

                    stream_indexPropertiesPrefixed.add(indexPropertiesPrefixed124.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:777:7: ( indexTblName )?
            int alt38=2;
            int LA38_0 = input.LA(1);

            if ( (LA38_0==KW_IN) ) {
                alt38=1;
            }
            switch (alt38) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:777:7: indexTblName
                    {
                    pushFollow(FOLLOW_indexTblName_in_createIndexStatement2705);
                    indexTblName125=indexTblName();

                    state._fsp--;

                    stream_indexTblName.add(indexTblName125.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:778:7: ( tableRowFormat )?
            int alt39=2;
            int LA39_0 = input.LA(1);

            if ( (LA39_0==KW_ROW) ) {
                alt39=1;
            }
            switch (alt39) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:778:7: tableRowFormat
                    {
                    pushFollow(FOLLOW_tableRowFormat_in_createIndexStatement2714);
                    tableRowFormat126=tableRowFormat();

                    state._fsp--;

                    stream_tableRowFormat.add(tableRowFormat126.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:779:7: ( tableFileFormat )?
            int alt40=2;
            int LA40_0 = input.LA(1);

            if ( (LA40_0==KW_STORED) ) {
                alt40=1;
            }
            switch (alt40) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:779:7: tableFileFormat
                    {
                    pushFollow(FOLLOW_tableFileFormat_in_createIndexStatement2723);
                    tableFileFormat127=tableFileFormat();

                    state._fsp--;

                    stream_tableFileFormat.add(tableFileFormat127.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:780:7: ( tableLocation )?
            int alt41=2;
            int LA41_0 = input.LA(1);

            if ( (LA41_0==KW_LOCATION) ) {
                alt41=1;
            }
            switch (alt41) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:780:7: tableLocation
                    {
                    pushFollow(FOLLOW_tableLocation_in_createIndexStatement2732);
                    tableLocation128=tableLocation();

                    state._fsp--;

                    stream_tableLocation.add(tableLocation128.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:781:7: ( tablePropertiesPrefixed )?
            int alt42=2;
            int LA42_0 = input.LA(1);

            if ( (LA42_0==KW_TBLPROPERTIES) ) {
                alt42=1;
            }
            switch (alt42) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:781:7: tablePropertiesPrefixed
                    {
                    pushFollow(FOLLOW_tablePropertiesPrefixed_in_createIndexStatement2741);
                    tablePropertiesPrefixed129=tablePropertiesPrefixed();

                    state._fsp--;

                    stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed129.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:782:7: ( indexComment )?
            int alt43=2;
            int LA43_0 = input.LA(1);

            if ( (LA43_0==KW_COMMENT) ) {
                alt43=1;
            }
            switch (alt43) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:782:7: indexComment
                    {
                    pushFollow(FOLLOW_indexComment_in_createIndexStatement2750);
                    indexComment130=indexComment();

                    state._fsp--;

                    stream_indexComment.add(indexComment130.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: typeName, tableLocation, indexedCols, tableRowFormat, indexName, tablePropertiesPrefixed, indexComment, autoRebuild, indexPropertiesPrefixed, tableFileFormat, indexTblName, tab
            // token labels: typeName
            // rule labels: indexedCols, retval, indexName, tab
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_typeName=new RewriteRuleTokenStream(adaptor,"token typeName",typeName);
            RewriteRuleSubtreeStream stream_indexedCols=new RewriteRuleSubtreeStream(adaptor,"rule indexedCols",indexedCols!=null?indexedCols.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_indexName=new RewriteRuleSubtreeStream(adaptor,"rule indexName",indexName!=null?indexName.tree:null);
            RewriteRuleSubtreeStream stream_tab=new RewriteRuleSubtreeStream(adaptor,"rule tab",tab!=null?tab.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 783:5: -> ^( TOK_CREATEINDEX $indexName $typeName $tab $indexedCols ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( indexComment )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:783:7: ^( TOK_CREATEINDEX $indexName $typeName $tab $indexedCols ( autoRebuild )? ( indexPropertiesPrefixed )? ( indexTblName )? ( tableRowFormat )? ( tableFileFormat )? ( tableLocation )? ( tablePropertiesPrefixed )? ( indexComment )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_CREATEINDEX, "TOK_CREATEINDEX")
                , root_1);

                adaptor.addChild(root_1, stream_indexName.nextTree());

                adaptor.addChild(root_1, stream_typeName.nextNode());

                adaptor.addChild(root_1, stream_tab.nextTree());

                adaptor.addChild(root_1, stream_indexedCols.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:784:9: ( autoRebuild )?
                if ( stream_autoRebuild.hasNext() ) {
                    adaptor.addChild(root_1, stream_autoRebuild.nextTree());

                }
                stream_autoRebuild.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:785:9: ( indexPropertiesPrefixed )?
                if ( stream_indexPropertiesPrefixed.hasNext() ) {
                    adaptor.addChild(root_1, stream_indexPropertiesPrefixed.nextTree());

                }
                stream_indexPropertiesPrefixed.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:786:9: ( indexTblName )?
                if ( stream_indexTblName.hasNext() ) {
                    adaptor.addChild(root_1, stream_indexTblName.nextTree());

                }
                stream_indexTblName.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:787:9: ( tableRowFormat )?
                if ( stream_tableRowFormat.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableRowFormat.nextTree());

                }
                stream_tableRowFormat.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:788:9: ( tableFileFormat )?
                if ( stream_tableFileFormat.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableFileFormat.nextTree());

                }
                stream_tableFileFormat.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:789:9: ( tableLocation )?
                if ( stream_tableLocation.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableLocation.nextTree());

                }
                stream_tableLocation.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:790:9: ( tablePropertiesPrefixed )?
                if ( stream_tablePropertiesPrefixed.hasNext() ) {
                    adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());

                }
                stream_tablePropertiesPrefixed.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:791:9: ( indexComment )?
                if ( stream_indexComment.hasNext() ) {
                    adaptor.addChild(root_1, stream_indexComment.nextTree());

                }
                stream_indexComment.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "createIndexStatement"


    public static class indexComment_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "indexComment"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:794:1: indexComment : KW_COMMENT comment= StringLiteral -> ^( TOK_INDEXCOMMENT $comment) ;
    public final HiveParser.indexComment_return indexComment() throws RecognitionException {
        HiveParser.indexComment_return retval = new HiveParser.indexComment_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token comment=null;
        Token KW_COMMENT131=null;

        CommonTree comment_tree=null;
        CommonTree KW_COMMENT131_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");

         msgs.push("comment on an index");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:797:9: ( KW_COMMENT comment= StringLiteral -> ^( TOK_INDEXCOMMENT $comment) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:798:17: KW_COMMENT comment= StringLiteral
            {
            KW_COMMENT131=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_indexComment2907);  
            stream_KW_COMMENT.add(KW_COMMENT131);


            comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_indexComment2911);  
            stream_StringLiteral.add(comment);


            // AST REWRITE
            // elements: comment
            // token labels: comment
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 798:51: -> ^( TOK_INDEXCOMMENT $comment)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:798:54: ^( TOK_INDEXCOMMENT $comment)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_INDEXCOMMENT, "TOK_INDEXCOMMENT")
                , root_1);

                adaptor.addChild(root_1, stream_comment.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "indexComment"


    public static class autoRebuild_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "autoRebuild"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:801:1: autoRebuild : KW_WITH KW_DEFERRED KW_REBUILD -> ^( TOK_DEFERRED_REBUILDINDEX ) ;
    public final HiveParser.autoRebuild_return autoRebuild() throws RecognitionException {
        HiveParser.autoRebuild_return retval = new HiveParser.autoRebuild_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_WITH132=null;
        Token KW_DEFERRED133=null;
        Token KW_REBUILD134=null;

        CommonTree KW_WITH132_tree=null;
        CommonTree KW_DEFERRED133_tree=null;
        CommonTree KW_REBUILD134_tree=null;
        RewriteRuleTokenStream stream_KW_REBUILD=new RewriteRuleTokenStream(adaptor,"token KW_REBUILD");
        RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
        RewriteRuleTokenStream stream_KW_DEFERRED=new RewriteRuleTokenStream(adaptor,"token KW_DEFERRED");

         msgs.push("auto rebuild index");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:804:5: ( KW_WITH KW_DEFERRED KW_REBUILD -> ^( TOK_DEFERRED_REBUILDINDEX ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:804:7: KW_WITH KW_DEFERRED KW_REBUILD
            {
            KW_WITH132=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_autoRebuild2952);  
            stream_KW_WITH.add(KW_WITH132);


            KW_DEFERRED133=(Token)match(input,KW_DEFERRED,FOLLOW_KW_DEFERRED_in_autoRebuild2954);  
            stream_KW_DEFERRED.add(KW_DEFERRED133);


            KW_REBUILD134=(Token)match(input,KW_REBUILD,FOLLOW_KW_REBUILD_in_autoRebuild2956);  
            stream_KW_REBUILD.add(KW_REBUILD134);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 805:5: -> ^( TOK_DEFERRED_REBUILDINDEX )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:805:7: ^( TOK_DEFERRED_REBUILDINDEX )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_DEFERRED_REBUILDINDEX, "TOK_DEFERRED_REBUILDINDEX")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "autoRebuild"


    public static class indexTblName_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "indexTblName"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:808:1: indexTblName : KW_IN KW_TABLE indexTbl= tableName -> ^( TOK_CREATEINDEX_INDEXTBLNAME $indexTbl) ;
    public final HiveParser.indexTblName_return indexTblName() throws RecognitionException {
        HiveParser.indexTblName_return retval = new HiveParser.indexTblName_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_IN135=null;
        Token KW_TABLE136=null;
        HiveParser_FromClauseParser.tableName_return indexTbl =null;


        CommonTree KW_IN135_tree=null;
        CommonTree KW_TABLE136_tree=null;
        RewriteRuleTokenStream stream_KW_IN=new RewriteRuleTokenStream(adaptor,"token KW_IN");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
         msgs.push("index table name");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:811:5: ( KW_IN KW_TABLE indexTbl= tableName -> ^( TOK_CREATEINDEX_INDEXTBLNAME $indexTbl) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:811:7: KW_IN KW_TABLE indexTbl= tableName
            {
            KW_IN135=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_indexTblName2992);  
            stream_KW_IN.add(KW_IN135);


            KW_TABLE136=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_indexTblName2994);  
            stream_KW_TABLE.add(KW_TABLE136);


            pushFollow(FOLLOW_tableName_in_indexTblName2998);
            indexTbl=tableName();

            state._fsp--;

            stream_tableName.add(indexTbl.getTree());

            // AST REWRITE
            // elements: indexTbl
            // token labels: 
            // rule labels: retval, indexTbl
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_indexTbl=new RewriteRuleSubtreeStream(adaptor,"rule indexTbl",indexTbl!=null?indexTbl.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 812:5: -> ^( TOK_CREATEINDEX_INDEXTBLNAME $indexTbl)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:812:7: ^( TOK_CREATEINDEX_INDEXTBLNAME $indexTbl)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_CREATEINDEX_INDEXTBLNAME, "TOK_CREATEINDEX_INDEXTBLNAME")
                , root_1);

                adaptor.addChild(root_1, stream_indexTbl.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "indexTblName"


    public static class indexPropertiesPrefixed_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "indexPropertiesPrefixed"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:815:1: indexPropertiesPrefixed : KW_IDXPROPERTIES ! indexProperties ;
    public final HiveParser.indexPropertiesPrefixed_return indexPropertiesPrefixed() throws RecognitionException {
        HiveParser.indexPropertiesPrefixed_return retval = new HiveParser.indexPropertiesPrefixed_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_IDXPROPERTIES137=null;
        HiveParser.indexProperties_return indexProperties138 =null;


        CommonTree KW_IDXPROPERTIES137_tree=null;

         msgs.push("table properties with prefix"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:818:5: ( KW_IDXPROPERTIES ! indexProperties )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:819:9: KW_IDXPROPERTIES ! indexProperties
            {
            root_0 = (CommonTree)adaptor.nil();


            KW_IDXPROPERTIES137=(Token)match(input,KW_IDXPROPERTIES,FOLLOW_KW_IDXPROPERTIES_in_indexPropertiesPrefixed3045); 

            pushFollow(FOLLOW_indexProperties_in_indexPropertiesPrefixed3048);
            indexProperties138=indexProperties();

            state._fsp--;

            adaptor.addChild(root_0, indexProperties138.getTree());

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "indexPropertiesPrefixed"


    public static class indexProperties_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "indexProperties"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:822:1: indexProperties : LPAREN indexPropertiesList RPAREN -> ^( TOK_INDEXPROPERTIES indexPropertiesList ) ;
    public final HiveParser.indexProperties_return indexProperties() throws RecognitionException {
        HiveParser.indexProperties_return retval = new HiveParser.indexProperties_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token LPAREN139=null;
        Token RPAREN141=null;
        HiveParser.indexPropertiesList_return indexPropertiesList140 =null;


        CommonTree LPAREN139_tree=null;
        CommonTree RPAREN141_tree=null;
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleSubtreeStream stream_indexPropertiesList=new RewriteRuleSubtreeStream(adaptor,"rule indexPropertiesList");
         msgs.push("index properties"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:825:5: ( LPAREN indexPropertiesList RPAREN -> ^( TOK_INDEXPROPERTIES indexPropertiesList ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:826:7: LPAREN indexPropertiesList RPAREN
            {
            LPAREN139=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_indexProperties3081);  
            stream_LPAREN.add(LPAREN139);


            pushFollow(FOLLOW_indexPropertiesList_in_indexProperties3083);
            indexPropertiesList140=indexPropertiesList();

            state._fsp--;

            stream_indexPropertiesList.add(indexPropertiesList140.getTree());

            RPAREN141=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_indexProperties3085);  
            stream_RPAREN.add(RPAREN141);


            // AST REWRITE
            // elements: indexPropertiesList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 826:41: -> ^( TOK_INDEXPROPERTIES indexPropertiesList )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:826:44: ^( TOK_INDEXPROPERTIES indexPropertiesList )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_INDEXPROPERTIES, "TOK_INDEXPROPERTIES")
                , root_1);

                adaptor.addChild(root_1, stream_indexPropertiesList.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "indexProperties"


    public static class indexPropertiesList_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "indexPropertiesList"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:829:1: indexPropertiesList : keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_INDEXPROPLIST ( keyValueProperty )+ ) ;
    public final HiveParser.indexPropertiesList_return indexPropertiesList() throws RecognitionException {
        HiveParser.indexPropertiesList_return retval = new HiveParser.indexPropertiesList_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token COMMA143=null;
        HiveParser.keyValueProperty_return keyValueProperty142 =null;

        HiveParser.keyValueProperty_return keyValueProperty144 =null;


        CommonTree COMMA143_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_keyValueProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyValueProperty");
         msgs.push("index properties list"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:832:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_INDEXPROPLIST ( keyValueProperty )+ ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:833:7: keyValueProperty ( COMMA keyValueProperty )*
            {
            pushFollow(FOLLOW_keyValueProperty_in_indexPropertiesList3126);
            keyValueProperty142=keyValueProperty();

            state._fsp--;

            stream_keyValueProperty.add(keyValueProperty142.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:833:24: ( COMMA keyValueProperty )*
            loop44:
            do {
                int alt44=2;
                int LA44_0 = input.LA(1);

                if ( (LA44_0==COMMA) ) {
                    alt44=1;
                }


                switch (alt44) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:833:25: COMMA keyValueProperty
            	    {
            	    COMMA143=(Token)match(input,COMMA,FOLLOW_COMMA_in_indexPropertiesList3129);  
            	    stream_COMMA.add(COMMA143);


            	    pushFollow(FOLLOW_keyValueProperty_in_indexPropertiesList3131);
            	    keyValueProperty144=keyValueProperty();

            	    state._fsp--;

            	    stream_keyValueProperty.add(keyValueProperty144.getTree());

            	    }
            	    break;

            	default :
            	    break loop44;
                }
            } while (true);


            // AST REWRITE
            // elements: keyValueProperty
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 833:50: -> ^( TOK_INDEXPROPLIST ( keyValueProperty )+ )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:833:53: ^( TOK_INDEXPROPLIST ( keyValueProperty )+ )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_INDEXPROPLIST, "TOK_INDEXPROPLIST")
                , root_1);

                if ( !(stream_keyValueProperty.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_keyValueProperty.hasNext() ) {
                    adaptor.addChild(root_1, stream_keyValueProperty.nextTree());

                }
                stream_keyValueProperty.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "indexPropertiesList"


    public static class dropIndexStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dropIndexStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:836:1: dropIndexStatement : KW_DROP KW_INDEX ( ifExists )? indexName= identifier KW_ON tab= tableName -> ^( TOK_DROPINDEX $indexName $tab ( ifExists )? ) ;
    public final HiveParser.dropIndexStatement_return dropIndexStatement() throws RecognitionException {
        HiveParser.dropIndexStatement_return retval = new HiveParser.dropIndexStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_DROP145=null;
        Token KW_INDEX146=null;
        Token KW_ON148=null;
        HiveParser_IdentifiersParser.identifier_return indexName =null;

        HiveParser_FromClauseParser.tableName_return tab =null;

        HiveParser.ifExists_return ifExists147 =null;


        CommonTree KW_DROP145_tree=null;
        CommonTree KW_INDEX146_tree=null;
        CommonTree KW_ON148_tree=null;
        RewriteRuleTokenStream stream_KW_INDEX=new RewriteRuleTokenStream(adaptor,"token KW_INDEX");
        RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
        RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
        RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("drop index statement");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:839:5: ( KW_DROP KW_INDEX ( ifExists )? indexName= identifier KW_ON tab= tableName -> ^( TOK_DROPINDEX $indexName $tab ( ifExists )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:839:7: KW_DROP KW_INDEX ( ifExists )? indexName= identifier KW_ON tab= tableName
            {
            KW_DROP145=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropIndexStatement3169);  
            stream_KW_DROP.add(KW_DROP145);


            KW_INDEX146=(Token)match(input,KW_INDEX,FOLLOW_KW_INDEX_in_dropIndexStatement3171);  
            stream_KW_INDEX.add(KW_INDEX146);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:839:24: ( ifExists )?
            int alt45=2;
            int LA45_0 = input.LA(1);

            if ( (LA45_0==KW_IF) ) {
                alt45=1;
            }
            switch (alt45) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:839:24: ifExists
                    {
                    pushFollow(FOLLOW_ifExists_in_dropIndexStatement3173);
                    ifExists147=ifExists();

                    state._fsp--;

                    stream_ifExists.add(ifExists147.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_identifier_in_dropIndexStatement3178);
            indexName=identifier();

            state._fsp--;

            stream_identifier.add(indexName.getTree());

            KW_ON148=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_dropIndexStatement3180);  
            stream_KW_ON.add(KW_ON148);


            pushFollow(FOLLOW_tableName_in_dropIndexStatement3184);
            tab=tableName();

            state._fsp--;

            stream_tableName.add(tab.getTree());

            // AST REWRITE
            // elements: ifExists, tab, indexName
            // token labels: 
            // rule labels: retval, indexName, tab
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_indexName=new RewriteRuleSubtreeStream(adaptor,"rule indexName",indexName!=null?indexName.tree:null);
            RewriteRuleSubtreeStream stream_tab=new RewriteRuleSubtreeStream(adaptor,"rule tab",tab!=null?tab.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 840:5: -> ^( TOK_DROPINDEX $indexName $tab ( ifExists )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:840:7: ^( TOK_DROPINDEX $indexName $tab ( ifExists )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_DROPINDEX, "TOK_DROPINDEX")
                , root_1);

                adaptor.addChild(root_1, stream_indexName.nextTree());

                adaptor.addChild(root_1, stream_tab.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:840:39: ( ifExists )?
                if ( stream_ifExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifExists.nextTree());

                }
                stream_ifExists.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dropIndexStatement"


    public static class dropTableStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dropTableStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:843:1: dropTableStatement : KW_DROP KW_TABLE ( ifExists )? tableName -> ^( TOK_DROPTABLE tableName ( ifExists )? ) ;
    public final HiveParser.dropTableStatement_return dropTableStatement() throws RecognitionException {
        HiveParser.dropTableStatement_return retval = new HiveParser.dropTableStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_DROP149=null;
        Token KW_TABLE150=null;
        HiveParser.ifExists_return ifExists151 =null;

        HiveParser_FromClauseParser.tableName_return tableName152 =null;


        CommonTree KW_DROP149_tree=null;
        CommonTree KW_TABLE150_tree=null;
        RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
        RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
         msgs.push("drop statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:846:5: ( KW_DROP KW_TABLE ( ifExists )? tableName -> ^( TOK_DROPTABLE tableName ( ifExists )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:846:7: KW_DROP KW_TABLE ( ifExists )? tableName
            {
            KW_DROP149=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropTableStatement3229);  
            stream_KW_DROP.add(KW_DROP149);


            KW_TABLE150=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_dropTableStatement3231);  
            stream_KW_TABLE.add(KW_TABLE150);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:846:24: ( ifExists )?
            int alt46=2;
            int LA46_0 = input.LA(1);

            if ( (LA46_0==KW_IF) ) {
                alt46=1;
            }
            switch (alt46) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:846:24: ifExists
                    {
                    pushFollow(FOLLOW_ifExists_in_dropTableStatement3233);
                    ifExists151=ifExists();

                    state._fsp--;

                    stream_ifExists.add(ifExists151.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_tableName_in_dropTableStatement3236);
            tableName152=tableName();

            state._fsp--;

            stream_tableName.add(tableName152.getTree());

            // AST REWRITE
            // elements: tableName, ifExists
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 846:44: -> ^( TOK_DROPTABLE tableName ( ifExists )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:846:47: ^( TOK_DROPTABLE tableName ( ifExists )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_DROPTABLE, "TOK_DROPTABLE")
                , root_1);

                adaptor.addChild(root_1, stream_tableName.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:846:73: ( ifExists )?
                if ( stream_ifExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifExists.nextTree());

                }
                stream_ifExists.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dropTableStatement"


    public static class alterStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:849:1: alterStatement : KW_ALTER ! ( KW_TABLE ! alterTableStatementSuffix | KW_VIEW ! alterViewStatementSuffix | KW_INDEX ! alterIndexStatementSuffix | KW_DATABASE ! alterDatabaseStatementSuffix ) ;
    public final HiveParser.alterStatement_return alterStatement() throws RecognitionException {
        HiveParser.alterStatement_return retval = new HiveParser.alterStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_ALTER153=null;
        Token KW_TABLE154=null;
        Token KW_VIEW156=null;
        Token KW_INDEX158=null;
        Token KW_DATABASE160=null;
        HiveParser.alterTableStatementSuffix_return alterTableStatementSuffix155 =null;

        HiveParser.alterViewStatementSuffix_return alterViewStatementSuffix157 =null;

        HiveParser.alterIndexStatementSuffix_return alterIndexStatementSuffix159 =null;

        HiveParser.alterDatabaseStatementSuffix_return alterDatabaseStatementSuffix161 =null;


        CommonTree KW_ALTER153_tree=null;
        CommonTree KW_TABLE154_tree=null;
        CommonTree KW_VIEW156_tree=null;
        CommonTree KW_INDEX158_tree=null;
        CommonTree KW_DATABASE160_tree=null;

         msgs.push("alter statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:852:5: ( KW_ALTER ! ( KW_TABLE ! alterTableStatementSuffix | KW_VIEW ! alterViewStatementSuffix | KW_INDEX ! alterIndexStatementSuffix | KW_DATABASE ! alterDatabaseStatementSuffix ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:852:7: KW_ALTER ! ( KW_TABLE ! alterTableStatementSuffix | KW_VIEW ! alterViewStatementSuffix | KW_INDEX ! alterIndexStatementSuffix | KW_DATABASE ! alterDatabaseStatementSuffix )
            {
            root_0 = (CommonTree)adaptor.nil();


            KW_ALTER153=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_alterStatement3274); 

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:853:9: ( KW_TABLE ! alterTableStatementSuffix | KW_VIEW ! alterViewStatementSuffix | KW_INDEX ! alterIndexStatementSuffix | KW_DATABASE ! alterDatabaseStatementSuffix )
            int alt47=4;
            switch ( input.LA(1) ) {
            case KW_TABLE:
                {
                alt47=1;
                }
                break;
            case KW_VIEW:
                {
                alt47=2;
                }
                break;
            case KW_INDEX:
                {
                alt47=3;
                }
                break;
            case KW_DATABASE:
                {
                alt47=4;
                }
                break;
            default:
                NoViableAltException nvae =
                    new NoViableAltException("", 47, 0, input);

                throw nvae;

            }

            switch (alt47) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:854:13: KW_TABLE ! alterTableStatementSuffix
                    {
                    KW_TABLE154=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_alterStatement3299); 

                    pushFollow(FOLLOW_alterTableStatementSuffix_in_alterStatement3302);
                    alterTableStatementSuffix155=alterTableStatementSuffix();

                    state._fsp--;

                    adaptor.addChild(root_0, alterTableStatementSuffix155.getTree());

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:856:13: KW_VIEW ! alterViewStatementSuffix
                    {
                    KW_VIEW156=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_alterStatement3326); 

                    pushFollow(FOLLOW_alterViewStatementSuffix_in_alterStatement3329);
                    alterViewStatementSuffix157=alterViewStatementSuffix();

                    state._fsp--;

                    adaptor.addChild(root_0, alterViewStatementSuffix157.getTree());

                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:858:13: KW_INDEX ! alterIndexStatementSuffix
                    {
                    KW_INDEX158=(Token)match(input,KW_INDEX,FOLLOW_KW_INDEX_in_alterStatement3353); 

                    pushFollow(FOLLOW_alterIndexStatementSuffix_in_alterStatement3356);
                    alterIndexStatementSuffix159=alterIndexStatementSuffix();

                    state._fsp--;

                    adaptor.addChild(root_0, alterIndexStatementSuffix159.getTree());

                    }
                    break;
                case 4 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:860:13: KW_DATABASE ! alterDatabaseStatementSuffix
                    {
                    KW_DATABASE160=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_alterStatement3380); 

                    pushFollow(FOLLOW_alterDatabaseStatementSuffix_in_alterStatement3383);
                    alterDatabaseStatementSuffix161=alterDatabaseStatementSuffix();

                    state._fsp--;

                    adaptor.addChild(root_0, alterDatabaseStatementSuffix161.getTree());

                    }
                    break;

            }


            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatement"


    public static class alterTableStatementSuffix_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterTableStatementSuffix"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:864:1: alterTableStatementSuffix : ( alterStatementSuffixRename | alterStatementSuffixAddCol | alterStatementSuffixRenameCol | alterStatementSuffixDropPartitions | alterStatementSuffixAddPartitions | alterStatementSuffixTouch | alterStatementSuffixArchive | alterStatementSuffixUnArchive | alterStatementSuffixProperties | alterTblPartitionStatement | alterStatementSuffixSkewedby | alterStatementSuffixExchangePartition );
    public final HiveParser.alterTableStatementSuffix_return alterTableStatementSuffix() throws RecognitionException {
        HiveParser.alterTableStatementSuffix_return retval = new HiveParser.alterTableStatementSuffix_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser.alterStatementSuffixRename_return alterStatementSuffixRename162 =null;

        HiveParser.alterStatementSuffixAddCol_return alterStatementSuffixAddCol163 =null;

        HiveParser.alterStatementSuffixRenameCol_return alterStatementSuffixRenameCol164 =null;

        HiveParser.alterStatementSuffixDropPartitions_return alterStatementSuffixDropPartitions165 =null;

        HiveParser.alterStatementSuffixAddPartitions_return alterStatementSuffixAddPartitions166 =null;

        HiveParser.alterStatementSuffixTouch_return alterStatementSuffixTouch167 =null;

        HiveParser.alterStatementSuffixArchive_return alterStatementSuffixArchive168 =null;

        HiveParser.alterStatementSuffixUnArchive_return alterStatementSuffixUnArchive169 =null;

        HiveParser.alterStatementSuffixProperties_return alterStatementSuffixProperties170 =null;

        HiveParser.alterTblPartitionStatement_return alterTblPartitionStatement171 =null;

        HiveParser.alterStatementSuffixSkewedby_return alterStatementSuffixSkewedby172 =null;

        HiveParser.alterStatementSuffixExchangePartition_return alterStatementSuffixExchangePartition173 =null;



         msgs.push("alter table statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:867:5: ( alterStatementSuffixRename | alterStatementSuffixAddCol | alterStatementSuffixRenameCol | alterStatementSuffixDropPartitions | alterStatementSuffixAddPartitions | alterStatementSuffixTouch | alterStatementSuffixArchive | alterStatementSuffixUnArchive | alterStatementSuffixProperties | alterTblPartitionStatement | alterStatementSuffixSkewedby | alterStatementSuffixExchangePartition )
            int alt48=12;
            alt48 = dfa48.predict(input);
            switch (alt48) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:867:7: alterStatementSuffixRename
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixRename_in_alterTableStatementSuffix3420);
                    alterStatementSuffixRename162=alterStatementSuffixRename();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatementSuffixRename162.getTree());

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:868:7: alterStatementSuffixAddCol
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixAddCol_in_alterTableStatementSuffix3428);
                    alterStatementSuffixAddCol163=alterStatementSuffixAddCol();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatementSuffixAddCol163.getTree());

                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:869:7: alterStatementSuffixRenameCol
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixRenameCol_in_alterTableStatementSuffix3436);
                    alterStatementSuffixRenameCol164=alterStatementSuffixRenameCol();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatementSuffixRenameCol164.getTree());

                    }
                    break;
                case 4 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:870:7: alterStatementSuffixDropPartitions
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixDropPartitions_in_alterTableStatementSuffix3444);
                    alterStatementSuffixDropPartitions165=alterStatementSuffixDropPartitions();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatementSuffixDropPartitions165.getTree());

                    }
                    break;
                case 5 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:871:7: alterStatementSuffixAddPartitions
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixAddPartitions_in_alterTableStatementSuffix3452);
                    alterStatementSuffixAddPartitions166=alterStatementSuffixAddPartitions();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatementSuffixAddPartitions166.getTree());

                    }
                    break;
                case 6 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:872:7: alterStatementSuffixTouch
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixTouch_in_alterTableStatementSuffix3460);
                    alterStatementSuffixTouch167=alterStatementSuffixTouch();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatementSuffixTouch167.getTree());

                    }
                    break;
                case 7 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:873:7: alterStatementSuffixArchive
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixArchive_in_alterTableStatementSuffix3468);
                    alterStatementSuffixArchive168=alterStatementSuffixArchive();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatementSuffixArchive168.getTree());

                    }
                    break;
                case 8 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:874:7: alterStatementSuffixUnArchive
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixUnArchive_in_alterTableStatementSuffix3476);
                    alterStatementSuffixUnArchive169=alterStatementSuffixUnArchive();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatementSuffixUnArchive169.getTree());

                    }
                    break;
                case 9 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:875:7: alterStatementSuffixProperties
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixProperties_in_alterTableStatementSuffix3484);
                    alterStatementSuffixProperties170=alterStatementSuffixProperties();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatementSuffixProperties170.getTree());

                    }
                    break;
                case 10 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:876:7: alterTblPartitionStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterTblPartitionStatement_in_alterTableStatementSuffix3492);
                    alterTblPartitionStatement171=alterTblPartitionStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, alterTblPartitionStatement171.getTree());

                    }
                    break;
                case 11 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:877:7: alterStatementSuffixSkewedby
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixSkewedby_in_alterTableStatementSuffix3500);
                    alterStatementSuffixSkewedby172=alterStatementSuffixSkewedby();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatementSuffixSkewedby172.getTree());

                    }
                    break;
                case 12 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:878:7: alterStatementSuffixExchangePartition
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixExchangePartition_in_alterTableStatementSuffix3508);
                    alterStatementSuffixExchangePartition173=alterStatementSuffixExchangePartition();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatementSuffixExchangePartition173.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterTableStatementSuffix"


    public static class alterViewStatementSuffix_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterViewStatementSuffix"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:881:1: alterViewStatementSuffix : ( alterViewSuffixProperties | alterStatementSuffixRename -> ^( TOK_ALTERVIEW_RENAME alterStatementSuffixRename ) | alterStatementSuffixAddPartitions -> ^( TOK_ALTERVIEW_ADDPARTS alterStatementSuffixAddPartitions ) | alterStatementSuffixDropPartitions -> ^( TOK_ALTERVIEW_DROPPARTS alterStatementSuffixDropPartitions ) |name= tableName KW_AS selectStatement -> ^( TOK_ALTERVIEW_AS $name selectStatement ) );
    public final HiveParser.alterViewStatementSuffix_return alterViewStatementSuffix() throws RecognitionException {
        HiveParser.alterViewStatementSuffix_return retval = new HiveParser.alterViewStatementSuffix_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_AS178=null;
        HiveParser_FromClauseParser.tableName_return name =null;

        HiveParser.alterViewSuffixProperties_return alterViewSuffixProperties174 =null;

        HiveParser.alterStatementSuffixRename_return alterStatementSuffixRename175 =null;

        HiveParser.alterStatementSuffixAddPartitions_return alterStatementSuffixAddPartitions176 =null;

        HiveParser.alterStatementSuffixDropPartitions_return alterStatementSuffixDropPartitions177 =null;

        HiveParser.selectStatement_return selectStatement179 =null;


        CommonTree KW_AS178_tree=null;
        RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
        RewriteRuleSubtreeStream stream_selectStatement=new RewriteRuleSubtreeStream(adaptor,"rule selectStatement");
        RewriteRuleSubtreeStream stream_alterStatementSuffixAddPartitions=new RewriteRuleSubtreeStream(adaptor,"rule alterStatementSuffixAddPartitions");
        RewriteRuleSubtreeStream stream_alterStatementSuffixRename=new RewriteRuleSubtreeStream(adaptor,"rule alterStatementSuffixRename");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
        RewriteRuleSubtreeStream stream_alterStatementSuffixDropPartitions=new RewriteRuleSubtreeStream(adaptor,"rule alterStatementSuffixDropPartitions");
         msgs.push("alter view statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:884:5: ( alterViewSuffixProperties | alterStatementSuffixRename -> ^( TOK_ALTERVIEW_RENAME alterStatementSuffixRename ) | alterStatementSuffixAddPartitions -> ^( TOK_ALTERVIEW_ADDPARTS alterStatementSuffixAddPartitions ) | alterStatementSuffixDropPartitions -> ^( TOK_ALTERVIEW_DROPPARTS alterStatementSuffixDropPartitions ) |name= tableName KW_AS selectStatement -> ^( TOK_ALTERVIEW_AS $name selectStatement ) )
            int alt49=5;
            int LA49_0 = input.LA(1);

            if ( (LA49_0==Identifier) ) {
                switch ( input.LA(2) ) {
                case KW_SET:
                case KW_UNSET:
                    {
                    alt49=1;
                    }
                    break;
                case KW_RENAME:
                    {
                    alt49=2;
                    }
                    break;
                case KW_ADD:
                    {
                    alt49=3;
                    }
                    break;
                case KW_DROP:
                    {
                    alt49=4;
                    }
                    break;
                case DOT:
                case KW_AS:
                    {
                    alt49=5;
                    }
                    break;
                default:
                    NoViableAltException nvae =
                        new NoViableAltException("", 49, 1, input);

                    throw nvae;

                }

            }
            else if ( ((LA49_0 >= KW_ADD && LA49_0 <= KW_AFTER)||(LA49_0 >= KW_ALTER && LA49_0 <= KW_ANALYZE)||(LA49_0 >= KW_ARCHIVE && LA49_0 <= KW_CASCADE)||(LA49_0 >= KW_CHANGE && LA49_0 <= KW_COLLECTION)||(LA49_0 >= KW_COLUMNS && LA49_0 <= KW_CREATE)||LA49_0==KW_CUBE||(LA49_0 >= KW_CURSOR && LA49_0 <= KW_DATA)||(LA49_0 >= KW_DATABASES && LA49_0 <= KW_DISABLE)||(LA49_0 >= KW_DISTRIBUTE && LA49_0 <= KW_ELEM_TYPE)||LA49_0==KW_ENABLE||LA49_0==KW_ESCAPED||(LA49_0 >= KW_EXCLUSIVE && LA49_0 <= KW_EXPORT)||(LA49_0 >= KW_EXTERNAL && LA49_0 <= KW_FLOAT)||(LA49_0 >= KW_FOR && LA49_0 <= KW_FORMATTED)||LA49_0==KW_FULL||(LA49_0 >= KW_FUNCTIONS && LA49_0 <= KW_GROUPING)||(LA49_0 >= KW_HOLD_DDLTIME && LA49_0 <= KW_IDXPROPERTIES)||(LA49_0 >= KW_IGNORE && LA49_0 <= KW_ITEMS)||(LA49_0 >= KW_KEYS && LA49_0 <= KW_LEFT)||(LA49_0 >= KW_LIKE && LA49_0 <= KW_LONG)||(LA49_0 >= KW_MAPJOIN && LA49_0 <= KW_MINUS)||(LA49_0 >= KW_MSCK && LA49_0 <= KW_NOSCAN)||(LA49_0 >= KW_NO_DROP && LA49_0 <= KW_OFFLINE)||LA49_0==KW_OPTION||(LA49_0 >= KW_ORCFILE && LA49_0 <= KW_OUTPUTFORMAT)||LA49_0==KW_OVERWRITE||(LA49_0 >= KW_PARTITION && LA49_0 <= KW_PLUS)||(LA49_0 >= KW_PRETTY && LA49_0 <= KW_RECORDWRITER)||(LA49_0 >= KW_REGEXP && LA49_0 <= KW_SCHEMAS)||(LA49_0 >= KW_SEMI && LA49_0 <= KW_TABLES)||(LA49_0 >= KW_TBLPROPERTIES && LA49_0 <= KW_TEXTFILE)||(LA49_0 >= KW_TIMESTAMP && LA49_0 <= KW_TOUCH)||(LA49_0 >= KW_TRIGGER && LA49_0 <= KW_UNARCHIVE)||(LA49_0 >= KW_UNDO && LA49_0 <= KW_UNIONTYPE)||(LA49_0 >= KW_UNLOCK && LA49_0 <= KW_VALUE_TYPE)||LA49_0==KW_VIEW||LA49_0==KW_WHILE||LA49_0==KW_WITH) ) {
                switch ( input.LA(2) ) {
                case KW_SET:
                case KW_UNSET:
                    {
                    alt49=1;
                    }
                    break;
                case KW_RENAME:
                    {
                    alt49=2;
                    }
                    break;
                case KW_ADD:
                    {
                    alt49=3;
                    }
                    break;
                case KW_DROP:
                    {
                    alt49=4;
                    }
                    break;
                case DOT:
                case KW_AS:
                    {
                    alt49=5;
                    }
                    break;
                default:
                    NoViableAltException nvae =
                        new NoViableAltException("", 49, 2, input);

                    throw nvae;

                }

            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 49, 0, input);

                throw nvae;

            }
            switch (alt49) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:884:7: alterViewSuffixProperties
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterViewSuffixProperties_in_alterViewStatementSuffix3535);
                    alterViewSuffixProperties174=alterViewSuffixProperties();

                    state._fsp--;

                    adaptor.addChild(root_0, alterViewSuffixProperties174.getTree());

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:885:7: alterStatementSuffixRename
                    {
                    pushFollow(FOLLOW_alterStatementSuffixRename_in_alterViewStatementSuffix3543);
                    alterStatementSuffixRename175=alterStatementSuffixRename();

                    state._fsp--;

                    stream_alterStatementSuffixRename.add(alterStatementSuffixRename175.getTree());

                    // AST REWRITE
                    // elements: alterStatementSuffixRename
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 886:9: -> ^( TOK_ALTERVIEW_RENAME alterStatementSuffixRename )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:886:12: ^( TOK_ALTERVIEW_RENAME alterStatementSuffixRename )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERVIEW_RENAME, "TOK_ALTERVIEW_RENAME")
                        , root_1);

                        adaptor.addChild(root_1, stream_alterStatementSuffixRename.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:887:7: alterStatementSuffixAddPartitions
                    {
                    pushFollow(FOLLOW_alterStatementSuffixAddPartitions_in_alterViewStatementSuffix3567);
                    alterStatementSuffixAddPartitions176=alterStatementSuffixAddPartitions();

                    state._fsp--;

                    stream_alterStatementSuffixAddPartitions.add(alterStatementSuffixAddPartitions176.getTree());

                    // AST REWRITE
                    // elements: alterStatementSuffixAddPartitions
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 888:9: -> ^( TOK_ALTERVIEW_ADDPARTS alterStatementSuffixAddPartitions )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:888:12: ^( TOK_ALTERVIEW_ADDPARTS alterStatementSuffixAddPartitions )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERVIEW_ADDPARTS, "TOK_ALTERVIEW_ADDPARTS")
                        , root_1);

                        adaptor.addChild(root_1, stream_alterStatementSuffixAddPartitions.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 4 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:889:7: alterStatementSuffixDropPartitions
                    {
                    pushFollow(FOLLOW_alterStatementSuffixDropPartitions_in_alterViewStatementSuffix3591);
                    alterStatementSuffixDropPartitions177=alterStatementSuffixDropPartitions();

                    state._fsp--;

                    stream_alterStatementSuffixDropPartitions.add(alterStatementSuffixDropPartitions177.getTree());

                    // AST REWRITE
                    // elements: alterStatementSuffixDropPartitions
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 890:9: -> ^( TOK_ALTERVIEW_DROPPARTS alterStatementSuffixDropPartitions )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:890:12: ^( TOK_ALTERVIEW_DROPPARTS alterStatementSuffixDropPartitions )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERVIEW_DROPPARTS, "TOK_ALTERVIEW_DROPPARTS")
                        , root_1);

                        adaptor.addChild(root_1, stream_alterStatementSuffixDropPartitions.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 5 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:891:7: name= tableName KW_AS selectStatement
                    {
                    pushFollow(FOLLOW_tableName_in_alterViewStatementSuffix3617);
                    name=tableName();

                    state._fsp--;

                    stream_tableName.add(name.getTree());

                    KW_AS178=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_alterViewStatementSuffix3619);  
                    stream_KW_AS.add(KW_AS178);


                    pushFollow(FOLLOW_selectStatement_in_alterViewStatementSuffix3621);
                    selectStatement179=selectStatement();

                    state._fsp--;

                    stream_selectStatement.add(selectStatement179.getTree());

                    // AST REWRITE
                    // elements: selectStatement, name
                    // token labels: 
                    // rule labels: retval, name
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 892:9: -> ^( TOK_ALTERVIEW_AS $name selectStatement )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:892:12: ^( TOK_ALTERVIEW_AS $name selectStatement )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERVIEW_AS, "TOK_ALTERVIEW_AS")
                        , root_1);

                        adaptor.addChild(root_1, stream_name.nextTree());

                        adaptor.addChild(root_1, stream_selectStatement.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterViewStatementSuffix"


    public static class alterIndexStatementSuffix_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterIndexStatementSuffix"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:895:1: alterIndexStatementSuffix : indexName= identifier ( KW_ON tableNameId= identifier ) ( partitionSpec )? ( KW_REBUILD -> ^( TOK_ALTERINDEX_REBUILD $tableNameId $indexName ( partitionSpec )? ) | KW_SET KW_IDXPROPERTIES indexProperties -> ^( TOK_ALTERINDEX_PROPERTIES $tableNameId $indexName indexProperties ) ) ;
    public final HiveParser.alterIndexStatementSuffix_return alterIndexStatementSuffix() throws RecognitionException {
        HiveParser.alterIndexStatementSuffix_return retval = new HiveParser.alterIndexStatementSuffix_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_ON180=null;
        Token KW_REBUILD182=null;
        Token KW_SET183=null;
        Token KW_IDXPROPERTIES184=null;
        HiveParser_IdentifiersParser.identifier_return indexName =null;

        HiveParser_IdentifiersParser.identifier_return tableNameId =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec181 =null;

        HiveParser.indexProperties_return indexProperties185 =null;


        CommonTree KW_ON180_tree=null;
        CommonTree KW_REBUILD182_tree=null;
        CommonTree KW_SET183_tree=null;
        CommonTree KW_IDXPROPERTIES184_tree=null;
        RewriteRuleTokenStream stream_KW_REBUILD=new RewriteRuleTokenStream(adaptor,"token KW_REBUILD");
        RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleTokenStream stream_KW_IDXPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_IDXPROPERTIES");
        RewriteRuleSubtreeStream stream_indexProperties=new RewriteRuleSubtreeStream(adaptor,"rule indexProperties");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("alter index statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:898:5: (indexName= identifier ( KW_ON tableNameId= identifier ) ( partitionSpec )? ( KW_REBUILD -> ^( TOK_ALTERINDEX_REBUILD $tableNameId $indexName ( partitionSpec )? ) | KW_SET KW_IDXPROPERTIES indexProperties -> ^( TOK_ALTERINDEX_PROPERTIES $tableNameId $indexName indexProperties ) ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:898:7: indexName= identifier ( KW_ON tableNameId= identifier ) ( partitionSpec )? ( KW_REBUILD -> ^( TOK_ALTERINDEX_REBUILD $tableNameId $indexName ( partitionSpec )? ) | KW_SET KW_IDXPROPERTIES indexProperties -> ^( TOK_ALTERINDEX_PROPERTIES $tableNameId $indexName indexProperties ) )
            {
            pushFollow(FOLLOW_identifier_in_alterIndexStatementSuffix3669);
            indexName=identifier();

            state._fsp--;

            stream_identifier.add(indexName.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:899:7: ( KW_ON tableNameId= identifier )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:899:8: KW_ON tableNameId= identifier
            {
            KW_ON180=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_alterIndexStatementSuffix3678);  
            stream_KW_ON.add(KW_ON180);


            pushFollow(FOLLOW_identifier_in_alterIndexStatementSuffix3682);
            tableNameId=identifier();

            state._fsp--;

            stream_identifier.add(tableNameId.getTree());

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:900:7: ( partitionSpec )?
            int alt50=2;
            int LA50_0 = input.LA(1);

            if ( (LA50_0==KW_PARTITION) ) {
                alt50=1;
            }
            switch (alt50) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:900:7: partitionSpec
                    {
                    pushFollow(FOLLOW_partitionSpec_in_alterIndexStatementSuffix3691);
                    partitionSpec181=partitionSpec();

                    state._fsp--;

                    stream_partitionSpec.add(partitionSpec181.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:901:5: ( KW_REBUILD -> ^( TOK_ALTERINDEX_REBUILD $tableNameId $indexName ( partitionSpec )? ) | KW_SET KW_IDXPROPERTIES indexProperties -> ^( TOK_ALTERINDEX_PROPERTIES $tableNameId $indexName indexProperties ) )
            int alt51=2;
            int LA51_0 = input.LA(1);

            if ( (LA51_0==KW_REBUILD) ) {
                alt51=1;
            }
            else if ( (LA51_0==KW_SET) ) {
                alt51=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 51, 0, input);

                throw nvae;

            }
            switch (alt51) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:902:7: KW_REBUILD
                    {
                    KW_REBUILD182=(Token)match(input,KW_REBUILD,FOLLOW_KW_REBUILD_in_alterIndexStatementSuffix3706);  
                    stream_KW_REBUILD.add(KW_REBUILD182);


                    // AST REWRITE
                    // elements: indexName, partitionSpec, tableNameId
                    // token labels: 
                    // rule labels: retval, tableNameId, indexName
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_tableNameId=new RewriteRuleSubtreeStream(adaptor,"rule tableNameId",tableNameId!=null?tableNameId.tree:null);
                    RewriteRuleSubtreeStream stream_indexName=new RewriteRuleSubtreeStream(adaptor,"rule indexName",indexName!=null?indexName.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 903:7: -> ^( TOK_ALTERINDEX_REBUILD $tableNameId $indexName ( partitionSpec )? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:903:9: ^( TOK_ALTERINDEX_REBUILD $tableNameId $indexName ( partitionSpec )? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERINDEX_REBUILD, "TOK_ALTERINDEX_REBUILD")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableNameId.nextTree());

                        adaptor.addChild(root_1, stream_indexName.nextTree());

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:903:58: ( partitionSpec )?
                        if ( stream_partitionSpec.hasNext() ) {
                            adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                        }
                        stream_partitionSpec.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:905:7: KW_SET KW_IDXPROPERTIES indexProperties
                    {
                    KW_SET183=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterIndexStatementSuffix3740);  
                    stream_KW_SET.add(KW_SET183);


                    KW_IDXPROPERTIES184=(Token)match(input,KW_IDXPROPERTIES,FOLLOW_KW_IDXPROPERTIES_in_alterIndexStatementSuffix3742);  
                    stream_KW_IDXPROPERTIES.add(KW_IDXPROPERTIES184);


                    pushFollow(FOLLOW_indexProperties_in_alterIndexStatementSuffix3750);
                    indexProperties185=indexProperties();

                    state._fsp--;

                    stream_indexProperties.add(indexProperties185.getTree());

                    // AST REWRITE
                    // elements: tableNameId, indexName, indexProperties
                    // token labels: 
                    // rule labels: retval, tableNameId, indexName
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_tableNameId=new RewriteRuleSubtreeStream(adaptor,"rule tableNameId",tableNameId!=null?tableNameId.tree:null);
                    RewriteRuleSubtreeStream stream_indexName=new RewriteRuleSubtreeStream(adaptor,"rule indexName",indexName!=null?indexName.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 907:7: -> ^( TOK_ALTERINDEX_PROPERTIES $tableNameId $indexName indexProperties )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:907:9: ^( TOK_ALTERINDEX_PROPERTIES $tableNameId $indexName indexProperties )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERINDEX_PROPERTIES, "TOK_ALTERINDEX_PROPERTIES")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableNameId.nextTree());

                        adaptor.addChild(root_1, stream_indexName.nextTree());

                        adaptor.addChild(root_1, stream_indexProperties.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }


            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterIndexStatementSuffix"


    public static class alterDatabaseStatementSuffix_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterDatabaseStatementSuffix"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:911:1: alterDatabaseStatementSuffix : alterDatabaseSuffixProperties ;
    public final HiveParser.alterDatabaseStatementSuffix_return alterDatabaseStatementSuffix() throws RecognitionException {
        HiveParser.alterDatabaseStatementSuffix_return retval = new HiveParser.alterDatabaseStatementSuffix_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser.alterDatabaseSuffixProperties_return alterDatabaseSuffixProperties186 =null;



         msgs.push("alter database statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:914:5: ( alterDatabaseSuffixProperties )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:914:7: alterDatabaseSuffixProperties
            {
            root_0 = (CommonTree)adaptor.nil();


            pushFollow(FOLLOW_alterDatabaseSuffixProperties_in_alterDatabaseStatementSuffix3802);
            alterDatabaseSuffixProperties186=alterDatabaseSuffixProperties();

            state._fsp--;

            adaptor.addChild(root_0, alterDatabaseSuffixProperties186.getTree());

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterDatabaseStatementSuffix"


    public static class alterDatabaseSuffixProperties_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterDatabaseSuffixProperties"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:917:1: alterDatabaseSuffixProperties : name= identifier KW_SET KW_DBPROPERTIES dbProperties -> ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties ) ;
    public final HiveParser.alterDatabaseSuffixProperties_return alterDatabaseSuffixProperties() throws RecognitionException {
        HiveParser.alterDatabaseSuffixProperties_return retval = new HiveParser.alterDatabaseSuffixProperties_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_SET187=null;
        Token KW_DBPROPERTIES188=null;
        HiveParser_IdentifiersParser.identifier_return name =null;

        HiveParser.dbProperties_return dbProperties189 =null;


        CommonTree KW_SET187_tree=null;
        CommonTree KW_DBPROPERTIES188_tree=null;
        RewriteRuleTokenStream stream_KW_DBPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_DBPROPERTIES");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleSubtreeStream stream_dbProperties=new RewriteRuleSubtreeStream(adaptor,"rule dbProperties");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("alter database properties statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:920:5: (name= identifier KW_SET KW_DBPROPERTIES dbProperties -> ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:920:7: name= identifier KW_SET KW_DBPROPERTIES dbProperties
            {
            pushFollow(FOLLOW_identifier_in_alterDatabaseSuffixProperties3831);
            name=identifier();

            state._fsp--;

            stream_identifier.add(name.getTree());

            KW_SET187=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterDatabaseSuffixProperties3833);  
            stream_KW_SET.add(KW_SET187);


            KW_DBPROPERTIES188=(Token)match(input,KW_DBPROPERTIES,FOLLOW_KW_DBPROPERTIES_in_alterDatabaseSuffixProperties3835);  
            stream_KW_DBPROPERTIES.add(KW_DBPROPERTIES188);


            pushFollow(FOLLOW_dbProperties_in_alterDatabaseSuffixProperties3837);
            dbProperties189=dbProperties();

            state._fsp--;

            stream_dbProperties.add(dbProperties189.getTree());

            // AST REWRITE
            // elements: dbProperties, name
            // token labels: 
            // rule labels: retval, name
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 921:5: -> ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:921:8: ^( TOK_ALTERDATABASE_PROPERTIES $name dbProperties )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_ALTERDATABASE_PROPERTIES, "TOK_ALTERDATABASE_PROPERTIES")
                , root_1);

                adaptor.addChild(root_1, stream_name.nextTree());

                adaptor.addChild(root_1, stream_dbProperties.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterDatabaseSuffixProperties"


    public static class alterStatementSuffixRename_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixRename"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:924:1: alterStatementSuffixRename : oldName= identifier KW_RENAME KW_TO newName= identifier -> ^( TOK_ALTERTABLE_RENAME $oldName $newName) ;
    public final HiveParser.alterStatementSuffixRename_return alterStatementSuffixRename() throws RecognitionException {
        HiveParser.alterStatementSuffixRename_return retval = new HiveParser.alterStatementSuffixRename_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_RENAME190=null;
        Token KW_TO191=null;
        HiveParser_IdentifiersParser.identifier_return oldName =null;

        HiveParser_IdentifiersParser.identifier_return newName =null;


        CommonTree KW_RENAME190_tree=null;
        CommonTree KW_TO191_tree=null;
        RewriteRuleTokenStream stream_KW_RENAME=new RewriteRuleTokenStream(adaptor,"token KW_RENAME");
        RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("rename statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:927:5: (oldName= identifier KW_RENAME KW_TO newName= identifier -> ^( TOK_ALTERTABLE_RENAME $oldName $newName) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:927:7: oldName= identifier KW_RENAME KW_TO newName= identifier
            {
            pushFollow(FOLLOW_identifier_in_alterStatementSuffixRename3881);
            oldName=identifier();

            state._fsp--;

            stream_identifier.add(oldName.getTree());

            KW_RENAME190=(Token)match(input,KW_RENAME,FOLLOW_KW_RENAME_in_alterStatementSuffixRename3883);  
            stream_KW_RENAME.add(KW_RENAME190);


            KW_TO191=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_alterStatementSuffixRename3885);  
            stream_KW_TO.add(KW_TO191);


            pushFollow(FOLLOW_identifier_in_alterStatementSuffixRename3889);
            newName=identifier();

            state._fsp--;

            stream_identifier.add(newName.getTree());

            // AST REWRITE
            // elements: oldName, newName
            // token labels: 
            // rule labels: retval, newName, oldName
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_newName=new RewriteRuleSubtreeStream(adaptor,"rule newName",newName!=null?newName.tree:null);
            RewriteRuleSubtreeStream stream_oldName=new RewriteRuleSubtreeStream(adaptor,"rule oldName",oldName!=null?oldName.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 928:5: -> ^( TOK_ALTERTABLE_RENAME $oldName $newName)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:928:8: ^( TOK_ALTERTABLE_RENAME $oldName $newName)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_ALTERTABLE_RENAME, "TOK_ALTERTABLE_RENAME")
                , root_1);

                adaptor.addChild(root_1, stream_oldName.nextTree());

                adaptor.addChild(root_1, stream_newName.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixRename"


    public static class alterStatementSuffixAddCol_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixAddCol"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:931:1: alterStatementSuffixAddCol : identifier (add= KW_ADD |replace= KW_REPLACE ) KW_COLUMNS LPAREN columnNameTypeList RPAREN -> {$add != null}? ^( TOK_ALTERTABLE_ADDCOLS identifier columnNameTypeList ) -> ^( TOK_ALTERTABLE_REPLACECOLS identifier columnNameTypeList ) ;
    public final HiveParser.alterStatementSuffixAddCol_return alterStatementSuffixAddCol() throws RecognitionException {
        HiveParser.alterStatementSuffixAddCol_return retval = new HiveParser.alterStatementSuffixAddCol_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token add=null;
        Token replace=null;
        Token KW_COLUMNS193=null;
        Token LPAREN194=null;
        Token RPAREN196=null;
        HiveParser_IdentifiersParser.identifier_return identifier192 =null;

        HiveParser.columnNameTypeList_return columnNameTypeList195 =null;


        CommonTree add_tree=null;
        CommonTree replace_tree=null;
        CommonTree KW_COLUMNS193_tree=null;
        CommonTree LPAREN194_tree=null;
        CommonTree RPAREN196_tree=null;
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_REPLACE=new RewriteRuleTokenStream(adaptor,"token KW_REPLACE");
        RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_KW_ADD=new RewriteRuleTokenStream(adaptor,"token KW_ADD");
        RewriteRuleSubtreeStream stream_columnNameTypeList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeList");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("add column statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:934:5: ( identifier (add= KW_ADD |replace= KW_REPLACE ) KW_COLUMNS LPAREN columnNameTypeList RPAREN -> {$add != null}? ^( TOK_ALTERTABLE_ADDCOLS identifier columnNameTypeList ) -> ^( TOK_ALTERTABLE_REPLACECOLS identifier columnNameTypeList ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:934:7: identifier (add= KW_ADD |replace= KW_REPLACE ) KW_COLUMNS LPAREN columnNameTypeList RPAREN
            {
            pushFollow(FOLLOW_identifier_in_alterStatementSuffixAddCol3932);
            identifier192=identifier();

            state._fsp--;

            stream_identifier.add(identifier192.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:934:18: (add= KW_ADD |replace= KW_REPLACE )
            int alt52=2;
            int LA52_0 = input.LA(1);

            if ( (LA52_0==KW_ADD) ) {
                alt52=1;
            }
            else if ( (LA52_0==KW_REPLACE) ) {
                alt52=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 52, 0, input);

                throw nvae;

            }
            switch (alt52) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:934:19: add= KW_ADD
                    {
                    add=(Token)match(input,KW_ADD,FOLLOW_KW_ADD_in_alterStatementSuffixAddCol3937);  
                    stream_KW_ADD.add(add);


                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:934:32: replace= KW_REPLACE
                    {
                    replace=(Token)match(input,KW_REPLACE,FOLLOW_KW_REPLACE_in_alterStatementSuffixAddCol3943);  
                    stream_KW_REPLACE.add(replace);


                    }
                    break;

            }


            KW_COLUMNS193=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_alterStatementSuffixAddCol3946);  
            stream_KW_COLUMNS.add(KW_COLUMNS193);


            LPAREN194=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_alterStatementSuffixAddCol3948);  
            stream_LPAREN.add(LPAREN194);


            pushFollow(FOLLOW_columnNameTypeList_in_alterStatementSuffixAddCol3950);
            columnNameTypeList195=columnNameTypeList();

            state._fsp--;

            stream_columnNameTypeList.add(columnNameTypeList195.getTree());

            RPAREN196=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_alterStatementSuffixAddCol3952);  
            stream_RPAREN.add(RPAREN196);


            // AST REWRITE
            // elements: identifier, columnNameTypeList, identifier, columnNameTypeList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 935:5: -> {$add != null}? ^( TOK_ALTERTABLE_ADDCOLS identifier columnNameTypeList )
            if (add != null) {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:935:24: ^( TOK_ALTERTABLE_ADDCOLS identifier columnNameTypeList )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_ALTERTABLE_ADDCOLS, "TOK_ALTERTABLE_ADDCOLS")
                , root_1);

                adaptor.addChild(root_1, stream_identifier.nextTree());

                adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 936:5: -> ^( TOK_ALTERTABLE_REPLACECOLS identifier columnNameTypeList )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:936:24: ^( TOK_ALTERTABLE_REPLACECOLS identifier columnNameTypeList )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_ALTERTABLE_REPLACECOLS, "TOK_ALTERTABLE_REPLACECOLS")
                , root_1);

                adaptor.addChild(root_1, stream_identifier.nextTree());

                adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixAddCol"


    public static class alterStatementSuffixRenameCol_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixRenameCol"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:939:1: alterStatementSuffixRenameCol : identifier KW_CHANGE ( KW_COLUMN )? oldName= identifier newName= identifier colType ( KW_COMMENT comment= StringLiteral )? ( alterStatementChangeColPosition )? -> ^( TOK_ALTERTABLE_RENAMECOL identifier $oldName $newName colType ( $comment)? ( alterStatementChangeColPosition )? ) ;
    public final HiveParser.alterStatementSuffixRenameCol_return alterStatementSuffixRenameCol() throws RecognitionException {
        HiveParser.alterStatementSuffixRenameCol_return retval = new HiveParser.alterStatementSuffixRenameCol_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token comment=null;
        Token KW_CHANGE198=null;
        Token KW_COLUMN199=null;
        Token KW_COMMENT201=null;
        HiveParser_IdentifiersParser.identifier_return oldName =null;

        HiveParser_IdentifiersParser.identifier_return newName =null;

        HiveParser_IdentifiersParser.identifier_return identifier197 =null;

        HiveParser.colType_return colType200 =null;

        HiveParser.alterStatementChangeColPosition_return alterStatementChangeColPosition202 =null;


        CommonTree comment_tree=null;
        CommonTree KW_CHANGE198_tree=null;
        CommonTree KW_COLUMN199_tree=null;
        CommonTree KW_COMMENT201_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
        RewriteRuleTokenStream stream_KW_COLUMN=new RewriteRuleTokenStream(adaptor,"token KW_COLUMN");
        RewriteRuleTokenStream stream_KW_CHANGE=new RewriteRuleTokenStream(adaptor,"token KW_CHANGE");
        RewriteRuleSubtreeStream stream_alterStatementChangeColPosition=new RewriteRuleSubtreeStream(adaptor,"rule alterStatementChangeColPosition");
        RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("rename column name"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:942:5: ( identifier KW_CHANGE ( KW_COLUMN )? oldName= identifier newName= identifier colType ( KW_COMMENT comment= StringLiteral )? ( alterStatementChangeColPosition )? -> ^( TOK_ALTERTABLE_RENAMECOL identifier $oldName $newName colType ( $comment)? ( alterStatementChangeColPosition )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:942:7: identifier KW_CHANGE ( KW_COLUMN )? oldName= identifier newName= identifier colType ( KW_COMMENT comment= StringLiteral )? ( alterStatementChangeColPosition )?
            {
            pushFollow(FOLLOW_identifier_in_alterStatementSuffixRenameCol4025);
            identifier197=identifier();

            state._fsp--;

            stream_identifier.add(identifier197.getTree());

            KW_CHANGE198=(Token)match(input,KW_CHANGE,FOLLOW_KW_CHANGE_in_alterStatementSuffixRenameCol4027);  
            stream_KW_CHANGE.add(KW_CHANGE198);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:942:28: ( KW_COLUMN )?
            int alt53=2;
            int LA53_0 = input.LA(1);

            if ( (LA53_0==KW_COLUMN) ) {
                alt53=1;
            }
            switch (alt53) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:942:28: KW_COLUMN
                    {
                    KW_COLUMN199=(Token)match(input,KW_COLUMN,FOLLOW_KW_COLUMN_in_alterStatementSuffixRenameCol4029);  
                    stream_KW_COLUMN.add(KW_COLUMN199);


                    }
                    break;

            }


            pushFollow(FOLLOW_identifier_in_alterStatementSuffixRenameCol4034);
            oldName=identifier();

            state._fsp--;

            stream_identifier.add(oldName.getTree());

            pushFollow(FOLLOW_identifier_in_alterStatementSuffixRenameCol4038);
            newName=identifier();

            state._fsp--;

            stream_identifier.add(newName.getTree());

            pushFollow(FOLLOW_colType_in_alterStatementSuffixRenameCol4040);
            colType200=colType();

            state._fsp--;

            stream_colType.add(colType200.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:942:85: ( KW_COMMENT comment= StringLiteral )?
            int alt54=2;
            int LA54_0 = input.LA(1);

            if ( (LA54_0==KW_COMMENT) ) {
                alt54=1;
            }
            switch (alt54) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:942:86: KW_COMMENT comment= StringLiteral
                    {
                    KW_COMMENT201=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_alterStatementSuffixRenameCol4043);  
                    stream_KW_COMMENT.add(KW_COMMENT201);


                    comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixRenameCol4047);  
                    stream_StringLiteral.add(comment);


                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:942:121: ( alterStatementChangeColPosition )?
            int alt55=2;
            int LA55_0 = input.LA(1);

            if ( (LA55_0==KW_AFTER||LA55_0==KW_FIRST) ) {
                alt55=1;
            }
            switch (alt55) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:942:121: alterStatementChangeColPosition
                    {
                    pushFollow(FOLLOW_alterStatementChangeColPosition_in_alterStatementSuffixRenameCol4051);
                    alterStatementChangeColPosition202=alterStatementChangeColPosition();

                    state._fsp--;

                    stream_alterStatementChangeColPosition.add(alterStatementChangeColPosition202.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: colType, newName, alterStatementChangeColPosition, identifier, comment, oldName
            // token labels: comment
            // rule labels: retval, newName, oldName
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_newName=new RewriteRuleSubtreeStream(adaptor,"rule newName",newName!=null?newName.tree:null);
            RewriteRuleSubtreeStream stream_oldName=new RewriteRuleSubtreeStream(adaptor,"rule oldName",oldName!=null?oldName.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 943:5: -> ^( TOK_ALTERTABLE_RENAMECOL identifier $oldName $newName colType ( $comment)? ( alterStatementChangeColPosition )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:943:7: ^( TOK_ALTERTABLE_RENAMECOL identifier $oldName $newName colType ( $comment)? ( alterStatementChangeColPosition )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_ALTERTABLE_RENAMECOL, "TOK_ALTERTABLE_RENAMECOL")
                , root_1);

                adaptor.addChild(root_1, stream_identifier.nextTree());

                adaptor.addChild(root_1, stream_oldName.nextTree());

                adaptor.addChild(root_1, stream_newName.nextTree());

                adaptor.addChild(root_1, stream_colType.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:943:72: ( $comment)?
                if ( stream_comment.hasNext() ) {
                    adaptor.addChild(root_1, stream_comment.nextNode());

                }
                stream_comment.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:943:81: ( alterStatementChangeColPosition )?
                if ( stream_alterStatementChangeColPosition.hasNext() ) {
                    adaptor.addChild(root_1, stream_alterStatementChangeColPosition.nextTree());

                }
                stream_alterStatementChangeColPosition.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixRenameCol"


    public static class alterStatementChangeColPosition_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementChangeColPosition"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:946:1: alterStatementChangeColPosition : (first= KW_FIRST | KW_AFTER afterCol= identifier -> {$first != null}? ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION ) -> ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol) );
    public final HiveParser.alterStatementChangeColPosition_return alterStatementChangeColPosition() throws RecognitionException {
        HiveParser.alterStatementChangeColPosition_return retval = new HiveParser.alterStatementChangeColPosition_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token first=null;
        Token KW_AFTER203=null;
        HiveParser_IdentifiersParser.identifier_return afterCol =null;


        CommonTree first_tree=null;
        CommonTree KW_AFTER203_tree=null;
        RewriteRuleTokenStream stream_KW_AFTER=new RewriteRuleTokenStream(adaptor,"token KW_AFTER");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:947:5: (first= KW_FIRST | KW_AFTER afterCol= identifier -> {$first != null}? ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION ) -> ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol) )
            int alt56=2;
            int LA56_0 = input.LA(1);

            if ( (LA56_0==KW_FIRST) ) {
                alt56=1;
            }
            else if ( (LA56_0==KW_AFTER) ) {
                alt56=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 56, 0, input);

                throw nvae;

            }
            switch (alt56) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:947:7: first= KW_FIRST
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    first=(Token)match(input,KW_FIRST,FOLLOW_KW_FIRST_in_alterStatementChangeColPosition4097); 
                    first_tree = 
                    (CommonTree)adaptor.create(first)
                    ;
                    adaptor.addChild(root_0, first_tree);


                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:947:22: KW_AFTER afterCol= identifier
                    {
                    KW_AFTER203=(Token)match(input,KW_AFTER,FOLLOW_KW_AFTER_in_alterStatementChangeColPosition4099);  
                    stream_KW_AFTER.add(KW_AFTER203);


                    pushFollow(FOLLOW_identifier_in_alterStatementChangeColPosition4103);
                    afterCol=identifier();

                    state._fsp--;

                    stream_identifier.add(afterCol.getTree());

                    // AST REWRITE
                    // elements: afterCol
                    // token labels: 
                    // rule labels: retval, afterCol
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_afterCol=new RewriteRuleSubtreeStream(adaptor,"rule afterCol",afterCol!=null?afterCol.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 948:5: -> {$first != null}? ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION )
                    if (first != null) {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:948:25: ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION, "TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }

                    else // 949:5: -> ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol)
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:949:8: ^( TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION $afterCol)
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION, "TOK_ALTERTABLE_CHANGECOL_AFTER_POSITION")
                        , root_1);

                        adaptor.addChild(root_1, stream_afterCol.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementChangeColPosition"


    public static class alterStatementSuffixAddPartitions_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixAddPartitions"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:952:1: alterStatementSuffixAddPartitions : identifier KW_ADD ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ -> ^( TOK_ALTERTABLE_ADDPARTS identifier ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) ;
    public final HiveParser.alterStatementSuffixAddPartitions_return alterStatementSuffixAddPartitions() throws RecognitionException {
        HiveParser.alterStatementSuffixAddPartitions_return retval = new HiveParser.alterStatementSuffixAddPartitions_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_ADD205=null;
        HiveParser_IdentifiersParser.identifier_return identifier204 =null;

        HiveParser.ifNotExists_return ifNotExists206 =null;

        HiveParser.alterStatementSuffixAddPartitionsElement_return alterStatementSuffixAddPartitionsElement207 =null;


        CommonTree KW_ADD205_tree=null;
        RewriteRuleTokenStream stream_KW_ADD=new RewriteRuleTokenStream(adaptor,"token KW_ADD");
        RewriteRuleSubtreeStream stream_alterStatementSuffixAddPartitionsElement=new RewriteRuleSubtreeStream(adaptor,"rule alterStatementSuffixAddPartitionsElement");
        RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("add partition statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:955:5: ( identifier KW_ADD ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ -> ^( TOK_ALTERTABLE_ADDPARTS identifier ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:955:7: identifier KW_ADD ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+
            {
            pushFollow(FOLLOW_identifier_in_alterStatementSuffixAddPartitions4155);
            identifier204=identifier();

            state._fsp--;

            stream_identifier.add(identifier204.getTree());

            KW_ADD205=(Token)match(input,KW_ADD,FOLLOW_KW_ADD_in_alterStatementSuffixAddPartitions4157);  
            stream_KW_ADD.add(KW_ADD205);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:955:25: ( ifNotExists )?
            int alt57=2;
            int LA57_0 = input.LA(1);

            if ( (LA57_0==KW_IF) ) {
                alt57=1;
            }
            switch (alt57) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:955:25: ifNotExists
                    {
                    pushFollow(FOLLOW_ifNotExists_in_alterStatementSuffixAddPartitions4159);
                    ifNotExists206=ifNotExists();

                    state._fsp--;

                    stream_ifNotExists.add(ifNotExists206.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:955:38: ( alterStatementSuffixAddPartitionsElement )+
            int cnt58=0;
            loop58:
            do {
                int alt58=2;
                int LA58_0 = input.LA(1);

                if ( (LA58_0==KW_PARTITION) ) {
                    alt58=1;
                }


                switch (alt58) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:955:38: alterStatementSuffixAddPartitionsElement
            	    {
            	    pushFollow(FOLLOW_alterStatementSuffixAddPartitionsElement_in_alterStatementSuffixAddPartitions4162);
            	    alterStatementSuffixAddPartitionsElement207=alterStatementSuffixAddPartitionsElement();

            	    state._fsp--;

            	    stream_alterStatementSuffixAddPartitionsElement.add(alterStatementSuffixAddPartitionsElement207.getTree());

            	    }
            	    break;

            	default :
            	    if ( cnt58 >= 1 ) break loop58;
                        EarlyExitException eee =
                            new EarlyExitException(58, input);
                        throw eee;
                }
                cnt58++;
            } while (true);


            // AST REWRITE
            // elements: alterStatementSuffixAddPartitionsElement, ifNotExists, identifier
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 956:5: -> ^( TOK_ALTERTABLE_ADDPARTS identifier ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:956:8: ^( TOK_ALTERTABLE_ADDPARTS identifier ( ifNotExists )? ( alterStatementSuffixAddPartitionsElement )+ )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_ALTERTABLE_ADDPARTS, "TOK_ALTERTABLE_ADDPARTS")
                , root_1);

                adaptor.addChild(root_1, stream_identifier.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:956:45: ( ifNotExists )?
                if ( stream_ifNotExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifNotExists.nextTree());

                }
                stream_ifNotExists.reset();

                if ( !(stream_alterStatementSuffixAddPartitionsElement.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_alterStatementSuffixAddPartitionsElement.hasNext() ) {
                    adaptor.addChild(root_1, stream_alterStatementSuffixAddPartitionsElement.nextTree());

                }
                stream_alterStatementSuffixAddPartitionsElement.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixAddPartitions"


    public static class alterStatementSuffixAddPartitionsElement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixAddPartitionsElement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:959:1: alterStatementSuffixAddPartitionsElement : partitionSpec ( partitionLocation )? ;
    public final HiveParser.alterStatementSuffixAddPartitionsElement_return alterStatementSuffixAddPartitionsElement() throws RecognitionException {
        HiveParser.alterStatementSuffixAddPartitionsElement_return retval = new HiveParser.alterStatementSuffixAddPartitionsElement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec208 =null;

        HiveParser.partitionLocation_return partitionLocation209 =null;



        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:960:5: ( partitionSpec ( partitionLocation )? )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:960:7: partitionSpec ( partitionLocation )?
            {
            root_0 = (CommonTree)adaptor.nil();


            pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixAddPartitionsElement4198);
            partitionSpec208=partitionSpec();

            state._fsp--;

            adaptor.addChild(root_0, partitionSpec208.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:960:21: ( partitionLocation )?
            int alt59=2;
            int LA59_0 = input.LA(1);

            if ( (LA59_0==KW_LOCATION) ) {
                alt59=1;
            }
            switch (alt59) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:960:21: partitionLocation
                    {
                    pushFollow(FOLLOW_partitionLocation_in_alterStatementSuffixAddPartitionsElement4200);
                    partitionLocation209=partitionLocation();

                    state._fsp--;

                    adaptor.addChild(root_0, partitionLocation209.getTree());

                    }
                    break;

            }


            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixAddPartitionsElement"


    public static class alterStatementSuffixTouch_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixTouch"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:963:1: alterStatementSuffixTouch : identifier KW_TOUCH ( partitionSpec )* -> ^( TOK_ALTERTABLE_TOUCH identifier ( partitionSpec )* ) ;
    public final HiveParser.alterStatementSuffixTouch_return alterStatementSuffixTouch() throws RecognitionException {
        HiveParser.alterStatementSuffixTouch_return retval = new HiveParser.alterStatementSuffixTouch_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_TOUCH211=null;
        HiveParser_IdentifiersParser.identifier_return identifier210 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec212 =null;


        CommonTree KW_TOUCH211_tree=null;
        RewriteRuleTokenStream stream_KW_TOUCH=new RewriteRuleTokenStream(adaptor,"token KW_TOUCH");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("touch statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:966:5: ( identifier KW_TOUCH ( partitionSpec )* -> ^( TOK_ALTERTABLE_TOUCH identifier ( partitionSpec )* ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:966:7: identifier KW_TOUCH ( partitionSpec )*
            {
            pushFollow(FOLLOW_identifier_in_alterStatementSuffixTouch4228);
            identifier210=identifier();

            state._fsp--;

            stream_identifier.add(identifier210.getTree());

            KW_TOUCH211=(Token)match(input,KW_TOUCH,FOLLOW_KW_TOUCH_in_alterStatementSuffixTouch4230);  
            stream_KW_TOUCH.add(KW_TOUCH211);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:966:27: ( partitionSpec )*
            loop60:
            do {
                int alt60=2;
                int LA60_0 = input.LA(1);

                if ( (LA60_0==KW_PARTITION) ) {
                    alt60=1;
                }


                switch (alt60) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:966:28: partitionSpec
            	    {
            	    pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixTouch4233);
            	    partitionSpec212=partitionSpec();

            	    state._fsp--;

            	    stream_partitionSpec.add(partitionSpec212.getTree());

            	    }
            	    break;

            	default :
            	    break loop60;
                }
            } while (true);


            // AST REWRITE
            // elements: partitionSpec, identifier
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 967:5: -> ^( TOK_ALTERTABLE_TOUCH identifier ( partitionSpec )* )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:967:8: ^( TOK_ALTERTABLE_TOUCH identifier ( partitionSpec )* )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_ALTERTABLE_TOUCH, "TOK_ALTERTABLE_TOUCH")
                , root_1);

                adaptor.addChild(root_1, stream_identifier.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:967:42: ( partitionSpec )*
                while ( stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                }
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixTouch"


    public static class alterStatementSuffixArchive_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixArchive"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:970:1: alterStatementSuffixArchive : identifier KW_ARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_ARCHIVE identifier ( partitionSpec )* ) ;
    public final HiveParser.alterStatementSuffixArchive_return alterStatementSuffixArchive() throws RecognitionException {
        HiveParser.alterStatementSuffixArchive_return retval = new HiveParser.alterStatementSuffixArchive_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_ARCHIVE214=null;
        HiveParser_IdentifiersParser.identifier_return identifier213 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec215 =null;


        CommonTree KW_ARCHIVE214_tree=null;
        RewriteRuleTokenStream stream_KW_ARCHIVE=new RewriteRuleTokenStream(adaptor,"token KW_ARCHIVE");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("archive statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:973:5: ( identifier KW_ARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_ARCHIVE identifier ( partitionSpec )* ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:973:7: identifier KW_ARCHIVE ( partitionSpec )*
            {
            pushFollow(FOLLOW_identifier_in_alterStatementSuffixArchive4279);
            identifier213=identifier();

            state._fsp--;

            stream_identifier.add(identifier213.getTree());

            KW_ARCHIVE214=(Token)match(input,KW_ARCHIVE,FOLLOW_KW_ARCHIVE_in_alterStatementSuffixArchive4281);  
            stream_KW_ARCHIVE.add(KW_ARCHIVE214);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:973:29: ( partitionSpec )*
            loop61:
            do {
                int alt61=2;
                int LA61_0 = input.LA(1);

                if ( (LA61_0==KW_PARTITION) ) {
                    alt61=1;
                }


                switch (alt61) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:973:30: partitionSpec
            	    {
            	    pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixArchive4284);
            	    partitionSpec215=partitionSpec();

            	    state._fsp--;

            	    stream_partitionSpec.add(partitionSpec215.getTree());

            	    }
            	    break;

            	default :
            	    break loop61;
                }
            } while (true);


            // AST REWRITE
            // elements: partitionSpec, identifier
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 974:5: -> ^( TOK_ALTERTABLE_ARCHIVE identifier ( partitionSpec )* )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:974:8: ^( TOK_ALTERTABLE_ARCHIVE identifier ( partitionSpec )* )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_ALTERTABLE_ARCHIVE, "TOK_ALTERTABLE_ARCHIVE")
                , root_1);

                adaptor.addChild(root_1, stream_identifier.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:974:44: ( partitionSpec )*
                while ( stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                }
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixArchive"


    public static class alterStatementSuffixUnArchive_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixUnArchive"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:977:1: alterStatementSuffixUnArchive : identifier KW_UNARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_UNARCHIVE identifier ( partitionSpec )* ) ;
    public final HiveParser.alterStatementSuffixUnArchive_return alterStatementSuffixUnArchive() throws RecognitionException {
        HiveParser.alterStatementSuffixUnArchive_return retval = new HiveParser.alterStatementSuffixUnArchive_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_UNARCHIVE217=null;
        HiveParser_IdentifiersParser.identifier_return identifier216 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec218 =null;


        CommonTree KW_UNARCHIVE217_tree=null;
        RewriteRuleTokenStream stream_KW_UNARCHIVE=new RewriteRuleTokenStream(adaptor,"token KW_UNARCHIVE");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("unarchive statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:980:5: ( identifier KW_UNARCHIVE ( partitionSpec )* -> ^( TOK_ALTERTABLE_UNARCHIVE identifier ( partitionSpec )* ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:980:7: identifier KW_UNARCHIVE ( partitionSpec )*
            {
            pushFollow(FOLLOW_identifier_in_alterStatementSuffixUnArchive4330);
            identifier216=identifier();

            state._fsp--;

            stream_identifier.add(identifier216.getTree());

            KW_UNARCHIVE217=(Token)match(input,KW_UNARCHIVE,FOLLOW_KW_UNARCHIVE_in_alterStatementSuffixUnArchive4332);  
            stream_KW_UNARCHIVE.add(KW_UNARCHIVE217);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:980:31: ( partitionSpec )*
            loop62:
            do {
                int alt62=2;
                int LA62_0 = input.LA(1);

                if ( (LA62_0==KW_PARTITION) ) {
                    alt62=1;
                }


                switch (alt62) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:980:32: partitionSpec
            	    {
            	    pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixUnArchive4335);
            	    partitionSpec218=partitionSpec();

            	    state._fsp--;

            	    stream_partitionSpec.add(partitionSpec218.getTree());

            	    }
            	    break;

            	default :
            	    break loop62;
                }
            } while (true);


            // AST REWRITE
            // elements: partitionSpec, identifier
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 981:5: -> ^( TOK_ALTERTABLE_UNARCHIVE identifier ( partitionSpec )* )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:981:8: ^( TOK_ALTERTABLE_UNARCHIVE identifier ( partitionSpec )* )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_ALTERTABLE_UNARCHIVE, "TOK_ALTERTABLE_UNARCHIVE")
                , root_1);

                adaptor.addChild(root_1, stream_identifier.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:981:46: ( partitionSpec )*
                while ( stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                }
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixUnArchive"


    public static class partitionLocation_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "partitionLocation"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:984:1: partitionLocation : KW_LOCATION locn= StringLiteral -> ^( TOK_PARTITIONLOCATION $locn) ;
    public final HiveParser.partitionLocation_return partitionLocation() throws RecognitionException {
        HiveParser.partitionLocation_return retval = new HiveParser.partitionLocation_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token locn=null;
        Token KW_LOCATION219=null;

        CommonTree locn_tree=null;
        CommonTree KW_LOCATION219_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");

         msgs.push("partition location"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:987:5: ( KW_LOCATION locn= StringLiteral -> ^( TOK_PARTITIONLOCATION $locn) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:988:7: KW_LOCATION locn= StringLiteral
            {
            KW_LOCATION219=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_partitionLocation4387);  
            stream_KW_LOCATION.add(KW_LOCATION219);


            locn=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_partitionLocation4391);  
            stream_StringLiteral.add(locn);


            // AST REWRITE
            // elements: locn
            // token labels: locn
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_locn=new RewriteRuleTokenStream(adaptor,"token locn",locn);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 988:38: -> ^( TOK_PARTITIONLOCATION $locn)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:988:41: ^( TOK_PARTITIONLOCATION $locn)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_PARTITIONLOCATION, "TOK_PARTITIONLOCATION")
                , root_1);

                adaptor.addChild(root_1, stream_locn.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "partitionLocation"


    public static class alterStatementSuffixDropPartitions_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixDropPartitions"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:991:1: alterStatementSuffixDropPartitions : identifier KW_DROP ( ifExists )? dropPartitionSpec ( COMMA dropPartitionSpec )* ( ignoreProtection )? -> ^( TOK_ALTERTABLE_DROPPARTS identifier ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? ) ;
    public final HiveParser.alterStatementSuffixDropPartitions_return alterStatementSuffixDropPartitions() throws RecognitionException {
        HiveParser.alterStatementSuffixDropPartitions_return retval = new HiveParser.alterStatementSuffixDropPartitions_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_DROP221=null;
        Token COMMA224=null;
        HiveParser_IdentifiersParser.identifier_return identifier220 =null;

        HiveParser.ifExists_return ifExists222 =null;

        HiveParser_IdentifiersParser.dropPartitionSpec_return dropPartitionSpec223 =null;

        HiveParser_IdentifiersParser.dropPartitionSpec_return dropPartitionSpec225 =null;

        HiveParser.ignoreProtection_return ignoreProtection226 =null;


        CommonTree KW_DROP221_tree=null;
        CommonTree COMMA224_tree=null;
        RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_dropPartitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule dropPartitionSpec");
        RewriteRuleSubtreeStream stream_ignoreProtection=new RewriteRuleSubtreeStream(adaptor,"rule ignoreProtection");
        RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("drop partition statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:994:5: ( identifier KW_DROP ( ifExists )? dropPartitionSpec ( COMMA dropPartitionSpec )* ( ignoreProtection )? -> ^( TOK_ALTERTABLE_DROPPARTS identifier ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:994:7: identifier KW_DROP ( ifExists )? dropPartitionSpec ( COMMA dropPartitionSpec )* ( ignoreProtection )?
            {
            pushFollow(FOLLOW_identifier_in_alterStatementSuffixDropPartitions4427);
            identifier220=identifier();

            state._fsp--;

            stream_identifier.add(identifier220.getTree());

            KW_DROP221=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_alterStatementSuffixDropPartitions4429);  
            stream_KW_DROP.add(KW_DROP221);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:994:26: ( ifExists )?
            int alt63=2;
            int LA63_0 = input.LA(1);

            if ( (LA63_0==KW_IF) ) {
                alt63=1;
            }
            switch (alt63) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:994:26: ifExists
                    {
                    pushFollow(FOLLOW_ifExists_in_alterStatementSuffixDropPartitions4431);
                    ifExists222=ifExists();

                    state._fsp--;

                    stream_ifExists.add(ifExists222.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions4434);
            dropPartitionSpec223=dropPartitionSpec();

            state._fsp--;

            stream_dropPartitionSpec.add(dropPartitionSpec223.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:994:54: ( COMMA dropPartitionSpec )*
            loop64:
            do {
                int alt64=2;
                int LA64_0 = input.LA(1);

                if ( (LA64_0==COMMA) ) {
                    alt64=1;
                }


                switch (alt64) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:994:55: COMMA dropPartitionSpec
            	    {
            	    COMMA224=(Token)match(input,COMMA,FOLLOW_COMMA_in_alterStatementSuffixDropPartitions4437);  
            	    stream_COMMA.add(COMMA224);


            	    pushFollow(FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions4439);
            	    dropPartitionSpec225=dropPartitionSpec();

            	    state._fsp--;

            	    stream_dropPartitionSpec.add(dropPartitionSpec225.getTree());

            	    }
            	    break;

            	default :
            	    break loop64;
                }
            } while (true);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:994:81: ( ignoreProtection )?
            int alt65=2;
            int LA65_0 = input.LA(1);

            if ( (LA65_0==KW_IGNORE) ) {
                alt65=1;
            }
            switch (alt65) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:994:81: ignoreProtection
                    {
                    pushFollow(FOLLOW_ignoreProtection_in_alterStatementSuffixDropPartitions4443);
                    ignoreProtection226=ignoreProtection();

                    state._fsp--;

                    stream_ignoreProtection.add(ignoreProtection226.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: dropPartitionSpec, identifier, ignoreProtection, ifExists
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 995:5: -> ^( TOK_ALTERTABLE_DROPPARTS identifier ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:995:8: ^( TOK_ALTERTABLE_DROPPARTS identifier ( dropPartitionSpec )+ ( ifExists )? ( ignoreProtection )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_ALTERTABLE_DROPPARTS, "TOK_ALTERTABLE_DROPPARTS")
                , root_1);

                adaptor.addChild(root_1, stream_identifier.nextTree());

                if ( !(stream_dropPartitionSpec.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_dropPartitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_dropPartitionSpec.nextTree());

                }
                stream_dropPartitionSpec.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:995:65: ( ifExists )?
                if ( stream_ifExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifExists.nextTree());

                }
                stream_ifExists.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:995:75: ( ignoreProtection )?
                if ( stream_ignoreProtection.hasNext() ) {
                    adaptor.addChild(root_1, stream_ignoreProtection.nextTree());

                }
                stream_ignoreProtection.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixDropPartitions"


    public static class alterStatementSuffixProperties_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixProperties"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:998:1: alterStatementSuffixProperties : (name= identifier KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_PROPERTIES $name tableProperties ) |name= identifier KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_DROPTABLE_PROPERTIES $name tableProperties ( ifExists )? ) );
    public final HiveParser.alterStatementSuffixProperties_return alterStatementSuffixProperties() throws RecognitionException {
        HiveParser.alterStatementSuffixProperties_return retval = new HiveParser.alterStatementSuffixProperties_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_SET227=null;
        Token KW_TBLPROPERTIES228=null;
        Token KW_UNSET230=null;
        Token KW_TBLPROPERTIES231=null;
        HiveParser_IdentifiersParser.identifier_return name =null;

        HiveParser.tableProperties_return tableProperties229 =null;

        HiveParser.ifExists_return ifExists232 =null;

        HiveParser.tableProperties_return tableProperties233 =null;


        CommonTree KW_SET227_tree=null;
        CommonTree KW_TBLPROPERTIES228_tree=null;
        CommonTree KW_UNSET230_tree=null;
        CommonTree KW_TBLPROPERTIES231_tree=null;
        RewriteRuleTokenStream stream_KW_UNSET=new RewriteRuleTokenStream(adaptor,"token KW_UNSET");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleTokenStream stream_KW_TBLPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_TBLPROPERTIES");
        RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");
        RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("alter properties statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1001:5: (name= identifier KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_PROPERTIES $name tableProperties ) |name= identifier KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_DROPTABLE_PROPERTIES $name tableProperties ( ifExists )? ) )
            int alt67=2;
            int LA67_0 = input.LA(1);

            if ( (LA67_0==Identifier) ) {
                int LA67_1 = input.LA(2);

                if ( (LA67_1==KW_SET) ) {
                    alt67=1;
                }
                else if ( (LA67_1==KW_UNSET) ) {
                    alt67=2;
                }
                else {
                    NoViableAltException nvae =
                        new NoViableAltException("", 67, 1, input);

                    throw nvae;

                }
            }
            else if ( ((LA67_0 >= KW_ADD && LA67_0 <= KW_AFTER)||(LA67_0 >= KW_ALTER && LA67_0 <= KW_ANALYZE)||(LA67_0 >= KW_ARCHIVE && LA67_0 <= KW_CASCADE)||(LA67_0 >= KW_CHANGE && LA67_0 <= KW_COLLECTION)||(LA67_0 >= KW_COLUMNS && LA67_0 <= KW_CREATE)||LA67_0==KW_CUBE||(LA67_0 >= KW_CURSOR && LA67_0 <= KW_DATA)||(LA67_0 >= KW_DATABASES && LA67_0 <= KW_DISABLE)||(LA67_0 >= KW_DISTRIBUTE && LA67_0 <= KW_ELEM_TYPE)||LA67_0==KW_ENABLE||LA67_0==KW_ESCAPED||(LA67_0 >= KW_EXCLUSIVE && LA67_0 <= KW_EXPORT)||(LA67_0 >= KW_EXTERNAL && LA67_0 <= KW_FLOAT)||(LA67_0 >= KW_FOR && LA67_0 <= KW_FORMATTED)||LA67_0==KW_FULL||(LA67_0 >= KW_FUNCTIONS && LA67_0 <= KW_GROUPING)||(LA67_0 >= KW_HOLD_DDLTIME && LA67_0 <= KW_IDXPROPERTIES)||(LA67_0 >= KW_IGNORE && LA67_0 <= KW_ITEMS)||(LA67_0 >= KW_KEYS && LA67_0 <= KW_LEFT)||(LA67_0 >= KW_LIKE && LA67_0 <= KW_LONG)||(LA67_0 >= KW_MAPJOIN && LA67_0 <= KW_MINUS)||(LA67_0 >= KW_MSCK && LA67_0 <= KW_NOSCAN)||(LA67_0 >= KW_NO_DROP && LA67_0 <= KW_OFFLINE)||LA67_0==KW_OPTION||(LA67_0 >= KW_ORCFILE && LA67_0 <= KW_OUTPUTFORMAT)||LA67_0==KW_OVERWRITE||(LA67_0 >= KW_PARTITION && LA67_0 <= KW_PLUS)||(LA67_0 >= KW_PRETTY && LA67_0 <= KW_RECORDWRITER)||(LA67_0 >= KW_REGEXP && LA67_0 <= KW_SCHEMAS)||(LA67_0 >= KW_SEMI && LA67_0 <= KW_TABLES)||(LA67_0 >= KW_TBLPROPERTIES && LA67_0 <= KW_TEXTFILE)||(LA67_0 >= KW_TIMESTAMP && LA67_0 <= KW_TOUCH)||(LA67_0 >= KW_TRIGGER && LA67_0 <= KW_UNARCHIVE)||(LA67_0 >= KW_UNDO && LA67_0 <= KW_UNIONTYPE)||(LA67_0 >= KW_UNLOCK && LA67_0 <= KW_VALUE_TYPE)||LA67_0==KW_VIEW||LA67_0==KW_WHILE||LA67_0==KW_WITH) ) {
                int LA67_2 = input.LA(2);

                if ( (LA67_2==KW_SET) ) {
                    alt67=1;
                }
                else if ( (LA67_2==KW_UNSET) ) {
                    alt67=2;
                }
                else {
                    NoViableAltException nvae =
                        new NoViableAltException("", 67, 2, input);

                    throw nvae;

                }
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 67, 0, input);

                throw nvae;

            }
            switch (alt67) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1001:7: name= identifier KW_SET KW_TBLPROPERTIES tableProperties
                    {
                    pushFollow(FOLLOW_identifier_in_alterStatementSuffixProperties4494);
                    name=identifier();

                    state._fsp--;

                    stream_identifier.add(name.getTree());

                    KW_SET227=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixProperties4496);  
                    stream_KW_SET.add(KW_SET227);


                    KW_TBLPROPERTIES228=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties4498);  
                    stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES228);


                    pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixProperties4500);
                    tableProperties229=tableProperties();

                    state._fsp--;

                    stream_tableProperties.add(tableProperties229.getTree());

                    // AST REWRITE
                    // elements: tableProperties, name
                    // token labels: 
                    // rule labels: retval, name
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1002:5: -> ^( TOK_ALTERTABLE_PROPERTIES $name tableProperties )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1002:8: ^( TOK_ALTERTABLE_PROPERTIES $name tableProperties )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERTABLE_PROPERTIES, "TOK_ALTERTABLE_PROPERTIES")
                        , root_1);

                        adaptor.addChild(root_1, stream_name.nextTree());

                        adaptor.addChild(root_1, stream_tableProperties.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1003:7: name= identifier KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties
                    {
                    pushFollow(FOLLOW_identifier_in_alterStatementSuffixProperties4525);
                    name=identifier();

                    state._fsp--;

                    stream_identifier.add(name.getTree());

                    KW_UNSET230=(Token)match(input,KW_UNSET,FOLLOW_KW_UNSET_in_alterStatementSuffixProperties4527);  
                    stream_KW_UNSET.add(KW_UNSET230);


                    KW_TBLPROPERTIES231=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties4529);  
                    stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES231);


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1003:49: ( ifExists )?
                    int alt66=2;
                    int LA66_0 = input.LA(1);

                    if ( (LA66_0==KW_IF) ) {
                        alt66=1;
                    }
                    switch (alt66) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1003:49: ifExists
                            {
                            pushFollow(FOLLOW_ifExists_in_alterStatementSuffixProperties4531);
                            ifExists232=ifExists();

                            state._fsp--;

                            stream_ifExists.add(ifExists232.getTree());

                            }
                            break;

                    }


                    pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixProperties4534);
                    tableProperties233=tableProperties();

                    state._fsp--;

                    stream_tableProperties.add(tableProperties233.getTree());

                    // AST REWRITE
                    // elements: name, tableProperties, ifExists
                    // token labels: 
                    // rule labels: retval, name
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1004:5: -> ^( TOK_DROPTABLE_PROPERTIES $name tableProperties ( ifExists )? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1004:8: ^( TOK_DROPTABLE_PROPERTIES $name tableProperties ( ifExists )? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_DROPTABLE_PROPERTIES, "TOK_DROPTABLE_PROPERTIES")
                        , root_1);

                        adaptor.addChild(root_1, stream_name.nextTree());

                        adaptor.addChild(root_1, stream_tableProperties.nextTree());

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1004:57: ( ifExists )?
                        if ( stream_ifExists.hasNext() ) {
                            adaptor.addChild(root_1, stream_ifExists.nextTree());

                        }
                        stream_ifExists.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixProperties"


    public static class alterViewSuffixProperties_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterViewSuffixProperties"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1007:1: alterViewSuffixProperties : (name= identifier KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERVIEW_PROPERTIES $name tableProperties ) |name= identifier KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_DROPVIEW_PROPERTIES $name tableProperties ( ifExists )? ) );
    public final HiveParser.alterViewSuffixProperties_return alterViewSuffixProperties() throws RecognitionException {
        HiveParser.alterViewSuffixProperties_return retval = new HiveParser.alterViewSuffixProperties_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_SET234=null;
        Token KW_TBLPROPERTIES235=null;
        Token KW_UNSET237=null;
        Token KW_TBLPROPERTIES238=null;
        HiveParser_IdentifiersParser.identifier_return name =null;

        HiveParser.tableProperties_return tableProperties236 =null;

        HiveParser.ifExists_return ifExists239 =null;

        HiveParser.tableProperties_return tableProperties240 =null;


        CommonTree KW_SET234_tree=null;
        CommonTree KW_TBLPROPERTIES235_tree=null;
        CommonTree KW_UNSET237_tree=null;
        CommonTree KW_TBLPROPERTIES238_tree=null;
        RewriteRuleTokenStream stream_KW_UNSET=new RewriteRuleTokenStream(adaptor,"token KW_UNSET");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleTokenStream stream_KW_TBLPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_TBLPROPERTIES");
        RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");
        RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("alter view properties statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1010:5: (name= identifier KW_SET KW_TBLPROPERTIES tableProperties -> ^( TOK_ALTERVIEW_PROPERTIES $name tableProperties ) |name= identifier KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties -> ^( TOK_DROPVIEW_PROPERTIES $name tableProperties ( ifExists )? ) )
            int alt69=2;
            int LA69_0 = input.LA(1);

            if ( (LA69_0==Identifier) ) {
                int LA69_1 = input.LA(2);

                if ( (LA69_1==KW_SET) ) {
                    alt69=1;
                }
                else if ( (LA69_1==KW_UNSET) ) {
                    alt69=2;
                }
                else {
                    NoViableAltException nvae =
                        new NoViableAltException("", 69, 1, input);

                    throw nvae;

                }
            }
            else if ( ((LA69_0 >= KW_ADD && LA69_0 <= KW_AFTER)||(LA69_0 >= KW_ALTER && LA69_0 <= KW_ANALYZE)||(LA69_0 >= KW_ARCHIVE && LA69_0 <= KW_CASCADE)||(LA69_0 >= KW_CHANGE && LA69_0 <= KW_COLLECTION)||(LA69_0 >= KW_COLUMNS && LA69_0 <= KW_CREATE)||LA69_0==KW_CUBE||(LA69_0 >= KW_CURSOR && LA69_0 <= KW_DATA)||(LA69_0 >= KW_DATABASES && LA69_0 <= KW_DISABLE)||(LA69_0 >= KW_DISTRIBUTE && LA69_0 <= KW_ELEM_TYPE)||LA69_0==KW_ENABLE||LA69_0==KW_ESCAPED||(LA69_0 >= KW_EXCLUSIVE && LA69_0 <= KW_EXPORT)||(LA69_0 >= KW_EXTERNAL && LA69_0 <= KW_FLOAT)||(LA69_0 >= KW_FOR && LA69_0 <= KW_FORMATTED)||LA69_0==KW_FULL||(LA69_0 >= KW_FUNCTIONS && LA69_0 <= KW_GROUPING)||(LA69_0 >= KW_HOLD_DDLTIME && LA69_0 <= KW_IDXPROPERTIES)||(LA69_0 >= KW_IGNORE && LA69_0 <= KW_ITEMS)||(LA69_0 >= KW_KEYS && LA69_0 <= KW_LEFT)||(LA69_0 >= KW_LIKE && LA69_0 <= KW_LONG)||(LA69_0 >= KW_MAPJOIN && LA69_0 <= KW_MINUS)||(LA69_0 >= KW_MSCK && LA69_0 <= KW_NOSCAN)||(LA69_0 >= KW_NO_DROP && LA69_0 <= KW_OFFLINE)||LA69_0==KW_OPTION||(LA69_0 >= KW_ORCFILE && LA69_0 <= KW_OUTPUTFORMAT)||LA69_0==KW_OVERWRITE||(LA69_0 >= KW_PARTITION && LA69_0 <= KW_PLUS)||(LA69_0 >= KW_PRETTY && LA69_0 <= KW_RECORDWRITER)||(LA69_0 >= KW_REGEXP && LA69_0 <= KW_SCHEMAS)||(LA69_0 >= KW_SEMI && LA69_0 <= KW_TABLES)||(LA69_0 >= KW_TBLPROPERTIES && LA69_0 <= KW_TEXTFILE)||(LA69_0 >= KW_TIMESTAMP && LA69_0 <= KW_TOUCH)||(LA69_0 >= KW_TRIGGER && LA69_0 <= KW_UNARCHIVE)||(LA69_0 >= KW_UNDO && LA69_0 <= KW_UNIONTYPE)||(LA69_0 >= KW_UNLOCK && LA69_0 <= KW_VALUE_TYPE)||LA69_0==KW_VIEW||LA69_0==KW_WHILE||LA69_0==KW_WITH) ) {
                int LA69_2 = input.LA(2);

                if ( (LA69_2==KW_SET) ) {
                    alt69=1;
                }
                else if ( (LA69_2==KW_UNSET) ) {
                    alt69=2;
                }
                else {
                    NoViableAltException nvae =
                        new NoViableAltException("", 69, 2, input);

                    throw nvae;

                }
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 69, 0, input);

                throw nvae;

            }
            switch (alt69) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1010:7: name= identifier KW_SET KW_TBLPROPERTIES tableProperties
                    {
                    pushFollow(FOLLOW_identifier_in_alterViewSuffixProperties4581);
                    name=identifier();

                    state._fsp--;

                    stream_identifier.add(name.getTree());

                    KW_SET234=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterViewSuffixProperties4583);  
                    stream_KW_SET.add(KW_SET234);


                    KW_TBLPROPERTIES235=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties4585);  
                    stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES235);


                    pushFollow(FOLLOW_tableProperties_in_alterViewSuffixProperties4587);
                    tableProperties236=tableProperties();

                    state._fsp--;

                    stream_tableProperties.add(tableProperties236.getTree());

                    // AST REWRITE
                    // elements: tableProperties, name
                    // token labels: 
                    // rule labels: retval, name
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1011:5: -> ^( TOK_ALTERVIEW_PROPERTIES $name tableProperties )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1011:8: ^( TOK_ALTERVIEW_PROPERTIES $name tableProperties )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERVIEW_PROPERTIES, "TOK_ALTERVIEW_PROPERTIES")
                        , root_1);

                        adaptor.addChild(root_1, stream_name.nextTree());

                        adaptor.addChild(root_1, stream_tableProperties.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1012:7: name= identifier KW_UNSET KW_TBLPROPERTIES ( ifExists )? tableProperties
                    {
                    pushFollow(FOLLOW_identifier_in_alterViewSuffixProperties4612);
                    name=identifier();

                    state._fsp--;

                    stream_identifier.add(name.getTree());

                    KW_UNSET237=(Token)match(input,KW_UNSET,FOLLOW_KW_UNSET_in_alterViewSuffixProperties4614);  
                    stream_KW_UNSET.add(KW_UNSET237);


                    KW_TBLPROPERTIES238=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties4616);  
                    stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES238);


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1012:49: ( ifExists )?
                    int alt68=2;
                    int LA68_0 = input.LA(1);

                    if ( (LA68_0==KW_IF) ) {
                        alt68=1;
                    }
                    switch (alt68) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1012:49: ifExists
                            {
                            pushFollow(FOLLOW_ifExists_in_alterViewSuffixProperties4618);
                            ifExists239=ifExists();

                            state._fsp--;

                            stream_ifExists.add(ifExists239.getTree());

                            }
                            break;

                    }


                    pushFollow(FOLLOW_tableProperties_in_alterViewSuffixProperties4621);
                    tableProperties240=tableProperties();

                    state._fsp--;

                    stream_tableProperties.add(tableProperties240.getTree());

                    // AST REWRITE
                    // elements: tableProperties, ifExists, name
                    // token labels: 
                    // rule labels: retval, name
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1013:5: -> ^( TOK_DROPVIEW_PROPERTIES $name tableProperties ( ifExists )? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1013:8: ^( TOK_DROPVIEW_PROPERTIES $name tableProperties ( ifExists )? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_DROPVIEW_PROPERTIES, "TOK_DROPVIEW_PROPERTIES")
                        , root_1);

                        adaptor.addChild(root_1, stream_name.nextTree());

                        adaptor.addChild(root_1, stream_tableProperties.nextTree());

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1013:56: ( ifExists )?
                        if ( stream_ifExists.hasNext() ) {
                            adaptor.addChild(root_1, stream_ifExists.nextTree());

                        }
                        stream_ifExists.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterViewSuffixProperties"


    public static class alterStatementSuffixSerdeProperties_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixSerdeProperties"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1016:1: alterStatementSuffixSerdeProperties : ( KW_SET KW_SERDE serdeName= StringLiteral ( KW_WITH KW_SERDEPROPERTIES tableProperties )? -> ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? ) | KW_SET KW_SERDEPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties ) );
    public final HiveParser.alterStatementSuffixSerdeProperties_return alterStatementSuffixSerdeProperties() throws RecognitionException {
        HiveParser.alterStatementSuffixSerdeProperties_return retval = new HiveParser.alterStatementSuffixSerdeProperties_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token serdeName=null;
        Token KW_SET241=null;
        Token KW_SERDE242=null;
        Token KW_WITH243=null;
        Token KW_SERDEPROPERTIES244=null;
        Token KW_SET246=null;
        Token KW_SERDEPROPERTIES247=null;
        HiveParser.tableProperties_return tableProperties245 =null;

        HiveParser.tableProperties_return tableProperties248 =null;


        CommonTree serdeName_tree=null;
        CommonTree KW_SET241_tree=null;
        CommonTree KW_SERDE242_tree=null;
        CommonTree KW_WITH243_tree=null;
        CommonTree KW_SERDEPROPERTIES244_tree=null;
        CommonTree KW_SET246_tree=null;
        CommonTree KW_SERDEPROPERTIES247_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
        RewriteRuleTokenStream stream_KW_SERDE=new RewriteRuleTokenStream(adaptor,"token KW_SERDE");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleTokenStream stream_KW_SERDEPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_SERDEPROPERTIES");
        RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");
         msgs.push("alter serdes statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1019:5: ( KW_SET KW_SERDE serdeName= StringLiteral ( KW_WITH KW_SERDEPROPERTIES tableProperties )? -> ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? ) | KW_SET KW_SERDEPROPERTIES tableProperties -> ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties ) )
            int alt71=2;
            int LA71_0 = input.LA(1);

            if ( (LA71_0==KW_SET) ) {
                int LA71_1 = input.LA(2);

                if ( (LA71_1==KW_SERDE) ) {
                    alt71=1;
                }
                else if ( (LA71_1==KW_SERDEPROPERTIES) ) {
                    alt71=2;
                }
                else {
                    NoViableAltException nvae =
                        new NoViableAltException("", 71, 1, input);

                    throw nvae;

                }
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 71, 0, input);

                throw nvae;

            }
            switch (alt71) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1019:7: KW_SET KW_SERDE serdeName= StringLiteral ( KW_WITH KW_SERDEPROPERTIES tableProperties )?
                    {
                    KW_SET241=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties4666);  
                    stream_KW_SET.add(KW_SET241);


                    KW_SERDE242=(Token)match(input,KW_SERDE,FOLLOW_KW_SERDE_in_alterStatementSuffixSerdeProperties4668);  
                    stream_KW_SERDE.add(KW_SERDE242);


                    serdeName=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixSerdeProperties4672);  
                    stream_StringLiteral.add(serdeName);


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1019:47: ( KW_WITH KW_SERDEPROPERTIES tableProperties )?
                    int alt70=2;
                    int LA70_0 = input.LA(1);

                    if ( (LA70_0==KW_WITH) ) {
                        alt70=1;
                    }
                    switch (alt70) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1019:48: KW_WITH KW_SERDEPROPERTIES tableProperties
                            {
                            KW_WITH243=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_alterStatementSuffixSerdeProperties4675);  
                            stream_KW_WITH.add(KW_WITH243);


                            KW_SERDEPROPERTIES244=(Token)match(input,KW_SERDEPROPERTIES,FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties4677);  
                            stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES244);


                            pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties4679);
                            tableProperties245=tableProperties();

                            state._fsp--;

                            stream_tableProperties.add(tableProperties245.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: tableProperties, serdeName
                    // token labels: serdeName
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_serdeName=new RewriteRuleTokenStream(adaptor,"token serdeName",serdeName);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1020:5: -> ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1020:8: ^( TOK_ALTERTABLE_SERIALIZER $serdeName ( tableProperties )? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERTABLE_SERIALIZER, "TOK_ALTERTABLE_SERIALIZER")
                        , root_1);

                        adaptor.addChild(root_1, stream_serdeName.nextNode());

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1020:47: ( tableProperties )?
                        if ( stream_tableProperties.hasNext() ) {
                            adaptor.addChild(root_1, stream_tableProperties.nextTree());

                        }
                        stream_tableProperties.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1021:7: KW_SET KW_SERDEPROPERTIES tableProperties
                    {
                    KW_SET246=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties4705);  
                    stream_KW_SET.add(KW_SET246);


                    KW_SERDEPROPERTIES247=(Token)match(input,KW_SERDEPROPERTIES,FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties4707);  
                    stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES247);


                    pushFollow(FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties4709);
                    tableProperties248=tableProperties();

                    state._fsp--;

                    stream_tableProperties.add(tableProperties248.getTree());

                    // AST REWRITE
                    // elements: tableProperties
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1022:5: -> ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1022:8: ^( TOK_ALTERTABLE_SERDEPROPERTIES tableProperties )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERTABLE_SERDEPROPERTIES, "TOK_ALTERTABLE_SERDEPROPERTIES")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableProperties.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixSerdeProperties"


    public static class tablePartitionPrefix_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tablePartitionPrefix"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1025:1: tablePartitionPrefix : name= identifier ( partitionSpec )? -> ^( TOK_TABLE_PARTITION $name ( partitionSpec )? ) ;
    public final HiveParser.tablePartitionPrefix_return tablePartitionPrefix() throws RecognitionException {
        HiveParser.tablePartitionPrefix_return retval = new HiveParser.tablePartitionPrefix_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser_IdentifiersParser.identifier_return name =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec249 =null;


        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        msgs.push("table partition prefix");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1028:3: (name= identifier ( partitionSpec )? -> ^( TOK_TABLE_PARTITION $name ( partitionSpec )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1028:4: name= identifier ( partitionSpec )?
            {
            pushFollow(FOLLOW_identifier_in_tablePartitionPrefix4747);
            name=identifier();

            state._fsp--;

            stream_identifier.add(name.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1028:20: ( partitionSpec )?
            int alt72=2;
            int LA72_0 = input.LA(1);

            if ( (LA72_0==KW_PARTITION) ) {
                alt72=1;
            }
            switch (alt72) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1028:20: partitionSpec
                    {
                    pushFollow(FOLLOW_partitionSpec_in_tablePartitionPrefix4749);
                    partitionSpec249=partitionSpec();

                    state._fsp--;

                    stream_partitionSpec.add(partitionSpec249.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: partitionSpec, name
            // token labels: 
            // rule labels: retval, name
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1029:3: -> ^( TOK_TABLE_PARTITION $name ( partitionSpec )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1029:5: ^( TOK_TABLE_PARTITION $name ( partitionSpec )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABLE_PARTITION, "TOK_TABLE_PARTITION")
                , root_1);

                adaptor.addChild(root_1, stream_name.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1029:33: ( partitionSpec )?
                if ( stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                }
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tablePartitionPrefix"


    public static class alterTblPartitionStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterTblPartitionStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1032:1: alterTblPartitionStatement : ( tablePartitionPrefix alterTblPartitionStatementSuffix -> ^( TOK_ALTERTABLE_PARTITION tablePartitionPrefix alterTblPartitionStatementSuffix ) | Identifier KW_PARTITION KW_COLUMN LPAREN columnNameType RPAREN -> ^( TOK_ALTERTABLE_ALTERPARTS Identifier columnNameType ) );
    public final HiveParser.alterTblPartitionStatement_return alterTblPartitionStatement() throws RecognitionException {
        HiveParser.alterTblPartitionStatement_return retval = new HiveParser.alterTblPartitionStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token Identifier252=null;
        Token KW_PARTITION253=null;
        Token KW_COLUMN254=null;
        Token LPAREN255=null;
        Token RPAREN257=null;
        HiveParser.tablePartitionPrefix_return tablePartitionPrefix250 =null;

        HiveParser.alterTblPartitionStatementSuffix_return alterTblPartitionStatementSuffix251 =null;

        HiveParser.columnNameType_return columnNameType256 =null;


        CommonTree Identifier252_tree=null;
        CommonTree KW_PARTITION253_tree=null;
        CommonTree KW_COLUMN254_tree=null;
        CommonTree LPAREN255_tree=null;
        CommonTree RPAREN257_tree=null;
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_COLUMN=new RewriteRuleTokenStream(adaptor,"token KW_COLUMN");
        RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
        RewriteRuleTokenStream stream_KW_PARTITION=new RewriteRuleTokenStream(adaptor,"token KW_PARTITION");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleSubtreeStream stream_columnNameType=new RewriteRuleSubtreeStream(adaptor,"rule columnNameType");
        RewriteRuleSubtreeStream stream_alterTblPartitionStatementSuffix=new RewriteRuleSubtreeStream(adaptor,"rule alterTblPartitionStatementSuffix");
        RewriteRuleSubtreeStream stream_tablePartitionPrefix=new RewriteRuleSubtreeStream(adaptor,"rule tablePartitionPrefix");
        msgs.push("alter table partition statement");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1035:3: ( tablePartitionPrefix alterTblPartitionStatementSuffix -> ^( TOK_ALTERTABLE_PARTITION tablePartitionPrefix alterTblPartitionStatementSuffix ) | Identifier KW_PARTITION KW_COLUMN LPAREN columnNameType RPAREN -> ^( TOK_ALTERTABLE_ALTERPARTS Identifier columnNameType ) )
            int alt73=2;
            int LA73_0 = input.LA(1);

            if ( (LA73_0==Identifier) ) {
                int LA73_1 = input.LA(2);

                if ( (LA73_1==KW_PARTITION) ) {
                    int LA73_3 = input.LA(3);

                    if ( (LA73_3==KW_COLUMN) ) {
                        alt73=2;
                    }
                    else if ( (LA73_3==LPAREN) ) {
                        alt73=1;
                    }
                    else {
                        NoViableAltException nvae =
                            new NoViableAltException("", 73, 3, input);

                        throw nvae;

                    }
                }
                else if ( (LA73_1==KW_CLUSTERED||LA73_1==KW_CONCATENATE||LA73_1==KW_DISABLE||LA73_1==KW_ENABLE||LA73_1==KW_INTO||LA73_1==KW_NOT||LA73_1==KW_RENAME||LA73_1==KW_SET) ) {
                    alt73=1;
                }
                else {
                    NoViableAltException nvae =
                        new NoViableAltException("", 73, 1, input);

                    throw nvae;

                }
            }
            else if ( ((LA73_0 >= KW_ADD && LA73_0 <= KW_AFTER)||(LA73_0 >= KW_ALTER && LA73_0 <= KW_ANALYZE)||(LA73_0 >= KW_ARCHIVE && LA73_0 <= KW_CASCADE)||(LA73_0 >= KW_CHANGE && LA73_0 <= KW_COLLECTION)||(LA73_0 >= KW_COLUMNS && LA73_0 <= KW_CREATE)||LA73_0==KW_CUBE||(LA73_0 >= KW_CURSOR && LA73_0 <= KW_DATA)||(LA73_0 >= KW_DATABASES && LA73_0 <= KW_DISABLE)||(LA73_0 >= KW_DISTRIBUTE && LA73_0 <= KW_ELEM_TYPE)||LA73_0==KW_ENABLE||LA73_0==KW_ESCAPED||(LA73_0 >= KW_EXCLUSIVE && LA73_0 <= KW_EXPORT)||(LA73_0 >= KW_EXTERNAL && LA73_0 <= KW_FLOAT)||(LA73_0 >= KW_FOR && LA73_0 <= KW_FORMATTED)||LA73_0==KW_FULL||(LA73_0 >= KW_FUNCTIONS && LA73_0 <= KW_GROUPING)||(LA73_0 >= KW_HOLD_DDLTIME && LA73_0 <= KW_IDXPROPERTIES)||(LA73_0 >= KW_IGNORE && LA73_0 <= KW_ITEMS)||(LA73_0 >= KW_KEYS && LA73_0 <= KW_LEFT)||(LA73_0 >= KW_LIKE && LA73_0 <= KW_LONG)||(LA73_0 >= KW_MAPJOIN && LA73_0 <= KW_MINUS)||(LA73_0 >= KW_MSCK && LA73_0 <= KW_NOSCAN)||(LA73_0 >= KW_NO_DROP && LA73_0 <= KW_OFFLINE)||LA73_0==KW_OPTION||(LA73_0 >= KW_ORCFILE && LA73_0 <= KW_OUTPUTFORMAT)||LA73_0==KW_OVERWRITE||(LA73_0 >= KW_PARTITION && LA73_0 <= KW_PLUS)||(LA73_0 >= KW_PRETTY && LA73_0 <= KW_RECORDWRITER)||(LA73_0 >= KW_REGEXP && LA73_0 <= KW_SCHEMAS)||(LA73_0 >= KW_SEMI && LA73_0 <= KW_TABLES)||(LA73_0 >= KW_TBLPROPERTIES && LA73_0 <= KW_TEXTFILE)||(LA73_0 >= KW_TIMESTAMP && LA73_0 <= KW_TOUCH)||(LA73_0 >= KW_TRIGGER && LA73_0 <= KW_UNARCHIVE)||(LA73_0 >= KW_UNDO && LA73_0 <= KW_UNIONTYPE)||(LA73_0 >= KW_UNLOCK && LA73_0 <= KW_VALUE_TYPE)||LA73_0==KW_VIEW||LA73_0==KW_WHILE||LA73_0==KW_WITH) ) {
                alt73=1;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 73, 0, input);

                throw nvae;

            }
            switch (alt73) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1035:5: tablePartitionPrefix alterTblPartitionStatementSuffix
                    {
                    pushFollow(FOLLOW_tablePartitionPrefix_in_alterTblPartitionStatement4786);
                    tablePartitionPrefix250=tablePartitionPrefix();

                    state._fsp--;

                    stream_tablePartitionPrefix.add(tablePartitionPrefix250.getTree());

                    pushFollow(FOLLOW_alterTblPartitionStatementSuffix_in_alterTblPartitionStatement4788);
                    alterTblPartitionStatementSuffix251=alterTblPartitionStatementSuffix();

                    state._fsp--;

                    stream_alterTblPartitionStatementSuffix.add(alterTblPartitionStatementSuffix251.getTree());

                    // AST REWRITE
                    // elements: alterTblPartitionStatementSuffix, tablePartitionPrefix
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1036:3: -> ^( TOK_ALTERTABLE_PARTITION tablePartitionPrefix alterTblPartitionStatementSuffix )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1036:6: ^( TOK_ALTERTABLE_PARTITION tablePartitionPrefix alterTblPartitionStatementSuffix )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERTABLE_PARTITION, "TOK_ALTERTABLE_PARTITION")
                        , root_1);

                        adaptor.addChild(root_1, stream_tablePartitionPrefix.nextTree());

                        adaptor.addChild(root_1, stream_alterTblPartitionStatementSuffix.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1037:4: Identifier KW_PARTITION KW_COLUMN LPAREN columnNameType RPAREN
                    {
                    Identifier252=(Token)match(input,Identifier,FOLLOW_Identifier_in_alterTblPartitionStatement4805);  
                    stream_Identifier.add(Identifier252);


                    KW_PARTITION253=(Token)match(input,KW_PARTITION,FOLLOW_KW_PARTITION_in_alterTblPartitionStatement4807);  
                    stream_KW_PARTITION.add(KW_PARTITION253);


                    KW_COLUMN254=(Token)match(input,KW_COLUMN,FOLLOW_KW_COLUMN_in_alterTblPartitionStatement4809);  
                    stream_KW_COLUMN.add(KW_COLUMN254);


                    LPAREN255=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_alterTblPartitionStatement4811);  
                    stream_LPAREN.add(LPAREN255);


                    pushFollow(FOLLOW_columnNameType_in_alterTblPartitionStatement4813);
                    columnNameType256=columnNameType();

                    state._fsp--;

                    stream_columnNameType.add(columnNameType256.getTree());

                    RPAREN257=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_alterTblPartitionStatement4815);  
                    stream_RPAREN.add(RPAREN257);


                    // AST REWRITE
                    // elements: Identifier, columnNameType
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1038:3: -> ^( TOK_ALTERTABLE_ALTERPARTS Identifier columnNameType )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1038:6: ^( TOK_ALTERTABLE_ALTERPARTS Identifier columnNameType )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERTABLE_ALTERPARTS, "TOK_ALTERTABLE_ALTERPARTS")
                        , root_1);

                        adaptor.addChild(root_1, 
                        stream_Identifier.nextNode()
                        );

                        adaptor.addChild(root_1, stream_columnNameType.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterTblPartitionStatement"


    public static class alterTblPartitionStatementSuffix_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterTblPartitionStatementSuffix"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1041:1: alterTblPartitionStatementSuffix : ( alterStatementSuffixFileFormat | alterStatementSuffixLocation | alterStatementSuffixProtectMode | alterStatementSuffixMergeFiles | alterStatementSuffixSerdeProperties | alterStatementSuffixRenamePart | alterStatementSuffixBucketNum | alterTblPartitionStatementSuffixSkewedLocation | alterStatementSuffixClusterbySortby );
    public final HiveParser.alterTblPartitionStatementSuffix_return alterTblPartitionStatementSuffix() throws RecognitionException {
        HiveParser.alterTblPartitionStatementSuffix_return retval = new HiveParser.alterTblPartitionStatementSuffix_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser.alterStatementSuffixFileFormat_return alterStatementSuffixFileFormat258 =null;

        HiveParser.alterStatementSuffixLocation_return alterStatementSuffixLocation259 =null;

        HiveParser.alterStatementSuffixProtectMode_return alterStatementSuffixProtectMode260 =null;

        HiveParser.alterStatementSuffixMergeFiles_return alterStatementSuffixMergeFiles261 =null;

        HiveParser.alterStatementSuffixSerdeProperties_return alterStatementSuffixSerdeProperties262 =null;

        HiveParser.alterStatementSuffixRenamePart_return alterStatementSuffixRenamePart263 =null;

        HiveParser.alterStatementSuffixBucketNum_return alterStatementSuffixBucketNum264 =null;

        HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return alterTblPartitionStatementSuffixSkewedLocation265 =null;

        HiveParser.alterStatementSuffixClusterbySortby_return alterStatementSuffixClusterbySortby266 =null;



        msgs.push("alter table partition statement suffix");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1044:3: ( alterStatementSuffixFileFormat | alterStatementSuffixLocation | alterStatementSuffixProtectMode | alterStatementSuffixMergeFiles | alterStatementSuffixSerdeProperties | alterStatementSuffixRenamePart | alterStatementSuffixBucketNum | alterTblPartitionStatementSuffixSkewedLocation | alterStatementSuffixClusterbySortby )
            int alt74=9;
            switch ( input.LA(1) ) {
            case KW_SET:
                {
                switch ( input.LA(2) ) {
                case KW_FILEFORMAT:
                    {
                    alt74=1;
                    }
                    break;
                case KW_LOCATION:
                    {
                    alt74=2;
                    }
                    break;
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                    {
                    alt74=5;
                    }
                    break;
                case KW_SKEWED:
                    {
                    alt74=8;
                    }
                    break;
                default:
                    NoViableAltException nvae =
                        new NoViableAltException("", 74, 1, input);

                    throw nvae;

                }

                }
                break;
            case KW_DISABLE:
            case KW_ENABLE:
                {
                alt74=3;
                }
                break;
            case KW_CONCATENATE:
                {
                alt74=4;
                }
                break;
            case KW_RENAME:
                {
                alt74=6;
                }
                break;
            case KW_INTO:
                {
                alt74=7;
                }
                break;
            case KW_CLUSTERED:
            case KW_NOT:
                {
                alt74=9;
                }
                break;
            default:
                NoViableAltException nvae =
                    new NoViableAltException("", 74, 0, input);

                throw nvae;

            }

            switch (alt74) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1044:5: alterStatementSuffixFileFormat
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixFileFormat_in_alterTblPartitionStatementSuffix4850);
                    alterStatementSuffixFileFormat258=alterStatementSuffixFileFormat();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatementSuffixFileFormat258.getTree());

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1045:5: alterStatementSuffixLocation
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixLocation_in_alterTblPartitionStatementSuffix4856);
                    alterStatementSuffixLocation259=alterStatementSuffixLocation();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatementSuffixLocation259.getTree());

                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1046:5: alterStatementSuffixProtectMode
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixProtectMode_in_alterTblPartitionStatementSuffix4862);
                    alterStatementSuffixProtectMode260=alterStatementSuffixProtectMode();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatementSuffixProtectMode260.getTree());

                    }
                    break;
                case 4 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1047:5: alterStatementSuffixMergeFiles
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixMergeFiles_in_alterTblPartitionStatementSuffix4868);
                    alterStatementSuffixMergeFiles261=alterStatementSuffixMergeFiles();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatementSuffixMergeFiles261.getTree());

                    }
                    break;
                case 5 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1048:5: alterStatementSuffixSerdeProperties
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixSerdeProperties_in_alterTblPartitionStatementSuffix4874);
                    alterStatementSuffixSerdeProperties262=alterStatementSuffixSerdeProperties();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatementSuffixSerdeProperties262.getTree());

                    }
                    break;
                case 6 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1049:5: alterStatementSuffixRenamePart
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixRenamePart_in_alterTblPartitionStatementSuffix4880);
                    alterStatementSuffixRenamePart263=alterStatementSuffixRenamePart();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatementSuffixRenamePart263.getTree());

                    }
                    break;
                case 7 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1050:5: alterStatementSuffixBucketNum
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixBucketNum_in_alterTblPartitionStatementSuffix4886);
                    alterStatementSuffixBucketNum264=alterStatementSuffixBucketNum();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatementSuffixBucketNum264.getTree());

                    }
                    break;
                case 8 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1051:5: alterTblPartitionStatementSuffixSkewedLocation
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterTblPartitionStatementSuffixSkewedLocation_in_alterTblPartitionStatementSuffix4892);
                    alterTblPartitionStatementSuffixSkewedLocation265=alterTblPartitionStatementSuffixSkewedLocation();

                    state._fsp--;

                    adaptor.addChild(root_0, alterTblPartitionStatementSuffixSkewedLocation265.getTree());

                    }
                    break;
                case 9 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1052:5: alterStatementSuffixClusterbySortby
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_alterStatementSuffixClusterbySortby_in_alterTblPartitionStatementSuffix4898);
                    alterStatementSuffixClusterbySortby266=alterStatementSuffixClusterbySortby();

                    state._fsp--;

                    adaptor.addChild(root_0, alterStatementSuffixClusterbySortby266.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterTblPartitionStatementSuffix"


    public static class alterStatementSuffixFileFormat_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixFileFormat"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1055:1: alterStatementSuffixFileFormat : KW_SET KW_FILEFORMAT fileFormat -> ^( TOK_ALTERTABLE_FILEFORMAT fileFormat ) ;
    public final HiveParser.alterStatementSuffixFileFormat_return alterStatementSuffixFileFormat() throws RecognitionException {
        HiveParser.alterStatementSuffixFileFormat_return retval = new HiveParser.alterStatementSuffixFileFormat_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_SET267=null;
        Token KW_FILEFORMAT268=null;
        HiveParser.fileFormat_return fileFormat269 =null;


        CommonTree KW_SET267_tree=null;
        CommonTree KW_FILEFORMAT268_tree=null;
        RewriteRuleTokenStream stream_KW_FILEFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_FILEFORMAT");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleSubtreeStream stream_fileFormat=new RewriteRuleSubtreeStream(adaptor,"rule fileFormat");
        msgs.push("alter fileformat statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1058:2: ( KW_SET KW_FILEFORMAT fileFormat -> ^( TOK_ALTERTABLE_FILEFORMAT fileFormat ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1058:4: KW_SET KW_FILEFORMAT fileFormat
            {
            KW_SET267=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixFileFormat4920);  
            stream_KW_SET.add(KW_SET267);


            KW_FILEFORMAT268=(Token)match(input,KW_FILEFORMAT,FOLLOW_KW_FILEFORMAT_in_alterStatementSuffixFileFormat4922);  
            stream_KW_FILEFORMAT.add(KW_FILEFORMAT268);


            pushFollow(FOLLOW_fileFormat_in_alterStatementSuffixFileFormat4924);
            fileFormat269=fileFormat();

            state._fsp--;

            stream_fileFormat.add(fileFormat269.getTree());

            // AST REWRITE
            // elements: fileFormat
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1059:2: -> ^( TOK_ALTERTABLE_FILEFORMAT fileFormat )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1059:5: ^( TOK_ALTERTABLE_FILEFORMAT fileFormat )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_ALTERTABLE_FILEFORMAT, "TOK_ALTERTABLE_FILEFORMAT")
                , root_1);

                adaptor.addChild(root_1, stream_fileFormat.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixFileFormat"


    public static class alterStatementSuffixClusterbySortby_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixClusterbySortby"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1062:1: alterStatementSuffixClusterbySortby : ( KW_NOT KW_CLUSTERED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED ) | KW_NOT KW_SORTED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED ) | tableBuckets -> ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets ) );
    public final HiveParser.alterStatementSuffixClusterbySortby_return alterStatementSuffixClusterbySortby() throws RecognitionException {
        HiveParser.alterStatementSuffixClusterbySortby_return retval = new HiveParser.alterStatementSuffixClusterbySortby_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_NOT270=null;
        Token KW_CLUSTERED271=null;
        Token KW_NOT272=null;
        Token KW_SORTED273=null;
        HiveParser.tableBuckets_return tableBuckets274 =null;


        CommonTree KW_NOT270_tree=null;
        CommonTree KW_CLUSTERED271_tree=null;
        CommonTree KW_NOT272_tree=null;
        CommonTree KW_SORTED273_tree=null;
        RewriteRuleTokenStream stream_KW_CLUSTERED=new RewriteRuleTokenStream(adaptor,"token KW_CLUSTERED");
        RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
        RewriteRuleTokenStream stream_KW_SORTED=new RewriteRuleTokenStream(adaptor,"token KW_SORTED");
        RewriteRuleSubtreeStream stream_tableBuckets=new RewriteRuleSubtreeStream(adaptor,"rule tableBuckets");
        msgs.push("alter partition cluster by sort by statement");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1065:3: ( KW_NOT KW_CLUSTERED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED ) | KW_NOT KW_SORTED -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED ) | tableBuckets -> ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets ) )
            int alt75=3;
            int LA75_0 = input.LA(1);

            if ( (LA75_0==KW_NOT) ) {
                int LA75_1 = input.LA(2);

                if ( (LA75_1==KW_CLUSTERED) ) {
                    alt75=1;
                }
                else if ( (LA75_1==KW_SORTED) ) {
                    alt75=2;
                }
                else {
                    NoViableAltException nvae =
                        new NoViableAltException("", 75, 1, input);

                    throw nvae;

                }
            }
            else if ( (LA75_0==KW_CLUSTERED) ) {
                alt75=3;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 75, 0, input);

                throw nvae;

            }
            switch (alt75) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1065:5: KW_NOT KW_CLUSTERED
                    {
                    KW_NOT270=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby4955);  
                    stream_KW_NOT.add(KW_NOT270);


                    KW_CLUSTERED271=(Token)match(input,KW_CLUSTERED,FOLLOW_KW_CLUSTERED_in_alterStatementSuffixClusterbySortby4957);  
                    stream_KW_CLUSTERED.add(KW_CLUSTERED271);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1065:25: -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1065:28: ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_CLUSTERED )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERTABLE_CLUSTER_SORT, "TOK_ALTERTABLE_CLUSTER_SORT")
                        , root_1);

                        adaptor.addChild(root_1, 
                        (CommonTree)adaptor.create(TOK_NOT_CLUSTERED, "TOK_NOT_CLUSTERED")
                        );

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1066:5: KW_NOT KW_SORTED
                    {
                    KW_NOT272=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby4971);  
                    stream_KW_NOT.add(KW_NOT272);


                    KW_SORTED273=(Token)match(input,KW_SORTED,FOLLOW_KW_SORTED_in_alterStatementSuffixClusterbySortby4973);  
                    stream_KW_SORTED.add(KW_SORTED273);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1066:22: -> ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1066:25: ^( TOK_ALTERTABLE_CLUSTER_SORT TOK_NOT_SORTED )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERTABLE_CLUSTER_SORT, "TOK_ALTERTABLE_CLUSTER_SORT")
                        , root_1);

                        adaptor.addChild(root_1, 
                        (CommonTree)adaptor.create(TOK_NOT_SORTED, "TOK_NOT_SORTED")
                        );

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1067:5: tableBuckets
                    {
                    pushFollow(FOLLOW_tableBuckets_in_alterStatementSuffixClusterbySortby4987);
                    tableBuckets274=tableBuckets();

                    state._fsp--;

                    stream_tableBuckets.add(tableBuckets274.getTree());

                    // AST REWRITE
                    // elements: tableBuckets
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1067:18: -> ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1067:21: ^( TOK_ALTERTABLE_CLUSTER_SORT tableBuckets )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERTABLE_CLUSTER_SORT, "TOK_ALTERTABLE_CLUSTER_SORT")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableBuckets.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixClusterbySortby"


    public static class alterTblPartitionStatementSuffixSkewedLocation_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterTblPartitionStatementSuffixSkewedLocation"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1070:1: alterTblPartitionStatementSuffixSkewedLocation : KW_SET KW_SKEWED KW_LOCATION skewedLocations -> ^( TOK_ALTERTBLPART_SKEWED_LOCATION skewedLocations ) ;
    public final HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return alterTblPartitionStatementSuffixSkewedLocation() throws RecognitionException {
        HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return retval = new HiveParser.alterTblPartitionStatementSuffixSkewedLocation_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_SET275=null;
        Token KW_SKEWED276=null;
        Token KW_LOCATION277=null;
        HiveParser.skewedLocations_return skewedLocations278 =null;


        CommonTree KW_SET275_tree=null;
        CommonTree KW_SKEWED276_tree=null;
        CommonTree KW_LOCATION277_tree=null;
        RewriteRuleTokenStream stream_KW_SKEWED=new RewriteRuleTokenStream(adaptor,"token KW_SKEWED");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");
        RewriteRuleSubtreeStream stream_skewedLocations=new RewriteRuleSubtreeStream(adaptor,"rule skewedLocations");
        msgs.push("alter partition skewed location");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1073:3: ( KW_SET KW_SKEWED KW_LOCATION skewedLocations -> ^( TOK_ALTERTBLPART_SKEWED_LOCATION skewedLocations ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1073:5: KW_SET KW_SKEWED KW_LOCATION skewedLocations
            {
            KW_SET275=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterTblPartitionStatementSuffixSkewedLocation5018);  
            stream_KW_SET.add(KW_SET275);


            KW_SKEWED276=(Token)match(input,KW_SKEWED,FOLLOW_KW_SKEWED_in_alterTblPartitionStatementSuffixSkewedLocation5020);  
            stream_KW_SKEWED.add(KW_SKEWED276);


            KW_LOCATION277=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_alterTblPartitionStatementSuffixSkewedLocation5022);  
            stream_KW_LOCATION.add(KW_LOCATION277);


            pushFollow(FOLLOW_skewedLocations_in_alterTblPartitionStatementSuffixSkewedLocation5024);
            skewedLocations278=skewedLocations();

            state._fsp--;

            stream_skewedLocations.add(skewedLocations278.getTree());

            // AST REWRITE
            // elements: skewedLocations
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1074:3: -> ^( TOK_ALTERTBLPART_SKEWED_LOCATION skewedLocations )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1074:6: ^( TOK_ALTERTBLPART_SKEWED_LOCATION skewedLocations )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_ALTERTBLPART_SKEWED_LOCATION, "TOK_ALTERTBLPART_SKEWED_LOCATION")
                , root_1);

                adaptor.addChild(root_1, stream_skewedLocations.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterTblPartitionStatementSuffixSkewedLocation"


    public static class skewedLocations_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "skewedLocations"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1077:1: skewedLocations : LPAREN skewedLocationsList RPAREN -> ^( TOK_SKEWED_LOCATIONS skewedLocationsList ) ;
    public final HiveParser.skewedLocations_return skewedLocations() throws RecognitionException {
        HiveParser.skewedLocations_return retval = new HiveParser.skewedLocations_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token LPAREN279=null;
        Token RPAREN281=null;
        HiveParser.skewedLocationsList_return skewedLocationsList280 =null;


        CommonTree LPAREN279_tree=null;
        CommonTree RPAREN281_tree=null;
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleSubtreeStream stream_skewedLocationsList=new RewriteRuleSubtreeStream(adaptor,"rule skewedLocationsList");
         msgs.push("skewed locations"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1080:5: ( LPAREN skewedLocationsList RPAREN -> ^( TOK_SKEWED_LOCATIONS skewedLocationsList ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1081:7: LPAREN skewedLocationsList RPAREN
            {
            LPAREN279=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_skewedLocations5067);  
            stream_LPAREN.add(LPAREN279);


            pushFollow(FOLLOW_skewedLocationsList_in_skewedLocations5069);
            skewedLocationsList280=skewedLocationsList();

            state._fsp--;

            stream_skewedLocationsList.add(skewedLocationsList280.getTree());

            RPAREN281=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_skewedLocations5071);  
            stream_RPAREN.add(RPAREN281);


            // AST REWRITE
            // elements: skewedLocationsList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1081:41: -> ^( TOK_SKEWED_LOCATIONS skewedLocationsList )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1081:44: ^( TOK_SKEWED_LOCATIONS skewedLocationsList )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_SKEWED_LOCATIONS, "TOK_SKEWED_LOCATIONS")
                , root_1);

                adaptor.addChild(root_1, stream_skewedLocationsList.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "skewedLocations"


    public static class skewedLocationsList_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "skewedLocationsList"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1084:1: skewedLocationsList : skewedLocationMap ( COMMA skewedLocationMap )* -> ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ ) ;
    public final HiveParser.skewedLocationsList_return skewedLocationsList() throws RecognitionException {
        HiveParser.skewedLocationsList_return retval = new HiveParser.skewedLocationsList_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token COMMA283=null;
        HiveParser.skewedLocationMap_return skewedLocationMap282 =null;

        HiveParser.skewedLocationMap_return skewedLocationMap284 =null;


        CommonTree COMMA283_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_skewedLocationMap=new RewriteRuleSubtreeStream(adaptor,"rule skewedLocationMap");
         msgs.push("skewed locations list"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1087:5: ( skewedLocationMap ( COMMA skewedLocationMap )* -> ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1088:7: skewedLocationMap ( COMMA skewedLocationMap )*
            {
            pushFollow(FOLLOW_skewedLocationMap_in_skewedLocationsList5112);
            skewedLocationMap282=skewedLocationMap();

            state._fsp--;

            stream_skewedLocationMap.add(skewedLocationMap282.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1088:25: ( COMMA skewedLocationMap )*
            loop76:
            do {
                int alt76=2;
                int LA76_0 = input.LA(1);

                if ( (LA76_0==COMMA) ) {
                    alt76=1;
                }


                switch (alt76) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1088:26: COMMA skewedLocationMap
            	    {
            	    COMMA283=(Token)match(input,COMMA,FOLLOW_COMMA_in_skewedLocationsList5115);  
            	    stream_COMMA.add(COMMA283);


            	    pushFollow(FOLLOW_skewedLocationMap_in_skewedLocationsList5117);
            	    skewedLocationMap284=skewedLocationMap();

            	    state._fsp--;

            	    stream_skewedLocationMap.add(skewedLocationMap284.getTree());

            	    }
            	    break;

            	default :
            	    break loop76;
                }
            } while (true);


            // AST REWRITE
            // elements: skewedLocationMap
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1088:52: -> ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1088:55: ^( TOK_SKEWED_LOCATION_LIST ( skewedLocationMap )+ )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_SKEWED_LOCATION_LIST, "TOK_SKEWED_LOCATION_LIST")
                , root_1);

                if ( !(stream_skewedLocationMap.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_skewedLocationMap.hasNext() ) {
                    adaptor.addChild(root_1, stream_skewedLocationMap.nextTree());

                }
                stream_skewedLocationMap.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "skewedLocationsList"


    public static class skewedLocationMap_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "skewedLocationMap"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1091:1: skewedLocationMap : key= skewedValueLocationElement EQUAL value= StringLiteral -> ^( TOK_SKEWED_LOCATION_MAP $key $value) ;
    public final HiveParser.skewedLocationMap_return skewedLocationMap() throws RecognitionException {
        HiveParser.skewedLocationMap_return retval = new HiveParser.skewedLocationMap_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token value=null;
        Token EQUAL285=null;
        HiveParser.skewedValueLocationElement_return key =null;


        CommonTree value_tree=null;
        CommonTree EQUAL285_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_EQUAL=new RewriteRuleTokenStream(adaptor,"token EQUAL");
        RewriteRuleSubtreeStream stream_skewedValueLocationElement=new RewriteRuleSubtreeStream(adaptor,"rule skewedValueLocationElement");
         msgs.push("specifying skewed location map"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1094:5: (key= skewedValueLocationElement EQUAL value= StringLiteral -> ^( TOK_SKEWED_LOCATION_MAP $key $value) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1095:7: key= skewedValueLocationElement EQUAL value= StringLiteral
            {
            pushFollow(FOLLOW_skewedValueLocationElement_in_skewedLocationMap5163);
            key=skewedValueLocationElement();

            state._fsp--;

            stream_skewedValueLocationElement.add(key.getTree());

            EQUAL285=(Token)match(input,EQUAL,FOLLOW_EQUAL_in_skewedLocationMap5165);  
            stream_EQUAL.add(EQUAL285);


            value=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_skewedLocationMap5169);  
            stream_StringLiteral.add(value);


            // AST REWRITE
            // elements: value, key
            // token labels: value
            // rule labels: retval, key
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_value=new RewriteRuleTokenStream(adaptor,"token value",value);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_key=new RewriteRuleSubtreeStream(adaptor,"rule key",key!=null?key.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1095:64: -> ^( TOK_SKEWED_LOCATION_MAP $key $value)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1095:67: ^( TOK_SKEWED_LOCATION_MAP $key $value)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_SKEWED_LOCATION_MAP, "TOK_SKEWED_LOCATION_MAP")
                , root_1);

                adaptor.addChild(root_1, stream_key.nextTree());

                adaptor.addChild(root_1, stream_value.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "skewedLocationMap"


    public static class alterStatementSuffixLocation_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixLocation"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1098:1: alterStatementSuffixLocation : KW_SET KW_LOCATION newLoc= StringLiteral -> ^( TOK_ALTERTABLE_LOCATION $newLoc) ;
    public final HiveParser.alterStatementSuffixLocation_return alterStatementSuffixLocation() throws RecognitionException {
        HiveParser.alterStatementSuffixLocation_return retval = new HiveParser.alterStatementSuffixLocation_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token newLoc=null;
        Token KW_SET286=null;
        Token KW_LOCATION287=null;

        CommonTree newLoc_tree=null;
        CommonTree KW_SET286_tree=null;
        CommonTree KW_LOCATION287_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_SET=new RewriteRuleTokenStream(adaptor,"token KW_SET");
        RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");

        msgs.push("alter location");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1101:3: ( KW_SET KW_LOCATION newLoc= StringLiteral -> ^( TOK_ALTERTABLE_LOCATION $newLoc) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1101:5: KW_SET KW_LOCATION newLoc= StringLiteral
            {
            KW_SET286=(Token)match(input,KW_SET,FOLLOW_KW_SET_in_alterStatementSuffixLocation5206);  
            stream_KW_SET.add(KW_SET286);


            KW_LOCATION287=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_alterStatementSuffixLocation5208);  
            stream_KW_LOCATION.add(KW_LOCATION287);


            newLoc=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_alterStatementSuffixLocation5212);  
            stream_StringLiteral.add(newLoc);


            // AST REWRITE
            // elements: newLoc
            // token labels: newLoc
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_newLoc=new RewriteRuleTokenStream(adaptor,"token newLoc",newLoc);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1102:3: -> ^( TOK_ALTERTABLE_LOCATION $newLoc)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1102:6: ^( TOK_ALTERTABLE_LOCATION $newLoc)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_ALTERTABLE_LOCATION, "TOK_ALTERTABLE_LOCATION")
                , root_1);

                adaptor.addChild(root_1, stream_newLoc.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixLocation"


    public static class alterStatementSuffixSkewedby_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixSkewedby"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1106:1: alterStatementSuffixSkewedby : (name= identifier tableSkewed -> ^( TOK_ALTERTABLE_SKEWED $name tableSkewed ) |name= identifier KW_NOT KW_SKEWED -> ^( TOK_ALTERTABLE_SKEWED $name) |name= identifier KW_NOT storedAsDirs -> ^( TOK_ALTERTABLE_SKEWED $name storedAsDirs ) );
    public final HiveParser.alterStatementSuffixSkewedby_return alterStatementSuffixSkewedby() throws RecognitionException {
        HiveParser.alterStatementSuffixSkewedby_return retval = new HiveParser.alterStatementSuffixSkewedby_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_NOT289=null;
        Token KW_SKEWED290=null;
        Token KW_NOT291=null;
        HiveParser_IdentifiersParser.identifier_return name =null;

        HiveParser.tableSkewed_return tableSkewed288 =null;

        HiveParser.storedAsDirs_return storedAsDirs292 =null;


        CommonTree KW_NOT289_tree=null;
        CommonTree KW_SKEWED290_tree=null;
        CommonTree KW_NOT291_tree=null;
        RewriteRuleTokenStream stream_KW_SKEWED=new RewriteRuleTokenStream(adaptor,"token KW_SKEWED");
        RewriteRuleTokenStream stream_KW_NOT=new RewriteRuleTokenStream(adaptor,"token KW_NOT");
        RewriteRuleSubtreeStream stream_storedAsDirs=new RewriteRuleSubtreeStream(adaptor,"rule storedAsDirs");
        RewriteRuleSubtreeStream stream_tableSkewed=new RewriteRuleSubtreeStream(adaptor,"rule tableSkewed");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        msgs.push("alter skewed by statement");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1109:2: (name= identifier tableSkewed -> ^( TOK_ALTERTABLE_SKEWED $name tableSkewed ) |name= identifier KW_NOT KW_SKEWED -> ^( TOK_ALTERTABLE_SKEWED $name) |name= identifier KW_NOT storedAsDirs -> ^( TOK_ALTERTABLE_SKEWED $name storedAsDirs ) )
            int alt77=3;
            int LA77_0 = input.LA(1);

            if ( (LA77_0==Identifier) ) {
                int LA77_1 = input.LA(2);

                if ( (LA77_1==KW_SKEWED) ) {
                    alt77=1;
                }
                else if ( (LA77_1==KW_NOT) ) {
                    int LA77_4 = input.LA(3);

                    if ( (LA77_4==KW_SKEWED) ) {
                        alt77=2;
                    }
                    else if ( (LA77_4==KW_STORED) ) {
                        alt77=3;
                    }
                    else {
                        NoViableAltException nvae =
                            new NoViableAltException("", 77, 4, input);

                        throw nvae;

                    }
                }
                else {
                    NoViableAltException nvae =
                        new NoViableAltException("", 77, 1, input);

                    throw nvae;

                }
            }
            else if ( ((LA77_0 >= KW_ADD && LA77_0 <= KW_AFTER)||(LA77_0 >= KW_ALTER && LA77_0 <= KW_ANALYZE)||(LA77_0 >= KW_ARCHIVE && LA77_0 <= KW_CASCADE)||(LA77_0 >= KW_CHANGE && LA77_0 <= KW_COLLECTION)||(LA77_0 >= KW_COLUMNS && LA77_0 <= KW_CREATE)||LA77_0==KW_CUBE||(LA77_0 >= KW_CURSOR && LA77_0 <= KW_DATA)||(LA77_0 >= KW_DATABASES && LA77_0 <= KW_DISABLE)||(LA77_0 >= KW_DISTRIBUTE && LA77_0 <= KW_ELEM_TYPE)||LA77_0==KW_ENABLE||LA77_0==KW_ESCAPED||(LA77_0 >= KW_EXCLUSIVE && LA77_0 <= KW_EXPORT)||(LA77_0 >= KW_EXTERNAL && LA77_0 <= KW_FLOAT)||(LA77_0 >= KW_FOR && LA77_0 <= KW_FORMATTED)||LA77_0==KW_FULL||(LA77_0 >= KW_FUNCTIONS && LA77_0 <= KW_GROUPING)||(LA77_0 >= KW_HOLD_DDLTIME && LA77_0 <= KW_IDXPROPERTIES)||(LA77_0 >= KW_IGNORE && LA77_0 <= KW_ITEMS)||(LA77_0 >= KW_KEYS && LA77_0 <= KW_LEFT)||(LA77_0 >= KW_LIKE && LA77_0 <= KW_LONG)||(LA77_0 >= KW_MAPJOIN && LA77_0 <= KW_MINUS)||(LA77_0 >= KW_MSCK && LA77_0 <= KW_NOSCAN)||(LA77_0 >= KW_NO_DROP && LA77_0 <= KW_OFFLINE)||LA77_0==KW_OPTION||(LA77_0 >= KW_ORCFILE && LA77_0 <= KW_OUTPUTFORMAT)||LA77_0==KW_OVERWRITE||(LA77_0 >= KW_PARTITION && LA77_0 <= KW_PLUS)||(LA77_0 >= KW_PRETTY && LA77_0 <= KW_RECORDWRITER)||(LA77_0 >= KW_REGEXP && LA77_0 <= KW_SCHEMAS)||(LA77_0 >= KW_SEMI && LA77_0 <= KW_TABLES)||(LA77_0 >= KW_TBLPROPERTIES && LA77_0 <= KW_TEXTFILE)||(LA77_0 >= KW_TIMESTAMP && LA77_0 <= KW_TOUCH)||(LA77_0 >= KW_TRIGGER && LA77_0 <= KW_UNARCHIVE)||(LA77_0 >= KW_UNDO && LA77_0 <= KW_UNIONTYPE)||(LA77_0 >= KW_UNLOCK && LA77_0 <= KW_VALUE_TYPE)||LA77_0==KW_VIEW||LA77_0==KW_WHILE||LA77_0==KW_WITH) ) {
                int LA77_2 = input.LA(2);

                if ( (LA77_2==KW_SKEWED) ) {
                    alt77=1;
                }
                else if ( (LA77_2==KW_NOT) ) {
                    int LA77_6 = input.LA(3);

                    if ( (LA77_6==KW_SKEWED) ) {
                        alt77=2;
                    }
                    else if ( (LA77_6==KW_STORED) ) {
                        alt77=3;
                    }
                    else {
                        NoViableAltException nvae =
                            new NoViableAltException("", 77, 6, input);

                        throw nvae;

                    }
                }
                else {
                    NoViableAltException nvae =
                        new NoViableAltException("", 77, 2, input);

                    throw nvae;

                }
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 77, 0, input);

                throw nvae;

            }
            switch (alt77) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1109:3: name= identifier tableSkewed
                    {
                    pushFollow(FOLLOW_identifier_in_alterStatementSuffixSkewedby5247);
                    name=identifier();

                    state._fsp--;

                    stream_identifier.add(name.getTree());

                    pushFollow(FOLLOW_tableSkewed_in_alterStatementSuffixSkewedby5249);
                    tableSkewed288=tableSkewed();

                    state._fsp--;

                    stream_tableSkewed.add(tableSkewed288.getTree());

                    // AST REWRITE
                    // elements: name, tableSkewed
                    // token labels: 
                    // rule labels: retval, name
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1110:2: -> ^( TOK_ALTERTABLE_SKEWED $name tableSkewed )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1110:4: ^( TOK_ALTERTABLE_SKEWED $name tableSkewed )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERTABLE_SKEWED, "TOK_ALTERTABLE_SKEWED")
                        , root_1);

                        adaptor.addChild(root_1, stream_name.nextTree());

                        adaptor.addChild(root_1, stream_tableSkewed.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1112:2: name= identifier KW_NOT KW_SKEWED
                    {
                    pushFollow(FOLLOW_identifier_in_alterStatementSuffixSkewedby5268);
                    name=identifier();

                    state._fsp--;

                    stream_identifier.add(name.getTree());

                    KW_NOT289=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby5270);  
                    stream_KW_NOT.add(KW_NOT289);


                    KW_SKEWED290=(Token)match(input,KW_SKEWED,FOLLOW_KW_SKEWED_in_alterStatementSuffixSkewedby5272);  
                    stream_KW_SKEWED.add(KW_SKEWED290);


                    // AST REWRITE
                    // elements: name
                    // token labels: 
                    // rule labels: retval, name
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1113:2: -> ^( TOK_ALTERTABLE_SKEWED $name)
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1113:4: ^( TOK_ALTERTABLE_SKEWED $name)
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERTABLE_SKEWED, "TOK_ALTERTABLE_SKEWED")
                        , root_1);

                        adaptor.addChild(root_1, stream_name.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1115:2: name= identifier KW_NOT storedAsDirs
                    {
                    pushFollow(FOLLOW_identifier_in_alterStatementSuffixSkewedby5289);
                    name=identifier();

                    state._fsp--;

                    stream_identifier.add(name.getTree());

                    KW_NOT291=(Token)match(input,KW_NOT,FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby5291);  
                    stream_KW_NOT.add(KW_NOT291);


                    pushFollow(FOLLOW_storedAsDirs_in_alterStatementSuffixSkewedby5293);
                    storedAsDirs292=storedAsDirs();

                    state._fsp--;

                    stream_storedAsDirs.add(storedAsDirs292.getTree());

                    // AST REWRITE
                    // elements: name, storedAsDirs
                    // token labels: 
                    // rule labels: retval, name
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1116:2: -> ^( TOK_ALTERTABLE_SKEWED $name storedAsDirs )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1116:4: ^( TOK_ALTERTABLE_SKEWED $name storedAsDirs )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ALTERTABLE_SKEWED, "TOK_ALTERTABLE_SKEWED")
                        , root_1);

                        adaptor.addChild(root_1, stream_name.nextTree());

                        adaptor.addChild(root_1, stream_storedAsDirs.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixSkewedby"


    public static class alterStatementSuffixExchangePartition_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixExchangePartition"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1119:1: alterStatementSuffixExchangePartition : name= tableName KW_EXCHANGE partitionSpec KW_WITH KW_TABLE exchangename= tableName -> ^( TOK_EXCHANGEPARTITION $name partitionSpec $exchangename) ;
    public final HiveParser.alterStatementSuffixExchangePartition_return alterStatementSuffixExchangePartition() throws RecognitionException {
        HiveParser.alterStatementSuffixExchangePartition_return retval = new HiveParser.alterStatementSuffixExchangePartition_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_EXCHANGE293=null;
        Token KW_WITH295=null;
        Token KW_TABLE296=null;
        HiveParser_FromClauseParser.tableName_return name =null;

        HiveParser_FromClauseParser.tableName_return exchangename =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec294 =null;


        CommonTree KW_EXCHANGE293_tree=null;
        CommonTree KW_WITH295_tree=null;
        CommonTree KW_TABLE296_tree=null;
        RewriteRuleTokenStream stream_KW_EXCHANGE=new RewriteRuleTokenStream(adaptor,"token KW_EXCHANGE");
        RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        msgs.push("alter exchange partition");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1122:5: (name= tableName KW_EXCHANGE partitionSpec KW_WITH KW_TABLE exchangename= tableName -> ^( TOK_EXCHANGEPARTITION $name partitionSpec $exchangename) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1122:7: name= tableName KW_EXCHANGE partitionSpec KW_WITH KW_TABLE exchangename= tableName
            {
            pushFollow(FOLLOW_tableName_in_alterStatementSuffixExchangePartition5329);
            name=tableName();

            state._fsp--;

            stream_tableName.add(name.getTree());

            KW_EXCHANGE293=(Token)match(input,KW_EXCHANGE,FOLLOW_KW_EXCHANGE_in_alterStatementSuffixExchangePartition5331);  
            stream_KW_EXCHANGE.add(KW_EXCHANGE293);


            pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixExchangePartition5333);
            partitionSpec294=partitionSpec();

            state._fsp--;

            stream_partitionSpec.add(partitionSpec294.getTree());

            KW_WITH295=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_alterStatementSuffixExchangePartition5335);  
            stream_KW_WITH.add(KW_WITH295);


            KW_TABLE296=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_alterStatementSuffixExchangePartition5337);  
            stream_KW_TABLE.add(KW_TABLE296);


            pushFollow(FOLLOW_tableName_in_alterStatementSuffixExchangePartition5341);
            exchangename=tableName();

            state._fsp--;

            stream_tableName.add(exchangename.getTree());

            // AST REWRITE
            // elements: exchangename, name, partitionSpec
            // token labels: 
            // rule labels: exchangename, retval, name
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_exchangename=new RewriteRuleSubtreeStream(adaptor,"rule exchangename",exchangename!=null?exchangename.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1123:5: -> ^( TOK_EXCHANGEPARTITION $name partitionSpec $exchangename)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1123:8: ^( TOK_EXCHANGEPARTITION $name partitionSpec $exchangename)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_EXCHANGEPARTITION, "TOK_EXCHANGEPARTITION")
                , root_1);

                adaptor.addChild(root_1, stream_name.nextTree());

                adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                adaptor.addChild(root_1, stream_exchangename.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixExchangePartition"


    public static class alterStatementSuffixProtectMode_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixProtectMode"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1126:1: alterStatementSuffixProtectMode : alterProtectMode -> ^( TOK_ALTERTABLE_ALTERPARTS_PROTECTMODE alterProtectMode ) ;
    public final HiveParser.alterStatementSuffixProtectMode_return alterStatementSuffixProtectMode() throws RecognitionException {
        HiveParser.alterStatementSuffixProtectMode_return retval = new HiveParser.alterStatementSuffixProtectMode_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser.alterProtectMode_return alterProtectMode297 =null;


        RewriteRuleSubtreeStream stream_alterProtectMode=new RewriteRuleSubtreeStream(adaptor,"rule alterProtectMode");
         msgs.push("alter partition protect mode statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1129:5: ( alterProtectMode -> ^( TOK_ALTERTABLE_ALTERPARTS_PROTECTMODE alterProtectMode ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1129:7: alterProtectMode
            {
            pushFollow(FOLLOW_alterProtectMode_in_alterStatementSuffixProtectMode5386);
            alterProtectMode297=alterProtectMode();

            state._fsp--;

            stream_alterProtectMode.add(alterProtectMode297.getTree());

            // AST REWRITE
            // elements: alterProtectMode
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1130:5: -> ^( TOK_ALTERTABLE_ALTERPARTS_PROTECTMODE alterProtectMode )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1130:8: ^( TOK_ALTERTABLE_ALTERPARTS_PROTECTMODE alterProtectMode )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_ALTERTABLE_ALTERPARTS_PROTECTMODE, "TOK_ALTERTABLE_ALTERPARTS_PROTECTMODE")
                , root_1);

                adaptor.addChild(root_1, stream_alterProtectMode.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixProtectMode"


    public static class alterStatementSuffixRenamePart_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixRenamePart"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1133:1: alterStatementSuffixRenamePart : KW_RENAME KW_TO partitionSpec -> ^( TOK_ALTERTABLE_RENAMEPART partitionSpec ) ;
    public final HiveParser.alterStatementSuffixRenamePart_return alterStatementSuffixRenamePart() throws RecognitionException {
        HiveParser.alterStatementSuffixRenamePart_return retval = new HiveParser.alterStatementSuffixRenamePart_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_RENAME298=null;
        Token KW_TO299=null;
        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec300 =null;


        CommonTree KW_RENAME298_tree=null;
        CommonTree KW_TO299_tree=null;
        RewriteRuleTokenStream stream_KW_RENAME=new RewriteRuleTokenStream(adaptor,"token KW_RENAME");
        RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
         msgs.push("alter table rename partition statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1136:5: ( KW_RENAME KW_TO partitionSpec -> ^( TOK_ALTERTABLE_RENAMEPART partitionSpec ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1136:7: KW_RENAME KW_TO partitionSpec
            {
            KW_RENAME298=(Token)match(input,KW_RENAME,FOLLOW_KW_RENAME_in_alterStatementSuffixRenamePart5425);  
            stream_KW_RENAME.add(KW_RENAME298);


            KW_TO299=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_alterStatementSuffixRenamePart5427);  
            stream_KW_TO.add(KW_TO299);


            pushFollow(FOLLOW_partitionSpec_in_alterStatementSuffixRenamePart5429);
            partitionSpec300=partitionSpec();

            state._fsp--;

            stream_partitionSpec.add(partitionSpec300.getTree());

            // AST REWRITE
            // elements: partitionSpec
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1137:5: -> ^( TOK_ALTERTABLE_RENAMEPART partitionSpec )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1137:7: ^( TOK_ALTERTABLE_RENAMEPART partitionSpec )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_ALTERTABLE_RENAMEPART, "TOK_ALTERTABLE_RENAMEPART")
                , root_1);

                adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixRenamePart"


    public static class alterStatementSuffixMergeFiles_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixMergeFiles"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1140:1: alterStatementSuffixMergeFiles : KW_CONCATENATE -> ^( TOK_ALTERTABLE_ALTERPARTS_MERGEFILES ) ;
    public final HiveParser.alterStatementSuffixMergeFiles_return alterStatementSuffixMergeFiles() throws RecognitionException {
        HiveParser.alterStatementSuffixMergeFiles_return retval = new HiveParser.alterStatementSuffixMergeFiles_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_CONCATENATE301=null;

        CommonTree KW_CONCATENATE301_tree=null;
        RewriteRuleTokenStream stream_KW_CONCATENATE=new RewriteRuleTokenStream(adaptor,"token KW_CONCATENATE");

         msgs.push(""); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1143:5: ( KW_CONCATENATE -> ^( TOK_ALTERTABLE_ALTERPARTS_MERGEFILES ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1143:7: KW_CONCATENATE
            {
            KW_CONCATENATE301=(Token)match(input,KW_CONCATENATE,FOLLOW_KW_CONCATENATE_in_alterStatementSuffixMergeFiles5467);  
            stream_KW_CONCATENATE.add(KW_CONCATENATE301);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1144:5: -> ^( TOK_ALTERTABLE_ALTERPARTS_MERGEFILES )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1144:8: ^( TOK_ALTERTABLE_ALTERPARTS_MERGEFILES )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_ALTERTABLE_ALTERPARTS_MERGEFILES, "TOK_ALTERTABLE_ALTERPARTS_MERGEFILES")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixMergeFiles"


    public static class alterProtectMode_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterProtectMode"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1147:1: alterProtectMode : ( KW_ENABLE alterProtectModeMode -> ^( TOK_ENABLE alterProtectModeMode ) | KW_DISABLE alterProtectModeMode -> ^( TOK_DISABLE alterProtectModeMode ) );
    public final HiveParser.alterProtectMode_return alterProtectMode() throws RecognitionException {
        HiveParser.alterProtectMode_return retval = new HiveParser.alterProtectMode_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_ENABLE302=null;
        Token KW_DISABLE304=null;
        HiveParser.alterProtectModeMode_return alterProtectModeMode303 =null;

        HiveParser.alterProtectModeMode_return alterProtectModeMode305 =null;


        CommonTree KW_ENABLE302_tree=null;
        CommonTree KW_DISABLE304_tree=null;
        RewriteRuleTokenStream stream_KW_DISABLE=new RewriteRuleTokenStream(adaptor,"token KW_DISABLE");
        RewriteRuleTokenStream stream_KW_ENABLE=new RewriteRuleTokenStream(adaptor,"token KW_ENABLE");
        RewriteRuleSubtreeStream stream_alterProtectModeMode=new RewriteRuleSubtreeStream(adaptor,"rule alterProtectModeMode");
         msgs.push("protect mode specification enable"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1150:5: ( KW_ENABLE alterProtectModeMode -> ^( TOK_ENABLE alterProtectModeMode ) | KW_DISABLE alterProtectModeMode -> ^( TOK_DISABLE alterProtectModeMode ) )
            int alt78=2;
            int LA78_0 = input.LA(1);

            if ( (LA78_0==KW_ENABLE) ) {
                alt78=1;
            }
            else if ( (LA78_0==KW_DISABLE) ) {
                alt78=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 78, 0, input);

                throw nvae;

            }
            switch (alt78) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1150:7: KW_ENABLE alterProtectModeMode
                    {
                    KW_ENABLE302=(Token)match(input,KW_ENABLE,FOLLOW_KW_ENABLE_in_alterProtectMode5504);  
                    stream_KW_ENABLE.add(KW_ENABLE302);


                    pushFollow(FOLLOW_alterProtectModeMode_in_alterProtectMode5506);
                    alterProtectModeMode303=alterProtectModeMode();

                    state._fsp--;

                    stream_alterProtectModeMode.add(alterProtectModeMode303.getTree());

                    // AST REWRITE
                    // elements: alterProtectModeMode
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1150:39: -> ^( TOK_ENABLE alterProtectModeMode )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1150:42: ^( TOK_ENABLE alterProtectModeMode )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ENABLE, "TOK_ENABLE")
                        , root_1);

                        adaptor.addChild(root_1, stream_alterProtectModeMode.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1151:7: KW_DISABLE alterProtectModeMode
                    {
                    KW_DISABLE304=(Token)match(input,KW_DISABLE,FOLLOW_KW_DISABLE_in_alterProtectMode5523);  
                    stream_KW_DISABLE.add(KW_DISABLE304);


                    pushFollow(FOLLOW_alterProtectModeMode_in_alterProtectMode5525);
                    alterProtectModeMode305=alterProtectModeMode();

                    state._fsp--;

                    stream_alterProtectModeMode.add(alterProtectModeMode305.getTree());

                    // AST REWRITE
                    // elements: alterProtectModeMode
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1151:40: -> ^( TOK_DISABLE alterProtectModeMode )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1151:43: ^( TOK_DISABLE alterProtectModeMode )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_DISABLE, "TOK_DISABLE")
                        , root_1);

                        adaptor.addChild(root_1, stream_alterProtectModeMode.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterProtectMode"


    public static class alterProtectModeMode_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterProtectModeMode"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1154:1: alterProtectModeMode : ( KW_OFFLINE -> ^( TOK_OFFLINE ) | KW_NO_DROP ( KW_CASCADE )? -> ^( TOK_NO_DROP ( KW_CASCADE )? ) | KW_READONLY -> ^( TOK_READONLY ) );
    public final HiveParser.alterProtectModeMode_return alterProtectModeMode() throws RecognitionException {
        HiveParser.alterProtectModeMode_return retval = new HiveParser.alterProtectModeMode_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_OFFLINE306=null;
        Token KW_NO_DROP307=null;
        Token KW_CASCADE308=null;
        Token KW_READONLY309=null;

        CommonTree KW_OFFLINE306_tree=null;
        CommonTree KW_NO_DROP307_tree=null;
        CommonTree KW_CASCADE308_tree=null;
        CommonTree KW_READONLY309_tree=null;
        RewriteRuleTokenStream stream_KW_READONLY=new RewriteRuleTokenStream(adaptor,"token KW_READONLY");
        RewriteRuleTokenStream stream_KW_NO_DROP=new RewriteRuleTokenStream(adaptor,"token KW_NO_DROP");
        RewriteRuleTokenStream stream_KW_CASCADE=new RewriteRuleTokenStream(adaptor,"token KW_CASCADE");
        RewriteRuleTokenStream stream_KW_OFFLINE=new RewriteRuleTokenStream(adaptor,"token KW_OFFLINE");

         msgs.push("protect mode specification enable"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1157:5: ( KW_OFFLINE -> ^( TOK_OFFLINE ) | KW_NO_DROP ( KW_CASCADE )? -> ^( TOK_NO_DROP ( KW_CASCADE )? ) | KW_READONLY -> ^( TOK_READONLY ) )
            int alt80=3;
            switch ( input.LA(1) ) {
            case KW_OFFLINE:
                {
                alt80=1;
                }
                break;
            case KW_NO_DROP:
                {
                alt80=2;
                }
                break;
            case KW_READONLY:
                {
                alt80=3;
                }
                break;
            default:
                NoViableAltException nvae =
                    new NoViableAltException("", 80, 0, input);

                throw nvae;

            }

            switch (alt80) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1157:7: KW_OFFLINE
                    {
                    KW_OFFLINE306=(Token)match(input,KW_OFFLINE,FOLLOW_KW_OFFLINE_in_alterProtectModeMode5561);  
                    stream_KW_OFFLINE.add(KW_OFFLINE306);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1157:19: -> ^( TOK_OFFLINE )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1157:22: ^( TOK_OFFLINE )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_OFFLINE, "TOK_OFFLINE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1158:7: KW_NO_DROP ( KW_CASCADE )?
                    {
                    KW_NO_DROP307=(Token)match(input,KW_NO_DROP,FOLLOW_KW_NO_DROP_in_alterProtectModeMode5576);  
                    stream_KW_NO_DROP.add(KW_NO_DROP307);


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1158:18: ( KW_CASCADE )?
                    int alt79=2;
                    int LA79_0 = input.LA(1);

                    if ( (LA79_0==KW_CASCADE) ) {
                        alt79=1;
                    }
                    switch (alt79) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1158:18: KW_CASCADE
                            {
                            KW_CASCADE308=(Token)match(input,KW_CASCADE,FOLLOW_KW_CASCADE_in_alterProtectModeMode5578);  
                            stream_KW_CASCADE.add(KW_CASCADE308);


                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: KW_CASCADE
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1158:30: -> ^( TOK_NO_DROP ( KW_CASCADE )? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1158:33: ^( TOK_NO_DROP ( KW_CASCADE )? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_NO_DROP, "TOK_NO_DROP")
                        , root_1);

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1158:47: ( KW_CASCADE )?
                        if ( stream_KW_CASCADE.hasNext() ) {
                            adaptor.addChild(root_1, 
                            stream_KW_CASCADE.nextNode()
                            );

                        }
                        stream_KW_CASCADE.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1159:7: KW_READONLY
                    {
                    KW_READONLY309=(Token)match(input,KW_READONLY,FOLLOW_KW_READONLY_in_alterProtectModeMode5596);  
                    stream_KW_READONLY.add(KW_READONLY309);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1159:20: -> ^( TOK_READONLY )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1159:23: ^( TOK_READONLY )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_READONLY, "TOK_READONLY")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterProtectModeMode"


    public static class alterStatementSuffixBucketNum_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "alterStatementSuffixBucketNum"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1162:1: alterStatementSuffixBucketNum : KW_INTO num= Number KW_BUCKETS -> ^( TOK_TABLEBUCKETS $num) ;
    public final HiveParser.alterStatementSuffixBucketNum_return alterStatementSuffixBucketNum() throws RecognitionException {
        HiveParser.alterStatementSuffixBucketNum_return retval = new HiveParser.alterStatementSuffixBucketNum_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token num=null;
        Token KW_INTO310=null;
        Token KW_BUCKETS311=null;

        CommonTree num_tree=null;
        CommonTree KW_INTO310_tree=null;
        CommonTree KW_BUCKETS311_tree=null;
        RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
        RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
        RewriteRuleTokenStream stream_KW_BUCKETS=new RewriteRuleTokenStream(adaptor,"token KW_BUCKETS");

         msgs.push(""); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1165:5: ( KW_INTO num= Number KW_BUCKETS -> ^( TOK_TABLEBUCKETS $num) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1165:7: KW_INTO num= Number KW_BUCKETS
            {
            KW_INTO310=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_alterStatementSuffixBucketNum5630);  
            stream_KW_INTO.add(KW_INTO310);


            num=(Token)match(input,Number,FOLLOW_Number_in_alterStatementSuffixBucketNum5634);  
            stream_Number.add(num);


            KW_BUCKETS311=(Token)match(input,KW_BUCKETS,FOLLOW_KW_BUCKETS_in_alterStatementSuffixBucketNum5636);  
            stream_KW_BUCKETS.add(KW_BUCKETS311);


            // AST REWRITE
            // elements: num
            // token labels: num
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_num=new RewriteRuleTokenStream(adaptor,"token num",num);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1166:5: -> ^( TOK_TABLEBUCKETS $num)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1166:8: ^( TOK_TABLEBUCKETS $num)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABLEBUCKETS, "TOK_TABLEBUCKETS")
                , root_1);

                adaptor.addChild(root_1, stream_num.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "alterStatementSuffixBucketNum"


    public static class fileFormat_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "fileFormat"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1169:1: fileFormat : ( KW_SEQUENCEFILE -> ^( TOK_TBLSEQUENCEFILE ) | KW_TEXTFILE -> ^( TOK_TBLTEXTFILE ) | KW_RCFILE -> ^( TOK_TBLRCFILE ) | KW_ORCFILE -> ^( TOK_TBLORCFILE ) | KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? ) |genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) );
    public final HiveParser.fileFormat_return fileFormat() throws RecognitionException {
        HiveParser.fileFormat_return retval = new HiveParser.fileFormat_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token inFmt=null;
        Token outFmt=null;
        Token inDriver=null;
        Token outDriver=null;
        Token KW_SEQUENCEFILE312=null;
        Token KW_TEXTFILE313=null;
        Token KW_RCFILE314=null;
        Token KW_ORCFILE315=null;
        Token KW_INPUTFORMAT316=null;
        Token KW_OUTPUTFORMAT317=null;
        Token KW_INPUTDRIVER318=null;
        Token KW_OUTPUTDRIVER319=null;
        HiveParser_IdentifiersParser.identifier_return genericSpec =null;


        CommonTree inFmt_tree=null;
        CommonTree outFmt_tree=null;
        CommonTree inDriver_tree=null;
        CommonTree outDriver_tree=null;
        CommonTree KW_SEQUENCEFILE312_tree=null;
        CommonTree KW_TEXTFILE313_tree=null;
        CommonTree KW_RCFILE314_tree=null;
        CommonTree KW_ORCFILE315_tree=null;
        CommonTree KW_INPUTFORMAT316_tree=null;
        CommonTree KW_OUTPUTFORMAT317_tree=null;
        CommonTree KW_INPUTDRIVER318_tree=null;
        CommonTree KW_OUTPUTDRIVER319_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_INPUTDRIVER=new RewriteRuleTokenStream(adaptor,"token KW_INPUTDRIVER");
        RewriteRuleTokenStream stream_KW_RCFILE=new RewriteRuleTokenStream(adaptor,"token KW_RCFILE");
        RewriteRuleTokenStream stream_KW_INPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_INPUTFORMAT");
        RewriteRuleTokenStream stream_KW_OUTPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_OUTPUTFORMAT");
        RewriteRuleTokenStream stream_KW_OUTPUTDRIVER=new RewriteRuleTokenStream(adaptor,"token KW_OUTPUTDRIVER");
        RewriteRuleTokenStream stream_KW_SEQUENCEFILE=new RewriteRuleTokenStream(adaptor,"token KW_SEQUENCEFILE");
        RewriteRuleTokenStream stream_KW_ORCFILE=new RewriteRuleTokenStream(adaptor,"token KW_ORCFILE");
        RewriteRuleTokenStream stream_KW_TEXTFILE=new RewriteRuleTokenStream(adaptor,"token KW_TEXTFILE");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("file format specification"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1172:5: ( KW_SEQUENCEFILE -> ^( TOK_TBLSEQUENCEFILE ) | KW_TEXTFILE -> ^( TOK_TBLTEXTFILE ) | KW_RCFILE -> ^( TOK_TBLRCFILE ) | KW_ORCFILE -> ^( TOK_TBLORCFILE ) | KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? ) |genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) )
            int alt82=6;
            switch ( input.LA(1) ) {
            case KW_SEQUENCEFILE:
                {
                alt82=1;
                }
                break;
            case KW_TEXTFILE:
                {
                alt82=2;
                }
                break;
            case KW_RCFILE:
                {
                alt82=3;
                }
                break;
            case KW_ORCFILE:
                {
                alt82=4;
                }
                break;
            case KW_INPUTFORMAT:
                {
                int LA82_5 = input.LA(2);

                if ( (LA82_5==StringLiteral) ) {
                    alt82=5;
                }
                else if ( (LA82_5==EOF) ) {
                    alt82=6;
                }
                else {
                    NoViableAltException nvae =
                        new NoViableAltException("", 82, 5, input);

                    throw nvae;

                }
                }
                break;
            case Identifier:
            case KW_ADD:
            case KW_AFTER:
            case KW_ALTER:
            case KW_ANALYZE:
            case KW_ARCHIVE:
            case KW_ARRAY:
            case KW_AS:
            case KW_ASC:
            case KW_BEFORE:
            case KW_BETWEEN:
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_BOTH:
            case KW_BUCKET:
            case KW_BUCKETS:
            case KW_BY:
            case KW_CASCADE:
            case KW_CHANGE:
            case KW_CLUSTER:
            case KW_CLUSTERED:
            case KW_CLUSTERSTATUS:
            case KW_COLLECTION:
            case KW_COLUMNS:
            case KW_COMMENT:
            case KW_COMPUTE:
            case KW_CONCATENATE:
            case KW_CONTINUE:
            case KW_CREATE:
            case KW_CUBE:
            case KW_CURSOR:
            case KW_DATA:
            case KW_DATABASES:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DBPROPERTIES:
            case KW_DECIMAL:
            case KW_DEFERRED:
            case KW_DELETE:
            case KW_DELIMITED:
            case KW_DEPENDENCY:
            case KW_DESC:
            case KW_DESCRIBE:
            case KW_DIRECTORIES:
            case KW_DIRECTORY:
            case KW_DISABLE:
            case KW_DISTRIBUTE:
            case KW_DOUBLE:
            case KW_DROP:
            case KW_ELEM_TYPE:
            case KW_ENABLE:
            case KW_ESCAPED:
            case KW_EXCLUSIVE:
            case KW_EXISTS:
            case KW_EXPLAIN:
            case KW_EXPORT:
            case KW_EXTERNAL:
            case KW_FALSE:
            case KW_FETCH:
            case KW_FIELDS:
            case KW_FILEFORMAT:
            case KW_FIRST:
            case KW_FLOAT:
            case KW_FOR:
            case KW_FORMAT:
            case KW_FORMATTED:
            case KW_FULL:
            case KW_FUNCTIONS:
            case KW_GRANT:
            case KW_GROUP:
            case KW_GROUPING:
            case KW_HOLD_DDLTIME:
            case KW_IDXPROPERTIES:
            case KW_IGNORE:
            case KW_IMPORT:
            case KW_IN:
            case KW_INDEX:
            case KW_INDEXES:
            case KW_INNER:
            case KW_INPATH:
            case KW_INPUTDRIVER:
            case KW_INSERT:
            case KW_INT:
            case KW_INTERSECT:
            case KW_INTO:
            case KW_IS:
            case KW_ITEMS:
            case KW_KEYS:
            case KW_KEY_TYPE:
            case KW_LATERAL:
            case KW_LEFT:
            case KW_LIKE:
            case KW_LIMIT:
            case KW_LINES:
            case KW_LOAD:
            case KW_LOCAL:
            case KW_LOCATION:
            case KW_LOCK:
            case KW_LOCKS:
            case KW_LOGICAL:
            case KW_LONG:
            case KW_MAPJOIN:
            case KW_MATERIALIZED:
            case KW_MINUS:
            case KW_MSCK:
            case KW_NOSCAN:
            case KW_NO_DROP:
            case KW_NULL:
            case KW_OF:
            case KW_OFFLINE:
            case KW_OPTION:
            case KW_ORDER:
            case KW_OUT:
            case KW_OUTER:
            case KW_OUTPUTDRIVER:
            case KW_OUTPUTFORMAT:
            case KW_OVERWRITE:
            case KW_PARTITION:
            case KW_PARTITIONED:
            case KW_PARTITIONS:
            case KW_PERCENT:
            case KW_PLUS:
            case KW_PRETTY:
            case KW_PROCEDURE:
            case KW_PROTECTION:
            case KW_PURGE:
            case KW_RANGE:
            case KW_READ:
            case KW_READONLY:
            case KW_READS:
            case KW_REBUILD:
            case KW_RECORDREADER:
            case KW_RECORDWRITER:
            case KW_REGEXP:
            case KW_RENAME:
            case KW_REPAIR:
            case KW_REPLACE:
            case KW_RESTRICT:
            case KW_REVOKE:
            case KW_RIGHT:
            case KW_RLIKE:
            case KW_ROLE:
            case KW_ROLLUP:
            case KW_ROW:
            case KW_ROWS:
            case KW_SCHEMA:
            case KW_SCHEMAS:
            case KW_SEMI:
            case KW_SERDE:
            case KW_SERDEPROPERTIES:
            case KW_SET:
            case KW_SETS:
            case KW_SHARED:
            case KW_SHOW:
            case KW_SHOW_DATABASE:
            case KW_SKEWED:
            case KW_SMALLINT:
            case KW_SORT:
            case KW_SORTED:
            case KW_SSL:
            case KW_STATISTICS:
            case KW_STORED:
            case KW_STREAMTABLE:
            case KW_STRING:
            case KW_STRUCT:
            case KW_TABLE:
            case KW_TABLES:
            case KW_TBLPROPERTIES:
            case KW_TEMPORARY:
            case KW_TERMINATED:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_TO:
            case KW_TOUCH:
            case KW_TRIGGER:
            case KW_TRUE:
            case KW_TRUNCATE:
            case KW_UNARCHIVE:
            case KW_UNDO:
            case KW_UNION:
            case KW_UNIONTYPE:
            case KW_UNLOCK:
            case KW_UNSET:
            case KW_UNSIGNED:
            case KW_UPDATE:
            case KW_USE:
            case KW_USER:
            case KW_USING:
            case KW_UTC:
            case KW_UTCTIMESTAMP:
            case KW_VALUE_TYPE:
            case KW_VIEW:
            case KW_WHILE:
            case KW_WITH:
                {
                alt82=6;
                }
                break;
            default:
                NoViableAltException nvae =
                    new NoViableAltException("", 82, 0, input);

                throw nvae;

            }

            switch (alt82) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1172:7: KW_SEQUENCEFILE
                    {
                    KW_SEQUENCEFILE312=(Token)match(input,KW_SEQUENCEFILE,FOLLOW_KW_SEQUENCEFILE_in_fileFormat5676);  
                    stream_KW_SEQUENCEFILE.add(KW_SEQUENCEFILE312);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1172:24: -> ^( TOK_TBLSEQUENCEFILE )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1172:27: ^( TOK_TBLSEQUENCEFILE )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_TBLSEQUENCEFILE, "TOK_TBLSEQUENCEFILE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1173:7: KW_TEXTFILE
                    {
                    KW_TEXTFILE313=(Token)match(input,KW_TEXTFILE,FOLLOW_KW_TEXTFILE_in_fileFormat5691);  
                    stream_KW_TEXTFILE.add(KW_TEXTFILE313);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1173:20: -> ^( TOK_TBLTEXTFILE )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1173:23: ^( TOK_TBLTEXTFILE )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_TBLTEXTFILE, "TOK_TBLTEXTFILE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1174:7: KW_RCFILE
                    {
                    KW_RCFILE314=(Token)match(input,KW_RCFILE,FOLLOW_KW_RCFILE_in_fileFormat5706);  
                    stream_KW_RCFILE.add(KW_RCFILE314);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1174:18: -> ^( TOK_TBLRCFILE )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1174:21: ^( TOK_TBLRCFILE )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_TBLRCFILE, "TOK_TBLRCFILE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 4 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1175:7: KW_ORCFILE
                    {
                    KW_ORCFILE315=(Token)match(input,KW_ORCFILE,FOLLOW_KW_ORCFILE_in_fileFormat5721);  
                    stream_KW_ORCFILE.add(KW_ORCFILE315);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1175:18: -> ^( TOK_TBLORCFILE )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1175:21: ^( TOK_TBLORCFILE )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_TBLORCFILE, "TOK_TBLORCFILE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 5 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1176:7: KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
                    {
                    KW_INPUTFORMAT316=(Token)match(input,KW_INPUTFORMAT,FOLLOW_KW_INPUTFORMAT_in_fileFormat5735);  
                    stream_KW_INPUTFORMAT.add(KW_INPUTFORMAT316);


                    inFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_fileFormat5739);  
                    stream_StringLiteral.add(inFmt);


                    KW_OUTPUTFORMAT317=(Token)match(input,KW_OUTPUTFORMAT,FOLLOW_KW_OUTPUTFORMAT_in_fileFormat5741);  
                    stream_KW_OUTPUTFORMAT.add(KW_OUTPUTFORMAT317);


                    outFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_fileFormat5745);  
                    stream_StringLiteral.add(outFmt);


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1176:79: ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
                    int alt81=2;
                    int LA81_0 = input.LA(1);

                    if ( (LA81_0==KW_INPUTDRIVER) ) {
                        alt81=1;
                    }
                    switch (alt81) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1176:80: KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral
                            {
                            KW_INPUTDRIVER318=(Token)match(input,KW_INPUTDRIVER,FOLLOW_KW_INPUTDRIVER_in_fileFormat5748);  
                            stream_KW_INPUTDRIVER.add(KW_INPUTDRIVER318);


                            inDriver=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_fileFormat5752);  
                            stream_StringLiteral.add(inDriver);


                            KW_OUTPUTDRIVER319=(Token)match(input,KW_OUTPUTDRIVER,FOLLOW_KW_OUTPUTDRIVER_in_fileFormat5754);  
                            stream_KW_OUTPUTDRIVER.add(KW_OUTPUTDRIVER319);


                            outDriver=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_fileFormat5758);  
                            stream_StringLiteral.add(outDriver);


                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: outFmt, outDriver, inDriver, inFmt
                    // token labels: outDriver, outFmt, inDriver, inFmt
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_outDriver=new RewriteRuleTokenStream(adaptor,"token outDriver",outDriver);
                    RewriteRuleTokenStream stream_outFmt=new RewriteRuleTokenStream(adaptor,"token outFmt",outFmt);
                    RewriteRuleTokenStream stream_inDriver=new RewriteRuleTokenStream(adaptor,"token inDriver",inDriver);
                    RewriteRuleTokenStream stream_inFmt=new RewriteRuleTokenStream(adaptor,"token inFmt",inFmt);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1177:7: -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:10: ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_TABLEFILEFORMAT, "TOK_TABLEFILEFORMAT")
                        , root_1);

                        adaptor.addChild(root_1, stream_inFmt.nextNode());

                        adaptor.addChild(root_1, stream_outFmt.nextNode());

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:48: ( $inDriver)?
                        if ( stream_inDriver.hasNext() ) {
                            adaptor.addChild(root_1, stream_inDriver.nextNode());

                        }
                        stream_inDriver.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1177:59: ( $outDriver)?
                        if ( stream_outDriver.hasNext() ) {
                            adaptor.addChild(root_1, stream_outDriver.nextNode());

                        }
                        stream_outDriver.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 6 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1178:7: genericSpec= identifier
                    {
                    pushFollow(FOLLOW_identifier_in_fileFormat5796);
                    genericSpec=identifier();

                    state._fsp--;

                    stream_identifier.add(genericSpec.getTree());

                    // AST REWRITE
                    // elements: genericSpec
                    // token labels: 
                    // rule labels: retval, genericSpec
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_genericSpec=new RewriteRuleSubtreeStream(adaptor,"rule genericSpec",genericSpec!=null?genericSpec.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1178:30: -> ^( TOK_FILEFORMAT_GENERIC $genericSpec)
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1178:33: ^( TOK_FILEFORMAT_GENERIC $genericSpec)
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_FILEFORMAT_GENERIC, "TOK_FILEFORMAT_GENERIC")
                        , root_1);

                        adaptor.addChild(root_1, stream_genericSpec.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "fileFormat"


    public static class tabTypeExpr_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tabTypeExpr"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1181:1: tabTypeExpr : identifier ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )* ;
    public final HiveParser.tabTypeExpr_return tabTypeExpr() throws RecognitionException {
        HiveParser.tabTypeExpr_return retval = new HiveParser.tabTypeExpr_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token DOT321=null;
        Token KW_ELEM_TYPE322=null;
        Token KW_KEY_TYPE323=null;
        Token KW_VALUE_TYPE324=null;
        HiveParser_IdentifiersParser.identifier_return identifier320 =null;

        HiveParser_IdentifiersParser.identifier_return identifier325 =null;


        CommonTree DOT321_tree=null;
        CommonTree KW_ELEM_TYPE322_tree=null;
        CommonTree KW_KEY_TYPE323_tree=null;
        CommonTree KW_VALUE_TYPE324_tree=null;

         msgs.push("specifying table types"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1185:4: ( identifier ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )* )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1185:6: identifier ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )*
            {
            root_0 = (CommonTree)adaptor.nil();


            pushFollow(FOLLOW_identifier_in_tabTypeExpr5832);
            identifier320=identifier();

            state._fsp--;

            adaptor.addChild(root_0, identifier320.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1185:17: ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )*
            loop84:
            do {
                int alt84=2;
                int LA84_0 = input.LA(1);

                if ( (LA84_0==DOT) ) {
                    alt84=1;
                }


                switch (alt84) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1185:18: DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier )
            	    {
            	    DOT321=(Token)match(input,DOT,FOLLOW_DOT_in_tabTypeExpr5835); 
            	    DOT321_tree = 
            	    (CommonTree)adaptor.create(DOT321)
            	    ;
            	    root_0 = (CommonTree)adaptor.becomeRoot(DOT321_tree, root_0);


            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1185:23: ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier )
            	    int alt83=4;
            	    switch ( input.LA(1) ) {
            	    case KW_ELEM_TYPE:
            	        {
            	        alt83=1;
            	        }
            	        break;
            	    case KW_KEY_TYPE:
            	        {
            	        alt83=2;
            	        }
            	        break;
            	    case KW_VALUE_TYPE:
            	        {
            	        alt83=3;
            	        }
            	        break;
            	    case Identifier:
            	    case KW_ADD:
            	    case KW_AFTER:
            	    case KW_ALTER:
            	    case KW_ANALYZE:
            	    case KW_ARCHIVE:
            	    case KW_ARRAY:
            	    case KW_AS:
            	    case KW_ASC:
            	    case KW_BEFORE:
            	    case KW_BETWEEN:
            	    case KW_BIGINT:
            	    case KW_BINARY:
            	    case KW_BOOLEAN:
            	    case KW_BOTH:
            	    case KW_BUCKET:
            	    case KW_BUCKETS:
            	    case KW_BY:
            	    case KW_CASCADE:
            	    case KW_CHANGE:
            	    case KW_CLUSTER:
            	    case KW_CLUSTERED:
            	    case KW_CLUSTERSTATUS:
            	    case KW_COLLECTION:
            	    case KW_COLUMNS:
            	    case KW_COMMENT:
            	    case KW_COMPUTE:
            	    case KW_CONCATENATE:
            	    case KW_CONTINUE:
            	    case KW_CREATE:
            	    case KW_CUBE:
            	    case KW_CURSOR:
            	    case KW_DATA:
            	    case KW_DATABASES:
            	    case KW_DATE:
            	    case KW_DATETIME:
            	    case KW_DBPROPERTIES:
            	    case KW_DECIMAL:
            	    case KW_DEFERRED:
            	    case KW_DELETE:
            	    case KW_DELIMITED:
            	    case KW_DEPENDENCY:
            	    case KW_DESC:
            	    case KW_DESCRIBE:
            	    case KW_DIRECTORIES:
            	    case KW_DIRECTORY:
            	    case KW_DISABLE:
            	    case KW_DISTRIBUTE:
            	    case KW_DOUBLE:
            	    case KW_DROP:
            	    case KW_ENABLE:
            	    case KW_ESCAPED:
            	    case KW_EXCLUSIVE:
            	    case KW_EXISTS:
            	    case KW_EXPLAIN:
            	    case KW_EXPORT:
            	    case KW_EXTERNAL:
            	    case KW_FALSE:
            	    case KW_FETCH:
            	    case KW_FIELDS:
            	    case KW_FILEFORMAT:
            	    case KW_FIRST:
            	    case KW_FLOAT:
            	    case KW_FOR:
            	    case KW_FORMAT:
            	    case KW_FORMATTED:
            	    case KW_FULL:
            	    case KW_FUNCTIONS:
            	    case KW_GRANT:
            	    case KW_GROUP:
            	    case KW_GROUPING:
            	    case KW_HOLD_DDLTIME:
            	    case KW_IDXPROPERTIES:
            	    case KW_IGNORE:
            	    case KW_IMPORT:
            	    case KW_IN:
            	    case KW_INDEX:
            	    case KW_INDEXES:
            	    case KW_INNER:
            	    case KW_INPATH:
            	    case KW_INPUTDRIVER:
            	    case KW_INPUTFORMAT:
            	    case KW_INSERT:
            	    case KW_INT:
            	    case KW_INTERSECT:
            	    case KW_INTO:
            	    case KW_IS:
            	    case KW_ITEMS:
            	    case KW_KEYS:
            	    case KW_LATERAL:
            	    case KW_LEFT:
            	    case KW_LIKE:
            	    case KW_LIMIT:
            	    case KW_LINES:
            	    case KW_LOAD:
            	    case KW_LOCAL:
            	    case KW_LOCATION:
            	    case KW_LOCK:
            	    case KW_LOCKS:
            	    case KW_LOGICAL:
            	    case KW_LONG:
            	    case KW_MAPJOIN:
            	    case KW_MATERIALIZED:
            	    case KW_MINUS:
            	    case KW_MSCK:
            	    case KW_NOSCAN:
            	    case KW_NO_DROP:
            	    case KW_NULL:
            	    case KW_OF:
            	    case KW_OFFLINE:
            	    case KW_OPTION:
            	    case KW_ORCFILE:
            	    case KW_ORDER:
            	    case KW_OUT:
            	    case KW_OUTER:
            	    case KW_OUTPUTDRIVER:
            	    case KW_OUTPUTFORMAT:
            	    case KW_OVERWRITE:
            	    case KW_PARTITION:
            	    case KW_PARTITIONED:
            	    case KW_PARTITIONS:
            	    case KW_PERCENT:
            	    case KW_PLUS:
            	    case KW_PRETTY:
            	    case KW_PROCEDURE:
            	    case KW_PROTECTION:
            	    case KW_PURGE:
            	    case KW_RANGE:
            	    case KW_RCFILE:
            	    case KW_READ:
            	    case KW_READONLY:
            	    case KW_READS:
            	    case KW_REBUILD:
            	    case KW_RECORDREADER:
            	    case KW_RECORDWRITER:
            	    case KW_REGEXP:
            	    case KW_RENAME:
            	    case KW_REPAIR:
            	    case KW_REPLACE:
            	    case KW_RESTRICT:
            	    case KW_REVOKE:
            	    case KW_RIGHT:
            	    case KW_RLIKE:
            	    case KW_ROLE:
            	    case KW_ROLLUP:
            	    case KW_ROW:
            	    case KW_ROWS:
            	    case KW_SCHEMA:
            	    case KW_SCHEMAS:
            	    case KW_SEMI:
            	    case KW_SEQUENCEFILE:
            	    case KW_SERDE:
            	    case KW_SERDEPROPERTIES:
            	    case KW_SET:
            	    case KW_SETS:
            	    case KW_SHARED:
            	    case KW_SHOW:
            	    case KW_SHOW_DATABASE:
            	    case KW_SKEWED:
            	    case KW_SMALLINT:
            	    case KW_SORT:
            	    case KW_SORTED:
            	    case KW_SSL:
            	    case KW_STATISTICS:
            	    case KW_STORED:
            	    case KW_STREAMTABLE:
            	    case KW_STRING:
            	    case KW_STRUCT:
            	    case KW_TABLE:
            	    case KW_TABLES:
            	    case KW_TBLPROPERTIES:
            	    case KW_TEMPORARY:
            	    case KW_TERMINATED:
            	    case KW_TEXTFILE:
            	    case KW_TIMESTAMP:
            	    case KW_TINYINT:
            	    case KW_TO:
            	    case KW_TOUCH:
            	    case KW_TRIGGER:
            	    case KW_TRUE:
            	    case KW_TRUNCATE:
            	    case KW_UNARCHIVE:
            	    case KW_UNDO:
            	    case KW_UNION:
            	    case KW_UNIONTYPE:
            	    case KW_UNLOCK:
            	    case KW_UNSET:
            	    case KW_UNSIGNED:
            	    case KW_UPDATE:
            	    case KW_USE:
            	    case KW_USER:
            	    case KW_USING:
            	    case KW_UTC:
            	    case KW_UTCTIMESTAMP:
            	    case KW_VIEW:
            	    case KW_WHILE:
            	    case KW_WITH:
            	        {
            	        alt83=4;
            	        }
            	        break;
            	    default:
            	        NoViableAltException nvae =
            	            new NoViableAltException("", 83, 0, input);

            	        throw nvae;

            	    }

            	    switch (alt83) {
            	        case 1 :
            	            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1185:24: KW_ELEM_TYPE
            	            {
            	            KW_ELEM_TYPE322=(Token)match(input,KW_ELEM_TYPE,FOLLOW_KW_ELEM_TYPE_in_tabTypeExpr5839); 
            	            KW_ELEM_TYPE322_tree = 
            	            (CommonTree)adaptor.create(KW_ELEM_TYPE322)
            	            ;
            	            adaptor.addChild(root_0, KW_ELEM_TYPE322_tree);


            	            }
            	            break;
            	        case 2 :
            	            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1185:39: KW_KEY_TYPE
            	            {
            	            KW_KEY_TYPE323=(Token)match(input,KW_KEY_TYPE,FOLLOW_KW_KEY_TYPE_in_tabTypeExpr5843); 
            	            KW_KEY_TYPE323_tree = 
            	            (CommonTree)adaptor.create(KW_KEY_TYPE323)
            	            ;
            	            adaptor.addChild(root_0, KW_KEY_TYPE323_tree);


            	            }
            	            break;
            	        case 3 :
            	            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1185:53: KW_VALUE_TYPE
            	            {
            	            KW_VALUE_TYPE324=(Token)match(input,KW_VALUE_TYPE,FOLLOW_KW_VALUE_TYPE_in_tabTypeExpr5847); 
            	            KW_VALUE_TYPE324_tree = 
            	            (CommonTree)adaptor.create(KW_VALUE_TYPE324)
            	            ;
            	            adaptor.addChild(root_0, KW_VALUE_TYPE324_tree);


            	            }
            	            break;
            	        case 4 :
            	            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1185:69: identifier
            	            {
            	            pushFollow(FOLLOW_identifier_in_tabTypeExpr5851);
            	            identifier325=identifier();

            	            state._fsp--;

            	            adaptor.addChild(root_0, identifier325.getTree());

            	            }
            	            break;

            	    }


            	    }
            	    break;

            	default :
            	    break loop84;
                }
            } while (true);


            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tabTypeExpr"


    public static class descTabTypeExpr_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "descTabTypeExpr"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1188:1: descTabTypeExpr : identifier ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )* ( identifier )? ;
    public final HiveParser.descTabTypeExpr_return descTabTypeExpr() throws RecognitionException {
        HiveParser.descTabTypeExpr_return retval = new HiveParser.descTabTypeExpr_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token DOT327=null;
        Token KW_ELEM_TYPE328=null;
        Token KW_KEY_TYPE329=null;
        Token KW_VALUE_TYPE330=null;
        HiveParser_IdentifiersParser.identifier_return identifier326 =null;

        HiveParser_IdentifiersParser.identifier_return identifier331 =null;

        HiveParser_IdentifiersParser.identifier_return identifier332 =null;


        CommonTree DOT327_tree=null;
        CommonTree KW_ELEM_TYPE328_tree=null;
        CommonTree KW_KEY_TYPE329_tree=null;
        CommonTree KW_VALUE_TYPE330_tree=null;

         msgs.push("specifying describe table types"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:4: ( identifier ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )* ( identifier )? )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:6: identifier ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )* ( identifier )?
            {
            root_0 = (CommonTree)adaptor.nil();


            pushFollow(FOLLOW_identifier_in_descTabTypeExpr5880);
            identifier326=identifier();

            state._fsp--;

            adaptor.addChild(root_0, identifier326.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:17: ( DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier ) )*
            loop86:
            do {
                int alt86=2;
                int LA86_0 = input.LA(1);

                if ( (LA86_0==DOT) ) {
                    alt86=1;
                }


                switch (alt86) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:18: DOT ^ ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier )
            	    {
            	    DOT327=(Token)match(input,DOT,FOLLOW_DOT_in_descTabTypeExpr5883); 
            	    DOT327_tree = 
            	    (CommonTree)adaptor.create(DOT327)
            	    ;
            	    root_0 = (CommonTree)adaptor.becomeRoot(DOT327_tree, root_0);


            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:23: ( KW_ELEM_TYPE | KW_KEY_TYPE | KW_VALUE_TYPE | identifier )
            	    int alt85=4;
            	    switch ( input.LA(1) ) {
            	    case KW_ELEM_TYPE:
            	        {
            	        alt85=1;
            	        }
            	        break;
            	    case KW_KEY_TYPE:
            	        {
            	        alt85=2;
            	        }
            	        break;
            	    case KW_VALUE_TYPE:
            	        {
            	        alt85=3;
            	        }
            	        break;
            	    case Identifier:
            	    case KW_ADD:
            	    case KW_AFTER:
            	    case KW_ALTER:
            	    case KW_ANALYZE:
            	    case KW_ARCHIVE:
            	    case KW_ARRAY:
            	    case KW_AS:
            	    case KW_ASC:
            	    case KW_BEFORE:
            	    case KW_BETWEEN:
            	    case KW_BIGINT:
            	    case KW_BINARY:
            	    case KW_BOOLEAN:
            	    case KW_BOTH:
            	    case KW_BUCKET:
            	    case KW_BUCKETS:
            	    case KW_BY:
            	    case KW_CASCADE:
            	    case KW_CHANGE:
            	    case KW_CLUSTER:
            	    case KW_CLUSTERED:
            	    case KW_CLUSTERSTATUS:
            	    case KW_COLLECTION:
            	    case KW_COLUMNS:
            	    case KW_COMMENT:
            	    case KW_COMPUTE:
            	    case KW_CONCATENATE:
            	    case KW_CONTINUE:
            	    case KW_CREATE:
            	    case KW_CUBE:
            	    case KW_CURSOR:
            	    case KW_DATA:
            	    case KW_DATABASES:
            	    case KW_DATE:
            	    case KW_DATETIME:
            	    case KW_DBPROPERTIES:
            	    case KW_DECIMAL:
            	    case KW_DEFERRED:
            	    case KW_DELETE:
            	    case KW_DELIMITED:
            	    case KW_DEPENDENCY:
            	    case KW_DESC:
            	    case KW_DESCRIBE:
            	    case KW_DIRECTORIES:
            	    case KW_DIRECTORY:
            	    case KW_DISABLE:
            	    case KW_DISTRIBUTE:
            	    case KW_DOUBLE:
            	    case KW_DROP:
            	    case KW_ENABLE:
            	    case KW_ESCAPED:
            	    case KW_EXCLUSIVE:
            	    case KW_EXISTS:
            	    case KW_EXPLAIN:
            	    case KW_EXPORT:
            	    case KW_EXTERNAL:
            	    case KW_FALSE:
            	    case KW_FETCH:
            	    case KW_FIELDS:
            	    case KW_FILEFORMAT:
            	    case KW_FIRST:
            	    case KW_FLOAT:
            	    case KW_FOR:
            	    case KW_FORMAT:
            	    case KW_FORMATTED:
            	    case KW_FULL:
            	    case KW_FUNCTIONS:
            	    case KW_GRANT:
            	    case KW_GROUP:
            	    case KW_GROUPING:
            	    case KW_HOLD_DDLTIME:
            	    case KW_IDXPROPERTIES:
            	    case KW_IGNORE:
            	    case KW_IMPORT:
            	    case KW_IN:
            	    case KW_INDEX:
            	    case KW_INDEXES:
            	    case KW_INNER:
            	    case KW_INPATH:
            	    case KW_INPUTDRIVER:
            	    case KW_INPUTFORMAT:
            	    case KW_INSERT:
            	    case KW_INT:
            	    case KW_INTERSECT:
            	    case KW_INTO:
            	    case KW_IS:
            	    case KW_ITEMS:
            	    case KW_KEYS:
            	    case KW_LATERAL:
            	    case KW_LEFT:
            	    case KW_LIKE:
            	    case KW_LIMIT:
            	    case KW_LINES:
            	    case KW_LOAD:
            	    case KW_LOCAL:
            	    case KW_LOCATION:
            	    case KW_LOCK:
            	    case KW_LOCKS:
            	    case KW_LOGICAL:
            	    case KW_LONG:
            	    case KW_MAPJOIN:
            	    case KW_MATERIALIZED:
            	    case KW_MINUS:
            	    case KW_MSCK:
            	    case KW_NOSCAN:
            	    case KW_NO_DROP:
            	    case KW_NULL:
            	    case KW_OF:
            	    case KW_OFFLINE:
            	    case KW_OPTION:
            	    case KW_ORCFILE:
            	    case KW_ORDER:
            	    case KW_OUT:
            	    case KW_OUTER:
            	    case KW_OUTPUTDRIVER:
            	    case KW_OUTPUTFORMAT:
            	    case KW_OVERWRITE:
            	    case KW_PARTITION:
            	    case KW_PARTITIONED:
            	    case KW_PARTITIONS:
            	    case KW_PERCENT:
            	    case KW_PLUS:
            	    case KW_PRETTY:
            	    case KW_PROCEDURE:
            	    case KW_PROTECTION:
            	    case KW_PURGE:
            	    case KW_RANGE:
            	    case KW_RCFILE:
            	    case KW_READ:
            	    case KW_READONLY:
            	    case KW_READS:
            	    case KW_REBUILD:
            	    case KW_RECORDREADER:
            	    case KW_RECORDWRITER:
            	    case KW_REGEXP:
            	    case KW_RENAME:
            	    case KW_REPAIR:
            	    case KW_REPLACE:
            	    case KW_RESTRICT:
            	    case KW_REVOKE:
            	    case KW_RIGHT:
            	    case KW_RLIKE:
            	    case KW_ROLE:
            	    case KW_ROLLUP:
            	    case KW_ROW:
            	    case KW_ROWS:
            	    case KW_SCHEMA:
            	    case KW_SCHEMAS:
            	    case KW_SEMI:
            	    case KW_SEQUENCEFILE:
            	    case KW_SERDE:
            	    case KW_SERDEPROPERTIES:
            	    case KW_SET:
            	    case KW_SETS:
            	    case KW_SHARED:
            	    case KW_SHOW:
            	    case KW_SHOW_DATABASE:
            	    case KW_SKEWED:
            	    case KW_SMALLINT:
            	    case KW_SORT:
            	    case KW_SORTED:
            	    case KW_SSL:
            	    case KW_STATISTICS:
            	    case KW_STORED:
            	    case KW_STREAMTABLE:
            	    case KW_STRING:
            	    case KW_STRUCT:
            	    case KW_TABLE:
            	    case KW_TABLES:
            	    case KW_TBLPROPERTIES:
            	    case KW_TEMPORARY:
            	    case KW_TERMINATED:
            	    case KW_TEXTFILE:
            	    case KW_TIMESTAMP:
            	    case KW_TINYINT:
            	    case KW_TO:
            	    case KW_TOUCH:
            	    case KW_TRIGGER:
            	    case KW_TRUE:
            	    case KW_TRUNCATE:
            	    case KW_UNARCHIVE:
            	    case KW_UNDO:
            	    case KW_UNION:
            	    case KW_UNIONTYPE:
            	    case KW_UNLOCK:
            	    case KW_UNSET:
            	    case KW_UNSIGNED:
            	    case KW_UPDATE:
            	    case KW_USE:
            	    case KW_USER:
            	    case KW_USING:
            	    case KW_UTC:
            	    case KW_UTCTIMESTAMP:
            	    case KW_VIEW:
            	    case KW_WHILE:
            	    case KW_WITH:
            	        {
            	        alt85=4;
            	        }
            	        break;
            	    default:
            	        NoViableAltException nvae =
            	            new NoViableAltException("", 85, 0, input);

            	        throw nvae;

            	    }

            	    switch (alt85) {
            	        case 1 :
            	            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:24: KW_ELEM_TYPE
            	            {
            	            KW_ELEM_TYPE328=(Token)match(input,KW_ELEM_TYPE,FOLLOW_KW_ELEM_TYPE_in_descTabTypeExpr5887); 
            	            KW_ELEM_TYPE328_tree = 
            	            (CommonTree)adaptor.create(KW_ELEM_TYPE328)
            	            ;
            	            adaptor.addChild(root_0, KW_ELEM_TYPE328_tree);


            	            }
            	            break;
            	        case 2 :
            	            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:39: KW_KEY_TYPE
            	            {
            	            KW_KEY_TYPE329=(Token)match(input,KW_KEY_TYPE,FOLLOW_KW_KEY_TYPE_in_descTabTypeExpr5891); 
            	            KW_KEY_TYPE329_tree = 
            	            (CommonTree)adaptor.create(KW_KEY_TYPE329)
            	            ;
            	            adaptor.addChild(root_0, KW_KEY_TYPE329_tree);


            	            }
            	            break;
            	        case 3 :
            	            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:53: KW_VALUE_TYPE
            	            {
            	            KW_VALUE_TYPE330=(Token)match(input,KW_VALUE_TYPE,FOLLOW_KW_VALUE_TYPE_in_descTabTypeExpr5895); 
            	            KW_VALUE_TYPE330_tree = 
            	            (CommonTree)adaptor.create(KW_VALUE_TYPE330)
            	            ;
            	            adaptor.addChild(root_0, KW_VALUE_TYPE330_tree);


            	            }
            	            break;
            	        case 4 :
            	            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:69: identifier
            	            {
            	            pushFollow(FOLLOW_identifier_in_descTabTypeExpr5899);
            	            identifier331=identifier();

            	            state._fsp--;

            	            adaptor.addChild(root_0, identifier331.getTree());

            	            }
            	            break;

            	    }


            	    }
            	    break;

            	default :
            	    break loop86;
                }
            } while (true);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:83: ( identifier )?
            int alt87=2;
            int LA87_0 = input.LA(1);

            if ( ((LA87_0 >= Identifier && LA87_0 <= KW_AFTER)||(LA87_0 >= KW_ALTER && LA87_0 <= KW_ANALYZE)||(LA87_0 >= KW_ARCHIVE && LA87_0 <= KW_CASCADE)||(LA87_0 >= KW_CHANGE && LA87_0 <= KW_COLLECTION)||(LA87_0 >= KW_COLUMNS && LA87_0 <= KW_CREATE)||LA87_0==KW_CUBE||(LA87_0 >= KW_CURSOR && LA87_0 <= KW_DATA)||(LA87_0 >= KW_DATABASES && LA87_0 <= KW_DISABLE)||(LA87_0 >= KW_DISTRIBUTE && LA87_0 <= KW_ELEM_TYPE)||LA87_0==KW_ENABLE||LA87_0==KW_ESCAPED||(LA87_0 >= KW_EXCLUSIVE && LA87_0 <= KW_EXPORT)||(LA87_0 >= KW_EXTERNAL && LA87_0 <= KW_FLOAT)||(LA87_0 >= KW_FOR && LA87_0 <= KW_FORMATTED)||LA87_0==KW_FULL||(LA87_0 >= KW_FUNCTIONS && LA87_0 <= KW_GROUPING)||(LA87_0 >= KW_HOLD_DDLTIME && LA87_0 <= KW_IDXPROPERTIES)||(LA87_0 >= KW_IGNORE && LA87_0 <= KW_ITEMS)||(LA87_0 >= KW_KEYS && LA87_0 <= KW_LEFT)||(LA87_0 >= KW_LIKE && LA87_0 <= KW_LONG)||(LA87_0 >= KW_MAPJOIN && LA87_0 <= KW_MINUS)||(LA87_0 >= KW_MSCK && LA87_0 <= KW_NOSCAN)||(LA87_0 >= KW_NO_DROP && LA87_0 <= KW_OFFLINE)||LA87_0==KW_OPTION||(LA87_0 >= KW_ORCFILE && LA87_0 <= KW_OUTPUTFORMAT)||LA87_0==KW_OVERWRITE||(LA87_0 >= KW_PARTITIONED && LA87_0 <= KW_PLUS)||(LA87_0 >= KW_PRETTY && LA87_0 <= KW_RECORDWRITER)||(LA87_0 >= KW_REGEXP && LA87_0 <= KW_SCHEMAS)||(LA87_0 >= KW_SEMI && LA87_0 <= KW_TABLES)||(LA87_0 >= KW_TBLPROPERTIES && LA87_0 <= KW_TEXTFILE)||(LA87_0 >= KW_TIMESTAMP && LA87_0 <= KW_TOUCH)||(LA87_0 >= KW_TRIGGER && LA87_0 <= KW_UNARCHIVE)||(LA87_0 >= KW_UNDO && LA87_0 <= KW_UNIONTYPE)||(LA87_0 >= KW_UNLOCK && LA87_0 <= KW_VALUE_TYPE)||LA87_0==KW_VIEW||LA87_0==KW_WHILE||LA87_0==KW_WITH) ) {
                alt87=1;
            }
            else if ( (LA87_0==KW_PARTITION) ) {
                int LA87_2 = input.LA(2);

                if ( (LA87_2==EOF||LA87_2==KW_PARTITION) ) {
                    alt87=1;
                }
            }
            switch (alt87) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1192:83: identifier
                    {
                    pushFollow(FOLLOW_identifier_in_descTabTypeExpr5904);
                    identifier332=identifier();

                    state._fsp--;

                    adaptor.addChild(root_0, identifier332.getTree());

                    }
                    break;

            }


            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "descTabTypeExpr"


    public static class partTypeExpr_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "partTypeExpr"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1195:1: partTypeExpr : tabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? ) ;
    public final HiveParser.partTypeExpr_return partTypeExpr() throws RecognitionException {
        HiveParser.partTypeExpr_return retval = new HiveParser.partTypeExpr_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser.tabTypeExpr_return tabTypeExpr333 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec334 =null;


        RewriteRuleSubtreeStream stream_tabTypeExpr=new RewriteRuleSubtreeStream(adaptor,"rule tabTypeExpr");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
         msgs.push("specifying table partitions"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1198:5: ( tabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1198:8: tabTypeExpr ( partitionSpec )?
            {
            pushFollow(FOLLOW_tabTypeExpr_in_partTypeExpr5932);
            tabTypeExpr333=tabTypeExpr();

            state._fsp--;

            stream_tabTypeExpr.add(tabTypeExpr333.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1198:20: ( partitionSpec )?
            int alt88=2;
            int LA88_0 = input.LA(1);

            if ( (LA88_0==KW_PARTITION) ) {
                alt88=1;
            }
            switch (alt88) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1198:20: partitionSpec
                    {
                    pushFollow(FOLLOW_partitionSpec_in_partTypeExpr5934);
                    partitionSpec334=partitionSpec();

                    state._fsp--;

                    stream_partitionSpec.add(partitionSpec334.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: partitionSpec, tabTypeExpr
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1198:35: -> ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1198:38: ^( TOK_TABTYPE tabTypeExpr ( partitionSpec )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABTYPE, "TOK_TABTYPE")
                , root_1);

                adaptor.addChild(root_1, stream_tabTypeExpr.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1198:64: ( partitionSpec )?
                if ( stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                }
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "partTypeExpr"


    public static class descPartTypeExpr_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "descPartTypeExpr"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1201:1: descPartTypeExpr : descTabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE descTabTypeExpr ( partitionSpec )? ) ;
    public final HiveParser.descPartTypeExpr_return descPartTypeExpr() throws RecognitionException {
        HiveParser.descPartTypeExpr_return retval = new HiveParser.descPartTypeExpr_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser.descTabTypeExpr_return descTabTypeExpr335 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec336 =null;


        RewriteRuleSubtreeStream stream_descTabTypeExpr=new RewriteRuleSubtreeStream(adaptor,"rule descTabTypeExpr");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
         msgs.push("specifying describe table partitions"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1204:5: ( descTabTypeExpr ( partitionSpec )? -> ^( TOK_TABTYPE descTabTypeExpr ( partitionSpec )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1204:8: descTabTypeExpr ( partitionSpec )?
            {
            pushFollow(FOLLOW_descTabTypeExpr_in_descPartTypeExpr5974);
            descTabTypeExpr335=descTabTypeExpr();

            state._fsp--;

            stream_descTabTypeExpr.add(descTabTypeExpr335.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1204:24: ( partitionSpec )?
            int alt89=2;
            int LA89_0 = input.LA(1);

            if ( (LA89_0==KW_PARTITION) ) {
                alt89=1;
            }
            switch (alt89) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1204:24: partitionSpec
                    {
                    pushFollow(FOLLOW_partitionSpec_in_descPartTypeExpr5976);
                    partitionSpec336=partitionSpec();

                    state._fsp--;

                    stream_partitionSpec.add(partitionSpec336.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: partitionSpec, descTabTypeExpr
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1204:39: -> ^( TOK_TABTYPE descTabTypeExpr ( partitionSpec )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1204:42: ^( TOK_TABTYPE descTabTypeExpr ( partitionSpec )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABTYPE, "TOK_TABTYPE")
                , root_1);

                adaptor.addChild(root_1, stream_descTabTypeExpr.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1204:72: ( partitionSpec )?
                if ( stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                }
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "descPartTypeExpr"


    public static class descStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "descStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1207:1: descStatement : ( ( KW_DESCRIBE | KW_DESC ) (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY )? (parttype= descPartTypeExpr ) -> ^( TOK_DESCTABLE $parttype ( $descOptions)? ) | ( KW_DESCRIBE | KW_DESC ) KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) | ( KW_DESCRIBE | KW_DESC ) KW_DATABASE ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) );
    public final HiveParser.descStatement_return descStatement() throws RecognitionException {
        HiveParser.descStatement_return retval = new HiveParser.descStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token descOptions=null;
        Token KW_DESCRIBE337=null;
        Token KW_DESC338=null;
        Token KW_DESCRIBE339=null;
        Token KW_DESC340=null;
        Token KW_FUNCTION341=null;
        Token KW_EXTENDED342=null;
        Token KW_DESCRIBE343=null;
        Token KW_DESC344=null;
        Token KW_DATABASE345=null;
        Token KW_EXTENDED346=null;
        HiveParser.descPartTypeExpr_return parttype =null;

        HiveParser_IdentifiersParser.descFuncNames_return name =null;

        HiveParser_IdentifiersParser.identifier_return dbName =null;


        CommonTree descOptions_tree=null;
        CommonTree KW_DESCRIBE337_tree=null;
        CommonTree KW_DESC338_tree=null;
        CommonTree KW_DESCRIBE339_tree=null;
        CommonTree KW_DESC340_tree=null;
        CommonTree KW_FUNCTION341_tree=null;
        CommonTree KW_EXTENDED342_tree=null;
        CommonTree KW_DESCRIBE343_tree=null;
        CommonTree KW_DESC344_tree=null;
        CommonTree KW_DATABASE345_tree=null;
        CommonTree KW_EXTENDED346_tree=null;
        RewriteRuleTokenStream stream_KW_DESC=new RewriteRuleTokenStream(adaptor,"token KW_DESC");
        RewriteRuleTokenStream stream_KW_FUNCTION=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTION");
        RewriteRuleTokenStream stream_KW_FORMATTED=new RewriteRuleTokenStream(adaptor,"token KW_FORMATTED");
        RewriteRuleTokenStream stream_KW_EXTENDED=new RewriteRuleTokenStream(adaptor,"token KW_EXTENDED");
        RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
        RewriteRuleTokenStream stream_KW_PRETTY=new RewriteRuleTokenStream(adaptor,"token KW_PRETTY");
        RewriteRuleTokenStream stream_KW_DESCRIBE=new RewriteRuleTokenStream(adaptor,"token KW_DESCRIBE");
        RewriteRuleSubtreeStream stream_descPartTypeExpr=new RewriteRuleSubtreeStream(adaptor,"rule descPartTypeExpr");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        RewriteRuleSubtreeStream stream_descFuncNames=new RewriteRuleSubtreeStream(adaptor,"rule descFuncNames");
         msgs.push("describe statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1210:5: ( ( KW_DESCRIBE | KW_DESC ) (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY )? (parttype= descPartTypeExpr ) -> ^( TOK_DESCTABLE $parttype ( $descOptions)? ) | ( KW_DESCRIBE | KW_DESC ) KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames ) -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? ) | ( KW_DESCRIBE | KW_DESC ) KW_DATABASE ( KW_EXTENDED )? (dbName= identifier ) -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? ) )
            int alt96=3;
            int LA96_0 = input.LA(1);

            if ( (LA96_0==KW_DESCRIBE) ) {
                switch ( input.LA(2) ) {
                case Identifier:
                case KW_ADD:
                case KW_AFTER:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFERRED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTENDED:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORCFILE:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_RCFILE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SEQUENCEFILE:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TEXTFILE:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH:
                    {
                    alt96=1;
                    }
                    break;
                case KW_FUNCTION:
                    {
                    alt96=2;
                    }
                    break;
                case KW_DATABASE:
                    {
                    alt96=3;
                    }
                    break;
                default:
                    NoViableAltException nvae =
                        new NoViableAltException("", 96, 1, input);

                    throw nvae;

                }

            }
            else if ( (LA96_0==KW_DESC) ) {
                switch ( input.LA(2) ) {
                case Identifier:
                case KW_ADD:
                case KW_AFTER:
                case KW_ALTER:
                case KW_ANALYZE:
                case KW_ARCHIVE:
                case KW_ARRAY:
                case KW_AS:
                case KW_ASC:
                case KW_BEFORE:
                case KW_BETWEEN:
                case KW_BIGINT:
                case KW_BINARY:
                case KW_BOOLEAN:
                case KW_BOTH:
                case KW_BUCKET:
                case KW_BUCKETS:
                case KW_BY:
                case KW_CASCADE:
                case KW_CHANGE:
                case KW_CLUSTER:
                case KW_CLUSTERED:
                case KW_CLUSTERSTATUS:
                case KW_COLLECTION:
                case KW_COLUMNS:
                case KW_COMMENT:
                case KW_COMPUTE:
                case KW_CONCATENATE:
                case KW_CONTINUE:
                case KW_CREATE:
                case KW_CUBE:
                case KW_CURSOR:
                case KW_DATA:
                case KW_DATABASES:
                case KW_DATE:
                case KW_DATETIME:
                case KW_DBPROPERTIES:
                case KW_DECIMAL:
                case KW_DEFERRED:
                case KW_DELETE:
                case KW_DELIMITED:
                case KW_DEPENDENCY:
                case KW_DESC:
                case KW_DESCRIBE:
                case KW_DIRECTORIES:
                case KW_DIRECTORY:
                case KW_DISABLE:
                case KW_DISTRIBUTE:
                case KW_DOUBLE:
                case KW_DROP:
                case KW_ELEM_TYPE:
                case KW_ENABLE:
                case KW_ESCAPED:
                case KW_EXCLUSIVE:
                case KW_EXISTS:
                case KW_EXPLAIN:
                case KW_EXPORT:
                case KW_EXTENDED:
                case KW_EXTERNAL:
                case KW_FALSE:
                case KW_FETCH:
                case KW_FIELDS:
                case KW_FILEFORMAT:
                case KW_FIRST:
                case KW_FLOAT:
                case KW_FOR:
                case KW_FORMAT:
                case KW_FORMATTED:
                case KW_FULL:
                case KW_FUNCTIONS:
                case KW_GRANT:
                case KW_GROUP:
                case KW_GROUPING:
                case KW_HOLD_DDLTIME:
                case KW_IDXPROPERTIES:
                case KW_IGNORE:
                case KW_IMPORT:
                case KW_IN:
                case KW_INDEX:
                case KW_INDEXES:
                case KW_INNER:
                case KW_INPATH:
                case KW_INPUTDRIVER:
                case KW_INPUTFORMAT:
                case KW_INSERT:
                case KW_INT:
                case KW_INTERSECT:
                case KW_INTO:
                case KW_IS:
                case KW_ITEMS:
                case KW_KEYS:
                case KW_KEY_TYPE:
                case KW_LATERAL:
                case KW_LEFT:
                case KW_LIKE:
                case KW_LIMIT:
                case KW_LINES:
                case KW_LOAD:
                case KW_LOCAL:
                case KW_LOCATION:
                case KW_LOCK:
                case KW_LOCKS:
                case KW_LOGICAL:
                case KW_LONG:
                case KW_MAPJOIN:
                case KW_MATERIALIZED:
                case KW_MINUS:
                case KW_MSCK:
                case KW_NOSCAN:
                case KW_NO_DROP:
                case KW_NULL:
                case KW_OF:
                case KW_OFFLINE:
                case KW_OPTION:
                case KW_ORCFILE:
                case KW_ORDER:
                case KW_OUT:
                case KW_OUTER:
                case KW_OUTPUTDRIVER:
                case KW_OUTPUTFORMAT:
                case KW_OVERWRITE:
                case KW_PARTITION:
                case KW_PARTITIONED:
                case KW_PARTITIONS:
                case KW_PERCENT:
                case KW_PLUS:
                case KW_PRETTY:
                case KW_PROCEDURE:
                case KW_PROTECTION:
                case KW_PURGE:
                case KW_RANGE:
                case KW_RCFILE:
                case KW_READ:
                case KW_READONLY:
                case KW_READS:
                case KW_REBUILD:
                case KW_RECORDREADER:
                case KW_RECORDWRITER:
                case KW_REGEXP:
                case KW_RENAME:
                case KW_REPAIR:
                case KW_REPLACE:
                case KW_RESTRICT:
                case KW_REVOKE:
                case KW_RIGHT:
                case KW_RLIKE:
                case KW_ROLE:
                case KW_ROLLUP:
                case KW_ROW:
                case KW_ROWS:
                case KW_SCHEMA:
                case KW_SCHEMAS:
                case KW_SEMI:
                case KW_SEQUENCEFILE:
                case KW_SERDE:
                case KW_SERDEPROPERTIES:
                case KW_SET:
                case KW_SETS:
                case KW_SHARED:
                case KW_SHOW:
                case KW_SHOW_DATABASE:
                case KW_SKEWED:
                case KW_SMALLINT:
                case KW_SORT:
                case KW_SORTED:
                case KW_SSL:
                case KW_STATISTICS:
                case KW_STORED:
                case KW_STREAMTABLE:
                case KW_STRING:
                case KW_STRUCT:
                case KW_TABLE:
                case KW_TABLES:
                case KW_TBLPROPERTIES:
                case KW_TEMPORARY:
                case KW_TERMINATED:
                case KW_TEXTFILE:
                case KW_TIMESTAMP:
                case KW_TINYINT:
                case KW_TO:
                case KW_TOUCH:
                case KW_TRIGGER:
                case KW_TRUE:
                case KW_TRUNCATE:
                case KW_UNARCHIVE:
                case KW_UNDO:
                case KW_UNION:
                case KW_UNIONTYPE:
                case KW_UNLOCK:
                case KW_UNSET:
                case KW_UNSIGNED:
                case KW_UPDATE:
                case KW_USE:
                case KW_USER:
                case KW_USING:
                case KW_UTC:
                case KW_UTCTIMESTAMP:
                case KW_VALUE_TYPE:
                case KW_VIEW:
                case KW_WHILE:
                case KW_WITH:
                    {
                    alt96=1;
                    }
                    break;
                case KW_FUNCTION:
                    {
                    alt96=2;
                    }
                    break;
                case KW_DATABASE:
                    {
                    alt96=3;
                    }
                    break;
                default:
                    NoViableAltException nvae =
                        new NoViableAltException("", 96, 2, input);

                    throw nvae;

                }

            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 96, 0, input);

                throw nvae;

            }
            switch (alt96) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1210:7: ( KW_DESCRIBE | KW_DESC ) (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY )? (parttype= descPartTypeExpr )
                    {
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1210:7: ( KW_DESCRIBE | KW_DESC )
                    int alt90=2;
                    int LA90_0 = input.LA(1);

                    if ( (LA90_0==KW_DESCRIBE) ) {
                        alt90=1;
                    }
                    else if ( (LA90_0==KW_DESC) ) {
                        alt90=2;
                    }
                    else {
                        NoViableAltException nvae =
                            new NoViableAltException("", 90, 0, input);

                        throw nvae;

                    }
                    switch (alt90) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1210:8: KW_DESCRIBE
                            {
                            KW_DESCRIBE337=(Token)match(input,KW_DESCRIBE,FOLLOW_KW_DESCRIBE_in_descStatement6016);  
                            stream_KW_DESCRIBE.add(KW_DESCRIBE337);


                            }
                            break;
                        case 2 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1210:20: KW_DESC
                            {
                            KW_DESC338=(Token)match(input,KW_DESC,FOLLOW_KW_DESC_in_descStatement6018);  
                            stream_KW_DESC.add(KW_DESC338);


                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1210:29: (descOptions= KW_FORMATTED |descOptions= KW_EXTENDED |descOptions= KW_PRETTY )?
                    int alt91=4;
                    switch ( input.LA(1) ) {
                        case KW_FORMATTED:
                            {
                            switch ( input.LA(2) ) {
                                case Identifier:
                                    {
                                    alt91=1;
                                    }
                                    break;
                                case KW_PARTITION:
                                    {
                                    alt91=1;
                                    }
                                    break;
                                case KW_ADD:
                                case KW_AFTER:
                                case KW_ALTER:
                                case KW_ANALYZE:
                                case KW_ARCHIVE:
                                case KW_ARRAY:
                                case KW_AS:
                                case KW_ASC:
                                case KW_BEFORE:
                                case KW_BETWEEN:
                                case KW_BIGINT:
                                case KW_BINARY:
                                case KW_BOOLEAN:
                                case KW_BOTH:
                                case KW_BUCKET:
                                case KW_BUCKETS:
                                case KW_BY:
                                case KW_CASCADE:
                                case KW_CHANGE:
                                case KW_CLUSTER:
                                case KW_CLUSTERED:
                                case KW_CLUSTERSTATUS:
                                case KW_COLLECTION:
                                case KW_COLUMNS:
                                case KW_COMMENT:
                                case KW_COMPUTE:
                                case KW_CONCATENATE:
                                case KW_CONTINUE:
                                case KW_CREATE:
                                case KW_CUBE:
                                case KW_CURSOR:
                                case KW_DATA:
                                case KW_DATABASES:
                                case KW_DATE:
                                case KW_DATETIME:
                                case KW_DBPROPERTIES:
                                case KW_DECIMAL:
                                case KW_DEFERRED:
                                case KW_DELETE:
                                case KW_DELIMITED:
                                case KW_DEPENDENCY:
                                case KW_DESC:
                                case KW_DESCRIBE:
                                case KW_DIRECTORIES:
                                case KW_DIRECTORY:
                                case KW_DISABLE:
                                case KW_DISTRIBUTE:
                                case KW_DOUBLE:
                                case KW_DROP:
                                case KW_ELEM_TYPE:
                                case KW_ENABLE:
                                case KW_ESCAPED:
                                case KW_EXCLUSIVE:
                                case KW_EXISTS:
                                case KW_EXPLAIN:
                                case KW_EXPORT:
                                case KW_EXTERNAL:
                                case KW_FALSE:
                                case KW_FETCH:
                                case KW_FIELDS:
                                case KW_FILEFORMAT:
                                case KW_FIRST:
                                case KW_FLOAT:
                                case KW_FOR:
                                case KW_FORMAT:
                                case KW_FORMATTED:
                                case KW_FULL:
                                case KW_FUNCTIONS:
                                case KW_GRANT:
                                case KW_GROUP:
                                case KW_GROUPING:
                                case KW_HOLD_DDLTIME:
                                case KW_IDXPROPERTIES:
                                case KW_IGNORE:
                                case KW_IMPORT:
                                case KW_IN:
                                case KW_INDEX:
                                case KW_INDEXES:
                                case KW_INNER:
                                case KW_INPATH:
                                case KW_INPUTDRIVER:
                                case KW_INPUTFORMAT:
                                case KW_INSERT:
                                case KW_INT:
                                case KW_INTERSECT:
                                case KW_INTO:
                                case KW_IS:
                                case KW_ITEMS:
                                case KW_KEYS:
                                case KW_KEY_TYPE:
                                case KW_LATERAL:
                                case KW_LEFT:
                                case KW_LIKE:
                                case KW_LIMIT:
                                case KW_LINES:
                                case KW_LOAD:
                                case KW_LOCAL:
                                case KW_LOCATION:
                                case KW_LOCK:
                                case KW_LOCKS:
                                case KW_LOGICAL:
                                case KW_LONG:
                                case KW_MAPJOIN:
                                case KW_MATERIALIZED:
                                case KW_MINUS:
                                case KW_MSCK:
                                case KW_NOSCAN:
                                case KW_NO_DROP:
                                case KW_NULL:
                                case KW_OF:
                                case KW_OFFLINE:
                                case KW_OPTION:
                                case KW_ORCFILE:
                                case KW_ORDER:
                                case KW_OUT:
                                case KW_OUTER:
                                case KW_OUTPUTDRIVER:
                                case KW_OUTPUTFORMAT:
                                case KW_OVERWRITE:
                                case KW_PARTITIONED:
                                case KW_PARTITIONS:
                                case KW_PERCENT:
                                case KW_PLUS:
                                case KW_PRETTY:
                                case KW_PROCEDURE:
                                case KW_PROTECTION:
                                case KW_PURGE:
                                case KW_RANGE:
                                case KW_RCFILE:
                                case KW_READ:
                                case KW_READONLY:
                                case KW_READS:
                                case KW_REBUILD:
                                case KW_RECORDREADER:
                                case KW_RECORDWRITER:
                                case KW_REGEXP:
                                case KW_RENAME:
                                case KW_REPAIR:
                                case KW_REPLACE:
                                case KW_RESTRICT:
                                case KW_REVOKE:
                                case KW_RIGHT:
                                case KW_RLIKE:
                                case KW_ROLE:
                                case KW_ROLLUP:
                                case KW_ROW:
                                case KW_ROWS:
                                case KW_SCHEMA:
                                case KW_SCHEMAS:
                                case KW_SEMI:
                                case KW_SEQUENCEFILE:
                                case KW_SERDE:
                                case KW_SERDEPROPERTIES:
                                case KW_SET:
                                case KW_SETS:
                                case KW_SHARED:
                                case KW_SHOW:
                                case KW_SHOW_DATABASE:
                                case KW_SKEWED:
                                case KW_SMALLINT:
                                case KW_SORT:
                                case KW_SORTED:
                                case KW_SSL:
                                case KW_STATISTICS:
                                case KW_STORED:
                                case KW_STREAMTABLE:
                                case KW_STRING:
                                case KW_STRUCT:
                                case KW_TABLE:
                                case KW_TABLES:
                                case KW_TBLPROPERTIES:
                                case KW_TEMPORARY:
                                case KW_TERMINATED:
                                case KW_TEXTFILE:
                                case KW_TIMESTAMP:
                                case KW_TINYINT:
                                case KW_TO:
                                case KW_TOUCH:
                                case KW_TRIGGER:
                                case KW_TRUE:
                                case KW_TRUNCATE:
                                case KW_UNARCHIVE:
                                case KW_UNDO:
                                case KW_UNION:
                                case KW_UNIONTYPE:
                                case KW_UNLOCK:
                                case KW_UNSET:
                                case KW_UNSIGNED:
                                case KW_UPDATE:
                                case KW_USE:
                                case KW_USER:
                                case KW_USING:
                                case KW_UTC:
                                case KW_UTCTIMESTAMP:
                                case KW_VALUE_TYPE:
                                case KW_VIEW:
                                case KW_WHILE:
                                case KW_WITH:
                                    {
                                    alt91=1;
                                    }
                                    break;
                            }

                            }
                            break;
                        case KW_EXTENDED:
                            {
                            alt91=2;
                            }
                            break;
                        case KW_PRETTY:
                            {
                            switch ( input.LA(2) ) {
                                case Identifier:
                                    {
                                    alt91=3;
                                    }
                                    break;
                                case KW_PARTITION:
                                    {
                                    alt91=3;
                                    }
                                    break;
                                case KW_ADD:
                                case KW_AFTER:
                                case KW_ALTER:
                                case KW_ANALYZE:
                                case KW_ARCHIVE:
                                case KW_ARRAY:
                                case KW_AS:
                                case KW_ASC:
                                case KW_BEFORE:
                                case KW_BETWEEN:
                                case KW_BIGINT:
                                case KW_BINARY:
                                case KW_BOOLEAN:
                                case KW_BOTH:
                                case KW_BUCKET:
                                case KW_BUCKETS:
                                case KW_BY:
                                case KW_CASCADE:
                                case KW_CHANGE:
                                case KW_CLUSTER:
                                case KW_CLUSTERED:
                                case KW_CLUSTERSTATUS:
                                case KW_COLLECTION:
                                case KW_COLUMNS:
                                case KW_COMMENT:
                                case KW_COMPUTE:
                                case KW_CONCATENATE:
                                case KW_CONTINUE:
                                case KW_CREATE:
                                case KW_CUBE:
                                case KW_CURSOR:
                                case KW_DATA:
                                case KW_DATABASES:
                                case KW_DATE:
                                case KW_DATETIME:
                                case KW_DBPROPERTIES:
                                case KW_DECIMAL:
                                case KW_DEFERRED:
                                case KW_DELETE:
                                case KW_DELIMITED:
                                case KW_DEPENDENCY:
                                case KW_DESC:
                                case KW_DESCRIBE:
                                case KW_DIRECTORIES:
                                case KW_DIRECTORY:
                                case KW_DISABLE:
                                case KW_DISTRIBUTE:
                                case KW_DOUBLE:
                                case KW_DROP:
                                case KW_ELEM_TYPE:
                                case KW_ENABLE:
                                case KW_ESCAPED:
                                case KW_EXCLUSIVE:
                                case KW_EXISTS:
                                case KW_EXPLAIN:
                                case KW_EXPORT:
                                case KW_EXTERNAL:
                                case KW_FALSE:
                                case KW_FETCH:
                                case KW_FIELDS:
                                case KW_FILEFORMAT:
                                case KW_FIRST:
                                case KW_FLOAT:
                                case KW_FOR:
                                case KW_FORMAT:
                                case KW_FORMATTED:
                                case KW_FULL:
                                case KW_FUNCTIONS:
                                case KW_GRANT:
                                case KW_GROUP:
                                case KW_GROUPING:
                                case KW_HOLD_DDLTIME:
                                case KW_IDXPROPERTIES:
                                case KW_IGNORE:
                                case KW_IMPORT:
                                case KW_IN:
                                case KW_INDEX:
                                case KW_INDEXES:
                                case KW_INNER:
                                case KW_INPATH:
                                case KW_INPUTDRIVER:
                                case KW_INPUTFORMAT:
                                case KW_INSERT:
                                case KW_INT:
                                case KW_INTERSECT:
                                case KW_INTO:
                                case KW_IS:
                                case KW_ITEMS:
                                case KW_KEYS:
                                case KW_KEY_TYPE:
                                case KW_LATERAL:
                                case KW_LEFT:
                                case KW_LIKE:
                                case KW_LIMIT:
                                case KW_LINES:
                                case KW_LOAD:
                                case KW_LOCAL:
                                case KW_LOCATION:
                                case KW_LOCK:
                                case KW_LOCKS:
                                case KW_LOGICAL:
                                case KW_LONG:
                                case KW_MAPJOIN:
                                case KW_MATERIALIZED:
                                case KW_MINUS:
                                case KW_MSCK:
                                case KW_NOSCAN:
                                case KW_NO_DROP:
                                case KW_NULL:
                                case KW_OF:
                                case KW_OFFLINE:
                                case KW_OPTION:
                                case KW_ORCFILE:
                                case KW_ORDER:
                                case KW_OUT:
                                case KW_OUTER:
                                case KW_OUTPUTDRIVER:
                                case KW_OUTPUTFORMAT:
                                case KW_OVERWRITE:
                                case KW_PARTITIONED:
                                case KW_PARTITIONS:
                                case KW_PERCENT:
                                case KW_PLUS:
                                case KW_PRETTY:
                                case KW_PROCEDURE:
                                case KW_PROTECTION:
                                case KW_PURGE:
                                case KW_RANGE:
                                case KW_RCFILE:
                                case KW_READ:
                                case KW_READONLY:
                                case KW_READS:
                                case KW_REBUILD:
                                case KW_RECORDREADER:
                                case KW_RECORDWRITER:
                                case KW_REGEXP:
                                case KW_RENAME:
                                case KW_REPAIR:
                                case KW_REPLACE:
                                case KW_RESTRICT:
                                case KW_REVOKE:
                                case KW_RIGHT:
                                case KW_RLIKE:
                                case KW_ROLE:
                                case KW_ROLLUP:
                                case KW_ROW:
                                case KW_ROWS:
                                case KW_SCHEMA:
                                case KW_SCHEMAS:
                                case KW_SEMI:
                                case KW_SEQUENCEFILE:
                                case KW_SERDE:
                                case KW_SERDEPROPERTIES:
                                case KW_SET:
                                case KW_SETS:
                                case KW_SHARED:
                                case KW_SHOW:
                                case KW_SHOW_DATABASE:
                                case KW_SKEWED:
                                case KW_SMALLINT:
                                case KW_SORT:
                                case KW_SORTED:
                                case KW_SSL:
                                case KW_STATISTICS:
                                case KW_STORED:
                                case KW_STREAMTABLE:
                                case KW_STRING:
                                case KW_STRUCT:
                                case KW_TABLE:
                                case KW_TABLES:
                                case KW_TBLPROPERTIES:
                                case KW_TEMPORARY:
                                case KW_TERMINATED:
                                case KW_TEXTFILE:
                                case KW_TIMESTAMP:
                                case KW_TINYINT:
                                case KW_TO:
                                case KW_TOUCH:
                                case KW_TRIGGER:
                                case KW_TRUE:
                                case KW_TRUNCATE:
                                case KW_UNARCHIVE:
                                case KW_UNDO:
                                case KW_UNION:
                                case KW_UNIONTYPE:
                                case KW_UNLOCK:
                                case KW_UNSET:
                                case KW_UNSIGNED:
                                case KW_UPDATE:
                                case KW_USE:
                                case KW_USER:
                                case KW_USING:
                                case KW_UTC:
                                case KW_UTCTIMESTAMP:
                                case KW_VALUE_TYPE:
                                case KW_VIEW:
                                case KW_WHILE:
                                case KW_WITH:
                                    {
                                    alt91=3;
                                    }
                                    break;
                            }

                            }
                            break;
                    }

                    switch (alt91) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1210:30: descOptions= KW_FORMATTED
                            {
                            descOptions=(Token)match(input,KW_FORMATTED,FOLLOW_KW_FORMATTED_in_descStatement6024);  
                            stream_KW_FORMATTED.add(descOptions);


                            }
                            break;
                        case 2 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1210:55: descOptions= KW_EXTENDED
                            {
                            descOptions=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_descStatement6028);  
                            stream_KW_EXTENDED.add(descOptions);


                            }
                            break;
                        case 3 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1210:79: descOptions= KW_PRETTY
                            {
                            descOptions=(Token)match(input,KW_PRETTY,FOLLOW_KW_PRETTY_in_descStatement6032);  
                            stream_KW_PRETTY.add(descOptions);


                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1210:103: (parttype= descPartTypeExpr )
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1210:104: parttype= descPartTypeExpr
                    {
                    pushFollow(FOLLOW_descPartTypeExpr_in_descStatement6039);
                    parttype=descPartTypeExpr();

                    state._fsp--;

                    stream_descPartTypeExpr.add(parttype.getTree());

                    }


                    // AST REWRITE
                    // elements: descOptions, parttype
                    // token labels: descOptions
                    // rule labels: retval, parttype
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_descOptions=new RewriteRuleTokenStream(adaptor,"token descOptions",descOptions);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1210:131: -> ^( TOK_DESCTABLE $parttype ( $descOptions)? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1210:134: ^( TOK_DESCTABLE $parttype ( $descOptions)? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_DESCTABLE, "TOK_DESCTABLE")
                        , root_1);

                        adaptor.addChild(root_1, stream_parttype.nextTree());

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1210:161: ( $descOptions)?
                        if ( stream_descOptions.hasNext() ) {
                            adaptor.addChild(root_1, stream_descOptions.nextNode());

                        }
                        stream_descOptions.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1211:7: ( KW_DESCRIBE | KW_DESC ) KW_FUNCTION ( KW_EXTENDED )? (name= descFuncNames )
                    {
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1211:7: ( KW_DESCRIBE | KW_DESC )
                    int alt92=2;
                    int LA92_0 = input.LA(1);

                    if ( (LA92_0==KW_DESCRIBE) ) {
                        alt92=1;
                    }
                    else if ( (LA92_0==KW_DESC) ) {
                        alt92=2;
                    }
                    else {
                        NoViableAltException nvae =
                            new NoViableAltException("", 92, 0, input);

                        throw nvae;

                    }
                    switch (alt92) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1211:8: KW_DESCRIBE
                            {
                            KW_DESCRIBE339=(Token)match(input,KW_DESCRIBE,FOLLOW_KW_DESCRIBE_in_descStatement6062);  
                            stream_KW_DESCRIBE.add(KW_DESCRIBE339);


                            }
                            break;
                        case 2 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1211:20: KW_DESC
                            {
                            KW_DESC340=(Token)match(input,KW_DESC,FOLLOW_KW_DESC_in_descStatement6064);  
                            stream_KW_DESC.add(KW_DESC340);


                            }
                            break;

                    }


                    KW_FUNCTION341=(Token)match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_descStatement6067);  
                    stream_KW_FUNCTION.add(KW_FUNCTION341);


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1211:41: ( KW_EXTENDED )?
                    int alt93=2;
                    int LA93_0 = input.LA(1);

                    if ( (LA93_0==KW_EXTENDED) ) {
                        alt93=1;
                    }
                    switch (alt93) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1211:41: KW_EXTENDED
                            {
                            KW_EXTENDED342=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_descStatement6069);  
                            stream_KW_EXTENDED.add(KW_EXTENDED342);


                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1211:54: (name= descFuncNames )
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1211:55: name= descFuncNames
                    {
                    pushFollow(FOLLOW_descFuncNames_in_descStatement6075);
                    name=descFuncNames();

                    state._fsp--;

                    stream_descFuncNames.add(name.getTree());

                    }


                    // AST REWRITE
                    // elements: name, KW_EXTENDED
                    // token labels: 
                    // rule labels: retval, name
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1211:75: -> ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1211:78: ^( TOK_DESCFUNCTION $name ( KW_EXTENDED )? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_DESCFUNCTION, "TOK_DESCFUNCTION")
                        , root_1);

                        adaptor.addChild(root_1, stream_name.nextTree());

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1211:103: ( KW_EXTENDED )?
                        if ( stream_KW_EXTENDED.hasNext() ) {
                            adaptor.addChild(root_1, 
                            stream_KW_EXTENDED.nextNode()
                            );

                        }
                        stream_KW_EXTENDED.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1212:7: ( KW_DESCRIBE | KW_DESC ) KW_DATABASE ( KW_EXTENDED )? (dbName= identifier )
                    {
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1212:7: ( KW_DESCRIBE | KW_DESC )
                    int alt94=2;
                    int LA94_0 = input.LA(1);

                    if ( (LA94_0==KW_DESCRIBE) ) {
                        alt94=1;
                    }
                    else if ( (LA94_0==KW_DESC) ) {
                        alt94=2;
                    }
                    else {
                        NoViableAltException nvae =
                            new NoViableAltException("", 94, 0, input);

                        throw nvae;

                    }
                    switch (alt94) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1212:8: KW_DESCRIBE
                            {
                            KW_DESCRIBE343=(Token)match(input,KW_DESCRIBE,FOLLOW_KW_DESCRIBE_in_descStatement6097);  
                            stream_KW_DESCRIBE.add(KW_DESCRIBE343);


                            }
                            break;
                        case 2 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1212:20: KW_DESC
                            {
                            KW_DESC344=(Token)match(input,KW_DESC,FOLLOW_KW_DESC_in_descStatement6099);  
                            stream_KW_DESC.add(KW_DESC344);


                            }
                            break;

                    }


                    KW_DATABASE345=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_descStatement6102);  
                    stream_KW_DATABASE.add(KW_DATABASE345);


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1212:41: ( KW_EXTENDED )?
                    int alt95=2;
                    int LA95_0 = input.LA(1);

                    if ( (LA95_0==KW_EXTENDED) ) {
                        alt95=1;
                    }
                    switch (alt95) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1212:41: KW_EXTENDED
                            {
                            KW_EXTENDED346=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_descStatement6104);  
                            stream_KW_EXTENDED.add(KW_EXTENDED346);


                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1212:54: (dbName= identifier )
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1212:55: dbName= identifier
                    {
                    pushFollow(FOLLOW_identifier_in_descStatement6110);
                    dbName=identifier();

                    state._fsp--;

                    stream_identifier.add(dbName.getTree());

                    }


                    // AST REWRITE
                    // elements: KW_EXTENDED, dbName
                    // token labels: 
                    // rule labels: retval, dbName
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_dbName=new RewriteRuleSubtreeStream(adaptor,"rule dbName",dbName!=null?dbName.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1212:74: -> ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1212:77: ^( TOK_DESCDATABASE $dbName ( KW_EXTENDED )? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_DESCDATABASE, "TOK_DESCDATABASE")
                        , root_1);

                        adaptor.addChild(root_1, stream_dbName.nextTree());

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1212:104: ( KW_EXTENDED )?
                        if ( stream_KW_EXTENDED.hasNext() ) {
                            adaptor.addChild(root_1, 
                            stream_KW_EXTENDED.nextNode()
                            );

                        }
                        stream_KW_EXTENDED.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "descStatement"


    public static class analyzeStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "analyzeStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1215:1: analyzeStatement : KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | (partialscan= KW_PARTIALSCAN ) | ( KW_FOR KW_COLUMNS statsColumnName= columnNameList ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( $partialscan)? ( $statsColumnName)? ) ;
    public final HiveParser.analyzeStatement_return analyzeStatement() throws RecognitionException {
        HiveParser.analyzeStatement_return retval = new HiveParser.analyzeStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token noscan=null;
        Token partialscan=null;
        Token KW_ANALYZE347=null;
        Token KW_TABLE348=null;
        Token KW_COMPUTE349=null;
        Token KW_STATISTICS350=null;
        Token KW_FOR351=null;
        Token KW_COLUMNS352=null;
        HiveParser_IdentifiersParser.tableOrPartition_return parttype =null;

        HiveParser.columnNameList_return statsColumnName =null;


        CommonTree noscan_tree=null;
        CommonTree partialscan_tree=null;
        CommonTree KW_ANALYZE347_tree=null;
        CommonTree KW_TABLE348_tree=null;
        CommonTree KW_COMPUTE349_tree=null;
        CommonTree KW_STATISTICS350_tree=null;
        CommonTree KW_FOR351_tree=null;
        CommonTree KW_COLUMNS352_tree=null;
        RewriteRuleTokenStream stream_KW_ANALYZE=new RewriteRuleTokenStream(adaptor,"token KW_ANALYZE");
        RewriteRuleTokenStream stream_KW_NOSCAN=new RewriteRuleTokenStream(adaptor,"token KW_NOSCAN");
        RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
        RewriteRuleTokenStream stream_KW_STATISTICS=new RewriteRuleTokenStream(adaptor,"token KW_STATISTICS");
        RewriteRuleTokenStream stream_KW_FOR=new RewriteRuleTokenStream(adaptor,"token KW_FOR");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_KW_COMPUTE=new RewriteRuleTokenStream(adaptor,"token KW_COMPUTE");
        RewriteRuleTokenStream stream_KW_PARTIALSCAN=new RewriteRuleTokenStream(adaptor,"token KW_PARTIALSCAN");
        RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
        RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
         msgs.push("analyze statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:5: ( KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | (partialscan= KW_PARTIALSCAN ) | ( KW_FOR KW_COLUMNS statsColumnName= columnNameList ) )? -> ^( TOK_ANALYZE $parttype ( $noscan)? ( $partialscan)? ( $statsColumnName)? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:7: KW_ANALYZE KW_TABLE (parttype= tableOrPartition ) KW_COMPUTE KW_STATISTICS ( (noscan= KW_NOSCAN ) | (partialscan= KW_PARTIALSCAN ) | ( KW_FOR KW_COLUMNS statsColumnName= columnNameList ) )?
            {
            KW_ANALYZE347=(Token)match(input,KW_ANALYZE,FOLLOW_KW_ANALYZE_in_analyzeStatement6150);  
            stream_KW_ANALYZE.add(KW_ANALYZE347);


            KW_TABLE348=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_analyzeStatement6152);  
            stream_KW_TABLE.add(KW_TABLE348);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:27: (parttype= tableOrPartition )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:28: parttype= tableOrPartition
            {
            pushFollow(FOLLOW_tableOrPartition_in_analyzeStatement6157);
            parttype=tableOrPartition();

            state._fsp--;

            stream_tableOrPartition.add(parttype.getTree());

            }


            KW_COMPUTE349=(Token)match(input,KW_COMPUTE,FOLLOW_KW_COMPUTE_in_analyzeStatement6160);  
            stream_KW_COMPUTE.add(KW_COMPUTE349);


            KW_STATISTICS350=(Token)match(input,KW_STATISTICS,FOLLOW_KW_STATISTICS_in_analyzeStatement6162);  
            stream_KW_STATISTICS.add(KW_STATISTICS350);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:80: ( (noscan= KW_NOSCAN ) | (partialscan= KW_PARTIALSCAN ) | ( KW_FOR KW_COLUMNS statsColumnName= columnNameList ) )?
            int alt97=4;
            switch ( input.LA(1) ) {
                case KW_NOSCAN:
                    {
                    alt97=1;
                    }
                    break;
                case KW_PARTIALSCAN:
                    {
                    alt97=2;
                    }
                    break;
                case KW_FOR:
                    {
                    alt97=3;
                    }
                    break;
            }

            switch (alt97) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:81: (noscan= KW_NOSCAN )
                    {
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:81: (noscan= KW_NOSCAN )
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:82: noscan= KW_NOSCAN
                    {
                    noscan=(Token)match(input,KW_NOSCAN,FOLLOW_KW_NOSCAN_in_analyzeStatement6168);  
                    stream_KW_NOSCAN.add(noscan);


                    }


                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:102: (partialscan= KW_PARTIALSCAN )
                    {
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:102: (partialscan= KW_PARTIALSCAN )
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:103: partialscan= KW_PARTIALSCAN
                    {
                    partialscan=(Token)match(input,KW_PARTIALSCAN,FOLLOW_KW_PARTIALSCAN_in_analyzeStatement6176);  
                    stream_KW_PARTIALSCAN.add(partialscan);


                    }


                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:133: ( KW_FOR KW_COLUMNS statsColumnName= columnNameList )
                    {
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:133: ( KW_FOR KW_COLUMNS statsColumnName= columnNameList )
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:134: KW_FOR KW_COLUMNS statsColumnName= columnNameList
                    {
                    KW_FOR351=(Token)match(input,KW_FOR,FOLLOW_KW_FOR_in_analyzeStatement6182);  
                    stream_KW_FOR.add(KW_FOR351);


                    KW_COLUMNS352=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_analyzeStatement6184);  
                    stream_KW_COLUMNS.add(KW_COLUMNS352);


                    pushFollow(FOLLOW_columnNameList_in_analyzeStatement6188);
                    statsColumnName=columnNameList();

                    state._fsp--;

                    stream_columnNameList.add(statsColumnName.getTree());

                    }


                    }
                    break;

            }


            // AST REWRITE
            // elements: partialscan, parttype, statsColumnName, noscan
            // token labels: partialscan, noscan
            // rule labels: retval, parttype, statsColumnName
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_partialscan=new RewriteRuleTokenStream(adaptor,"token partialscan",partialscan);
            RewriteRuleTokenStream stream_noscan=new RewriteRuleTokenStream(adaptor,"token noscan",noscan);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.tree:null);
            RewriteRuleSubtreeStream stream_statsColumnName=new RewriteRuleSubtreeStream(adaptor,"rule statsColumnName",statsColumnName!=null?statsColumnName.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1218:186: -> ^( TOK_ANALYZE $parttype ( $noscan)? ( $partialscan)? ( $statsColumnName)? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:189: ^( TOK_ANALYZE $parttype ( $noscan)? ( $partialscan)? ( $statsColumnName)? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_ANALYZE, "TOK_ANALYZE")
                , root_1);

                adaptor.addChild(root_1, stream_parttype.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:214: ( $noscan)?
                if ( stream_noscan.hasNext() ) {
                    adaptor.addChild(root_1, stream_noscan.nextNode());

                }
                stream_noscan.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:223: ( $partialscan)?
                if ( stream_partialscan.hasNext() ) {
                    adaptor.addChild(root_1, stream_partialscan.nextNode());

                }
                stream_partialscan.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1218:237: ( $statsColumnName)?
                if ( stream_statsColumnName.hasNext() ) {
                    adaptor.addChild(root_1, stream_statsColumnName.nextTree());

                }
                stream_statsColumnName.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "analyzeStatement"


    public static class showStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "showStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1221:1: showStatement : ( KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )? -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? ) | KW_SHOW KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_COLUMNS ( KW_FROM | KW_IN ) tabname= tableName ( ( KW_FROM | KW_IN ) db_name= identifier )? -> ^( TOK_SHOWCOLUMNS ( $db_name)? $tabname) | KW_SHOW KW_FUNCTIONS ( showStmtIdentifier )? -> ^( TOK_SHOWFUNCTIONS ( showStmtIdentifier )? ) | KW_SHOW KW_PARTITIONS identifier ( partitionSpec )? -> ^( TOK_SHOWPARTITIONS identifier ( partitionSpec )? ) | KW_SHOW KW_CREATE KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) | KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )? -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? ) | KW_SHOW KW_TBLPROPERTIES tblName= identifier ( LPAREN prptyName= StringLiteral RPAREN )? -> ^( TOK_SHOW_TBLPROPERTIES $tblName ( $prptyName)? ) | KW_SHOW KW_LOCKS (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) | KW_SHOW (showOptions= KW_FORMATTED )? ( KW_INDEX | KW_INDEXES ) KW_ON showStmtIdentifier ( ( KW_FROM | KW_IN ) db_name= identifier )? -> ^( TOK_SHOWINDEXES showStmtIdentifier ( $showOptions)? ( $db_name)? ) );
    public final HiveParser.showStatement_return showStatement() throws RecognitionException {
        HiveParser.showStatement_return retval = new HiveParser.showStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token prptyName=null;
        Token isExtended=null;
        Token showOptions=null;
        Token KW_SHOW353=null;
        Token KW_DATABASES354=null;
        Token KW_SCHEMAS355=null;
        Token KW_LIKE356=null;
        Token KW_SHOW358=null;
        Token KW_TABLES359=null;
        Token KW_FROM360=null;
        Token KW_IN361=null;
        Token KW_LIKE362=null;
        Token KW_SHOW365=null;
        Token KW_COLUMNS366=null;
        Token KW_FROM367=null;
        Token KW_IN368=null;
        Token KW_FROM369=null;
        Token KW_IN370=null;
        Token KW_SHOW371=null;
        Token KW_FUNCTIONS372=null;
        Token KW_SHOW374=null;
        Token KW_PARTITIONS375=null;
        Token KW_SHOW378=null;
        Token KW_CREATE379=null;
        Token KW_TABLE380=null;
        Token KW_SHOW381=null;
        Token KW_TABLE382=null;
        Token KW_EXTENDED383=null;
        Token KW_FROM384=null;
        Token KW_IN385=null;
        Token KW_LIKE386=null;
        Token KW_SHOW389=null;
        Token KW_TBLPROPERTIES390=null;
        Token LPAREN391=null;
        Token RPAREN392=null;
        Token KW_SHOW393=null;
        Token KW_LOCKS394=null;
        Token KW_SHOW395=null;
        Token KW_INDEX396=null;
        Token KW_INDEXES397=null;
        Token KW_ON398=null;
        Token KW_FROM400=null;
        Token KW_IN401=null;
        HiveParser_IdentifiersParser.identifier_return db_name =null;

        HiveParser_FromClauseParser.tableName_return tabname =null;

        HiveParser_FromClauseParser.tableName_return tabName =null;

        HiveParser_IdentifiersParser.identifier_return tblName =null;

        HiveParser.partTypeExpr_return parttype =null;

        HiveParser.showStmtIdentifier_return showStmtIdentifier357 =null;

        HiveParser.showStmtIdentifier_return showStmtIdentifier363 =null;

        HiveParser.showStmtIdentifier_return showStmtIdentifier364 =null;

        HiveParser.showStmtIdentifier_return showStmtIdentifier373 =null;

        HiveParser_IdentifiersParser.identifier_return identifier376 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec377 =null;

        HiveParser.showStmtIdentifier_return showStmtIdentifier387 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec388 =null;

        HiveParser.showStmtIdentifier_return showStmtIdentifier399 =null;


        CommonTree prptyName_tree=null;
        CommonTree isExtended_tree=null;
        CommonTree showOptions_tree=null;
        CommonTree KW_SHOW353_tree=null;
        CommonTree KW_DATABASES354_tree=null;
        CommonTree KW_SCHEMAS355_tree=null;
        CommonTree KW_LIKE356_tree=null;
        CommonTree KW_SHOW358_tree=null;
        CommonTree KW_TABLES359_tree=null;
        CommonTree KW_FROM360_tree=null;
        CommonTree KW_IN361_tree=null;
        CommonTree KW_LIKE362_tree=null;
        CommonTree KW_SHOW365_tree=null;
        CommonTree KW_COLUMNS366_tree=null;
        CommonTree KW_FROM367_tree=null;
        CommonTree KW_IN368_tree=null;
        CommonTree KW_FROM369_tree=null;
        CommonTree KW_IN370_tree=null;
        CommonTree KW_SHOW371_tree=null;
        CommonTree KW_FUNCTIONS372_tree=null;
        CommonTree KW_SHOW374_tree=null;
        CommonTree KW_PARTITIONS375_tree=null;
        CommonTree KW_SHOW378_tree=null;
        CommonTree KW_CREATE379_tree=null;
        CommonTree KW_TABLE380_tree=null;
        CommonTree KW_SHOW381_tree=null;
        CommonTree KW_TABLE382_tree=null;
        CommonTree KW_EXTENDED383_tree=null;
        CommonTree KW_FROM384_tree=null;
        CommonTree KW_IN385_tree=null;
        CommonTree KW_LIKE386_tree=null;
        CommonTree KW_SHOW389_tree=null;
        CommonTree KW_TBLPROPERTIES390_tree=null;
        CommonTree LPAREN391_tree=null;
        CommonTree RPAREN392_tree=null;
        CommonTree KW_SHOW393_tree=null;
        CommonTree KW_LOCKS394_tree=null;
        CommonTree KW_SHOW395_tree=null;
        CommonTree KW_INDEX396_tree=null;
        CommonTree KW_INDEXES397_tree=null;
        CommonTree KW_ON398_tree=null;
        CommonTree KW_FROM400_tree=null;
        CommonTree KW_IN401_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
        RewriteRuleTokenStream stream_KW_LOCKS=new RewriteRuleTokenStream(adaptor,"token KW_LOCKS");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_LIKE=new RewriteRuleTokenStream(adaptor,"token KW_LIKE");
        RewriteRuleTokenStream stream_KW_FORMATTED=new RewriteRuleTokenStream(adaptor,"token KW_FORMATTED");
        RewriteRuleTokenStream stream_KW_COLUMNS=new RewriteRuleTokenStream(adaptor,"token KW_COLUMNS");
        RewriteRuleTokenStream stream_KW_PARTITIONS=new RewriteRuleTokenStream(adaptor,"token KW_PARTITIONS");
        RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
        RewriteRuleTokenStream stream_KW_FUNCTIONS=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTIONS");
        RewriteRuleTokenStream stream_KW_IN=new RewriteRuleTokenStream(adaptor,"token KW_IN");
        RewriteRuleTokenStream stream_KW_INDEXES=new RewriteRuleTokenStream(adaptor,"token KW_INDEXES");
        RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
        RewriteRuleTokenStream stream_KW_SCHEMAS=new RewriteRuleTokenStream(adaptor,"token KW_SCHEMAS");
        RewriteRuleTokenStream stream_KW_INDEX=new RewriteRuleTokenStream(adaptor,"token KW_INDEX");
        RewriteRuleTokenStream stream_KW_TABLES=new RewriteRuleTokenStream(adaptor,"token KW_TABLES");
        RewriteRuleTokenStream stream_KW_EXTENDED=new RewriteRuleTokenStream(adaptor,"token KW_EXTENDED");
        RewriteRuleTokenStream stream_KW_DATABASES=new RewriteRuleTokenStream(adaptor,"token KW_DATABASES");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_KW_TBLPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_TBLPROPERTIES");
        RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
        RewriteRuleSubtreeStream stream_showStmtIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule showStmtIdentifier");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_partTypeExpr=new RewriteRuleSubtreeStream(adaptor,"rule partTypeExpr");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("show statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1224:5: ( KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )? -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? ) | KW_SHOW KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )? -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( showStmtIdentifier )? ) | KW_SHOW KW_COLUMNS ( KW_FROM | KW_IN ) tabname= tableName ( ( KW_FROM | KW_IN ) db_name= identifier )? -> ^( TOK_SHOWCOLUMNS ( $db_name)? $tabname) | KW_SHOW KW_FUNCTIONS ( showStmtIdentifier )? -> ^( TOK_SHOWFUNCTIONS ( showStmtIdentifier )? ) | KW_SHOW KW_PARTITIONS identifier ( partitionSpec )? -> ^( TOK_SHOWPARTITIONS identifier ( partitionSpec )? ) | KW_SHOW KW_CREATE KW_TABLE tabName= tableName -> ^( TOK_SHOW_CREATETABLE $tabName) | KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )? -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? ) | KW_SHOW KW_TBLPROPERTIES tblName= identifier ( LPAREN prptyName= StringLiteral RPAREN )? -> ^( TOK_SHOW_TBLPROPERTIES $tblName ( $prptyName)? ) | KW_SHOW KW_LOCKS (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )? -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? ) | KW_SHOW (showOptions= KW_FORMATTED )? ( KW_INDEX | KW_INDEXES ) KW_ON showStmtIdentifier ( ( KW_FROM | KW_IN ) db_name= identifier )? -> ^( TOK_SHOWINDEXES showStmtIdentifier ( $showOptions)? ( $db_name)? ) )
            int alt118=10;
            int LA118_0 = input.LA(1);

            if ( (LA118_0==KW_SHOW) ) {
                switch ( input.LA(2) ) {
                case KW_TABLES:
                    {
                    alt118=2;
                    }
                    break;
                case KW_COLUMNS:
                    {
                    alt118=3;
                    }
                    break;
                case KW_FUNCTIONS:
                    {
                    alt118=4;
                    }
                    break;
                case KW_PARTITIONS:
                    {
                    alt118=5;
                    }
                    break;
                case KW_CREATE:
                    {
                    alt118=6;
                    }
                    break;
                case KW_TABLE:
                    {
                    alt118=7;
                    }
                    break;
                case KW_TBLPROPERTIES:
                    {
                    alt118=8;
                    }
                    break;
                case KW_LOCKS:
                    {
                    alt118=9;
                    }
                    break;
                case KW_DATABASES:
                case KW_SCHEMAS:
                    {
                    alt118=1;
                    }
                    break;
                case KW_FORMATTED:
                case KW_INDEX:
                case KW_INDEXES:
                    {
                    alt118=10;
                    }
                    break;
                default:
                    NoViableAltException nvae =
                        new NoViableAltException("", 118, 1, input);

                    throw nvae;

                }

            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 118, 0, input);

                throw nvae;

            }
            switch (alt118) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1224:7: KW_SHOW ( KW_DATABASES | KW_SCHEMAS ) ( KW_LIKE showStmtIdentifier )?
                    {
                    KW_SHOW353=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement6239);  
                    stream_KW_SHOW.add(KW_SHOW353);


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1224:15: ( KW_DATABASES | KW_SCHEMAS )
                    int alt98=2;
                    int LA98_0 = input.LA(1);

                    if ( (LA98_0==KW_DATABASES) ) {
                        alt98=1;
                    }
                    else if ( (LA98_0==KW_SCHEMAS) ) {
                        alt98=2;
                    }
                    else {
                        NoViableAltException nvae =
                            new NoViableAltException("", 98, 0, input);

                        throw nvae;

                    }
                    switch (alt98) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1224:16: KW_DATABASES
                            {
                            KW_DATABASES354=(Token)match(input,KW_DATABASES,FOLLOW_KW_DATABASES_in_showStatement6242);  
                            stream_KW_DATABASES.add(KW_DATABASES354);


                            }
                            break;
                        case 2 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1224:29: KW_SCHEMAS
                            {
                            KW_SCHEMAS355=(Token)match(input,KW_SCHEMAS,FOLLOW_KW_SCHEMAS_in_showStatement6244);  
                            stream_KW_SCHEMAS.add(KW_SCHEMAS355);


                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1224:41: ( KW_LIKE showStmtIdentifier )?
                    int alt99=2;
                    int LA99_0 = input.LA(1);

                    if ( (LA99_0==KW_LIKE) ) {
                        alt99=1;
                    }
                    switch (alt99) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1224:42: KW_LIKE showStmtIdentifier
                            {
                            KW_LIKE356=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement6248);  
                            stream_KW_LIKE.add(KW_LIKE356);


                            pushFollow(FOLLOW_showStmtIdentifier_in_showStatement6250);
                            showStmtIdentifier357=showStmtIdentifier();

                            state._fsp--;

                            stream_showStmtIdentifier.add(showStmtIdentifier357.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: showStmtIdentifier
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1224:71: -> ^( TOK_SHOWDATABASES ( showStmtIdentifier )? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1224:74: ^( TOK_SHOWDATABASES ( showStmtIdentifier )? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_SHOWDATABASES, "TOK_SHOWDATABASES")
                        , root_1);

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1224:94: ( showStmtIdentifier )?
                        if ( stream_showStmtIdentifier.hasNext() ) {
                            adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());

                        }
                        stream_showStmtIdentifier.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1225:7: KW_SHOW KW_TABLES ( ( KW_FROM | KW_IN ) db_name= identifier )? ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
                    {
                    KW_SHOW358=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement6269);  
                    stream_KW_SHOW.add(KW_SHOW358);


                    KW_TABLES359=(Token)match(input,KW_TABLES,FOLLOW_KW_TABLES_in_showStatement6271);  
                    stream_KW_TABLES.add(KW_TABLES359);


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1225:25: ( ( KW_FROM | KW_IN ) db_name= identifier )?
                    int alt101=2;
                    int LA101_0 = input.LA(1);

                    if ( (LA101_0==KW_FROM) ) {
                        alt101=1;
                    }
                    else if ( (LA101_0==KW_IN) ) {
                        int LA101_2 = input.LA(2);

                        if ( ((LA101_2 >= Identifier && LA101_2 <= KW_AFTER)||(LA101_2 >= KW_ALTER && LA101_2 <= KW_ANALYZE)||(LA101_2 >= KW_ARCHIVE && LA101_2 <= KW_CASCADE)||(LA101_2 >= KW_CHANGE && LA101_2 <= KW_COLLECTION)||(LA101_2 >= KW_COLUMNS && LA101_2 <= KW_CREATE)||LA101_2==KW_CUBE||(LA101_2 >= KW_CURSOR && LA101_2 <= KW_DATA)||(LA101_2 >= KW_DATABASES && LA101_2 <= KW_DISABLE)||(LA101_2 >= KW_DISTRIBUTE && LA101_2 <= KW_ELEM_TYPE)||LA101_2==KW_ENABLE||LA101_2==KW_ESCAPED||(LA101_2 >= KW_EXCLUSIVE && LA101_2 <= KW_EXPORT)||(LA101_2 >= KW_EXTERNAL && LA101_2 <= KW_FLOAT)||(LA101_2 >= KW_FOR && LA101_2 <= KW_FORMATTED)||LA101_2==KW_FULL||(LA101_2 >= KW_FUNCTIONS && LA101_2 <= KW_GROUPING)||(LA101_2 >= KW_HOLD_DDLTIME && LA101_2 <= KW_IDXPROPERTIES)||(LA101_2 >= KW_IGNORE && LA101_2 <= KW_ITEMS)||(LA101_2 >= KW_KEYS && LA101_2 <= KW_LEFT)||(LA101_2 >= KW_LIKE && LA101_2 <= KW_LONG)||(LA101_2 >= KW_MAPJOIN && LA101_2 <= KW_MINUS)||(LA101_2 >= KW_MSCK && LA101_2 <= KW_NOSCAN)||(LA101_2 >= KW_NO_DROP && LA101_2 <= KW_OFFLINE)||LA101_2==KW_OPTION||(LA101_2 >= KW_ORCFILE && LA101_2 <= KW_OUTPUTFORMAT)||LA101_2==KW_OVERWRITE||(LA101_2 >= KW_PARTITION && LA101_2 <= KW_PLUS)||(LA101_2 >= KW_PRETTY && LA101_2 <= KW_RECORDWRITER)||(LA101_2 >= KW_REGEXP && LA101_2 <= KW_SCHEMAS)||(LA101_2 >= KW_SEMI && LA101_2 <= KW_TABLES)||(LA101_2 >= KW_TBLPROPERTIES && LA101_2 <= KW_TEXTFILE)||(LA101_2 >= KW_TIMESTAMP && LA101_2 <= KW_TOUCH)||(LA101_2 >= KW_TRIGGER && LA101_2 <= KW_UNARCHIVE)||(LA101_2 >= KW_UNDO && LA101_2 <= KW_UNIONTYPE)||(LA101_2 >= KW_UNLOCK && LA101_2 <= KW_VALUE_TYPE)||LA101_2==KW_VIEW||LA101_2==KW_WHILE||LA101_2==KW_WITH) ) {
                            alt101=1;
                        }
                    }
                    switch (alt101) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1225:26: ( KW_FROM | KW_IN ) db_name= identifier
                            {
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1225:26: ( KW_FROM | KW_IN )
                            int alt100=2;
                            int LA100_0 = input.LA(1);

                            if ( (LA100_0==KW_FROM) ) {
                                alt100=1;
                            }
                            else if ( (LA100_0==KW_IN) ) {
                                alt100=2;
                            }
                            else {
                                NoViableAltException nvae =
                                    new NoViableAltException("", 100, 0, input);

                                throw nvae;

                            }
                            switch (alt100) {
                                case 1 :
                                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1225:27: KW_FROM
                                    {
                                    KW_FROM360=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement6275);  
                                    stream_KW_FROM.add(KW_FROM360);


                                    }
                                    break;
                                case 2 :
                                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1225:35: KW_IN
                                    {
                                    KW_IN361=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement6277);  
                                    stream_KW_IN.add(KW_IN361);


                                    }
                                    break;

                            }


                            pushFollow(FOLLOW_identifier_in_showStatement6282);
                            db_name=identifier();

                            state._fsp--;

                            stream_identifier.add(db_name.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1225:63: ( KW_LIKE showStmtIdentifier | showStmtIdentifier )?
                    int alt102=3;
                    int LA102_0 = input.LA(1);

                    if ( (LA102_0==KW_LIKE) ) {
                        int LA102_1 = input.LA(2);

                        if ( ((LA102_1 >= Identifier && LA102_1 <= KW_AFTER)||(LA102_1 >= KW_ALTER && LA102_1 <= KW_ANALYZE)||(LA102_1 >= KW_ARCHIVE && LA102_1 <= KW_CASCADE)||(LA102_1 >= KW_CHANGE && LA102_1 <= KW_COLLECTION)||(LA102_1 >= KW_COLUMNS && LA102_1 <= KW_CREATE)||LA102_1==KW_CUBE||(LA102_1 >= KW_CURSOR && LA102_1 <= KW_DATA)||(LA102_1 >= KW_DATABASES && LA102_1 <= KW_DISABLE)||(LA102_1 >= KW_DISTRIBUTE && LA102_1 <= KW_ELEM_TYPE)||LA102_1==KW_ENABLE||LA102_1==KW_ESCAPED||(LA102_1 >= KW_EXCLUSIVE && LA102_1 <= KW_EXPORT)||(LA102_1 >= KW_EXTERNAL && LA102_1 <= KW_FLOAT)||(LA102_1 >= KW_FOR && LA102_1 <= KW_FORMATTED)||LA102_1==KW_FULL||(LA102_1 >= KW_FUNCTIONS && LA102_1 <= KW_GROUPING)||(LA102_1 >= KW_HOLD_DDLTIME && LA102_1 <= KW_IDXPROPERTIES)||(LA102_1 >= KW_IGNORE && LA102_1 <= KW_ITEMS)||(LA102_1 >= KW_KEYS && LA102_1 <= KW_LEFT)||(LA102_1 >= KW_LIKE && LA102_1 <= KW_LONG)||(LA102_1 >= KW_MAPJOIN && LA102_1 <= KW_MINUS)||(LA102_1 >= KW_MSCK && LA102_1 <= KW_NOSCAN)||(LA102_1 >= KW_NO_DROP && LA102_1 <= KW_OFFLINE)||LA102_1==KW_OPTION||(LA102_1 >= KW_ORCFILE && LA102_1 <= KW_OUTPUTFORMAT)||LA102_1==KW_OVERWRITE||(LA102_1 >= KW_PARTITION && LA102_1 <= KW_PLUS)||(LA102_1 >= KW_PRETTY && LA102_1 <= KW_RECORDWRITER)||(LA102_1 >= KW_REGEXP && LA102_1 <= KW_SCHEMAS)||(LA102_1 >= KW_SEMI && LA102_1 <= KW_TABLES)||(LA102_1 >= KW_TBLPROPERTIES && LA102_1 <= KW_TEXTFILE)||(LA102_1 >= KW_TIMESTAMP && LA102_1 <= KW_TOUCH)||(LA102_1 >= KW_TRIGGER && LA102_1 <= KW_UNARCHIVE)||(LA102_1 >= KW_UNDO && LA102_1 <= KW_UNIONTYPE)||(LA102_1 >= KW_UNLOCK && LA102_1 <= KW_VALUE_TYPE)||LA102_1==KW_VIEW||LA102_1==KW_WHILE||LA102_1==KW_WITH||LA102_1==StringLiteral) ) {
                            alt102=1;
                        }
                        else if ( (LA102_1==EOF) ) {
                            alt102=2;
                        }
                    }
                    else if ( ((LA102_0 >= Identifier && LA102_0 <= KW_AFTER)||(LA102_0 >= KW_ALTER && LA102_0 <= KW_ANALYZE)||(LA102_0 >= KW_ARCHIVE && LA102_0 <= KW_CASCADE)||(LA102_0 >= KW_CHANGE && LA102_0 <= KW_COLLECTION)||(LA102_0 >= KW_COLUMNS && LA102_0 <= KW_CREATE)||LA102_0==KW_CUBE||(LA102_0 >= KW_CURSOR && LA102_0 <= KW_DATA)||(LA102_0 >= KW_DATABASES && LA102_0 <= KW_DISABLE)||(LA102_0 >= KW_DISTRIBUTE && LA102_0 <= KW_ELEM_TYPE)||LA102_0==KW_ENABLE||LA102_0==KW_ESCAPED||(LA102_0 >= KW_EXCLUSIVE && LA102_0 <= KW_EXPORT)||(LA102_0 >= KW_EXTERNAL && LA102_0 <= KW_FLOAT)||(LA102_0 >= KW_FOR && LA102_0 <= KW_FORMATTED)||LA102_0==KW_FULL||(LA102_0 >= KW_FUNCTIONS && LA102_0 <= KW_GROUPING)||(LA102_0 >= KW_HOLD_DDLTIME && LA102_0 <= KW_IDXPROPERTIES)||(LA102_0 >= KW_IGNORE && LA102_0 <= KW_ITEMS)||(LA102_0 >= KW_KEYS && LA102_0 <= KW_LEFT)||(LA102_0 >= KW_LIMIT && LA102_0 <= KW_LONG)||(LA102_0 >= KW_MAPJOIN && LA102_0 <= KW_MINUS)||(LA102_0 >= KW_MSCK && LA102_0 <= KW_NOSCAN)||(LA102_0 >= KW_NO_DROP && LA102_0 <= KW_OFFLINE)||LA102_0==KW_OPTION||(LA102_0 >= KW_ORCFILE && LA102_0 <= KW_OUTPUTFORMAT)||LA102_0==KW_OVERWRITE||(LA102_0 >= KW_PARTITION && LA102_0 <= KW_PLUS)||(LA102_0 >= KW_PRETTY && LA102_0 <= KW_RECORDWRITER)||(LA102_0 >= KW_REGEXP && LA102_0 <= KW_SCHEMAS)||(LA102_0 >= KW_SEMI && LA102_0 <= KW_TABLES)||(LA102_0 >= KW_TBLPROPERTIES && LA102_0 <= KW_TEXTFILE)||(LA102_0 >= KW_TIMESTAMP && LA102_0 <= KW_TOUCH)||(LA102_0 >= KW_TRIGGER && LA102_0 <= KW_UNARCHIVE)||(LA102_0 >= KW_UNDO && LA102_0 <= KW_UNIONTYPE)||(LA102_0 >= KW_UNLOCK && LA102_0 <= KW_VALUE_TYPE)||LA102_0==KW_VIEW||LA102_0==KW_WHILE||LA102_0==KW_WITH||LA102_0==StringLiteral) ) {
                        alt102=2;
                    }
                    switch (alt102) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1225:64: KW_LIKE showStmtIdentifier
                            {
                            KW_LIKE362=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement6287);  
                            stream_KW_LIKE.add(KW_LIKE362);


                            pushFollow(FOLLOW_showStmtIdentifier_in_showStatement6289);
                            showStmtIdentifier363=showStmtIdentifier();

                            state._fsp--;

                            stream_showStmtIdentifier.add(showStmtIdentifier363.getTree());

                            }
                            break;
                        case 2 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1225:91: showStmtIdentifier
                            {
                            pushFollow(FOLLOW_showStmtIdentifier_in_showStatement6291);
                            showStmtIdentifier364=showStmtIdentifier();

                            state._fsp--;

                            stream_showStmtIdentifier.add(showStmtIdentifier364.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: db_name, showStmtIdentifier
                    // token labels: 
                    // rule labels: retval, db_name
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1225:113: -> ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1225:116: ^( TOK_SHOWTABLES ( TOK_FROM $db_name)? ( showStmtIdentifier )? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_SHOWTABLES, "TOK_SHOWTABLES")
                        , root_1);

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1225:133: ( TOK_FROM $db_name)?
                        if ( stream_db_name.hasNext() ) {
                            adaptor.addChild(root_1, 
                            (CommonTree)adaptor.create(TOK_FROM, "TOK_FROM")
                            );

                            adaptor.addChild(root_1, stream_db_name.nextTree());

                        }
                        stream_db_name.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1225:154: ( showStmtIdentifier )?
                        if ( stream_showStmtIdentifier.hasNext() ) {
                            adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());

                        }
                        stream_showStmtIdentifier.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1226:7: KW_SHOW KW_COLUMNS ( KW_FROM | KW_IN ) tabname= tableName ( ( KW_FROM | KW_IN ) db_name= identifier )?
                    {
                    KW_SHOW365=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement6319);  
                    stream_KW_SHOW.add(KW_SHOW365);


                    KW_COLUMNS366=(Token)match(input,KW_COLUMNS,FOLLOW_KW_COLUMNS_in_showStatement6321);  
                    stream_KW_COLUMNS.add(KW_COLUMNS366);


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1226:26: ( KW_FROM | KW_IN )
                    int alt103=2;
                    int LA103_0 = input.LA(1);

                    if ( (LA103_0==KW_FROM) ) {
                        alt103=1;
                    }
                    else if ( (LA103_0==KW_IN) ) {
                        alt103=2;
                    }
                    else {
                        NoViableAltException nvae =
                            new NoViableAltException("", 103, 0, input);

                        throw nvae;

                    }
                    switch (alt103) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1226:27: KW_FROM
                            {
                            KW_FROM367=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement6324);  
                            stream_KW_FROM.add(KW_FROM367);


                            }
                            break;
                        case 2 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1226:35: KW_IN
                            {
                            KW_IN368=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement6326);  
                            stream_KW_IN.add(KW_IN368);


                            }
                            break;

                    }


                    pushFollow(FOLLOW_tableName_in_showStatement6331);
                    tabname=tableName();

                    state._fsp--;

                    stream_tableName.add(tabname.getTree());

                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1226:60: ( ( KW_FROM | KW_IN ) db_name= identifier )?
                    int alt105=2;
                    int LA105_0 = input.LA(1);

                    if ( (LA105_0==KW_FROM||LA105_0==KW_IN) ) {
                        alt105=1;
                    }
                    switch (alt105) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1226:61: ( KW_FROM | KW_IN ) db_name= identifier
                            {
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1226:61: ( KW_FROM | KW_IN )
                            int alt104=2;
                            int LA104_0 = input.LA(1);

                            if ( (LA104_0==KW_FROM) ) {
                                alt104=1;
                            }
                            else if ( (LA104_0==KW_IN) ) {
                                alt104=2;
                            }
                            else {
                                NoViableAltException nvae =
                                    new NoViableAltException("", 104, 0, input);

                                throw nvae;

                            }
                            switch (alt104) {
                                case 1 :
                                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1226:62: KW_FROM
                                    {
                                    KW_FROM369=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement6335);  
                                    stream_KW_FROM.add(KW_FROM369);


                                    }
                                    break;
                                case 2 :
                                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1226:70: KW_IN
                                    {
                                    KW_IN370=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement6337);  
                                    stream_KW_IN.add(KW_IN370);


                                    }
                                    break;

                            }


                            pushFollow(FOLLOW_identifier_in_showStatement6342);
                            db_name=identifier();

                            state._fsp--;

                            stream_identifier.add(db_name.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: db_name, tabname
                    // token labels: 
                    // rule labels: retval, db_name, tabname
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.tree:null);
                    RewriteRuleSubtreeStream stream_tabname=new RewriteRuleSubtreeStream(adaptor,"rule tabname",tabname!=null?tabname.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1227:5: -> ^( TOK_SHOWCOLUMNS ( $db_name)? $tabname)
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1227:8: ^( TOK_SHOWCOLUMNS ( $db_name)? $tabname)
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_SHOWCOLUMNS, "TOK_SHOWCOLUMNS")
                        , root_1);

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1227:27: ( $db_name)?
                        if ( stream_db_name.hasNext() ) {
                            adaptor.addChild(root_1, stream_db_name.nextTree());

                        }
                        stream_db_name.reset();

                        adaptor.addChild(root_1, stream_tabname.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 4 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1228:7: KW_SHOW KW_FUNCTIONS ( showStmtIdentifier )?
                    {
                    KW_SHOW371=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement6370);  
                    stream_KW_SHOW.add(KW_SHOW371);


                    KW_FUNCTIONS372=(Token)match(input,KW_FUNCTIONS,FOLLOW_KW_FUNCTIONS_in_showStatement6372);  
                    stream_KW_FUNCTIONS.add(KW_FUNCTIONS372);


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1228:28: ( showStmtIdentifier )?
                    int alt106=2;
                    int LA106_0 = input.LA(1);

                    if ( ((LA106_0 >= Identifier && LA106_0 <= KW_AFTER)||(LA106_0 >= KW_ALTER && LA106_0 <= KW_ANALYZE)||(LA106_0 >= KW_ARCHIVE && LA106_0 <= KW_CASCADE)||(LA106_0 >= KW_CHANGE && LA106_0 <= KW_COLLECTION)||(LA106_0 >= KW_COLUMNS && LA106_0 <= KW_CREATE)||LA106_0==KW_CUBE||(LA106_0 >= KW_CURSOR && LA106_0 <= KW_DATA)||(LA106_0 >= KW_DATABASES && LA106_0 <= KW_DISABLE)||(LA106_0 >= KW_DISTRIBUTE && LA106_0 <= KW_ELEM_TYPE)||LA106_0==KW_ENABLE||LA106_0==KW_ESCAPED||(LA106_0 >= KW_EXCLUSIVE && LA106_0 <= KW_EXPORT)||(LA106_0 >= KW_EXTERNAL && LA106_0 <= KW_FLOAT)||(LA106_0 >= KW_FOR && LA106_0 <= KW_FORMATTED)||LA106_0==KW_FULL||(LA106_0 >= KW_FUNCTIONS && LA106_0 <= KW_GROUPING)||(LA106_0 >= KW_HOLD_DDLTIME && LA106_0 <= KW_IDXPROPERTIES)||(LA106_0 >= KW_IGNORE && LA106_0 <= KW_ITEMS)||(LA106_0 >= KW_KEYS && LA106_0 <= KW_LEFT)||(LA106_0 >= KW_LIKE && LA106_0 <= KW_LONG)||(LA106_0 >= KW_MAPJOIN && LA106_0 <= KW_MINUS)||(LA106_0 >= KW_MSCK && LA106_0 <= KW_NOSCAN)||(LA106_0 >= KW_NO_DROP && LA106_0 <= KW_OFFLINE)||LA106_0==KW_OPTION||(LA106_0 >= KW_ORCFILE && LA106_0 <= KW_OUTPUTFORMAT)||LA106_0==KW_OVERWRITE||(LA106_0 >= KW_PARTITION && LA106_0 <= KW_PLUS)||(LA106_0 >= KW_PRETTY && LA106_0 <= KW_RECORDWRITER)||(LA106_0 >= KW_REGEXP && LA106_0 <= KW_SCHEMAS)||(LA106_0 >= KW_SEMI && LA106_0 <= KW_TABLES)||(LA106_0 >= KW_TBLPROPERTIES && LA106_0 <= KW_TEXTFILE)||(LA106_0 >= KW_TIMESTAMP && LA106_0 <= KW_TOUCH)||(LA106_0 >= KW_TRIGGER && LA106_0 <= KW_UNARCHIVE)||(LA106_0 >= KW_UNDO && LA106_0 <= KW_UNIONTYPE)||(LA106_0 >= KW_UNLOCK && LA106_0 <= KW_VALUE_TYPE)||LA106_0==KW_VIEW||LA106_0==KW_WHILE||LA106_0==KW_WITH||LA106_0==StringLiteral) ) {
                        alt106=1;
                    }
                    switch (alt106) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1228:28: showStmtIdentifier
                            {
                            pushFollow(FOLLOW_showStmtIdentifier_in_showStatement6374);
                            showStmtIdentifier373=showStmtIdentifier();

                            state._fsp--;

                            stream_showStmtIdentifier.add(showStmtIdentifier373.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: showStmtIdentifier
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1228:49: -> ^( TOK_SHOWFUNCTIONS ( showStmtIdentifier )? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1228:52: ^( TOK_SHOWFUNCTIONS ( showStmtIdentifier )? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_SHOWFUNCTIONS, "TOK_SHOWFUNCTIONS")
                        , root_1);

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1228:72: ( showStmtIdentifier )?
                        if ( stream_showStmtIdentifier.hasNext() ) {
                            adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());

                        }
                        stream_showStmtIdentifier.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 5 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1229:7: KW_SHOW KW_PARTITIONS identifier ( partitionSpec )?
                    {
                    KW_SHOW374=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement6393);  
                    stream_KW_SHOW.add(KW_SHOW374);


                    KW_PARTITIONS375=(Token)match(input,KW_PARTITIONS,FOLLOW_KW_PARTITIONS_in_showStatement6395);  
                    stream_KW_PARTITIONS.add(KW_PARTITIONS375);


                    pushFollow(FOLLOW_identifier_in_showStatement6397);
                    identifier376=identifier();

                    state._fsp--;

                    stream_identifier.add(identifier376.getTree());

                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1229:40: ( partitionSpec )?
                    int alt107=2;
                    int LA107_0 = input.LA(1);

                    if ( (LA107_0==KW_PARTITION) ) {
                        alt107=1;
                    }
                    switch (alt107) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1229:40: partitionSpec
                            {
                            pushFollow(FOLLOW_partitionSpec_in_showStatement6399);
                            partitionSpec377=partitionSpec();

                            state._fsp--;

                            stream_partitionSpec.add(partitionSpec377.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: identifier, partitionSpec
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1229:55: -> ^( TOK_SHOWPARTITIONS identifier ( partitionSpec )? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1229:58: ^( TOK_SHOWPARTITIONS identifier ( partitionSpec )? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_SHOWPARTITIONS, "TOK_SHOWPARTITIONS")
                        , root_1);

                        adaptor.addChild(root_1, stream_identifier.nextTree());

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1229:90: ( partitionSpec )?
                        if ( stream_partitionSpec.hasNext() ) {
                            adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                        }
                        stream_partitionSpec.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 6 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1230:7: KW_SHOW KW_CREATE KW_TABLE tabName= tableName
                    {
                    KW_SHOW378=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement6419);  
                    stream_KW_SHOW.add(KW_SHOW378);


                    KW_CREATE379=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_showStatement6421);  
                    stream_KW_CREATE.add(KW_CREATE379);


                    KW_TABLE380=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_showStatement6423);  
                    stream_KW_TABLE.add(KW_TABLE380);


                    pushFollow(FOLLOW_tableName_in_showStatement6427);
                    tabName=tableName();

                    state._fsp--;

                    stream_tableName.add(tabName.getTree());

                    // AST REWRITE
                    // elements: tabName
                    // token labels: 
                    // rule labels: retval, tabName
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_tabName=new RewriteRuleSubtreeStream(adaptor,"rule tabName",tabName!=null?tabName.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1230:52: -> ^( TOK_SHOW_CREATETABLE $tabName)
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1230:55: ^( TOK_SHOW_CREATETABLE $tabName)
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_SHOW_CREATETABLE, "TOK_SHOW_CREATETABLE")
                        , root_1);

                        adaptor.addChild(root_1, stream_tabName.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 7 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1231:7: KW_SHOW KW_TABLE KW_EXTENDED ( ( KW_FROM | KW_IN ) db_name= identifier )? KW_LIKE showStmtIdentifier ( partitionSpec )?
                    {
                    KW_SHOW381=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement6444);  
                    stream_KW_SHOW.add(KW_SHOW381);


                    KW_TABLE382=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_showStatement6446);  
                    stream_KW_TABLE.add(KW_TABLE382);


                    KW_EXTENDED383=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_showStatement6448);  
                    stream_KW_EXTENDED.add(KW_EXTENDED383);


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1231:36: ( ( KW_FROM | KW_IN ) db_name= identifier )?
                    int alt109=2;
                    int LA109_0 = input.LA(1);

                    if ( (LA109_0==KW_FROM||LA109_0==KW_IN) ) {
                        alt109=1;
                    }
                    switch (alt109) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1231:37: ( KW_FROM | KW_IN ) db_name= identifier
                            {
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1231:37: ( KW_FROM | KW_IN )
                            int alt108=2;
                            int LA108_0 = input.LA(1);

                            if ( (LA108_0==KW_FROM) ) {
                                alt108=1;
                            }
                            else if ( (LA108_0==KW_IN) ) {
                                alt108=2;
                            }
                            else {
                                NoViableAltException nvae =
                                    new NoViableAltException("", 108, 0, input);

                                throw nvae;

                            }
                            switch (alt108) {
                                case 1 :
                                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1231:38: KW_FROM
                                    {
                                    KW_FROM384=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement6452);  
                                    stream_KW_FROM.add(KW_FROM384);


                                    }
                                    break;
                                case 2 :
                                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1231:46: KW_IN
                                    {
                                    KW_IN385=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement6454);  
                                    stream_KW_IN.add(KW_IN385);


                                    }
                                    break;

                            }


                            pushFollow(FOLLOW_identifier_in_showStatement6459);
                            db_name=identifier();

                            state._fsp--;

                            stream_identifier.add(db_name.getTree());

                            }
                            break;

                    }


                    KW_LIKE386=(Token)match(input,KW_LIKE,FOLLOW_KW_LIKE_in_showStatement6463);  
                    stream_KW_LIKE.add(KW_LIKE386);


                    pushFollow(FOLLOW_showStmtIdentifier_in_showStatement6465);
                    showStmtIdentifier387=showStmtIdentifier();

                    state._fsp--;

                    stream_showStmtIdentifier.add(showStmtIdentifier387.getTree());

                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1231:101: ( partitionSpec )?
                    int alt110=2;
                    int LA110_0 = input.LA(1);

                    if ( (LA110_0==KW_PARTITION) ) {
                        alt110=1;
                    }
                    switch (alt110) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1231:101: partitionSpec
                            {
                            pushFollow(FOLLOW_partitionSpec_in_showStatement6467);
                            partitionSpec388=partitionSpec();

                            state._fsp--;

                            stream_partitionSpec.add(partitionSpec388.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: partitionSpec, db_name, showStmtIdentifier
                    // token labels: 
                    // rule labels: retval, db_name
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1232:5: -> ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1232:8: ^( TOK_SHOW_TABLESTATUS showStmtIdentifier ( $db_name)? ( partitionSpec )? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_SHOW_TABLESTATUS, "TOK_SHOW_TABLESTATUS")
                        , root_1);

                        adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1232:51: ( $db_name)?
                        if ( stream_db_name.hasNext() ) {
                            adaptor.addChild(root_1, stream_db_name.nextTree());

                        }
                        stream_db_name.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1232:60: ( partitionSpec )?
                        if ( stream_partitionSpec.hasNext() ) {
                            adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                        }
                        stream_partitionSpec.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 8 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1233:7: KW_SHOW KW_TBLPROPERTIES tblName= identifier ( LPAREN prptyName= StringLiteral RPAREN )?
                    {
                    KW_SHOW389=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement6495);  
                    stream_KW_SHOW.add(KW_SHOW389);


                    KW_TBLPROPERTIES390=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_showStatement6497);  
                    stream_KW_TBLPROPERTIES.add(KW_TBLPROPERTIES390);


                    pushFollow(FOLLOW_identifier_in_showStatement6501);
                    tblName=identifier();

                    state._fsp--;

                    stream_identifier.add(tblName.getTree());

                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1233:51: ( LPAREN prptyName= StringLiteral RPAREN )?
                    int alt111=2;
                    int LA111_0 = input.LA(1);

                    if ( (LA111_0==LPAREN) ) {
                        alt111=1;
                    }
                    switch (alt111) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1233:52: LPAREN prptyName= StringLiteral RPAREN
                            {
                            LPAREN391=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_showStatement6504);  
                            stream_LPAREN.add(LPAREN391);


                            prptyName=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showStatement6508);  
                            stream_StringLiteral.add(prptyName);


                            RPAREN392=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_showStatement6510);  
                            stream_RPAREN.add(RPAREN392);


                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: prptyName, tblName
                    // token labels: prptyName
                    // rule labels: retval, tblName
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_prptyName=new RewriteRuleTokenStream(adaptor,"token prptyName",prptyName);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_tblName=new RewriteRuleSubtreeStream(adaptor,"rule tblName",tblName!=null?tblName.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1233:92: -> ^( TOK_SHOW_TBLPROPERTIES $tblName ( $prptyName)? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1233:95: ^( TOK_SHOW_TBLPROPERTIES $tblName ( $prptyName)? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_SHOW_TBLPROPERTIES, "TOK_SHOW_TBLPROPERTIES")
                        , root_1);

                        adaptor.addChild(root_1, stream_tblName.nextTree());

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1233:130: ( $prptyName)?
                        if ( stream_prptyName.hasNext() ) {
                            adaptor.addChild(root_1, stream_prptyName.nextNode());

                        }
                        stream_prptyName.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 9 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1234:7: KW_SHOW KW_LOCKS (parttype= partTypeExpr )? (isExtended= KW_EXTENDED )?
                    {
                    KW_SHOW393=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement6533);  
                    stream_KW_SHOW.add(KW_SHOW393);


                    KW_LOCKS394=(Token)match(input,KW_LOCKS,FOLLOW_KW_LOCKS_in_showStatement6535);  
                    stream_KW_LOCKS.add(KW_LOCKS394);


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1234:24: (parttype= partTypeExpr )?
                    int alt112=2;
                    int LA112_0 = input.LA(1);

                    if ( ((LA112_0 >= Identifier && LA112_0 <= KW_AFTER)||(LA112_0 >= KW_ALTER && LA112_0 <= KW_ANALYZE)||(LA112_0 >= KW_ARCHIVE && LA112_0 <= KW_CASCADE)||(LA112_0 >= KW_CHANGE && LA112_0 <= KW_COLLECTION)||(LA112_0 >= KW_COLUMNS && LA112_0 <= KW_CREATE)||LA112_0==KW_CUBE||(LA112_0 >= KW_CURSOR && LA112_0 <= KW_DATA)||(LA112_0 >= KW_DATABASES && LA112_0 <= KW_DISABLE)||(LA112_0 >= KW_DISTRIBUTE && LA112_0 <= KW_ELEM_TYPE)||LA112_0==KW_ENABLE||LA112_0==KW_ESCAPED||(LA112_0 >= KW_EXCLUSIVE && LA112_0 <= KW_EXPORT)||(LA112_0 >= KW_EXTERNAL && LA112_0 <= KW_FLOAT)||(LA112_0 >= KW_FOR && LA112_0 <= KW_FORMATTED)||LA112_0==KW_FULL||(LA112_0 >= KW_FUNCTIONS && LA112_0 <= KW_GROUPING)||(LA112_0 >= KW_HOLD_DDLTIME && LA112_0 <= KW_IDXPROPERTIES)||(LA112_0 >= KW_IGNORE && LA112_0 <= KW_ITEMS)||(LA112_0 >= KW_KEYS && LA112_0 <= KW_LEFT)||(LA112_0 >= KW_LIKE && LA112_0 <= KW_LONG)||(LA112_0 >= KW_MAPJOIN && LA112_0 <= KW_MINUS)||(LA112_0 >= KW_MSCK && LA112_0 <= KW_NOSCAN)||(LA112_0 >= KW_NO_DROP && LA112_0 <= KW_OFFLINE)||LA112_0==KW_OPTION||(LA112_0 >= KW_ORCFILE && LA112_0 <= KW_OUTPUTFORMAT)||LA112_0==KW_OVERWRITE||(LA112_0 >= KW_PARTITION && LA112_0 <= KW_PLUS)||(LA112_0 >= KW_PRETTY && LA112_0 <= KW_RECORDWRITER)||(LA112_0 >= KW_REGEXP && LA112_0 <= KW_SCHEMAS)||(LA112_0 >= KW_SEMI && LA112_0 <= KW_TABLES)||(LA112_0 >= KW_TBLPROPERTIES && LA112_0 <= KW_TEXTFILE)||(LA112_0 >= KW_TIMESTAMP && LA112_0 <= KW_TOUCH)||(LA112_0 >= KW_TRIGGER && LA112_0 <= KW_UNARCHIVE)||(LA112_0 >= KW_UNDO && LA112_0 <= KW_UNIONTYPE)||(LA112_0 >= KW_UNLOCK && LA112_0 <= KW_VALUE_TYPE)||LA112_0==KW_VIEW||LA112_0==KW_WHILE||LA112_0==KW_WITH) ) {
                        alt112=1;
                    }
                    switch (alt112) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1234:25: parttype= partTypeExpr
                            {
                            pushFollow(FOLLOW_partTypeExpr_in_showStatement6540);
                            parttype=partTypeExpr();

                            state._fsp--;

                            stream_partTypeExpr.add(parttype.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1234:49: (isExtended= KW_EXTENDED )?
                    int alt113=2;
                    int LA113_0 = input.LA(1);

                    if ( (LA113_0==KW_EXTENDED) ) {
                        alt113=1;
                    }
                    switch (alt113) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1234:50: isExtended= KW_EXTENDED
                            {
                            isExtended=(Token)match(input,KW_EXTENDED,FOLLOW_KW_EXTENDED_in_showStatement6547);  
                            stream_KW_EXTENDED.add(isExtended);


                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: isExtended, parttype
                    // token labels: isExtended
                    // rule labels: retval, parttype
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_isExtended=new RewriteRuleTokenStream(adaptor,"token isExtended",isExtended);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_parttype=new RewriteRuleSubtreeStream(adaptor,"rule parttype",parttype!=null?parttype.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1234:75: -> ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1234:78: ^( TOK_SHOWLOCKS ( $parttype)? ( $isExtended)? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_SHOWLOCKS, "TOK_SHOWLOCKS")
                        , root_1);

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1234:95: ( $parttype)?
                        if ( stream_parttype.hasNext() ) {
                            adaptor.addChild(root_1, stream_parttype.nextTree());

                        }
                        stream_parttype.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1234:106: ( $isExtended)?
                        if ( stream_isExtended.hasNext() ) {
                            adaptor.addChild(root_1, stream_isExtended.nextNode());

                        }
                        stream_isExtended.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 10 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1235:7: KW_SHOW (showOptions= KW_FORMATTED )? ( KW_INDEX | KW_INDEXES ) KW_ON showStmtIdentifier ( ( KW_FROM | KW_IN ) db_name= identifier )?
                    {
                    KW_SHOW395=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showStatement6571);  
                    stream_KW_SHOW.add(KW_SHOW395);


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1235:15: (showOptions= KW_FORMATTED )?
                    int alt114=2;
                    int LA114_0 = input.LA(1);

                    if ( (LA114_0==KW_FORMATTED) ) {
                        alt114=1;
                    }
                    switch (alt114) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1235:16: showOptions= KW_FORMATTED
                            {
                            showOptions=(Token)match(input,KW_FORMATTED,FOLLOW_KW_FORMATTED_in_showStatement6576);  
                            stream_KW_FORMATTED.add(showOptions);


                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1235:43: ( KW_INDEX | KW_INDEXES )
                    int alt115=2;
                    int LA115_0 = input.LA(1);

                    if ( (LA115_0==KW_INDEX) ) {
                        alt115=1;
                    }
                    else if ( (LA115_0==KW_INDEXES) ) {
                        alt115=2;
                    }
                    else {
                        NoViableAltException nvae =
                            new NoViableAltException("", 115, 0, input);

                        throw nvae;

                    }
                    switch (alt115) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1235:44: KW_INDEX
                            {
                            KW_INDEX396=(Token)match(input,KW_INDEX,FOLLOW_KW_INDEX_in_showStatement6581);  
                            stream_KW_INDEX.add(KW_INDEX396);


                            }
                            break;
                        case 2 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1235:53: KW_INDEXES
                            {
                            KW_INDEXES397=(Token)match(input,KW_INDEXES,FOLLOW_KW_INDEXES_in_showStatement6583);  
                            stream_KW_INDEXES.add(KW_INDEXES397);


                            }
                            break;

                    }


                    KW_ON398=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_showStatement6586);  
                    stream_KW_ON.add(KW_ON398);


                    pushFollow(FOLLOW_showStmtIdentifier_in_showStatement6588);
                    showStmtIdentifier399=showStmtIdentifier();

                    state._fsp--;

                    stream_showStmtIdentifier.add(showStmtIdentifier399.getTree());

                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1235:90: ( ( KW_FROM | KW_IN ) db_name= identifier )?
                    int alt117=2;
                    int LA117_0 = input.LA(1);

                    if ( (LA117_0==KW_FROM||LA117_0==KW_IN) ) {
                        alt117=1;
                    }
                    switch (alt117) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1235:91: ( KW_FROM | KW_IN ) db_name= identifier
                            {
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1235:91: ( KW_FROM | KW_IN )
                            int alt116=2;
                            int LA116_0 = input.LA(1);

                            if ( (LA116_0==KW_FROM) ) {
                                alt116=1;
                            }
                            else if ( (LA116_0==KW_IN) ) {
                                alt116=2;
                            }
                            else {
                                NoViableAltException nvae =
                                    new NoViableAltException("", 116, 0, input);

                                throw nvae;

                            }
                            switch (alt116) {
                                case 1 :
                                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1235:92: KW_FROM
                                    {
                                    KW_FROM400=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_showStatement6592);  
                                    stream_KW_FROM.add(KW_FROM400);


                                    }
                                    break;
                                case 2 :
                                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1235:100: KW_IN
                                    {
                                    KW_IN401=(Token)match(input,KW_IN,FOLLOW_KW_IN_in_showStatement6594);  
                                    stream_KW_IN.add(KW_IN401);


                                    }
                                    break;

                            }


                            pushFollow(FOLLOW_identifier_in_showStatement6599);
                            db_name=identifier();

                            state._fsp--;

                            stream_identifier.add(db_name.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: showOptions, showStmtIdentifier, db_name
                    // token labels: showOptions
                    // rule labels: retval, db_name
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_showOptions=new RewriteRuleTokenStream(adaptor,"token showOptions",showOptions);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_db_name=new RewriteRuleSubtreeStream(adaptor,"rule db_name",db_name!=null?db_name.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1236:5: -> ^( TOK_SHOWINDEXES showStmtIdentifier ( $showOptions)? ( $db_name)? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1236:8: ^( TOK_SHOWINDEXES showStmtIdentifier ( $showOptions)? ( $db_name)? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_SHOWINDEXES, "TOK_SHOWINDEXES")
                        , root_1);

                        adaptor.addChild(root_1, stream_showStmtIdentifier.nextTree());

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1236:46: ( $showOptions)?
                        if ( stream_showOptions.hasNext() ) {
                            adaptor.addChild(root_1, stream_showOptions.nextNode());

                        }
                        stream_showOptions.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1236:60: ( $db_name)?
                        if ( stream_db_name.hasNext() ) {
                            adaptor.addChild(root_1, stream_db_name.nextTree());

                        }
                        stream_db_name.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "showStatement"


    public static class lockStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "lockStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1239:1: lockStatement : KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? ) ;
    public final HiveParser.lockStatement_return lockStatement() throws RecognitionException {
        HiveParser.lockStatement_return retval = new HiveParser.lockStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_LOCK402=null;
        Token KW_TABLE403=null;
        HiveParser_FromClauseParser.tableName_return tableName404 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec405 =null;

        HiveParser.lockMode_return lockMode406 =null;


        CommonTree KW_LOCK402_tree=null;
        CommonTree KW_TABLE403_tree=null;
        RewriteRuleTokenStream stream_KW_LOCK=new RewriteRuleTokenStream(adaptor,"token KW_LOCK");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_lockMode=new RewriteRuleSubtreeStream(adaptor,"rule lockMode");
         msgs.push("lock statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1242:5: ( KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1242:7: KW_LOCK KW_TABLE tableName ( partitionSpec )? lockMode
            {
            KW_LOCK402=(Token)match(input,KW_LOCK,FOLLOW_KW_LOCK_in_lockStatement6648);  
            stream_KW_LOCK.add(KW_LOCK402);


            KW_TABLE403=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_lockStatement6650);  
            stream_KW_TABLE.add(KW_TABLE403);


            pushFollow(FOLLOW_tableName_in_lockStatement6652);
            tableName404=tableName();

            state._fsp--;

            stream_tableName.add(tableName404.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1242:34: ( partitionSpec )?
            int alt119=2;
            int LA119_0 = input.LA(1);

            if ( (LA119_0==KW_PARTITION) ) {
                alt119=1;
            }
            switch (alt119) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1242:34: partitionSpec
                    {
                    pushFollow(FOLLOW_partitionSpec_in_lockStatement6654);
                    partitionSpec405=partitionSpec();

                    state._fsp--;

                    stream_partitionSpec.add(partitionSpec405.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_lockMode_in_lockStatement6657);
            lockMode406=lockMode();

            state._fsp--;

            stream_lockMode.add(lockMode406.getTree());

            // AST REWRITE
            // elements: lockMode, tableName, partitionSpec
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1242:58: -> ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1242:61: ^( TOK_LOCKTABLE tableName lockMode ( partitionSpec )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_LOCKTABLE, "TOK_LOCKTABLE")
                , root_1);

                adaptor.addChild(root_1, stream_tableName.nextTree());

                adaptor.addChild(root_1, stream_lockMode.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1242:96: ( partitionSpec )?
                if ( stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                }
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "lockStatement"


    public static class lockMode_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "lockMode"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1245:1: lockMode : ( KW_SHARED | KW_EXCLUSIVE );
    public final HiveParser.lockMode_return lockMode() throws RecognitionException {
        HiveParser.lockMode_return retval = new HiveParser.lockMode_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token set407=null;

        CommonTree set407_tree=null;

         msgs.push("lock mode"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1248:5: ( KW_SHARED | KW_EXCLUSIVE )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:
            {
            root_0 = (CommonTree)adaptor.nil();


            set407=(Token)input.LT(1);

            if ( input.LA(1)==KW_EXCLUSIVE||input.LA(1)==KW_SHARED ) {
                input.consume();
                adaptor.addChild(root_0, 
                (CommonTree)adaptor.create(set407)
                );
                state.errorRecovery=false;
            }
            else {
                MismatchedSetException mse = new MismatchedSetException(null,input);
                throw mse;
            }


            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "lockMode"


    public static class unlockStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "unlockStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1251:1: unlockStatement : KW_UNLOCK KW_TABLE tableName ( partitionSpec )? -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? ) ;
    public final HiveParser.unlockStatement_return unlockStatement() throws RecognitionException {
        HiveParser.unlockStatement_return retval = new HiveParser.unlockStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_UNLOCK408=null;
        Token KW_TABLE409=null;
        HiveParser_FromClauseParser.tableName_return tableName410 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec411 =null;


        CommonTree KW_UNLOCK408_tree=null;
        CommonTree KW_TABLE409_tree=null;
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_KW_UNLOCK=new RewriteRuleTokenStream(adaptor,"token KW_UNLOCK");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
         msgs.push("unlock statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1254:5: ( KW_UNLOCK KW_TABLE tableName ( partitionSpec )? -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1254:7: KW_UNLOCK KW_TABLE tableName ( partitionSpec )?
            {
            KW_UNLOCK408=(Token)match(input,KW_UNLOCK,FOLLOW_KW_UNLOCK_in_unlockStatement6728);  
            stream_KW_UNLOCK.add(KW_UNLOCK408);


            KW_TABLE409=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_unlockStatement6730);  
            stream_KW_TABLE.add(KW_TABLE409);


            pushFollow(FOLLOW_tableName_in_unlockStatement6732);
            tableName410=tableName();

            state._fsp--;

            stream_tableName.add(tableName410.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1254:36: ( partitionSpec )?
            int alt120=2;
            int LA120_0 = input.LA(1);

            if ( (LA120_0==KW_PARTITION) ) {
                alt120=1;
            }
            switch (alt120) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1254:36: partitionSpec
                    {
                    pushFollow(FOLLOW_partitionSpec_in_unlockStatement6734);
                    partitionSpec411=partitionSpec();

                    state._fsp--;

                    stream_partitionSpec.add(partitionSpec411.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: tableName, partitionSpec
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1254:52: -> ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1254:55: ^( TOK_UNLOCKTABLE tableName ( partitionSpec )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_UNLOCKTABLE, "TOK_UNLOCKTABLE")
                , root_1);

                adaptor.addChild(root_1, stream_tableName.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1254:83: ( partitionSpec )?
                if ( stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                }
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "unlockStatement"


    public static class createRoleStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "createRoleStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1257:1: createRoleStatement : KW_CREATE KW_ROLE roleName= identifier -> ^( TOK_CREATEROLE $roleName) ;
    public final HiveParser.createRoleStatement_return createRoleStatement() throws RecognitionException {
        HiveParser.createRoleStatement_return retval = new HiveParser.createRoleStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_CREATE412=null;
        Token KW_ROLE413=null;
        HiveParser_IdentifiersParser.identifier_return roleName =null;


        CommonTree KW_CREATE412_tree=null;
        CommonTree KW_ROLE413_tree=null;
        RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
        RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("create role"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1260:5: ( KW_CREATE KW_ROLE roleName= identifier -> ^( TOK_CREATEROLE $roleName) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1260:7: KW_CREATE KW_ROLE roleName= identifier
            {
            KW_CREATE412=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createRoleStatement6774);  
            stream_KW_CREATE.add(KW_CREATE412);


            KW_ROLE413=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_createRoleStatement6776);  
            stream_KW_ROLE.add(KW_ROLE413);


            pushFollow(FOLLOW_identifier_in_createRoleStatement6780);
            roleName=identifier();

            state._fsp--;

            stream_identifier.add(roleName.getTree());

            // AST REWRITE
            // elements: roleName
            // token labels: 
            // rule labels: retval, roleName
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_roleName=new RewriteRuleSubtreeStream(adaptor,"rule roleName",roleName!=null?roleName.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1261:5: -> ^( TOK_CREATEROLE $roleName)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1261:8: ^( TOK_CREATEROLE $roleName)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_CREATEROLE, "TOK_CREATEROLE")
                , root_1);

                adaptor.addChild(root_1, stream_roleName.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "createRoleStatement"


    public static class dropRoleStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dropRoleStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1264:1: dropRoleStatement : KW_DROP KW_ROLE roleName= identifier -> ^( TOK_DROPROLE $roleName) ;
    public final HiveParser.dropRoleStatement_return dropRoleStatement() throws RecognitionException {
        HiveParser.dropRoleStatement_return retval = new HiveParser.dropRoleStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_DROP414=null;
        Token KW_ROLE415=null;
        HiveParser_IdentifiersParser.identifier_return roleName =null;


        CommonTree KW_DROP414_tree=null;
        CommonTree KW_ROLE415_tree=null;
        RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
        RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        msgs.push("drop role");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1267:5: ( KW_DROP KW_ROLE roleName= identifier -> ^( TOK_DROPROLE $roleName) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1267:7: KW_DROP KW_ROLE roleName= identifier
            {
            KW_DROP414=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropRoleStatement6820);  
            stream_KW_DROP.add(KW_DROP414);


            KW_ROLE415=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_dropRoleStatement6822);  
            stream_KW_ROLE.add(KW_ROLE415);


            pushFollow(FOLLOW_identifier_in_dropRoleStatement6826);
            roleName=identifier();

            state._fsp--;

            stream_identifier.add(roleName.getTree());

            // AST REWRITE
            // elements: roleName
            // token labels: 
            // rule labels: retval, roleName
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_roleName=new RewriteRuleSubtreeStream(adaptor,"rule roleName",roleName!=null?roleName.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1268:5: -> ^( TOK_DROPROLE $roleName)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1268:8: ^( TOK_DROPROLE $roleName)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_DROPROLE, "TOK_DROPROLE")
                , root_1);

                adaptor.addChild(root_1, stream_roleName.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dropRoleStatement"


    public static class grantPrivileges_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "grantPrivileges"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1271:1: grantPrivileges : KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( KW_WITH withOption )? -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withOption )? ) ;
    public final HiveParser.grantPrivileges_return grantPrivileges() throws RecognitionException {
        HiveParser.grantPrivileges_return retval = new HiveParser.grantPrivileges_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_GRANT416=null;
        Token KW_TO418=null;
        Token KW_WITH420=null;
        HiveParser.privilegeList_return privList =null;

        HiveParser.privilegeObject_return privilegeObject417 =null;

        HiveParser.principalSpecification_return principalSpecification419 =null;

        HiveParser.withOption_return withOption421 =null;


        CommonTree KW_GRANT416_tree=null;
        CommonTree KW_TO418_tree=null;
        CommonTree KW_WITH420_tree=null;
        RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
        RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
        RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
        RewriteRuleSubtreeStream stream_privilegeList=new RewriteRuleSubtreeStream(adaptor,"rule privilegeList");
        RewriteRuleSubtreeStream stream_privilegeObject=new RewriteRuleSubtreeStream(adaptor,"rule privilegeObject");
        RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");
        RewriteRuleSubtreeStream stream_withOption=new RewriteRuleSubtreeStream(adaptor,"rule withOption");
        msgs.push("grant privileges");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1274:5: ( KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( KW_WITH withOption )? -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withOption )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1274:7: KW_GRANT privList= privilegeList ( privilegeObject )? KW_TO principalSpecification ( KW_WITH withOption )?
            {
            KW_GRANT416=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_grantPrivileges6866);  
            stream_KW_GRANT.add(KW_GRANT416);


            pushFollow(FOLLOW_privilegeList_in_grantPrivileges6870);
            privList=privilegeList();

            state._fsp--;

            stream_privilegeList.add(privList.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1275:7: ( privilegeObject )?
            int alt121=2;
            int LA121_0 = input.LA(1);

            if ( (LA121_0==KW_ON) ) {
                alt121=1;
            }
            switch (alt121) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1275:7: privilegeObject
                    {
                    pushFollow(FOLLOW_privilegeObject_in_grantPrivileges6878);
                    privilegeObject417=privilegeObject();

                    state._fsp--;

                    stream_privilegeObject.add(privilegeObject417.getTree());

                    }
                    break;

            }


            KW_TO418=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_grantPrivileges6887);  
            stream_KW_TO.add(KW_TO418);


            pushFollow(FOLLOW_principalSpecification_in_grantPrivileges6889);
            principalSpecification419=principalSpecification();

            state._fsp--;

            stream_principalSpecification.add(principalSpecification419.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1277:7: ( KW_WITH withOption )?
            int alt122=2;
            int LA122_0 = input.LA(1);

            if ( (LA122_0==KW_WITH) ) {
                alt122=1;
            }
            switch (alt122) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1277:8: KW_WITH withOption
                    {
                    KW_WITH420=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_grantPrivileges6898);  
                    stream_KW_WITH.add(KW_WITH420);


                    pushFollow(FOLLOW_withOption_in_grantPrivileges6900);
                    withOption421=withOption();

                    state._fsp--;

                    stream_withOption.add(withOption421.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: privilegeObject, withOption, principalSpecification, privList
            // token labels: 
            // rule labels: retval, privList
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_privList=new RewriteRuleSubtreeStream(adaptor,"rule privList",privList!=null?privList.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1278:5: -> ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withOption )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1278:8: ^( TOK_GRANT $privList principalSpecification ( privilegeObject )? ( withOption )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_GRANT, "TOK_GRANT")
                , root_1);

                adaptor.addChild(root_1, stream_privList.nextTree());

                adaptor.addChild(root_1, stream_principalSpecification.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1278:53: ( privilegeObject )?
                if ( stream_privilegeObject.hasNext() ) {
                    adaptor.addChild(root_1, stream_privilegeObject.nextTree());

                }
                stream_privilegeObject.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1278:70: ( withOption )?
                if ( stream_withOption.hasNext() ) {
                    adaptor.addChild(root_1, stream_withOption.nextTree());

                }
                stream_withOption.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "grantPrivileges"


    public static class revokePrivileges_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "revokePrivileges"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1281:1: revokePrivileges : KW_REVOKE privilegeList ( privilegeObject )? KW_FROM principalSpecification -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ) ;
    public final HiveParser.revokePrivileges_return revokePrivileges() throws RecognitionException {
        HiveParser.revokePrivileges_return retval = new HiveParser.revokePrivileges_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_REVOKE422=null;
        Token KW_FROM425=null;
        HiveParser.privilegeList_return privilegeList423 =null;

        HiveParser.privilegeObject_return privilegeObject424 =null;

        HiveParser.principalSpecification_return principalSpecification426 =null;


        CommonTree KW_REVOKE422_tree=null;
        CommonTree KW_FROM425_tree=null;
        RewriteRuleTokenStream stream_KW_REVOKE=new RewriteRuleTokenStream(adaptor,"token KW_REVOKE");
        RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
        RewriteRuleSubtreeStream stream_privilegeList=new RewriteRuleSubtreeStream(adaptor,"rule privilegeList");
        RewriteRuleSubtreeStream stream_privilegeObject=new RewriteRuleSubtreeStream(adaptor,"rule privilegeObject");
        RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");
        msgs.push("revoke privileges");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1284:5: ( KW_REVOKE privilegeList ( privilegeObject )? KW_FROM principalSpecification -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1284:7: KW_REVOKE privilegeList ( privilegeObject )? KW_FROM principalSpecification
            {
            KW_REVOKE422=(Token)match(input,KW_REVOKE,FOLLOW_KW_REVOKE_in_revokePrivileges6950);  
            stream_KW_REVOKE.add(KW_REVOKE422);


            pushFollow(FOLLOW_privilegeList_in_revokePrivileges6952);
            privilegeList423=privilegeList();

            state._fsp--;

            stream_privilegeList.add(privilegeList423.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1284:31: ( privilegeObject )?
            int alt123=2;
            int LA123_0 = input.LA(1);

            if ( (LA123_0==KW_ON) ) {
                alt123=1;
            }
            switch (alt123) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1284:31: privilegeObject
                    {
                    pushFollow(FOLLOW_privilegeObject_in_revokePrivileges6954);
                    privilegeObject424=privilegeObject();

                    state._fsp--;

                    stream_privilegeObject.add(privilegeObject424.getTree());

                    }
                    break;

            }


            KW_FROM425=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_revokePrivileges6957);  
            stream_KW_FROM.add(KW_FROM425);


            pushFollow(FOLLOW_principalSpecification_in_revokePrivileges6959);
            principalSpecification426=principalSpecification();

            state._fsp--;

            stream_principalSpecification.add(principalSpecification426.getTree());

            // AST REWRITE
            // elements: privilegeObject, principalSpecification, privilegeList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1285:5: -> ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1285:8: ^( TOK_REVOKE privilegeList principalSpecification ( privilegeObject )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_REVOKE, "TOK_REVOKE")
                , root_1);

                adaptor.addChild(root_1, stream_privilegeList.nextTree());

                adaptor.addChild(root_1, stream_principalSpecification.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1285:58: ( privilegeObject )?
                if ( stream_privilegeObject.hasNext() ) {
                    adaptor.addChild(root_1, stream_privilegeObject.nextTree());

                }
                stream_privilegeObject.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "revokePrivileges"


    public static class grantRole_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "grantRole"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1288:1: grantRole : KW_GRANT KW_ROLE identifier ( COMMA identifier )* KW_TO principalSpecification -> ^( TOK_GRANT_ROLE principalSpecification ( identifier )+ ) ;
    public final HiveParser.grantRole_return grantRole() throws RecognitionException {
        HiveParser.grantRole_return retval = new HiveParser.grantRole_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_GRANT427=null;
        Token KW_ROLE428=null;
        Token COMMA430=null;
        Token KW_TO432=null;
        HiveParser_IdentifiersParser.identifier_return identifier429 =null;

        HiveParser_IdentifiersParser.identifier_return identifier431 =null;

        HiveParser.principalSpecification_return principalSpecification433 =null;


        CommonTree KW_GRANT427_tree=null;
        CommonTree KW_ROLE428_tree=null;
        CommonTree COMMA430_tree=null;
        CommonTree KW_TO432_tree=null;
        RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
        RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleTokenStream stream_KW_TO=new RewriteRuleTokenStream(adaptor,"token KW_TO");
        RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        msgs.push("grant role");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1291:5: ( KW_GRANT KW_ROLE identifier ( COMMA identifier )* KW_TO principalSpecification -> ^( TOK_GRANT_ROLE principalSpecification ( identifier )+ ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1291:7: KW_GRANT KW_ROLE identifier ( COMMA identifier )* KW_TO principalSpecification
            {
            KW_GRANT427=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_grantRole7003);  
            stream_KW_GRANT.add(KW_GRANT427);


            KW_ROLE428=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_grantRole7005);  
            stream_KW_ROLE.add(KW_ROLE428);


            pushFollow(FOLLOW_identifier_in_grantRole7007);
            identifier429=identifier();

            state._fsp--;

            stream_identifier.add(identifier429.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1291:35: ( COMMA identifier )*
            loop124:
            do {
                int alt124=2;
                int LA124_0 = input.LA(1);

                if ( (LA124_0==COMMA) ) {
                    alt124=1;
                }


                switch (alt124) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1291:36: COMMA identifier
            	    {
            	    COMMA430=(Token)match(input,COMMA,FOLLOW_COMMA_in_grantRole7010);  
            	    stream_COMMA.add(COMMA430);


            	    pushFollow(FOLLOW_identifier_in_grantRole7012);
            	    identifier431=identifier();

            	    state._fsp--;

            	    stream_identifier.add(identifier431.getTree());

            	    }
            	    break;

            	default :
            	    break loop124;
                }
            } while (true);


            KW_TO432=(Token)match(input,KW_TO,FOLLOW_KW_TO_in_grantRole7016);  
            stream_KW_TO.add(KW_TO432);


            pushFollow(FOLLOW_principalSpecification_in_grantRole7018);
            principalSpecification433=principalSpecification();

            state._fsp--;

            stream_principalSpecification.add(principalSpecification433.getTree());

            // AST REWRITE
            // elements: principalSpecification, identifier
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1292:5: -> ^( TOK_GRANT_ROLE principalSpecification ( identifier )+ )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1292:8: ^( TOK_GRANT_ROLE principalSpecification ( identifier )+ )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_GRANT_ROLE, "TOK_GRANT_ROLE")
                , root_1);

                adaptor.addChild(root_1, stream_principalSpecification.nextTree());

                if ( !(stream_identifier.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_identifier.hasNext() ) {
                    adaptor.addChild(root_1, stream_identifier.nextTree());

                }
                stream_identifier.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "grantRole"


    public static class revokeRole_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "revokeRole"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1295:1: revokeRole : KW_REVOKE KW_ROLE identifier ( COMMA identifier )* KW_FROM principalSpecification -> ^( TOK_REVOKE_ROLE principalSpecification ( identifier )+ ) ;
    public final HiveParser.revokeRole_return revokeRole() throws RecognitionException {
        HiveParser.revokeRole_return retval = new HiveParser.revokeRole_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_REVOKE434=null;
        Token KW_ROLE435=null;
        Token COMMA437=null;
        Token KW_FROM439=null;
        HiveParser_IdentifiersParser.identifier_return identifier436 =null;

        HiveParser_IdentifiersParser.identifier_return identifier438 =null;

        HiveParser.principalSpecification_return principalSpecification440 =null;


        CommonTree KW_REVOKE434_tree=null;
        CommonTree KW_ROLE435_tree=null;
        CommonTree COMMA437_tree=null;
        CommonTree KW_FROM439_tree=null;
        RewriteRuleTokenStream stream_KW_REVOKE=new RewriteRuleTokenStream(adaptor,"token KW_REVOKE");
        RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleTokenStream stream_KW_FROM=new RewriteRuleTokenStream(adaptor,"token KW_FROM");
        RewriteRuleSubtreeStream stream_principalSpecification=new RewriteRuleSubtreeStream(adaptor,"rule principalSpecification");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        msgs.push("revoke role");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1298:5: ( KW_REVOKE KW_ROLE identifier ( COMMA identifier )* KW_FROM principalSpecification -> ^( TOK_REVOKE_ROLE principalSpecification ( identifier )+ ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1298:7: KW_REVOKE KW_ROLE identifier ( COMMA identifier )* KW_FROM principalSpecification
            {
            KW_REVOKE434=(Token)match(input,KW_REVOKE,FOLLOW_KW_REVOKE_in_revokeRole7060);  
            stream_KW_REVOKE.add(KW_REVOKE434);


            KW_ROLE435=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_revokeRole7062);  
            stream_KW_ROLE.add(KW_ROLE435);


            pushFollow(FOLLOW_identifier_in_revokeRole7064);
            identifier436=identifier();

            state._fsp--;

            stream_identifier.add(identifier436.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1298:36: ( COMMA identifier )*
            loop125:
            do {
                int alt125=2;
                int LA125_0 = input.LA(1);

                if ( (LA125_0==COMMA) ) {
                    alt125=1;
                }


                switch (alt125) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1298:37: COMMA identifier
            	    {
            	    COMMA437=(Token)match(input,COMMA,FOLLOW_COMMA_in_revokeRole7067);  
            	    stream_COMMA.add(COMMA437);


            	    pushFollow(FOLLOW_identifier_in_revokeRole7069);
            	    identifier438=identifier();

            	    state._fsp--;

            	    stream_identifier.add(identifier438.getTree());

            	    }
            	    break;

            	default :
            	    break loop125;
                }
            } while (true);


            KW_FROM439=(Token)match(input,KW_FROM,FOLLOW_KW_FROM_in_revokeRole7073);  
            stream_KW_FROM.add(KW_FROM439);


            pushFollow(FOLLOW_principalSpecification_in_revokeRole7075);
            principalSpecification440=principalSpecification();

            state._fsp--;

            stream_principalSpecification.add(principalSpecification440.getTree());

            // AST REWRITE
            // elements: identifier, principalSpecification
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1299:5: -> ^( TOK_REVOKE_ROLE principalSpecification ( identifier )+ )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1299:8: ^( TOK_REVOKE_ROLE principalSpecification ( identifier )+ )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_REVOKE_ROLE, "TOK_REVOKE_ROLE")
                , root_1);

                adaptor.addChild(root_1, stream_principalSpecification.nextTree());

                if ( !(stream_identifier.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_identifier.hasNext() ) {
                    adaptor.addChild(root_1, stream_identifier.nextTree());

                }
                stream_identifier.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "revokeRole"


    public static class showRoleGrants_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "showRoleGrants"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1302:1: showRoleGrants : KW_SHOW KW_ROLE KW_GRANT principalName -> ^( TOK_SHOW_ROLE_GRANT principalName ) ;
    public final HiveParser.showRoleGrants_return showRoleGrants() throws RecognitionException {
        HiveParser.showRoleGrants_return retval = new HiveParser.showRoleGrants_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_SHOW441=null;
        Token KW_ROLE442=null;
        Token KW_GRANT443=null;
        HiveParser.principalName_return principalName444 =null;


        CommonTree KW_SHOW441_tree=null;
        CommonTree KW_ROLE442_tree=null;
        CommonTree KW_GRANT443_tree=null;
        RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
        RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
        RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
        RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");
        msgs.push("show role grants");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1305:5: ( KW_SHOW KW_ROLE KW_GRANT principalName -> ^( TOK_SHOW_ROLE_GRANT principalName ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1305:7: KW_SHOW KW_ROLE KW_GRANT principalName
            {
            KW_SHOW441=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showRoleGrants7117);  
            stream_KW_SHOW.add(KW_SHOW441);


            KW_ROLE442=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_showRoleGrants7119);  
            stream_KW_ROLE.add(KW_ROLE442);


            KW_GRANT443=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_showRoleGrants7121);  
            stream_KW_GRANT.add(KW_GRANT443);


            pushFollow(FOLLOW_principalName_in_showRoleGrants7123);
            principalName444=principalName();

            state._fsp--;

            stream_principalName.add(principalName444.getTree());

            // AST REWRITE
            // elements: principalName
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1306:5: -> ^( TOK_SHOW_ROLE_GRANT principalName )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1306:8: ^( TOK_SHOW_ROLE_GRANT principalName )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_SHOW_ROLE_GRANT, "TOK_SHOW_ROLE_GRANT")
                , root_1);

                adaptor.addChild(root_1, stream_principalName.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "showRoleGrants"


    public static class showGrants_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "showGrants"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1309:1: showGrants : KW_SHOW KW_GRANT principalName ( privilegeIncludeColObject )? -> ^( TOK_SHOW_GRANT principalName ( privilegeIncludeColObject )? ) ;
    public final HiveParser.showGrants_return showGrants() throws RecognitionException {
        HiveParser.showGrants_return retval = new HiveParser.showGrants_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_SHOW445=null;
        Token KW_GRANT446=null;
        HiveParser.principalName_return principalName447 =null;

        HiveParser.privilegeIncludeColObject_return privilegeIncludeColObject448 =null;


        CommonTree KW_SHOW445_tree=null;
        CommonTree KW_GRANT446_tree=null;
        RewriteRuleTokenStream stream_KW_SHOW=new RewriteRuleTokenStream(adaptor,"token KW_SHOW");
        RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");
        RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");
        RewriteRuleSubtreeStream stream_privilegeIncludeColObject=new RewriteRuleSubtreeStream(adaptor,"rule privilegeIncludeColObject");
        msgs.push("show grants");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1312:5: ( KW_SHOW KW_GRANT principalName ( privilegeIncludeColObject )? -> ^( TOK_SHOW_GRANT principalName ( privilegeIncludeColObject )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1312:7: KW_SHOW KW_GRANT principalName ( privilegeIncludeColObject )?
            {
            KW_SHOW445=(Token)match(input,KW_SHOW,FOLLOW_KW_SHOW_in_showGrants7162);  
            stream_KW_SHOW.add(KW_SHOW445);


            KW_GRANT446=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_showGrants7164);  
            stream_KW_GRANT.add(KW_GRANT446);


            pushFollow(FOLLOW_principalName_in_showGrants7166);
            principalName447=principalName();

            state._fsp--;

            stream_principalName.add(principalName447.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1312:38: ( privilegeIncludeColObject )?
            int alt126=2;
            int LA126_0 = input.LA(1);

            if ( (LA126_0==KW_ON) ) {
                alt126=1;
            }
            switch (alt126) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1312:38: privilegeIncludeColObject
                    {
                    pushFollow(FOLLOW_privilegeIncludeColObject_in_showGrants7168);
                    privilegeIncludeColObject448=privilegeIncludeColObject();

                    state._fsp--;

                    stream_privilegeIncludeColObject.add(privilegeIncludeColObject448.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: privilegeIncludeColObject, principalName
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1313:5: -> ^( TOK_SHOW_GRANT principalName ( privilegeIncludeColObject )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1313:8: ^( TOK_SHOW_GRANT principalName ( privilegeIncludeColObject )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_SHOW_GRANT, "TOK_SHOW_GRANT")
                , root_1);

                adaptor.addChild(root_1, stream_principalName.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1313:39: ( privilegeIncludeColObject )?
                if ( stream_privilegeIncludeColObject.hasNext() ) {
                    adaptor.addChild(root_1, stream_privilegeIncludeColObject.nextTree());

                }
                stream_privilegeIncludeColObject.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "showGrants"


    public static class privilegeIncludeColObject_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "privilegeIncludeColObject"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1316:1: privilegeIncludeColObject : KW_ON (table= KW_TABLE | KW_DATABASE ) identifier ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )? -> ^( TOK_PRIV_OBJECT_COL identifier ( $table)? ( $cols)? ( partitionSpec )? ) ;
    public final HiveParser.privilegeIncludeColObject_return privilegeIncludeColObject() throws RecognitionException {
        HiveParser.privilegeIncludeColObject_return retval = new HiveParser.privilegeIncludeColObject_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token table=null;
        Token KW_ON449=null;
        Token KW_DATABASE450=null;
        Token LPAREN452=null;
        Token RPAREN453=null;
        HiveParser.columnNameList_return cols =null;

        HiveParser_IdentifiersParser.identifier_return identifier451 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec454 =null;


        CommonTree table_tree=null;
        CommonTree KW_ON449_tree=null;
        CommonTree KW_DATABASE450_tree=null;
        CommonTree LPAREN452_tree=null;
        CommonTree RPAREN453_tree=null;
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        msgs.push("privilege object including columns");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1319:5: ( KW_ON (table= KW_TABLE | KW_DATABASE ) identifier ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )? -> ^( TOK_PRIV_OBJECT_COL identifier ( $table)? ( $cols)? ( partitionSpec )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1319:7: KW_ON (table= KW_TABLE | KW_DATABASE ) identifier ( LPAREN cols= columnNameList RPAREN )? ( partitionSpec )?
            {
            KW_ON449=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_privilegeIncludeColObject7211);  
            stream_KW_ON.add(KW_ON449);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1319:13: (table= KW_TABLE | KW_DATABASE )
            int alt127=2;
            int LA127_0 = input.LA(1);

            if ( (LA127_0==KW_TABLE) ) {
                alt127=1;
            }
            else if ( (LA127_0==KW_DATABASE) ) {
                alt127=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 127, 0, input);

                throw nvae;

            }
            switch (alt127) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1319:14: table= KW_TABLE
                    {
                    table=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_privilegeIncludeColObject7216);  
                    stream_KW_TABLE.add(table);


                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1319:29: KW_DATABASE
                    {
                    KW_DATABASE450=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_privilegeIncludeColObject7218);  
                    stream_KW_DATABASE.add(KW_DATABASE450);


                    }
                    break;

            }


            pushFollow(FOLLOW_identifier_in_privilegeIncludeColObject7221);
            identifier451=identifier();

            state._fsp--;

            stream_identifier.add(identifier451.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1319:53: ( LPAREN cols= columnNameList RPAREN )?
            int alt128=2;
            int LA128_0 = input.LA(1);

            if ( (LA128_0==LPAREN) ) {
                alt128=1;
            }
            switch (alt128) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1319:54: LPAREN cols= columnNameList RPAREN
                    {
                    LPAREN452=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_privilegeIncludeColObject7224);  
                    stream_LPAREN.add(LPAREN452);


                    pushFollow(FOLLOW_columnNameList_in_privilegeIncludeColObject7228);
                    cols=columnNameList();

                    state._fsp--;

                    stream_columnNameList.add(cols.getTree());

                    RPAREN453=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_privilegeIncludeColObject7230);  
                    stream_RPAREN.add(RPAREN453);


                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1319:90: ( partitionSpec )?
            int alt129=2;
            int LA129_0 = input.LA(1);

            if ( (LA129_0==KW_PARTITION) ) {
                alt129=1;
            }
            switch (alt129) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1319:90: partitionSpec
                    {
                    pushFollow(FOLLOW_partitionSpec_in_privilegeIncludeColObject7234);
                    partitionSpec454=partitionSpec();

                    state._fsp--;

                    stream_partitionSpec.add(partitionSpec454.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: partitionSpec, cols, identifier, table
            // token labels: table
            // rule labels: retval, cols
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_table=new RewriteRuleTokenStream(adaptor,"token table",table);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_cols=new RewriteRuleSubtreeStream(adaptor,"rule cols",cols!=null?cols.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1320:5: -> ^( TOK_PRIV_OBJECT_COL identifier ( $table)? ( $cols)? ( partitionSpec )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1320:8: ^( TOK_PRIV_OBJECT_COL identifier ( $table)? ( $cols)? ( partitionSpec )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_PRIV_OBJECT_COL, "TOK_PRIV_OBJECT_COL")
                , root_1);

                adaptor.addChild(root_1, stream_identifier.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1320:42: ( $table)?
                if ( stream_table.hasNext() ) {
                    adaptor.addChild(root_1, stream_table.nextNode());

                }
                stream_table.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1320:50: ( $cols)?
                if ( stream_cols.hasNext() ) {
                    adaptor.addChild(root_1, stream_cols.nextTree());

                }
                stream_cols.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1320:56: ( partitionSpec )?
                if ( stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                }
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "privilegeIncludeColObject"


    public static class privilegeObject_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "privilegeObject"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1323:1: privilegeObject : KW_ON (table= KW_TABLE | KW_DATABASE ) identifier ( partitionSpec )? -> ^( TOK_PRIV_OBJECT identifier ( $table)? ( partitionSpec )? ) ;
    public final HiveParser.privilegeObject_return privilegeObject() throws RecognitionException {
        HiveParser.privilegeObject_return retval = new HiveParser.privilegeObject_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token table=null;
        Token KW_ON455=null;
        Token KW_DATABASE456=null;
        HiveParser_IdentifiersParser.identifier_return identifier457 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec458 =null;


        CommonTree table_tree=null;
        CommonTree KW_ON455_tree=null;
        CommonTree KW_DATABASE456_tree=null;
        RewriteRuleTokenStream stream_KW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_DATABASE");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        msgs.push("privilege subject");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1326:5: ( KW_ON (table= KW_TABLE | KW_DATABASE ) identifier ( partitionSpec )? -> ^( TOK_PRIV_OBJECT identifier ( $table)? ( partitionSpec )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1326:7: KW_ON (table= KW_TABLE | KW_DATABASE ) identifier ( partitionSpec )?
            {
            KW_ON455=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_privilegeObject7285);  
            stream_KW_ON.add(KW_ON455);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1326:13: (table= KW_TABLE | KW_DATABASE )
            int alt130=2;
            int LA130_0 = input.LA(1);

            if ( (LA130_0==KW_TABLE) ) {
                alt130=1;
            }
            else if ( (LA130_0==KW_DATABASE) ) {
                alt130=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 130, 0, input);

                throw nvae;

            }
            switch (alt130) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1326:14: table= KW_TABLE
                    {
                    table=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_privilegeObject7290);  
                    stream_KW_TABLE.add(table);


                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1326:29: KW_DATABASE
                    {
                    KW_DATABASE456=(Token)match(input,KW_DATABASE,FOLLOW_KW_DATABASE_in_privilegeObject7292);  
                    stream_KW_DATABASE.add(KW_DATABASE456);


                    }
                    break;

            }


            pushFollow(FOLLOW_identifier_in_privilegeObject7295);
            identifier457=identifier();

            state._fsp--;

            stream_identifier.add(identifier457.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1326:53: ( partitionSpec )?
            int alt131=2;
            int LA131_0 = input.LA(1);

            if ( (LA131_0==KW_PARTITION) ) {
                alt131=1;
            }
            switch (alt131) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1326:53: partitionSpec
                    {
                    pushFollow(FOLLOW_partitionSpec_in_privilegeObject7297);
                    partitionSpec458=partitionSpec();

                    state._fsp--;

                    stream_partitionSpec.add(partitionSpec458.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: partitionSpec, identifier, table
            // token labels: table
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_table=new RewriteRuleTokenStream(adaptor,"token table",table);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1327:5: -> ^( TOK_PRIV_OBJECT identifier ( $table)? ( partitionSpec )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:8: ^( TOK_PRIV_OBJECT identifier ( $table)? ( partitionSpec )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_PRIV_OBJECT, "TOK_PRIV_OBJECT")
                , root_1);

                adaptor.addChild(root_1, stream_identifier.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:38: ( $table)?
                if ( stream_table.hasNext() ) {
                    adaptor.addChild(root_1, stream_table.nextNode());

                }
                stream_table.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1327:45: ( partitionSpec )?
                if ( stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                }
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "privilegeObject"


    public static class privilegeList_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "privilegeList"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1330:1: privilegeList : privlegeDef ( COMMA privlegeDef )* -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ ) ;
    public final HiveParser.privilegeList_return privilegeList() throws RecognitionException {
        HiveParser.privilegeList_return retval = new HiveParser.privilegeList_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token COMMA460=null;
        HiveParser.privlegeDef_return privlegeDef459 =null;

        HiveParser.privlegeDef_return privlegeDef461 =null;


        CommonTree COMMA460_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_privlegeDef=new RewriteRuleSubtreeStream(adaptor,"rule privlegeDef");
        msgs.push("grant privilege list");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1333:5: ( privlegeDef ( COMMA privlegeDef )* -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1333:7: privlegeDef ( COMMA privlegeDef )*
            {
            pushFollow(FOLLOW_privlegeDef_in_privilegeList7344);
            privlegeDef459=privlegeDef();

            state._fsp--;

            stream_privlegeDef.add(privlegeDef459.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1333:19: ( COMMA privlegeDef )*
            loop132:
            do {
                int alt132=2;
                int LA132_0 = input.LA(1);

                if ( (LA132_0==COMMA) ) {
                    alt132=1;
                }


                switch (alt132) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1333:20: COMMA privlegeDef
            	    {
            	    COMMA460=(Token)match(input,COMMA,FOLLOW_COMMA_in_privilegeList7347);  
            	    stream_COMMA.add(COMMA460);


            	    pushFollow(FOLLOW_privlegeDef_in_privilegeList7349);
            	    privlegeDef461=privlegeDef();

            	    state._fsp--;

            	    stream_privlegeDef.add(privlegeDef461.getTree());

            	    }
            	    break;

            	default :
            	    break loop132;
                }
            } while (true);


            // AST REWRITE
            // elements: privlegeDef
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1334:5: -> ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1334:8: ^( TOK_PRIVILEGE_LIST ( privlegeDef )+ )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_PRIVILEGE_LIST, "TOK_PRIVILEGE_LIST")
                , root_1);

                if ( !(stream_privlegeDef.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_privlegeDef.hasNext() ) {
                    adaptor.addChild(root_1, stream_privlegeDef.nextTree());

                }
                stream_privlegeDef.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "privilegeList"


    public static class privlegeDef_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "privlegeDef"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1337:1: privlegeDef : privilegeType ( LPAREN cols= columnNameList RPAREN )? -> ^( TOK_PRIVILEGE privilegeType ( $cols)? ) ;
    public final HiveParser.privlegeDef_return privlegeDef() throws RecognitionException {
        HiveParser.privlegeDef_return retval = new HiveParser.privlegeDef_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token LPAREN463=null;
        Token RPAREN464=null;
        HiveParser.columnNameList_return cols =null;

        HiveParser.privilegeType_return privilegeType462 =null;


        CommonTree LPAREN463_tree=null;
        CommonTree RPAREN464_tree=null;
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleSubtreeStream stream_privilegeType=new RewriteRuleSubtreeStream(adaptor,"rule privilegeType");
        RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
        msgs.push("grant privilege");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1340:5: ( privilegeType ( LPAREN cols= columnNameList RPAREN )? -> ^( TOK_PRIVILEGE privilegeType ( $cols)? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1340:7: privilegeType ( LPAREN cols= columnNameList RPAREN )?
            {
            pushFollow(FOLLOW_privilegeType_in_privlegeDef7391);
            privilegeType462=privilegeType();

            state._fsp--;

            stream_privilegeType.add(privilegeType462.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1340:21: ( LPAREN cols= columnNameList RPAREN )?
            int alt133=2;
            int LA133_0 = input.LA(1);

            if ( (LA133_0==LPAREN) ) {
                alt133=1;
            }
            switch (alt133) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1340:22: LPAREN cols= columnNameList RPAREN
                    {
                    LPAREN463=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_privlegeDef7394);  
                    stream_LPAREN.add(LPAREN463);


                    pushFollow(FOLLOW_columnNameList_in_privlegeDef7398);
                    cols=columnNameList();

                    state._fsp--;

                    stream_columnNameList.add(cols.getTree());

                    RPAREN464=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_privlegeDef7400);  
                    stream_RPAREN.add(RPAREN464);


                    }
                    break;

            }


            // AST REWRITE
            // elements: cols, privilegeType
            // token labels: 
            // rule labels: retval, cols
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_cols=new RewriteRuleSubtreeStream(adaptor,"rule cols",cols!=null?cols.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1341:5: -> ^( TOK_PRIVILEGE privilegeType ( $cols)? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:8: ^( TOK_PRIVILEGE privilegeType ( $cols)? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_PRIVILEGE, "TOK_PRIVILEGE")
                , root_1);

                adaptor.addChild(root_1, stream_privilegeType.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1341:39: ( $cols)?
                if ( stream_cols.hasNext() ) {
                    adaptor.addChild(root_1, stream_cols.nextTree());

                }
                stream_cols.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "privlegeDef"


    public static class privilegeType_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "privilegeType"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1344:1: privilegeType : ( KW_ALL -> ^( TOK_PRIV_ALL ) | KW_ALTER -> ^( TOK_PRIV_ALTER_METADATA ) | KW_UPDATE -> ^( TOK_PRIV_ALTER_DATA ) | KW_CREATE -> ^( TOK_PRIV_CREATE ) | KW_DROP -> ^( TOK_PRIV_DROP ) | KW_INDEX -> ^( TOK_PRIV_INDEX ) | KW_LOCK -> ^( TOK_PRIV_LOCK ) | KW_SELECT -> ^( TOK_PRIV_SELECT ) | KW_SHOW_DATABASE -> ^( TOK_PRIV_SHOW_DATABASE ) );
    public final HiveParser.privilegeType_return privilegeType() throws RecognitionException {
        HiveParser.privilegeType_return retval = new HiveParser.privilegeType_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_ALL465=null;
        Token KW_ALTER466=null;
        Token KW_UPDATE467=null;
        Token KW_CREATE468=null;
        Token KW_DROP469=null;
        Token KW_INDEX470=null;
        Token KW_LOCK471=null;
        Token KW_SELECT472=null;
        Token KW_SHOW_DATABASE473=null;

        CommonTree KW_ALL465_tree=null;
        CommonTree KW_ALTER466_tree=null;
        CommonTree KW_UPDATE467_tree=null;
        CommonTree KW_CREATE468_tree=null;
        CommonTree KW_DROP469_tree=null;
        CommonTree KW_INDEX470_tree=null;
        CommonTree KW_LOCK471_tree=null;
        CommonTree KW_SELECT472_tree=null;
        CommonTree KW_SHOW_DATABASE473_tree=null;
        RewriteRuleTokenStream stream_KW_ALTER=new RewriteRuleTokenStream(adaptor,"token KW_ALTER");
        RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
        RewriteRuleTokenStream stream_KW_ALL=new RewriteRuleTokenStream(adaptor,"token KW_ALL");
        RewriteRuleTokenStream stream_KW_SELECT=new RewriteRuleTokenStream(adaptor,"token KW_SELECT");
        RewriteRuleTokenStream stream_KW_UPDATE=new RewriteRuleTokenStream(adaptor,"token KW_UPDATE");
        RewriteRuleTokenStream stream_KW_SHOW_DATABASE=new RewriteRuleTokenStream(adaptor,"token KW_SHOW_DATABASE");
        RewriteRuleTokenStream stream_KW_INDEX=new RewriteRuleTokenStream(adaptor,"token KW_INDEX");
        RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
        RewriteRuleTokenStream stream_KW_LOCK=new RewriteRuleTokenStream(adaptor,"token KW_LOCK");

        msgs.push("privilege type");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1347:5: ( KW_ALL -> ^( TOK_PRIV_ALL ) | KW_ALTER -> ^( TOK_PRIV_ALTER_METADATA ) | KW_UPDATE -> ^( TOK_PRIV_ALTER_DATA ) | KW_CREATE -> ^( TOK_PRIV_CREATE ) | KW_DROP -> ^( TOK_PRIV_DROP ) | KW_INDEX -> ^( TOK_PRIV_INDEX ) | KW_LOCK -> ^( TOK_PRIV_LOCK ) | KW_SELECT -> ^( TOK_PRIV_SELECT ) | KW_SHOW_DATABASE -> ^( TOK_PRIV_SHOW_DATABASE ) )
            int alt134=9;
            switch ( input.LA(1) ) {
            case KW_ALL:
                {
                alt134=1;
                }
                break;
            case KW_ALTER:
                {
                alt134=2;
                }
                break;
            case KW_UPDATE:
                {
                alt134=3;
                }
                break;
            case KW_CREATE:
                {
                alt134=4;
                }
                break;
            case KW_DROP:
                {
                alt134=5;
                }
                break;
            case KW_INDEX:
                {
                alt134=6;
                }
                break;
            case KW_LOCK:
                {
                alt134=7;
                }
                break;
            case KW_SELECT:
                {
                alt134=8;
                }
                break;
            case KW_SHOW_DATABASE:
                {
                alt134=9;
                }
                break;
            default:
                NoViableAltException nvae =
                    new NoViableAltException("", 134, 0, input);

                throw nvae;

            }

            switch (alt134) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1347:7: KW_ALL
                    {
                    KW_ALL465=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_privilegeType7445);  
                    stream_KW_ALL.add(KW_ALL465);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1347:14: -> ^( TOK_PRIV_ALL )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1347:17: ^( TOK_PRIV_ALL )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_PRIV_ALL, "TOK_PRIV_ALL")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1348:7: KW_ALTER
                    {
                    KW_ALTER466=(Token)match(input,KW_ALTER,FOLLOW_KW_ALTER_in_privilegeType7459);  
                    stream_KW_ALTER.add(KW_ALTER466);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1348:16: -> ^( TOK_PRIV_ALTER_METADATA )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1348:19: ^( TOK_PRIV_ALTER_METADATA )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_PRIV_ALTER_METADATA, "TOK_PRIV_ALTER_METADATA")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1349:7: KW_UPDATE
                    {
                    KW_UPDATE467=(Token)match(input,KW_UPDATE,FOLLOW_KW_UPDATE_in_privilegeType7473);  
                    stream_KW_UPDATE.add(KW_UPDATE467);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1349:17: -> ^( TOK_PRIV_ALTER_DATA )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1349:20: ^( TOK_PRIV_ALTER_DATA )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_PRIV_ALTER_DATA, "TOK_PRIV_ALTER_DATA")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 4 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:7: KW_CREATE
                    {
                    KW_CREATE468=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_privilegeType7487);  
                    stream_KW_CREATE.add(KW_CREATE468);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1350:17: -> ^( TOK_PRIV_CREATE )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1350:20: ^( TOK_PRIV_CREATE )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_PRIV_CREATE, "TOK_PRIV_CREATE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 5 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:7: KW_DROP
                    {
                    KW_DROP469=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_privilegeType7501);  
                    stream_KW_DROP.add(KW_DROP469);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1351:15: -> ^( TOK_PRIV_DROP )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1351:18: ^( TOK_PRIV_DROP )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_PRIV_DROP, "TOK_PRIV_DROP")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 6 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1352:7: KW_INDEX
                    {
                    KW_INDEX470=(Token)match(input,KW_INDEX,FOLLOW_KW_INDEX_in_privilegeType7515);  
                    stream_KW_INDEX.add(KW_INDEX470);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1352:16: -> ^( TOK_PRIV_INDEX )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1352:19: ^( TOK_PRIV_INDEX )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_PRIV_INDEX, "TOK_PRIV_INDEX")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 7 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:7: KW_LOCK
                    {
                    KW_LOCK471=(Token)match(input,KW_LOCK,FOLLOW_KW_LOCK_in_privilegeType7529);  
                    stream_KW_LOCK.add(KW_LOCK471);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1353:15: -> ^( TOK_PRIV_LOCK )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1353:18: ^( TOK_PRIV_LOCK )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_PRIV_LOCK, "TOK_PRIV_LOCK")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 8 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1354:7: KW_SELECT
                    {
                    KW_SELECT472=(Token)match(input,KW_SELECT,FOLLOW_KW_SELECT_in_privilegeType7543);  
                    stream_KW_SELECT.add(KW_SELECT472);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1354:17: -> ^( TOK_PRIV_SELECT )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1354:20: ^( TOK_PRIV_SELECT )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_PRIV_SELECT, "TOK_PRIV_SELECT")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 9 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1355:7: KW_SHOW_DATABASE
                    {
                    KW_SHOW_DATABASE473=(Token)match(input,KW_SHOW_DATABASE,FOLLOW_KW_SHOW_DATABASE_in_privilegeType7557);  
                    stream_KW_SHOW_DATABASE.add(KW_SHOW_DATABASE473);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1355:24: -> ^( TOK_PRIV_SHOW_DATABASE )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1355:27: ^( TOK_PRIV_SHOW_DATABASE )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_PRIV_SHOW_DATABASE, "TOK_PRIV_SHOW_DATABASE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "privilegeType"


    public static class principalSpecification_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "principalSpecification"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1358:1: principalSpecification : principalName ( COMMA principalName )* -> ^( TOK_PRINCIPAL_NAME ( principalName )+ ) ;
    public final HiveParser.principalSpecification_return principalSpecification() throws RecognitionException {
        HiveParser.principalSpecification_return retval = new HiveParser.principalSpecification_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token COMMA475=null;
        HiveParser.principalName_return principalName474 =null;

        HiveParser.principalName_return principalName476 =null;


        CommonTree COMMA475_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_principalName=new RewriteRuleSubtreeStream(adaptor,"rule principalName");
         msgs.push("user/group/role name list"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1361:5: ( principalName ( COMMA principalName )* -> ^( TOK_PRINCIPAL_NAME ( principalName )+ ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1361:7: principalName ( COMMA principalName )*
            {
            pushFollow(FOLLOW_principalName_in_principalSpecification7590);
            principalName474=principalName();

            state._fsp--;

            stream_principalName.add(principalName474.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1361:21: ( COMMA principalName )*
            loop135:
            do {
                int alt135=2;
                int LA135_0 = input.LA(1);

                if ( (LA135_0==COMMA) ) {
                    alt135=1;
                }


                switch (alt135) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1361:22: COMMA principalName
            	    {
            	    COMMA475=(Token)match(input,COMMA,FOLLOW_COMMA_in_principalSpecification7593);  
            	    stream_COMMA.add(COMMA475);


            	    pushFollow(FOLLOW_principalName_in_principalSpecification7595);
            	    principalName476=principalName();

            	    state._fsp--;

            	    stream_principalName.add(principalName476.getTree());

            	    }
            	    break;

            	default :
            	    break loop135;
                }
            } while (true);


            // AST REWRITE
            // elements: principalName
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1361:44: -> ^( TOK_PRINCIPAL_NAME ( principalName )+ )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1361:47: ^( TOK_PRINCIPAL_NAME ( principalName )+ )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_PRINCIPAL_NAME, "TOK_PRINCIPAL_NAME")
                , root_1);

                if ( !(stream_principalName.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_principalName.hasNext() ) {
                    adaptor.addChild(root_1, stream_principalName.nextTree());

                }
                stream_principalName.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "principalSpecification"


    public static class principalName_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "principalName"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1364:1: principalName : ( KW_USER identifier -> ^( TOK_USER identifier ) | KW_GROUP identifier -> ^( TOK_GROUP identifier ) | KW_ROLE identifier -> ^( TOK_ROLE identifier ) );
    public final HiveParser.principalName_return principalName() throws RecognitionException {
        HiveParser.principalName_return retval = new HiveParser.principalName_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_USER477=null;
        Token KW_GROUP479=null;
        Token KW_ROLE481=null;
        HiveParser_IdentifiersParser.identifier_return identifier478 =null;

        HiveParser_IdentifiersParser.identifier_return identifier480 =null;

        HiveParser_IdentifiersParser.identifier_return identifier482 =null;


        CommonTree KW_USER477_tree=null;
        CommonTree KW_GROUP479_tree=null;
        CommonTree KW_ROLE481_tree=null;
        RewriteRuleTokenStream stream_KW_ROLE=new RewriteRuleTokenStream(adaptor,"token KW_ROLE");
        RewriteRuleTokenStream stream_KW_GROUP=new RewriteRuleTokenStream(adaptor,"token KW_GROUP");
        RewriteRuleTokenStream stream_KW_USER=new RewriteRuleTokenStream(adaptor,"token KW_USER");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
        msgs.push("user|group|role name");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:5: ( KW_USER identifier -> ^( TOK_USER identifier ) | KW_GROUP identifier -> ^( TOK_GROUP identifier ) | KW_ROLE identifier -> ^( TOK_ROLE identifier ) )
            int alt136=3;
            switch ( input.LA(1) ) {
            case KW_USER:
                {
                alt136=1;
                }
                break;
            case KW_GROUP:
                {
                alt136=2;
                }
                break;
            case KW_ROLE:
                {
                alt136=3;
                }
                break;
            default:
                NoViableAltException nvae =
                    new NoViableAltException("", 136, 0, input);

                throw nvae;

            }

            switch (alt136) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:7: KW_USER identifier
                    {
                    KW_USER477=(Token)match(input,KW_USER,FOLLOW_KW_USER_in_principalName7633);  
                    stream_KW_USER.add(KW_USER477);


                    pushFollow(FOLLOW_identifier_in_principalName7635);
                    identifier478=identifier();

                    state._fsp--;

                    stream_identifier.add(identifier478.getTree());

                    // AST REWRITE
                    // elements: identifier
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1367:26: -> ^( TOK_USER identifier )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1367:29: ^( TOK_USER identifier )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_USER, "TOK_USER")
                        , root_1);

                        adaptor.addChild(root_1, stream_identifier.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:7: KW_GROUP identifier
                    {
                    KW_GROUP479=(Token)match(input,KW_GROUP,FOLLOW_KW_GROUP_in_principalName7651);  
                    stream_KW_GROUP.add(KW_GROUP479);


                    pushFollow(FOLLOW_identifier_in_principalName7653);
                    identifier480=identifier();

                    state._fsp--;

                    stream_identifier.add(identifier480.getTree());

                    // AST REWRITE
                    // elements: identifier
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1368:27: -> ^( TOK_GROUP identifier )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1368:30: ^( TOK_GROUP identifier )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_GROUP, "TOK_GROUP")
                        , root_1);

                        adaptor.addChild(root_1, stream_identifier.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:7: KW_ROLE identifier
                    {
                    KW_ROLE481=(Token)match(input,KW_ROLE,FOLLOW_KW_ROLE_in_principalName7669);  
                    stream_KW_ROLE.add(KW_ROLE481);


                    pushFollow(FOLLOW_identifier_in_principalName7671);
                    identifier482=identifier();

                    state._fsp--;

                    stream_identifier.add(identifier482.getTree());

                    // AST REWRITE
                    // elements: identifier
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1369:26: -> ^( TOK_ROLE identifier )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1369:29: ^( TOK_ROLE identifier )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_ROLE, "TOK_ROLE")
                        , root_1);

                        adaptor.addChild(root_1, stream_identifier.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "principalName"


    public static class withOption_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "withOption"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1372:1: withOption : KW_GRANT KW_OPTION -> ^( TOK_GRANT_WITH_OPTION ) ;
    public final HiveParser.withOption_return withOption() throws RecognitionException {
        HiveParser.withOption_return retval = new HiveParser.withOption_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_GRANT483=null;
        Token KW_OPTION484=null;

        CommonTree KW_GRANT483_tree=null;
        CommonTree KW_OPTION484_tree=null;
        RewriteRuleTokenStream stream_KW_OPTION=new RewriteRuleTokenStream(adaptor,"token KW_OPTION");
        RewriteRuleTokenStream stream_KW_GRANT=new RewriteRuleTokenStream(adaptor,"token KW_GRANT");

        msgs.push("grant with option");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1375:5: ( KW_GRANT KW_OPTION -> ^( TOK_GRANT_WITH_OPTION ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1375:7: KW_GRANT KW_OPTION
            {
            KW_GRANT483=(Token)match(input,KW_GRANT,FOLLOW_KW_GRANT_in_withOption7706);  
            stream_KW_GRANT.add(KW_GRANT483);


            KW_OPTION484=(Token)match(input,KW_OPTION,FOLLOW_KW_OPTION_in_withOption7708);  
            stream_KW_OPTION.add(KW_OPTION484);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1376:5: -> ^( TOK_GRANT_WITH_OPTION )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1376:8: ^( TOK_GRANT_WITH_OPTION )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_GRANT_WITH_OPTION, "TOK_GRANT_WITH_OPTION")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

            msgs.pop();
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "withOption"


    public static class metastoreCheck_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "metastoreCheck"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1379:1: metastoreCheck : KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE table= identifier ( partitionSpec )? ( COMMA partitionSpec )* )? -> ^( TOK_MSCK ( $repair)? ( $table ( partitionSpec )* )? ) ;
    public final HiveParser.metastoreCheck_return metastoreCheck() throws RecognitionException {
        HiveParser.metastoreCheck_return retval = new HiveParser.metastoreCheck_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token repair=null;
        Token KW_MSCK485=null;
        Token KW_TABLE486=null;
        Token COMMA488=null;
        HiveParser_IdentifiersParser.identifier_return table =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec487 =null;

        HiveParser_IdentifiersParser.partitionSpec_return partitionSpec489 =null;


        CommonTree repair_tree=null;
        CommonTree KW_MSCK485_tree=null;
        CommonTree KW_TABLE486_tree=null;
        CommonTree COMMA488_tree=null;
        RewriteRuleTokenStream stream_KW_MSCK=new RewriteRuleTokenStream(adaptor,"token KW_MSCK");
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleTokenStream stream_KW_REPAIR=new RewriteRuleTokenStream(adaptor,"token KW_REPAIR");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleSubtreeStream stream_partitionSpec=new RewriteRuleSubtreeStream(adaptor,"rule partitionSpec");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("metastore check statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1382:5: ( KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE table= identifier ( partitionSpec )? ( COMMA partitionSpec )* )? -> ^( TOK_MSCK ( $repair)? ( $table ( partitionSpec )* )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1382:7: KW_MSCK (repair= KW_REPAIR )? ( KW_TABLE table= identifier ( partitionSpec )? ( COMMA partitionSpec )* )?
            {
            KW_MSCK485=(Token)match(input,KW_MSCK,FOLLOW_KW_MSCK_in_metastoreCheck7745);  
            stream_KW_MSCK.add(KW_MSCK485);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1382:15: (repair= KW_REPAIR )?
            int alt137=2;
            int LA137_0 = input.LA(1);

            if ( (LA137_0==KW_REPAIR) ) {
                alt137=1;
            }
            switch (alt137) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1382:16: repair= KW_REPAIR
                    {
                    repair=(Token)match(input,KW_REPAIR,FOLLOW_KW_REPAIR_in_metastoreCheck7750);  
                    stream_KW_REPAIR.add(repair);


                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1382:35: ( KW_TABLE table= identifier ( partitionSpec )? ( COMMA partitionSpec )* )?
            int alt140=2;
            int LA140_0 = input.LA(1);

            if ( (LA140_0==KW_TABLE) ) {
                alt140=1;
            }
            switch (alt140) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1382:36: KW_TABLE table= identifier ( partitionSpec )? ( COMMA partitionSpec )*
                    {
                    KW_TABLE486=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_metastoreCheck7755);  
                    stream_KW_TABLE.add(KW_TABLE486);


                    pushFollow(FOLLOW_identifier_in_metastoreCheck7759);
                    table=identifier();

                    state._fsp--;

                    stream_identifier.add(table.getTree());

                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1382:62: ( partitionSpec )?
                    int alt138=2;
                    int LA138_0 = input.LA(1);

                    if ( (LA138_0==KW_PARTITION) ) {
                        alt138=1;
                    }
                    switch (alt138) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1382:62: partitionSpec
                            {
                            pushFollow(FOLLOW_partitionSpec_in_metastoreCheck7761);
                            partitionSpec487=partitionSpec();

                            state._fsp--;

                            stream_partitionSpec.add(partitionSpec487.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1382:77: ( COMMA partitionSpec )*
                    loop139:
                    do {
                        int alt139=2;
                        int LA139_0 = input.LA(1);

                        if ( (LA139_0==COMMA) ) {
                            alt139=1;
                        }


                        switch (alt139) {
                    	case 1 :
                    	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1382:78: COMMA partitionSpec
                    	    {
                    	    COMMA488=(Token)match(input,COMMA,FOLLOW_COMMA_in_metastoreCheck7765);  
                    	    stream_COMMA.add(COMMA488);


                    	    pushFollow(FOLLOW_partitionSpec_in_metastoreCheck7767);
                    	    partitionSpec489=partitionSpec();

                    	    state._fsp--;

                    	    stream_partitionSpec.add(partitionSpec489.getTree());

                    	    }
                    	    break;

                    	default :
                    	    break loop139;
                        }
                    } while (true);


                    }
                    break;

            }


            // AST REWRITE
            // elements: table, partitionSpec, repair
            // token labels: repair
            // rule labels: retval, table
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_repair=new RewriteRuleTokenStream(adaptor,"token repair",repair);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_table=new RewriteRuleSubtreeStream(adaptor,"rule table",table!=null?table.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1383:5: -> ^( TOK_MSCK ( $repair)? ( $table ( partitionSpec )* )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1383:8: ^( TOK_MSCK ( $repair)? ( $table ( partitionSpec )* )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_MSCK, "TOK_MSCK")
                , root_1);

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1383:20: ( $repair)?
                if ( stream_repair.hasNext() ) {
                    adaptor.addChild(root_1, stream_repair.nextNode());

                }
                stream_repair.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1383:28: ( $table ( partitionSpec )* )?
                if ( stream_table.hasNext()||stream_partitionSpec.hasNext() ) {
                    adaptor.addChild(root_1, stream_table.nextTree());

                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1383:36: ( partitionSpec )*
                    while ( stream_partitionSpec.hasNext() ) {
                        adaptor.addChild(root_1, stream_partitionSpec.nextTree());

                    }
                    stream_partitionSpec.reset();

                }
                stream_table.reset();
                stream_partitionSpec.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "metastoreCheck"


    public static class createFunctionStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "createFunctionStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1386:1: createFunctionStatement : KW_CREATE KW_TEMPORARY KW_FUNCTION identifier KW_AS StringLiteral -> ^( TOK_CREATEFUNCTION identifier StringLiteral ) ;
    public final HiveParser.createFunctionStatement_return createFunctionStatement() throws RecognitionException {
        HiveParser.createFunctionStatement_return retval = new HiveParser.createFunctionStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_CREATE490=null;
        Token KW_TEMPORARY491=null;
        Token KW_FUNCTION492=null;
        Token KW_AS494=null;
        Token StringLiteral495=null;
        HiveParser_IdentifiersParser.identifier_return identifier493 =null;


        CommonTree KW_CREATE490_tree=null;
        CommonTree KW_TEMPORARY491_tree=null;
        CommonTree KW_FUNCTION492_tree=null;
        CommonTree KW_AS494_tree=null;
        CommonTree StringLiteral495_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
        RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
        RewriteRuleTokenStream stream_KW_FUNCTION=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTION");
        RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("create function statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1389:5: ( KW_CREATE KW_TEMPORARY KW_FUNCTION identifier KW_AS StringLiteral -> ^( TOK_CREATEFUNCTION identifier StringLiteral ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1389:7: KW_CREATE KW_TEMPORARY KW_FUNCTION identifier KW_AS StringLiteral
            {
            KW_CREATE490=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createFunctionStatement7821);  
            stream_KW_CREATE.add(KW_CREATE490);


            KW_TEMPORARY491=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_createFunctionStatement7823);  
            stream_KW_TEMPORARY.add(KW_TEMPORARY491);


            KW_FUNCTION492=(Token)match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_createFunctionStatement7825);  
            stream_KW_FUNCTION.add(KW_FUNCTION492);


            pushFollow(FOLLOW_identifier_in_createFunctionStatement7827);
            identifier493=identifier();

            state._fsp--;

            stream_identifier.add(identifier493.getTree());

            KW_AS494=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_createFunctionStatement7829);  
            stream_KW_AS.add(KW_AS494);


            StringLiteral495=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_createFunctionStatement7831);  
            stream_StringLiteral.add(StringLiteral495);


            // AST REWRITE
            // elements: StringLiteral, identifier
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1390:5: -> ^( TOK_CREATEFUNCTION identifier StringLiteral )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1390:8: ^( TOK_CREATEFUNCTION identifier StringLiteral )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_CREATEFUNCTION, "TOK_CREATEFUNCTION")
                , root_1);

                adaptor.addChild(root_1, stream_identifier.nextTree());

                adaptor.addChild(root_1, 
                stream_StringLiteral.nextNode()
                );

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "createFunctionStatement"


    public static class dropFunctionStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dropFunctionStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1393:1: dropFunctionStatement : KW_DROP KW_TEMPORARY KW_FUNCTION ( ifExists )? identifier -> ^( TOK_DROPFUNCTION identifier ( ifExists )? ) ;
    public final HiveParser.dropFunctionStatement_return dropFunctionStatement() throws RecognitionException {
        HiveParser.dropFunctionStatement_return retval = new HiveParser.dropFunctionStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_DROP496=null;
        Token KW_TEMPORARY497=null;
        Token KW_FUNCTION498=null;
        HiveParser.ifExists_return ifExists499 =null;

        HiveParser_IdentifiersParser.identifier_return identifier500 =null;


        CommonTree KW_DROP496_tree=null;
        CommonTree KW_TEMPORARY497_tree=null;
        CommonTree KW_FUNCTION498_tree=null;
        RewriteRuleTokenStream stream_KW_FUNCTION=new RewriteRuleTokenStream(adaptor,"token KW_FUNCTION");
        RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
        RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
        RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("drop temporary function statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1396:5: ( KW_DROP KW_TEMPORARY KW_FUNCTION ( ifExists )? identifier -> ^( TOK_DROPFUNCTION identifier ( ifExists )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1396:7: KW_DROP KW_TEMPORARY KW_FUNCTION ( ifExists )? identifier
            {
            KW_DROP496=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropFunctionStatement7872);  
            stream_KW_DROP.add(KW_DROP496);


            KW_TEMPORARY497=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_dropFunctionStatement7874);  
            stream_KW_TEMPORARY.add(KW_TEMPORARY497);


            KW_FUNCTION498=(Token)match(input,KW_FUNCTION,FOLLOW_KW_FUNCTION_in_dropFunctionStatement7876);  
            stream_KW_FUNCTION.add(KW_FUNCTION498);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1396:40: ( ifExists )?
            int alt141=2;
            int LA141_0 = input.LA(1);

            if ( (LA141_0==KW_IF) ) {
                alt141=1;
            }
            switch (alt141) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1396:40: ifExists
                    {
                    pushFollow(FOLLOW_ifExists_in_dropFunctionStatement7878);
                    ifExists499=ifExists();

                    state._fsp--;

                    stream_ifExists.add(ifExists499.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_identifier_in_dropFunctionStatement7881);
            identifier500=identifier();

            state._fsp--;

            stream_identifier.add(identifier500.getTree());

            // AST REWRITE
            // elements: ifExists, identifier
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1397:5: -> ^( TOK_DROPFUNCTION identifier ( ifExists )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1397:8: ^( TOK_DROPFUNCTION identifier ( ifExists )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_DROPFUNCTION, "TOK_DROPFUNCTION")
                , root_1);

                adaptor.addChild(root_1, stream_identifier.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1397:38: ( ifExists )?
                if ( stream_ifExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifExists.nextTree());

                }
                stream_ifExists.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dropFunctionStatement"


    public static class createMacroStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "createMacroStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1400:1: createMacroStatement : KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression ) ;
    public final HiveParser.createMacroStatement_return createMacroStatement() throws RecognitionException {
        HiveParser.createMacroStatement_return retval = new HiveParser.createMacroStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_CREATE501=null;
        Token KW_TEMPORARY502=null;
        Token KW_MACRO503=null;
        Token Identifier504=null;
        Token LPAREN505=null;
        Token RPAREN507=null;
        HiveParser.columnNameTypeList_return columnNameTypeList506 =null;

        HiveParser_IdentifiersParser.expression_return expression508 =null;


        CommonTree KW_CREATE501_tree=null;
        CommonTree KW_TEMPORARY502_tree=null;
        CommonTree KW_MACRO503_tree=null;
        CommonTree Identifier504_tree=null;
        CommonTree LPAREN505_tree=null;
        CommonTree RPAREN507_tree=null;
        RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
        RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
        RewriteRuleTokenStream stream_KW_MACRO=new RewriteRuleTokenStream(adaptor,"token KW_MACRO");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
        RewriteRuleSubtreeStream stream_columnNameTypeList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeList");
         msgs.push("create macro statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1403:5: ( KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1403:7: KW_CREATE KW_TEMPORARY KW_MACRO Identifier LPAREN ( columnNameTypeList )? RPAREN expression
            {
            KW_CREATE501=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createMacroStatement7923);  
            stream_KW_CREATE.add(KW_CREATE501);


            KW_TEMPORARY502=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_createMacroStatement7925);  
            stream_KW_TEMPORARY.add(KW_TEMPORARY502);


            KW_MACRO503=(Token)match(input,KW_MACRO,FOLLOW_KW_MACRO_in_createMacroStatement7927);  
            stream_KW_MACRO.add(KW_MACRO503);


            Identifier504=(Token)match(input,Identifier,FOLLOW_Identifier_in_createMacroStatement7929);  
            stream_Identifier.add(Identifier504);


            LPAREN505=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createMacroStatement7937);  
            stream_LPAREN.add(LPAREN505);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1404:14: ( columnNameTypeList )?
            int alt142=2;
            int LA142_0 = input.LA(1);

            if ( ((LA142_0 >= Identifier && LA142_0 <= KW_AFTER)||(LA142_0 >= KW_ALTER && LA142_0 <= KW_ANALYZE)||(LA142_0 >= KW_ARCHIVE && LA142_0 <= KW_CASCADE)||(LA142_0 >= KW_CHANGE && LA142_0 <= KW_COLLECTION)||(LA142_0 >= KW_COLUMNS && LA142_0 <= KW_CREATE)||LA142_0==KW_CUBE||(LA142_0 >= KW_CURSOR && LA142_0 <= KW_DATA)||(LA142_0 >= KW_DATABASES && LA142_0 <= KW_DISABLE)||(LA142_0 >= KW_DISTRIBUTE && LA142_0 <= KW_ELEM_TYPE)||LA142_0==KW_ENABLE||LA142_0==KW_ESCAPED||(LA142_0 >= KW_EXCLUSIVE && LA142_0 <= KW_EXPORT)||(LA142_0 >= KW_EXTERNAL && LA142_0 <= KW_FLOAT)||(LA142_0 >= KW_FOR && LA142_0 <= KW_FORMATTED)||LA142_0==KW_FULL||(LA142_0 >= KW_FUNCTIONS && LA142_0 <= KW_GROUPING)||(LA142_0 >= KW_HOLD_DDLTIME && LA142_0 <= KW_IDXPROPERTIES)||(LA142_0 >= KW_IGNORE && LA142_0 <= KW_ITEMS)||(LA142_0 >= KW_KEYS && LA142_0 <= KW_LEFT)||(LA142_0 >= KW_LIKE && LA142_0 <= KW_LONG)||(LA142_0 >= KW_MAPJOIN && LA142_0 <= KW_MINUS)||(LA142_0 >= KW_MSCK && LA142_0 <= KW_NOSCAN)||(LA142_0 >= KW_NO_DROP && LA142_0 <= KW_OFFLINE)||LA142_0==KW_OPTION||(LA142_0 >= KW_ORCFILE && LA142_0 <= KW_OUTPUTFORMAT)||LA142_0==KW_OVERWRITE||(LA142_0 >= KW_PARTITION && LA142_0 <= KW_PLUS)||(LA142_0 >= KW_PRETTY && LA142_0 <= KW_RECORDWRITER)||(LA142_0 >= KW_REGEXP && LA142_0 <= KW_SCHEMAS)||(LA142_0 >= KW_SEMI && LA142_0 <= KW_TABLES)||(LA142_0 >= KW_TBLPROPERTIES && LA142_0 <= KW_TEXTFILE)||(LA142_0 >= KW_TIMESTAMP && LA142_0 <= KW_TOUCH)||(LA142_0 >= KW_TRIGGER && LA142_0 <= KW_UNARCHIVE)||(LA142_0 >= KW_UNDO && LA142_0 <= KW_UNIONTYPE)||(LA142_0 >= KW_UNLOCK && LA142_0 <= KW_VALUE_TYPE)||LA142_0==KW_VIEW||LA142_0==KW_WHILE||LA142_0==KW_WITH) ) {
                alt142=1;
            }
            switch (alt142) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1404:14: columnNameTypeList
                    {
                    pushFollow(FOLLOW_columnNameTypeList_in_createMacroStatement7939);
                    columnNameTypeList506=columnNameTypeList();

                    state._fsp--;

                    stream_columnNameTypeList.add(columnNameTypeList506.getTree());

                    }
                    break;

            }


            RPAREN507=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createMacroStatement7942);  
            stream_RPAREN.add(RPAREN507);


            pushFollow(FOLLOW_expression_in_createMacroStatement7944);
            expression508=expression();

            state._fsp--;

            stream_expression.add(expression508.getTree());

            // AST REWRITE
            // elements: expression, columnNameTypeList, Identifier
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1405:5: -> ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1405:8: ^( TOK_CREATEMACRO Identifier ( columnNameTypeList )? expression )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_CREATEMACRO, "TOK_CREATEMACRO")
                , root_1);

                adaptor.addChild(root_1, 
                stream_Identifier.nextNode()
                );

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1405:37: ( columnNameTypeList )?
                if ( stream_columnNameTypeList.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());

                }
                stream_columnNameTypeList.reset();

                adaptor.addChild(root_1, stream_expression.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "createMacroStatement"


    public static class dropMacroStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dropMacroStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1408:1: dropMacroStatement : KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier -> ^( TOK_DROPMACRO Identifier ( ifExists )? ) ;
    public final HiveParser.dropMacroStatement_return dropMacroStatement() throws RecognitionException {
        HiveParser.dropMacroStatement_return retval = new HiveParser.dropMacroStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_DROP509=null;
        Token KW_TEMPORARY510=null;
        Token KW_MACRO511=null;
        Token Identifier513=null;
        HiveParser.ifExists_return ifExists512 =null;


        CommonTree KW_DROP509_tree=null;
        CommonTree KW_TEMPORARY510_tree=null;
        CommonTree KW_MACRO511_tree=null;
        CommonTree Identifier513_tree=null;
        RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
        RewriteRuleTokenStream stream_KW_TEMPORARY=new RewriteRuleTokenStream(adaptor,"token KW_TEMPORARY");
        RewriteRuleTokenStream stream_Identifier=new RewriteRuleTokenStream(adaptor,"token Identifier");
        RewriteRuleTokenStream stream_KW_MACRO=new RewriteRuleTokenStream(adaptor,"token KW_MACRO");
        RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
         msgs.push("drop macro statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1411:5: ( KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier -> ^( TOK_DROPMACRO Identifier ( ifExists )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1411:7: KW_DROP KW_TEMPORARY KW_MACRO ( ifExists )? Identifier
            {
            KW_DROP509=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropMacroStatement7988);  
            stream_KW_DROP.add(KW_DROP509);


            KW_TEMPORARY510=(Token)match(input,KW_TEMPORARY,FOLLOW_KW_TEMPORARY_in_dropMacroStatement7990);  
            stream_KW_TEMPORARY.add(KW_TEMPORARY510);


            KW_MACRO511=(Token)match(input,KW_MACRO,FOLLOW_KW_MACRO_in_dropMacroStatement7992);  
            stream_KW_MACRO.add(KW_MACRO511);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1411:37: ( ifExists )?
            int alt143=2;
            int LA143_0 = input.LA(1);

            if ( (LA143_0==KW_IF) ) {
                alt143=1;
            }
            switch (alt143) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1411:37: ifExists
                    {
                    pushFollow(FOLLOW_ifExists_in_dropMacroStatement7994);
                    ifExists512=ifExists();

                    state._fsp--;

                    stream_ifExists.add(ifExists512.getTree());

                    }
                    break;

            }


            Identifier513=(Token)match(input,Identifier,FOLLOW_Identifier_in_dropMacroStatement7997);  
            stream_Identifier.add(Identifier513);


            // AST REWRITE
            // elements: ifExists, Identifier
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1412:5: -> ^( TOK_DROPMACRO Identifier ( ifExists )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1412:8: ^( TOK_DROPMACRO Identifier ( ifExists )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_DROPMACRO, "TOK_DROPMACRO")
                , root_1);

                adaptor.addChild(root_1, 
                stream_Identifier.nextNode()
                );

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1412:35: ( ifExists )?
                if ( stream_ifExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifExists.nextTree());

                }
                stream_ifExists.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dropMacroStatement"


    public static class createViewStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "createViewStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1415:1: createViewStatement : KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatement -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatement ) ;
    public final HiveParser.createViewStatement_return createViewStatement() throws RecognitionException {
        HiveParser.createViewStatement_return retval = new HiveParser.createViewStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_CREATE514=null;
        Token KW_VIEW516=null;
        Token LPAREN518=null;
        Token RPAREN520=null;
        Token KW_AS524=null;
        HiveParser_FromClauseParser.tableName_return name =null;

        HiveParser.orReplace_return orReplace515 =null;

        HiveParser.ifNotExists_return ifNotExists517 =null;

        HiveParser.columnNameCommentList_return columnNameCommentList519 =null;

        HiveParser.tableComment_return tableComment521 =null;

        HiveParser.viewPartition_return viewPartition522 =null;

        HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed523 =null;

        HiveParser.selectStatement_return selectStatement525 =null;


        CommonTree KW_CREATE514_tree=null;
        CommonTree KW_VIEW516_tree=null;
        CommonTree LPAREN518_tree=null;
        CommonTree RPAREN520_tree=null;
        CommonTree KW_AS524_tree=null;
        RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
        RewriteRuleTokenStream stream_KW_CREATE=new RewriteRuleTokenStream(adaptor,"token KW_CREATE");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_VIEW=new RewriteRuleTokenStream(adaptor,"token KW_VIEW");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleSubtreeStream stream_selectStatement=new RewriteRuleSubtreeStream(adaptor,"rule selectStatement");
        RewriteRuleSubtreeStream stream_columnNameCommentList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameCommentList");
        RewriteRuleSubtreeStream stream_tableName=new RewriteRuleSubtreeStream(adaptor,"rule tableName");
        RewriteRuleSubtreeStream stream_orReplace=new RewriteRuleSubtreeStream(adaptor,"rule orReplace");
        RewriteRuleSubtreeStream stream_tableComment=new RewriteRuleSubtreeStream(adaptor,"rule tableComment");
        RewriteRuleSubtreeStream stream_tablePropertiesPrefixed=new RewriteRuleSubtreeStream(adaptor,"rule tablePropertiesPrefixed");
        RewriteRuleSubtreeStream stream_viewPartition=new RewriteRuleSubtreeStream(adaptor,"rule viewPartition");
        RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");

            msgs.push("create view statement");

        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1420:5: ( KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatement -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatement ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1420:7: KW_CREATE ( orReplace )? KW_VIEW ( ifNotExists )? name= tableName ( LPAREN columnNameCommentList RPAREN )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? KW_AS selectStatement
            {
            KW_CREATE514=(Token)match(input,KW_CREATE,FOLLOW_KW_CREATE_in_createViewStatement8039);  
            stream_KW_CREATE.add(KW_CREATE514);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1420:17: ( orReplace )?
            int alt144=2;
            int LA144_0 = input.LA(1);

            if ( (LA144_0==KW_OR) ) {
                alt144=1;
            }
            switch (alt144) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1420:18: orReplace
                    {
                    pushFollow(FOLLOW_orReplace_in_createViewStatement8042);
                    orReplace515=orReplace();

                    state._fsp--;

                    stream_orReplace.add(orReplace515.getTree());

                    }
                    break;

            }


            KW_VIEW516=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_createViewStatement8046);  
            stream_KW_VIEW.add(KW_VIEW516);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1420:38: ( ifNotExists )?
            int alt145=2;
            int LA145_0 = input.LA(1);

            if ( (LA145_0==KW_IF) ) {
                alt145=1;
            }
            switch (alt145) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1420:39: ifNotExists
                    {
                    pushFollow(FOLLOW_ifNotExists_in_createViewStatement8049);
                    ifNotExists517=ifNotExists();

                    state._fsp--;

                    stream_ifNotExists.add(ifNotExists517.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_tableName_in_createViewStatement8055);
            name=tableName();

            state._fsp--;

            stream_tableName.add(name.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1421:9: ( LPAREN columnNameCommentList RPAREN )?
            int alt146=2;
            int LA146_0 = input.LA(1);

            if ( (LA146_0==LPAREN) ) {
                alt146=1;
            }
            switch (alt146) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1421:10: LPAREN columnNameCommentList RPAREN
                    {
                    LPAREN518=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_createViewStatement8066);  
                    stream_LPAREN.add(LPAREN518);


                    pushFollow(FOLLOW_columnNameCommentList_in_createViewStatement8068);
                    columnNameCommentList519=columnNameCommentList();

                    state._fsp--;

                    stream_columnNameCommentList.add(columnNameCommentList519.getTree());

                    RPAREN520=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_createViewStatement8070);  
                    stream_RPAREN.add(RPAREN520);


                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1421:48: ( tableComment )?
            int alt147=2;
            int LA147_0 = input.LA(1);

            if ( (LA147_0==KW_COMMENT) ) {
                alt147=1;
            }
            switch (alt147) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1421:48: tableComment
                    {
                    pushFollow(FOLLOW_tableComment_in_createViewStatement8074);
                    tableComment521=tableComment();

                    state._fsp--;

                    stream_tableComment.add(tableComment521.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1421:62: ( viewPartition )?
            int alt148=2;
            int LA148_0 = input.LA(1);

            if ( (LA148_0==KW_PARTITIONED) ) {
                alt148=1;
            }
            switch (alt148) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1421:62: viewPartition
                    {
                    pushFollow(FOLLOW_viewPartition_in_createViewStatement8077);
                    viewPartition522=viewPartition();

                    state._fsp--;

                    stream_viewPartition.add(viewPartition522.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1422:9: ( tablePropertiesPrefixed )?
            int alt149=2;
            int LA149_0 = input.LA(1);

            if ( (LA149_0==KW_TBLPROPERTIES) ) {
                alt149=1;
            }
            switch (alt149) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1422:9: tablePropertiesPrefixed
                    {
                    pushFollow(FOLLOW_tablePropertiesPrefixed_in_createViewStatement8088);
                    tablePropertiesPrefixed523=tablePropertiesPrefixed();

                    state._fsp--;

                    stream_tablePropertiesPrefixed.add(tablePropertiesPrefixed523.getTree());

                    }
                    break;

            }


            KW_AS524=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_createViewStatement8099);  
            stream_KW_AS.add(KW_AS524);


            pushFollow(FOLLOW_selectStatement_in_createViewStatement8109);
            selectStatement525=selectStatement();

            state._fsp--;

            stream_selectStatement.add(selectStatement525.getTree());

            // AST REWRITE
            // elements: columnNameCommentList, viewPartition, tableComment, ifNotExists, selectStatement, tablePropertiesPrefixed, orReplace, name
            // token labels: 
            // rule labels: retval, name
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_name=new RewriteRuleSubtreeStream(adaptor,"rule name",name!=null?name.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1425:5: -> ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatement )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1425:8: ^( TOK_CREATEVIEW $name ( orReplace )? ( ifNotExists )? ( columnNameCommentList )? ( tableComment )? ( viewPartition )? ( tablePropertiesPrefixed )? selectStatement )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_CREATEVIEW, "TOK_CREATEVIEW")
                , root_1);

                adaptor.addChild(root_1, stream_name.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1425:31: ( orReplace )?
                if ( stream_orReplace.hasNext() ) {
                    adaptor.addChild(root_1, stream_orReplace.nextTree());

                }
                stream_orReplace.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1426:10: ( ifNotExists )?
                if ( stream_ifNotExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifNotExists.nextTree());

                }
                stream_ifNotExists.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1427:10: ( columnNameCommentList )?
                if ( stream_columnNameCommentList.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnNameCommentList.nextTree());

                }
                stream_columnNameCommentList.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1428:10: ( tableComment )?
                if ( stream_tableComment.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableComment.nextTree());

                }
                stream_tableComment.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1429:10: ( viewPartition )?
                if ( stream_viewPartition.hasNext() ) {
                    adaptor.addChild(root_1, stream_viewPartition.nextTree());

                }
                stream_viewPartition.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1430:10: ( tablePropertiesPrefixed )?
                if ( stream_tablePropertiesPrefixed.hasNext() ) {
                    adaptor.addChild(root_1, stream_tablePropertiesPrefixed.nextTree());

                }
                stream_tablePropertiesPrefixed.reset();

                adaptor.addChild(root_1, stream_selectStatement.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "createViewStatement"


    public static class viewPartition_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "viewPartition"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1435:1: viewPartition : KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWPARTCOLS columnNameList ) ;
    public final HiveParser.viewPartition_return viewPartition() throws RecognitionException {
        HiveParser.viewPartition_return retval = new HiveParser.viewPartition_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_PARTITIONED526=null;
        Token KW_ON527=null;
        Token LPAREN528=null;
        Token RPAREN530=null;
        HiveParser.columnNameList_return columnNameList529 =null;


        CommonTree KW_PARTITIONED526_tree=null;
        CommonTree KW_ON527_tree=null;
        CommonTree LPAREN528_tree=null;
        CommonTree RPAREN530_tree=null;
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_PARTITIONED=new RewriteRuleTokenStream(adaptor,"token KW_PARTITIONED");
        RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
         msgs.push("view partition specification"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1438:5: ( KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN -> ^( TOK_VIEWPARTCOLS columnNameList ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1438:7: KW_PARTITIONED KW_ON LPAREN columnNameList RPAREN
            {
            KW_PARTITIONED526=(Token)match(input,KW_PARTITIONED,FOLLOW_KW_PARTITIONED_in_viewPartition8232);  
            stream_KW_PARTITIONED.add(KW_PARTITIONED526);


            KW_ON527=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_viewPartition8234);  
            stream_KW_ON.add(KW_ON527);


            LPAREN528=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_viewPartition8236);  
            stream_LPAREN.add(LPAREN528);


            pushFollow(FOLLOW_columnNameList_in_viewPartition8238);
            columnNameList529=columnNameList();

            state._fsp--;

            stream_columnNameList.add(columnNameList529.getTree());

            RPAREN530=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_viewPartition8240);  
            stream_RPAREN.add(RPAREN530);


            // AST REWRITE
            // elements: columnNameList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1439:5: -> ^( TOK_VIEWPARTCOLS columnNameList )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1439:8: ^( TOK_VIEWPARTCOLS columnNameList )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_VIEWPARTCOLS, "TOK_VIEWPARTCOLS")
                , root_1);

                adaptor.addChild(root_1, stream_columnNameList.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "viewPartition"


    public static class dropViewStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "dropViewStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1442:1: dropViewStatement : KW_DROP KW_VIEW ( ifExists )? viewName -> ^( TOK_DROPVIEW viewName ( ifExists )? ) ;
    public final HiveParser.dropViewStatement_return dropViewStatement() throws RecognitionException {
        HiveParser.dropViewStatement_return retval = new HiveParser.dropViewStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_DROP531=null;
        Token KW_VIEW532=null;
        HiveParser.ifExists_return ifExists533 =null;

        HiveParser_FromClauseParser.viewName_return viewName534 =null;


        CommonTree KW_DROP531_tree=null;
        CommonTree KW_VIEW532_tree=null;
        RewriteRuleTokenStream stream_KW_DROP=new RewriteRuleTokenStream(adaptor,"token KW_DROP");
        RewriteRuleTokenStream stream_KW_VIEW=new RewriteRuleTokenStream(adaptor,"token KW_VIEW");
        RewriteRuleSubtreeStream stream_viewName=new RewriteRuleSubtreeStream(adaptor,"rule viewName");
        RewriteRuleSubtreeStream stream_ifExists=new RewriteRuleSubtreeStream(adaptor,"rule ifExists");
         msgs.push("drop view statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1445:5: ( KW_DROP KW_VIEW ( ifExists )? viewName -> ^( TOK_DROPVIEW viewName ( ifExists )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1445:7: KW_DROP KW_VIEW ( ifExists )? viewName
            {
            KW_DROP531=(Token)match(input,KW_DROP,FOLLOW_KW_DROP_in_dropViewStatement8279);  
            stream_KW_DROP.add(KW_DROP531);


            KW_VIEW532=(Token)match(input,KW_VIEW,FOLLOW_KW_VIEW_in_dropViewStatement8281);  
            stream_KW_VIEW.add(KW_VIEW532);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1445:23: ( ifExists )?
            int alt150=2;
            int LA150_0 = input.LA(1);

            if ( (LA150_0==KW_IF) ) {
                alt150=1;
            }
            switch (alt150) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1445:23: ifExists
                    {
                    pushFollow(FOLLOW_ifExists_in_dropViewStatement8283);
                    ifExists533=ifExists();

                    state._fsp--;

                    stream_ifExists.add(ifExists533.getTree());

                    }
                    break;

            }


            pushFollow(FOLLOW_viewName_in_dropViewStatement8286);
            viewName534=viewName();

            state._fsp--;

            stream_viewName.add(viewName534.getTree());

            // AST REWRITE
            // elements: ifExists, viewName
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1445:42: -> ^( TOK_DROPVIEW viewName ( ifExists )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1445:45: ^( TOK_DROPVIEW viewName ( ifExists )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_DROPVIEW, "TOK_DROPVIEW")
                , root_1);

                adaptor.addChild(root_1, stream_viewName.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1445:69: ( ifExists )?
                if ( stream_ifExists.hasNext() ) {
                    adaptor.addChild(root_1, stream_ifExists.nextTree());

                }
                stream_ifExists.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "dropViewStatement"


    public static class showStmtIdentifier_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "showStmtIdentifier"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1448:1: showStmtIdentifier : ( identifier | StringLiteral );
    public final HiveParser.showStmtIdentifier_return showStmtIdentifier() throws RecognitionException {
        HiveParser.showStmtIdentifier_return retval = new HiveParser.showStmtIdentifier_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token StringLiteral536=null;
        HiveParser_IdentifiersParser.identifier_return identifier535 =null;


        CommonTree StringLiteral536_tree=null;

         msgs.push("identifier for show statement"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1451:5: ( identifier | StringLiteral )
            int alt151=2;
            int LA151_0 = input.LA(1);

            if ( ((LA151_0 >= Identifier && LA151_0 <= KW_AFTER)||(LA151_0 >= KW_ALTER && LA151_0 <= KW_ANALYZE)||(LA151_0 >= KW_ARCHIVE && LA151_0 <= KW_CASCADE)||(LA151_0 >= KW_CHANGE && LA151_0 <= KW_COLLECTION)||(LA151_0 >= KW_COLUMNS && LA151_0 <= KW_CREATE)||LA151_0==KW_CUBE||(LA151_0 >= KW_CURSOR && LA151_0 <= KW_DATA)||(LA151_0 >= KW_DATABASES && LA151_0 <= KW_DISABLE)||(LA151_0 >= KW_DISTRIBUTE && LA151_0 <= KW_ELEM_TYPE)||LA151_0==KW_ENABLE||LA151_0==KW_ESCAPED||(LA151_0 >= KW_EXCLUSIVE && LA151_0 <= KW_EXPORT)||(LA151_0 >= KW_EXTERNAL && LA151_0 <= KW_FLOAT)||(LA151_0 >= KW_FOR && LA151_0 <= KW_FORMATTED)||LA151_0==KW_FULL||(LA151_0 >= KW_FUNCTIONS && LA151_0 <= KW_GROUPING)||(LA151_0 >= KW_HOLD_DDLTIME && LA151_0 <= KW_IDXPROPERTIES)||(LA151_0 >= KW_IGNORE && LA151_0 <= KW_ITEMS)||(LA151_0 >= KW_KEYS && LA151_0 <= KW_LEFT)||(LA151_0 >= KW_LIKE && LA151_0 <= KW_LONG)||(LA151_0 >= KW_MAPJOIN && LA151_0 <= KW_MINUS)||(LA151_0 >= KW_MSCK && LA151_0 <= KW_NOSCAN)||(LA151_0 >= KW_NO_DROP && LA151_0 <= KW_OFFLINE)||LA151_0==KW_OPTION||(LA151_0 >= KW_ORCFILE && LA151_0 <= KW_OUTPUTFORMAT)||LA151_0==KW_OVERWRITE||(LA151_0 >= KW_PARTITION && LA151_0 <= KW_PLUS)||(LA151_0 >= KW_PRETTY && LA151_0 <= KW_RECORDWRITER)||(LA151_0 >= KW_REGEXP && LA151_0 <= KW_SCHEMAS)||(LA151_0 >= KW_SEMI && LA151_0 <= KW_TABLES)||(LA151_0 >= KW_TBLPROPERTIES && LA151_0 <= KW_TEXTFILE)||(LA151_0 >= KW_TIMESTAMP && LA151_0 <= KW_TOUCH)||(LA151_0 >= KW_TRIGGER && LA151_0 <= KW_UNARCHIVE)||(LA151_0 >= KW_UNDO && LA151_0 <= KW_UNIONTYPE)||(LA151_0 >= KW_UNLOCK && LA151_0 <= KW_VALUE_TYPE)||LA151_0==KW_VIEW||LA151_0==KW_WHILE||LA151_0==KW_WITH) ) {
                alt151=1;
            }
            else if ( (LA151_0==StringLiteral) ) {
                alt151=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 151, 0, input);

                throw nvae;

            }
            switch (alt151) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1451:7: identifier
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_identifier_in_showStmtIdentifier8324);
                    identifier535=identifier();

                    state._fsp--;

                    adaptor.addChild(root_0, identifier535.getTree());

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1452:7: StringLiteral
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    StringLiteral536=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_showStmtIdentifier8332); 
                    StringLiteral536_tree = 
                    (CommonTree)adaptor.create(StringLiteral536)
                    ;
                    adaptor.addChild(root_0, StringLiteral536_tree);


                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "showStmtIdentifier"


    public static class tableComment_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableComment"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1455:1: tableComment : KW_COMMENT comment= StringLiteral -> ^( TOK_TABLECOMMENT $comment) ;
    public final HiveParser.tableComment_return tableComment() throws RecognitionException {
        HiveParser.tableComment_return retval = new HiveParser.tableComment_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token comment=null;
        Token KW_COMMENT537=null;

        CommonTree comment_tree=null;
        CommonTree KW_COMMENT537_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");

         msgs.push("table's comment"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1458:5: ( KW_COMMENT comment= StringLiteral -> ^( TOK_TABLECOMMENT $comment) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1459:7: KW_COMMENT comment= StringLiteral
            {
            KW_COMMENT537=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_tableComment8365);  
            stream_KW_COMMENT.add(KW_COMMENT537);


            comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableComment8369);  
            stream_StringLiteral.add(comment);


            // AST REWRITE
            // elements: comment
            // token labels: comment
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1459:41: -> ^( TOK_TABLECOMMENT $comment)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1459:44: ^( TOK_TABLECOMMENT $comment)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABLECOMMENT, "TOK_TABLECOMMENT")
                , root_1);

                adaptor.addChild(root_1, stream_comment.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableComment"


    public static class tablePartition_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tablePartition"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1462:1: tablePartition : KW_PARTITIONED KW_BY LPAREN columnNameTypeList RPAREN -> ^( TOK_TABLEPARTCOLS columnNameTypeList ) ;
    public final HiveParser.tablePartition_return tablePartition() throws RecognitionException {
        HiveParser.tablePartition_return retval = new HiveParser.tablePartition_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_PARTITIONED538=null;
        Token KW_BY539=null;
        Token LPAREN540=null;
        Token RPAREN542=null;
        HiveParser.columnNameTypeList_return columnNameTypeList541 =null;


        CommonTree KW_PARTITIONED538_tree=null;
        CommonTree KW_BY539_tree=null;
        CommonTree LPAREN540_tree=null;
        CommonTree RPAREN542_tree=null;
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_PARTITIONED=new RewriteRuleTokenStream(adaptor,"token KW_PARTITIONED");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
        RewriteRuleSubtreeStream stream_columnNameTypeList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameTypeList");
         msgs.push("table partition specification"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1465:5: ( KW_PARTITIONED KW_BY LPAREN columnNameTypeList RPAREN -> ^( TOK_TABLEPARTCOLS columnNameTypeList ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1465:7: KW_PARTITIONED KW_BY LPAREN columnNameTypeList RPAREN
            {
            KW_PARTITIONED538=(Token)match(input,KW_PARTITIONED,FOLLOW_KW_PARTITIONED_in_tablePartition8406);  
            stream_KW_PARTITIONED.add(KW_PARTITIONED538);


            KW_BY539=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tablePartition8408);  
            stream_KW_BY.add(KW_BY539);


            LPAREN540=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tablePartition8410);  
            stream_LPAREN.add(LPAREN540);


            pushFollow(FOLLOW_columnNameTypeList_in_tablePartition8412);
            columnNameTypeList541=columnNameTypeList();

            state._fsp--;

            stream_columnNameTypeList.add(columnNameTypeList541.getTree());

            RPAREN542=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tablePartition8414);  
            stream_RPAREN.add(RPAREN542);


            // AST REWRITE
            // elements: columnNameTypeList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1466:5: -> ^( TOK_TABLEPARTCOLS columnNameTypeList )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1466:8: ^( TOK_TABLEPARTCOLS columnNameTypeList )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABLEPARTCOLS, "TOK_TABLEPARTCOLS")
                , root_1);

                adaptor.addChild(root_1, stream_columnNameTypeList.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tablePartition"


    public static class tableBuckets_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableBuckets"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1469:1: tableBuckets : KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS -> ^( TOK_TABLEBUCKETS $bucketCols ( $sortCols)? $num) ;
    public final HiveParser.tableBuckets_return tableBuckets() throws RecognitionException {
        HiveParser.tableBuckets_return retval = new HiveParser.tableBuckets_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token num=null;
        Token KW_CLUSTERED543=null;
        Token KW_BY544=null;
        Token LPAREN545=null;
        Token RPAREN546=null;
        Token KW_SORTED547=null;
        Token KW_BY548=null;
        Token LPAREN549=null;
        Token RPAREN550=null;
        Token KW_INTO551=null;
        Token KW_BUCKETS552=null;
        HiveParser.columnNameList_return bucketCols =null;

        HiveParser.columnNameOrderList_return sortCols =null;


        CommonTree num_tree=null;
        CommonTree KW_CLUSTERED543_tree=null;
        CommonTree KW_BY544_tree=null;
        CommonTree LPAREN545_tree=null;
        CommonTree RPAREN546_tree=null;
        CommonTree KW_SORTED547_tree=null;
        CommonTree KW_BY548_tree=null;
        CommonTree LPAREN549_tree=null;
        CommonTree RPAREN550_tree=null;
        CommonTree KW_INTO551_tree=null;
        CommonTree KW_BUCKETS552_tree=null;
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
        RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
        RewriteRuleTokenStream stream_KW_BUCKETS=new RewriteRuleTokenStream(adaptor,"token KW_BUCKETS");
        RewriteRuleTokenStream stream_KW_CLUSTERED=new RewriteRuleTokenStream(adaptor,"token KW_CLUSTERED");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
        RewriteRuleTokenStream stream_KW_SORTED=new RewriteRuleTokenStream(adaptor,"token KW_SORTED");
        RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
        RewriteRuleSubtreeStream stream_columnNameOrderList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameOrderList");
         msgs.push("table buckets specification"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1472:5: ( KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS -> ^( TOK_TABLEBUCKETS $bucketCols ( $sortCols)? $num) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1473:7: KW_CLUSTERED KW_BY LPAREN bucketCols= columnNameList RPAREN ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )? KW_INTO num= Number KW_BUCKETS
            {
            KW_CLUSTERED543=(Token)match(input,KW_CLUSTERED,FOLLOW_KW_CLUSTERED_in_tableBuckets8459);  
            stream_KW_CLUSTERED.add(KW_CLUSTERED543);


            KW_BY544=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableBuckets8461);  
            stream_KW_BY.add(KW_BY544);


            LPAREN545=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableBuckets8463);  
            stream_LPAREN.add(LPAREN545);


            pushFollow(FOLLOW_columnNameList_in_tableBuckets8467);
            bucketCols=columnNameList();

            state._fsp--;

            stream_columnNameList.add(bucketCols.getTree());

            RPAREN546=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableBuckets8469);  
            stream_RPAREN.add(RPAREN546);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1473:66: ( KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN )?
            int alt152=2;
            int LA152_0 = input.LA(1);

            if ( (LA152_0==KW_SORTED) ) {
                alt152=1;
            }
            switch (alt152) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1473:67: KW_SORTED KW_BY LPAREN sortCols= columnNameOrderList RPAREN
                    {
                    KW_SORTED547=(Token)match(input,KW_SORTED,FOLLOW_KW_SORTED_in_tableBuckets8472);  
                    stream_KW_SORTED.add(KW_SORTED547);


                    KW_BY548=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableBuckets8474);  
                    stream_KW_BY.add(KW_BY548);


                    LPAREN549=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableBuckets8476);  
                    stream_LPAREN.add(LPAREN549);


                    pushFollow(FOLLOW_columnNameOrderList_in_tableBuckets8480);
                    sortCols=columnNameOrderList();

                    state._fsp--;

                    stream_columnNameOrderList.add(sortCols.getTree());

                    RPAREN550=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableBuckets8482);  
                    stream_RPAREN.add(RPAREN550);


                    }
                    break;

            }


            KW_INTO551=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_tableBuckets8486);  
            stream_KW_INTO.add(KW_INTO551);


            num=(Token)match(input,Number,FOLLOW_Number_in_tableBuckets8490);  
            stream_Number.add(num);


            KW_BUCKETS552=(Token)match(input,KW_BUCKETS,FOLLOW_KW_BUCKETS_in_tableBuckets8492);  
            stream_KW_BUCKETS.add(KW_BUCKETS552);


            // AST REWRITE
            // elements: sortCols, num, bucketCols
            // token labels: num
            // rule labels: sortCols, retval, bucketCols
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_num=new RewriteRuleTokenStream(adaptor,"token num",num);
            RewriteRuleSubtreeStream stream_sortCols=new RewriteRuleSubtreeStream(adaptor,"rule sortCols",sortCols!=null?sortCols.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_bucketCols=new RewriteRuleSubtreeStream(adaptor,"rule bucketCols",bucketCols!=null?bucketCols.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1474:5: -> ^( TOK_TABLEBUCKETS $bucketCols ( $sortCols)? $num)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1474:8: ^( TOK_TABLEBUCKETS $bucketCols ( $sortCols)? $num)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABLEBUCKETS, "TOK_TABLEBUCKETS")
                , root_1);

                adaptor.addChild(root_1, stream_bucketCols.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1474:40: ( $sortCols)?
                if ( stream_sortCols.hasNext() ) {
                    adaptor.addChild(root_1, stream_sortCols.nextTree());

                }
                stream_sortCols.reset();

                adaptor.addChild(root_1, stream_num.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableBuckets"


    public static class tableSkewed_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableSkewed"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1477:1: tableSkewed : KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( storedAsDirs )? -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? ) ;
    public final HiveParser.tableSkewed_return tableSkewed() throws RecognitionException {
        HiveParser.tableSkewed_return retval = new HiveParser.tableSkewed_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_SKEWED553=null;
        Token KW_BY554=null;
        Token LPAREN555=null;
        Token RPAREN556=null;
        Token KW_ON557=null;
        Token LPAREN558=null;
        Token RPAREN559=null;
        HiveParser.columnNameList_return skewedCols =null;

        HiveParser.skewedValueElement_return skewedValues =null;

        HiveParser.storedAsDirs_return storedAsDirs560 =null;


        CommonTree KW_SKEWED553_tree=null;
        CommonTree KW_BY554_tree=null;
        CommonTree LPAREN555_tree=null;
        CommonTree RPAREN556_tree=null;
        CommonTree KW_ON557_tree=null;
        CommonTree LPAREN558_tree=null;
        CommonTree RPAREN559_tree=null;
        RewriteRuleTokenStream stream_KW_SKEWED=new RewriteRuleTokenStream(adaptor,"token KW_SKEWED");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_KW_ON=new RewriteRuleTokenStream(adaptor,"token KW_ON");
        RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
        RewriteRuleSubtreeStream stream_columnNameList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameList");
        RewriteRuleSubtreeStream stream_storedAsDirs=new RewriteRuleSubtreeStream(adaptor,"rule storedAsDirs");
        RewriteRuleSubtreeStream stream_skewedValueElement=new RewriteRuleSubtreeStream(adaptor,"rule skewedValueElement");
         msgs.push("table skewed specification"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1480:5: ( KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( storedAsDirs )? -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1481:6: KW_SKEWED KW_BY LPAREN skewedCols= columnNameList RPAREN KW_ON LPAREN (skewedValues= skewedValueElement ) RPAREN ( storedAsDirs )?
            {
            KW_SKEWED553=(Token)match(input,KW_SKEWED,FOLLOW_KW_SKEWED_in_tableSkewed8544);  
            stream_KW_SKEWED.add(KW_SKEWED553);


            KW_BY554=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableSkewed8546);  
            stream_KW_BY.add(KW_BY554);


            LPAREN555=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableSkewed8548);  
            stream_LPAREN.add(LPAREN555);


            pushFollow(FOLLOW_columnNameList_in_tableSkewed8552);
            skewedCols=columnNameList();

            state._fsp--;

            stream_columnNameList.add(skewedCols.getTree());

            RPAREN556=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableSkewed8554);  
            stream_RPAREN.add(RPAREN556);


            KW_ON557=(Token)match(input,KW_ON,FOLLOW_KW_ON_in_tableSkewed8556);  
            stream_KW_ON.add(KW_ON557);


            LPAREN558=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableSkewed8558);  
            stream_LPAREN.add(LPAREN558);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1481:75: (skewedValues= skewedValueElement )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1481:76: skewedValues= skewedValueElement
            {
            pushFollow(FOLLOW_skewedValueElement_in_tableSkewed8563);
            skewedValues=skewedValueElement();

            state._fsp--;

            stream_skewedValueElement.add(skewedValues.getTree());

            }


            RPAREN559=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableSkewed8566);  
            stream_RPAREN.add(RPAREN559);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1481:116: ( storedAsDirs )?
            int alt153=2;
            int LA153_0 = input.LA(1);

            if ( (LA153_0==KW_STORED) ) {
                int LA153_1 = input.LA(2);

                if ( (LA153_1==KW_AS) ) {
                    int LA153_7 = input.LA(3);

                    if ( (LA153_7==KW_DIRECTORIES) ) {
                        alt153=1;
                    }
                }
            }
            switch (alt153) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1481:117: storedAsDirs
                    {
                    pushFollow(FOLLOW_storedAsDirs_in_tableSkewed8569);
                    storedAsDirs560=storedAsDirs();

                    state._fsp--;

                    stream_storedAsDirs.add(storedAsDirs560.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: storedAsDirs, skewedCols, skewedValues
            // token labels: 
            // rule labels: retval, skewedValues, skewedCols
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_skewedValues=new RewriteRuleSubtreeStream(adaptor,"rule skewedValues",skewedValues!=null?skewedValues.tree:null);
            RewriteRuleSubtreeStream stream_skewedCols=new RewriteRuleSubtreeStream(adaptor,"rule skewedCols",skewedCols!=null?skewedCols.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1482:5: -> ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1482:8: ^( TOK_TABLESKEWED $skewedCols $skewedValues ( storedAsDirs )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABLESKEWED, "TOK_TABLESKEWED")
                , root_1);

                adaptor.addChild(root_1, stream_skewedCols.nextTree());

                adaptor.addChild(root_1, stream_skewedValues.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1482:52: ( storedAsDirs )?
                if ( stream_storedAsDirs.hasNext() ) {
                    adaptor.addChild(root_1, stream_storedAsDirs.nextTree());

                }
                stream_storedAsDirs.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableSkewed"


    public static class rowFormat_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "rowFormat"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1485:1: rowFormat : ( rowFormatSerde -> ^( TOK_SERDE rowFormatSerde ) | rowFormatDelimited -> ^( TOK_SERDE rowFormatDelimited ) | -> ^( TOK_SERDE ) );
    public final HiveParser.rowFormat_return rowFormat() throws RecognitionException {
        HiveParser.rowFormat_return retval = new HiveParser.rowFormat_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser.rowFormatSerde_return rowFormatSerde561 =null;

        HiveParser.rowFormatDelimited_return rowFormatDelimited562 =null;


        RewriteRuleSubtreeStream stream_rowFormatSerde=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatSerde");
        RewriteRuleSubtreeStream stream_rowFormatDelimited=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatDelimited");
         msgs.push("serde specification"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1488:5: ( rowFormatSerde -> ^( TOK_SERDE rowFormatSerde ) | rowFormatDelimited -> ^( TOK_SERDE rowFormatDelimited ) | -> ^( TOK_SERDE ) )
            int alt154=3;
            int LA154_0 = input.LA(1);

            if ( (LA154_0==KW_ROW) ) {
                int LA154_1 = input.LA(2);

                if ( (LA154_1==KW_FORMAT) ) {
                    int LA154_23 = input.LA(3);

                    if ( (LA154_23==KW_SERDE) ) {
                        alt154=1;
                    }
                    else if ( (LA154_23==KW_DELIMITED) ) {
                        alt154=2;
                    }
                    else {
                        NoViableAltException nvae =
                            new NoViableAltException("", 154, 23, input);

                        throw nvae;

                    }
                }
                else {
                    NoViableAltException nvae =
                        new NoViableAltException("", 154, 1, input);

                    throw nvae;

                }
            }
            else if ( (LA154_0==EOF||LA154_0==KW_CLUSTER||LA154_0==KW_DISTRIBUTE||LA154_0==KW_FROM||LA154_0==KW_GROUP||LA154_0==KW_HAVING||LA154_0==KW_INSERT||LA154_0==KW_LATERAL||LA154_0==KW_LIMIT||LA154_0==KW_MAP||LA154_0==KW_ORDER||(LA154_0 >= KW_RECORDREADER && LA154_0 <= KW_REDUCE)||LA154_0==KW_SELECT||LA154_0==KW_SORT||LA154_0==KW_UNION||LA154_0==KW_USING||LA154_0==KW_WHERE||LA154_0==KW_WINDOW||LA154_0==RPAREN) ) {
                alt154=3;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 154, 0, input);

                throw nvae;

            }
            switch (alt154) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1488:7: rowFormatSerde
                    {
                    pushFollow(FOLLOW_rowFormatSerde_in_rowFormat8617);
                    rowFormatSerde561=rowFormatSerde();

                    state._fsp--;

                    stream_rowFormatSerde.add(rowFormatSerde561.getTree());

                    // AST REWRITE
                    // elements: rowFormatSerde
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1488:22: -> ^( TOK_SERDE rowFormatSerde )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1488:25: ^( TOK_SERDE rowFormatSerde )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_SERDE, "TOK_SERDE")
                        , root_1);

                        adaptor.addChild(root_1, stream_rowFormatSerde.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1489:7: rowFormatDelimited
                    {
                    pushFollow(FOLLOW_rowFormatDelimited_in_rowFormat8633);
                    rowFormatDelimited562=rowFormatDelimited();

                    state._fsp--;

                    stream_rowFormatDelimited.add(rowFormatDelimited562.getTree());

                    // AST REWRITE
                    // elements: rowFormatDelimited
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1489:26: -> ^( TOK_SERDE rowFormatDelimited )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1489:29: ^( TOK_SERDE rowFormatDelimited )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_SERDE, "TOK_SERDE")
                        , root_1);

                        adaptor.addChild(root_1, stream_rowFormatDelimited.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1490:9: 
                    {
                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1490:9: -> ^( TOK_SERDE )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1490:12: ^( TOK_SERDE )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_SERDE, "TOK_SERDE")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "rowFormat"


    public static class recordReader_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "recordReader"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1493:1: recordReader : ( KW_RECORDREADER StringLiteral -> ^( TOK_RECORDREADER StringLiteral ) | -> ^( TOK_RECORDREADER ) );
    public final HiveParser.recordReader_return recordReader() throws RecognitionException {
        HiveParser.recordReader_return retval = new HiveParser.recordReader_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_RECORDREADER563=null;
        Token StringLiteral564=null;

        CommonTree KW_RECORDREADER563_tree=null;
        CommonTree StringLiteral564_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_RECORDREADER=new RewriteRuleTokenStream(adaptor,"token KW_RECORDREADER");

         msgs.push("record reader specification"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1496:5: ( KW_RECORDREADER StringLiteral -> ^( TOK_RECORDREADER StringLiteral ) | -> ^( TOK_RECORDREADER ) )
            int alt155=2;
            int LA155_0 = input.LA(1);

            if ( (LA155_0==KW_RECORDREADER) ) {
                alt155=1;
            }
            else if ( (LA155_0==EOF||LA155_0==KW_CLUSTER||LA155_0==KW_DISTRIBUTE||LA155_0==KW_FROM||LA155_0==KW_GROUP||LA155_0==KW_HAVING||LA155_0==KW_INSERT||LA155_0==KW_LATERAL||LA155_0==KW_LIMIT||LA155_0==KW_MAP||LA155_0==KW_ORDER||LA155_0==KW_REDUCE||LA155_0==KW_SELECT||LA155_0==KW_SORT||LA155_0==KW_UNION||LA155_0==KW_WHERE||LA155_0==KW_WINDOW||LA155_0==RPAREN) ) {
                alt155=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 155, 0, input);

                throw nvae;

            }
            switch (alt155) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1496:7: KW_RECORDREADER StringLiteral
                    {
                    KW_RECORDREADER563=(Token)match(input,KW_RECORDREADER,FOLLOW_KW_RECORDREADER_in_recordReader8682);  
                    stream_KW_RECORDREADER.add(KW_RECORDREADER563);


                    StringLiteral564=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_recordReader8684);  
                    stream_StringLiteral.add(StringLiteral564);


                    // AST REWRITE
                    // elements: StringLiteral
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1496:37: -> ^( TOK_RECORDREADER StringLiteral )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1496:40: ^( TOK_RECORDREADER StringLiteral )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_RECORDREADER, "TOK_RECORDREADER")
                        , root_1);

                        adaptor.addChild(root_1, 
                        stream_StringLiteral.nextNode()
                        );

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1497:9: 
                    {
                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1497:9: -> ^( TOK_RECORDREADER )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1497:12: ^( TOK_RECORDREADER )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_RECORDREADER, "TOK_RECORDREADER")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "recordReader"


    public static class recordWriter_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "recordWriter"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1500:1: recordWriter : ( KW_RECORDWRITER StringLiteral -> ^( TOK_RECORDWRITER StringLiteral ) | -> ^( TOK_RECORDWRITER ) );
    public final HiveParser.recordWriter_return recordWriter() throws RecognitionException {
        HiveParser.recordWriter_return retval = new HiveParser.recordWriter_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_RECORDWRITER565=null;
        Token StringLiteral566=null;

        CommonTree KW_RECORDWRITER565_tree=null;
        CommonTree StringLiteral566_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_RECORDWRITER=new RewriteRuleTokenStream(adaptor,"token KW_RECORDWRITER");

         msgs.push("record writer specification"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1503:5: ( KW_RECORDWRITER StringLiteral -> ^( TOK_RECORDWRITER StringLiteral ) | -> ^( TOK_RECORDWRITER ) )
            int alt156=2;
            int LA156_0 = input.LA(1);

            if ( (LA156_0==KW_RECORDWRITER) ) {
                alt156=1;
            }
            else if ( (LA156_0==KW_USING) ) {
                alt156=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 156, 0, input);

                throw nvae;

            }
            switch (alt156) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1503:7: KW_RECORDWRITER StringLiteral
                    {
                    KW_RECORDWRITER565=(Token)match(input,KW_RECORDWRITER,FOLLOW_KW_RECORDWRITER_in_recordWriter8733);  
                    stream_KW_RECORDWRITER.add(KW_RECORDWRITER565);


                    StringLiteral566=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_recordWriter8735);  
                    stream_StringLiteral.add(StringLiteral566);


                    // AST REWRITE
                    // elements: StringLiteral
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1503:37: -> ^( TOK_RECORDWRITER StringLiteral )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1503:40: ^( TOK_RECORDWRITER StringLiteral )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_RECORDWRITER, "TOK_RECORDWRITER")
                        , root_1);

                        adaptor.addChild(root_1, 
                        stream_StringLiteral.nextNode()
                        );

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1504:9: 
                    {
                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1504:9: -> ^( TOK_RECORDWRITER )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1504:12: ^( TOK_RECORDWRITER )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_RECORDWRITER, "TOK_RECORDWRITER")
                        , root_1);

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "recordWriter"


    public static class rowFormatSerde_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "rowFormatSerde"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1507:1: rowFormatSerde : KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_SERDENAME $name ( $serdeprops)? ) ;
    public final HiveParser.rowFormatSerde_return rowFormatSerde() throws RecognitionException {
        HiveParser.rowFormatSerde_return retval = new HiveParser.rowFormatSerde_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token name=null;
        Token KW_ROW567=null;
        Token KW_FORMAT568=null;
        Token KW_SERDE569=null;
        Token KW_WITH570=null;
        Token KW_SERDEPROPERTIES571=null;
        HiveParser.tableProperties_return serdeprops =null;


        CommonTree name_tree=null;
        CommonTree KW_ROW567_tree=null;
        CommonTree KW_FORMAT568_tree=null;
        CommonTree KW_SERDE569_tree=null;
        CommonTree KW_WITH570_tree=null;
        CommonTree KW_SERDEPROPERTIES571_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_ROW=new RewriteRuleTokenStream(adaptor,"token KW_ROW");
        RewriteRuleTokenStream stream_KW_FORMAT=new RewriteRuleTokenStream(adaptor,"token KW_FORMAT");
        RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
        RewriteRuleTokenStream stream_KW_SERDE=new RewriteRuleTokenStream(adaptor,"token KW_SERDE");
        RewriteRuleTokenStream stream_KW_SERDEPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_SERDEPROPERTIES");
        RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");
         msgs.push("serde format specification"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1510:5: ( KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_SERDENAME $name ( $serdeprops)? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1510:7: KW_ROW KW_FORMAT KW_SERDE name= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
            {
            KW_ROW567=(Token)match(input,KW_ROW,FOLLOW_KW_ROW_in_rowFormatSerde8784);  
            stream_KW_ROW.add(KW_ROW567);


            KW_FORMAT568=(Token)match(input,KW_FORMAT,FOLLOW_KW_FORMAT_in_rowFormatSerde8786);  
            stream_KW_FORMAT.add(KW_FORMAT568);


            KW_SERDE569=(Token)match(input,KW_SERDE,FOLLOW_KW_SERDE_in_rowFormatSerde8788);  
            stream_KW_SERDE.add(KW_SERDE569);


            name=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_rowFormatSerde8792);  
            stream_StringLiteral.add(name);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1510:52: ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
            int alt157=2;
            int LA157_0 = input.LA(1);

            if ( (LA157_0==KW_WITH) ) {
                alt157=1;
            }
            switch (alt157) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1510:53: KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties
                    {
                    KW_WITH570=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_rowFormatSerde8795);  
                    stream_KW_WITH.add(KW_WITH570);


                    KW_SERDEPROPERTIES571=(Token)match(input,KW_SERDEPROPERTIES,FOLLOW_KW_SERDEPROPERTIES_in_rowFormatSerde8797);  
                    stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES571);


                    pushFollow(FOLLOW_tableProperties_in_rowFormatSerde8801);
                    serdeprops=tableProperties();

                    state._fsp--;

                    stream_tableProperties.add(serdeprops.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: name, serdeprops
            // token labels: name
            // rule labels: serdeprops, retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_name=new RewriteRuleTokenStream(adaptor,"token name",name);
            RewriteRuleSubtreeStream stream_serdeprops=new RewriteRuleSubtreeStream(adaptor,"rule serdeprops",serdeprops!=null?serdeprops.tree:null);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1511:5: -> ^( TOK_SERDENAME $name ( $serdeprops)? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1511:8: ^( TOK_SERDENAME $name ( $serdeprops)? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_SERDENAME, "TOK_SERDENAME")
                , root_1);

                adaptor.addChild(root_1, stream_name.nextNode());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1511:31: ( $serdeprops)?
                if ( stream_serdeprops.hasNext() ) {
                    adaptor.addChild(root_1, stream_serdeprops.nextTree());

                }
                stream_serdeprops.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "rowFormatSerde"


    public static class rowFormatDelimited_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "rowFormatDelimited"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1514:1: rowFormatDelimited : KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ) ;
    public final HiveParser.rowFormatDelimited_return rowFormatDelimited() throws RecognitionException {
        HiveParser.rowFormatDelimited_return retval = new HiveParser.rowFormatDelimited_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_ROW572=null;
        Token KW_FORMAT573=null;
        Token KW_DELIMITED574=null;
        HiveParser.tableRowFormatFieldIdentifier_return tableRowFormatFieldIdentifier575 =null;

        HiveParser.tableRowFormatCollItemsIdentifier_return tableRowFormatCollItemsIdentifier576 =null;

        HiveParser.tableRowFormatMapKeysIdentifier_return tableRowFormatMapKeysIdentifier577 =null;

        HiveParser.tableRowFormatLinesIdentifier_return tableRowFormatLinesIdentifier578 =null;


        CommonTree KW_ROW572_tree=null;
        CommonTree KW_FORMAT573_tree=null;
        CommonTree KW_DELIMITED574_tree=null;
        RewriteRuleTokenStream stream_KW_DELIMITED=new RewriteRuleTokenStream(adaptor,"token KW_DELIMITED");
        RewriteRuleTokenStream stream_KW_ROW=new RewriteRuleTokenStream(adaptor,"token KW_ROW");
        RewriteRuleTokenStream stream_KW_FORMAT=new RewriteRuleTokenStream(adaptor,"token KW_FORMAT");
        RewriteRuleSubtreeStream stream_tableRowFormatMapKeysIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatMapKeysIdentifier");
        RewriteRuleSubtreeStream stream_tableRowFormatFieldIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatFieldIdentifier");
        RewriteRuleSubtreeStream stream_tableRowFormatCollItemsIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatCollItemsIdentifier");
        RewriteRuleSubtreeStream stream_tableRowFormatLinesIdentifier=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormatLinesIdentifier");
         msgs.push("serde properties specification"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1517:5: ( KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:7: KW_ROW KW_FORMAT KW_DELIMITED ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )?
            {
            KW_ROW572=(Token)match(input,KW_ROW,FOLLOW_KW_ROW_in_rowFormatDelimited8853);  
            stream_KW_ROW.add(KW_ROW572);


            KW_FORMAT573=(Token)match(input,KW_FORMAT,FOLLOW_KW_FORMAT_in_rowFormatDelimited8855);  
            stream_KW_FORMAT.add(KW_FORMAT573);


            KW_DELIMITED574=(Token)match(input,KW_DELIMITED,FOLLOW_KW_DELIMITED_in_rowFormatDelimited8857);  
            stream_KW_DELIMITED.add(KW_DELIMITED574);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:37: ( tableRowFormatFieldIdentifier )?
            int alt158=2;
            int LA158_0 = input.LA(1);

            if ( (LA158_0==KW_FIELDS) ) {
                alt158=1;
            }
            switch (alt158) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:37: tableRowFormatFieldIdentifier
                    {
                    pushFollow(FOLLOW_tableRowFormatFieldIdentifier_in_rowFormatDelimited8859);
                    tableRowFormatFieldIdentifier575=tableRowFormatFieldIdentifier();

                    state._fsp--;

                    stream_tableRowFormatFieldIdentifier.add(tableRowFormatFieldIdentifier575.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:68: ( tableRowFormatCollItemsIdentifier )?
            int alt159=2;
            int LA159_0 = input.LA(1);

            if ( (LA159_0==KW_COLLECTION) ) {
                alt159=1;
            }
            switch (alt159) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:68: tableRowFormatCollItemsIdentifier
                    {
                    pushFollow(FOLLOW_tableRowFormatCollItemsIdentifier_in_rowFormatDelimited8862);
                    tableRowFormatCollItemsIdentifier576=tableRowFormatCollItemsIdentifier();

                    state._fsp--;

                    stream_tableRowFormatCollItemsIdentifier.add(tableRowFormatCollItemsIdentifier576.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:103: ( tableRowFormatMapKeysIdentifier )?
            int alt160=2;
            alt160 = dfa160.predict(input);
            switch (alt160) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:103: tableRowFormatMapKeysIdentifier
                    {
                    pushFollow(FOLLOW_tableRowFormatMapKeysIdentifier_in_rowFormatDelimited8865);
                    tableRowFormatMapKeysIdentifier577=tableRowFormatMapKeysIdentifier();

                    state._fsp--;

                    stream_tableRowFormatMapKeysIdentifier.add(tableRowFormatMapKeysIdentifier577.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:136: ( tableRowFormatLinesIdentifier )?
            int alt161=2;
            int LA161_0 = input.LA(1);

            if ( (LA161_0==KW_LINES) ) {
                alt161=1;
            }
            switch (alt161) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1518:136: tableRowFormatLinesIdentifier
                    {
                    pushFollow(FOLLOW_tableRowFormatLinesIdentifier_in_rowFormatDelimited8868);
                    tableRowFormatLinesIdentifier578=tableRowFormatLinesIdentifier();

                    state._fsp--;

                    stream_tableRowFormatLinesIdentifier.add(tableRowFormatLinesIdentifier578.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: tableRowFormatCollItemsIdentifier, tableRowFormatFieldIdentifier, tableRowFormatMapKeysIdentifier, tableRowFormatLinesIdentifier
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1519:5: -> ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:8: ^( TOK_SERDEPROPS ( tableRowFormatFieldIdentifier )? ( tableRowFormatCollItemsIdentifier )? ( tableRowFormatMapKeysIdentifier )? ( tableRowFormatLinesIdentifier )? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_SERDEPROPS, "TOK_SERDEPROPS")
                , root_1);

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:25: ( tableRowFormatFieldIdentifier )?
                if ( stream_tableRowFormatFieldIdentifier.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableRowFormatFieldIdentifier.nextTree());

                }
                stream_tableRowFormatFieldIdentifier.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:56: ( tableRowFormatCollItemsIdentifier )?
                if ( stream_tableRowFormatCollItemsIdentifier.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableRowFormatCollItemsIdentifier.nextTree());

                }
                stream_tableRowFormatCollItemsIdentifier.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:91: ( tableRowFormatMapKeysIdentifier )?
                if ( stream_tableRowFormatMapKeysIdentifier.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableRowFormatMapKeysIdentifier.nextTree());

                }
                stream_tableRowFormatMapKeysIdentifier.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1519:124: ( tableRowFormatLinesIdentifier )?
                if ( stream_tableRowFormatLinesIdentifier.hasNext() ) {
                    adaptor.addChild(root_1, stream_tableRowFormatLinesIdentifier.nextTree());

                }
                stream_tableRowFormatLinesIdentifier.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "rowFormatDelimited"


    public static class tableRowFormat_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableRowFormat"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1522:1: tableRowFormat : ( rowFormatDelimited -> ^( TOK_TABLEROWFORMAT rowFormatDelimited ) | rowFormatSerde -> ^( TOK_TABLESERIALIZER rowFormatSerde ) );
    public final HiveParser.tableRowFormat_return tableRowFormat() throws RecognitionException {
        HiveParser.tableRowFormat_return retval = new HiveParser.tableRowFormat_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser.rowFormatDelimited_return rowFormatDelimited579 =null;

        HiveParser.rowFormatSerde_return rowFormatSerde580 =null;


        RewriteRuleSubtreeStream stream_rowFormatSerde=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatSerde");
        RewriteRuleSubtreeStream stream_rowFormatDelimited=new RewriteRuleSubtreeStream(adaptor,"rule rowFormatDelimited");
         msgs.push("table row format specification"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1525:5: ( rowFormatDelimited -> ^( TOK_TABLEROWFORMAT rowFormatDelimited ) | rowFormatSerde -> ^( TOK_TABLESERIALIZER rowFormatSerde ) )
            int alt162=2;
            int LA162_0 = input.LA(1);

            if ( (LA162_0==KW_ROW) ) {
                int LA162_1 = input.LA(2);

                if ( (LA162_1==KW_FORMAT) ) {
                    int LA162_2 = input.LA(3);

                    if ( (LA162_2==KW_DELIMITED) ) {
                        alt162=1;
                    }
                    else if ( (LA162_2==KW_SERDE) ) {
                        alt162=2;
                    }
                    else {
                        NoViableAltException nvae =
                            new NoViableAltException("", 162, 2, input);

                        throw nvae;

                    }
                }
                else {
                    NoViableAltException nvae =
                        new NoViableAltException("", 162, 1, input);

                    throw nvae;

                }
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 162, 0, input);

                throw nvae;

            }
            switch (alt162) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1526:7: rowFormatDelimited
                    {
                    pushFollow(FOLLOW_rowFormatDelimited_in_tableRowFormat8924);
                    rowFormatDelimited579=rowFormatDelimited();

                    state._fsp--;

                    stream_rowFormatDelimited.add(rowFormatDelimited579.getTree());

                    // AST REWRITE
                    // elements: rowFormatDelimited
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1527:5: -> ^( TOK_TABLEROWFORMAT rowFormatDelimited )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1527:8: ^( TOK_TABLEROWFORMAT rowFormatDelimited )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_TABLEROWFORMAT, "TOK_TABLEROWFORMAT")
                        , root_1);

                        adaptor.addChild(root_1, stream_rowFormatDelimited.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1528:7: rowFormatSerde
                    {
                    pushFollow(FOLLOW_rowFormatSerde_in_tableRowFormat8944);
                    rowFormatSerde580=rowFormatSerde();

                    state._fsp--;

                    stream_rowFormatSerde.add(rowFormatSerde580.getTree());

                    // AST REWRITE
                    // elements: rowFormatSerde
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1529:5: -> ^( TOK_TABLESERIALIZER rowFormatSerde )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1529:8: ^( TOK_TABLESERIALIZER rowFormatSerde )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_TABLESERIALIZER, "TOK_TABLESERIALIZER")
                        , root_1);

                        adaptor.addChild(root_1, stream_rowFormatSerde.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableRowFormat"


    public static class tablePropertiesPrefixed_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tablePropertiesPrefixed"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1532:1: tablePropertiesPrefixed : KW_TBLPROPERTIES ! tableProperties ;
    public final HiveParser.tablePropertiesPrefixed_return tablePropertiesPrefixed() throws RecognitionException {
        HiveParser.tablePropertiesPrefixed_return retval = new HiveParser.tablePropertiesPrefixed_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_TBLPROPERTIES581=null;
        HiveParser.tableProperties_return tableProperties582 =null;


        CommonTree KW_TBLPROPERTIES581_tree=null;

         msgs.push("table properties with prefix"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1535:5: ( KW_TBLPROPERTIES ! tableProperties )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1536:9: KW_TBLPROPERTIES ! tableProperties
            {
            root_0 = (CommonTree)adaptor.nil();


            KW_TBLPROPERTIES581=(Token)match(input,KW_TBLPROPERTIES,FOLLOW_KW_TBLPROPERTIES_in_tablePropertiesPrefixed8991); 

            pushFollow(FOLLOW_tableProperties_in_tablePropertiesPrefixed8994);
            tableProperties582=tableProperties();

            state._fsp--;

            adaptor.addChild(root_0, tableProperties582.getTree());

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tablePropertiesPrefixed"


    public static class tableProperties_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableProperties"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1539:1: tableProperties : LPAREN tablePropertiesList RPAREN -> ^( TOK_TABLEPROPERTIES tablePropertiesList ) ;
    public final HiveParser.tableProperties_return tableProperties() throws RecognitionException {
        HiveParser.tableProperties_return retval = new HiveParser.tableProperties_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token LPAREN583=null;
        Token RPAREN585=null;
        HiveParser.tablePropertiesList_return tablePropertiesList584 =null;


        CommonTree LPAREN583_tree=null;
        CommonTree RPAREN585_tree=null;
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleSubtreeStream stream_tablePropertiesList=new RewriteRuleSubtreeStream(adaptor,"rule tablePropertiesList");
         msgs.push("table properties"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1542:5: ( LPAREN tablePropertiesList RPAREN -> ^( TOK_TABLEPROPERTIES tablePropertiesList ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1543:7: LPAREN tablePropertiesList RPAREN
            {
            LPAREN583=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_tableProperties9027);  
            stream_LPAREN.add(LPAREN583);


            pushFollow(FOLLOW_tablePropertiesList_in_tableProperties9029);
            tablePropertiesList584=tablePropertiesList();

            state._fsp--;

            stream_tablePropertiesList.add(tablePropertiesList584.getTree());

            RPAREN585=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_tableProperties9031);  
            stream_RPAREN.add(RPAREN585);


            // AST REWRITE
            // elements: tablePropertiesList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1543:41: -> ^( TOK_TABLEPROPERTIES tablePropertiesList )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1543:44: ^( TOK_TABLEPROPERTIES tablePropertiesList )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABLEPROPERTIES, "TOK_TABLEPROPERTIES")
                , root_1);

                adaptor.addChild(root_1, stream_tablePropertiesList.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableProperties"


    public static class tablePropertiesList_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tablePropertiesList"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1546:1: tablePropertiesList : ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ ) | keyProperty ( COMMA keyProperty )* -> ^( TOK_TABLEPROPLIST ( keyProperty )+ ) );
    public final HiveParser.tablePropertiesList_return tablePropertiesList() throws RecognitionException {
        HiveParser.tablePropertiesList_return retval = new HiveParser.tablePropertiesList_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token COMMA587=null;
        Token COMMA590=null;
        HiveParser.keyValueProperty_return keyValueProperty586 =null;

        HiveParser.keyValueProperty_return keyValueProperty588 =null;

        HiveParser.keyProperty_return keyProperty589 =null;

        HiveParser.keyProperty_return keyProperty591 =null;


        CommonTree COMMA587_tree=null;
        CommonTree COMMA590_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_keyValueProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyValueProperty");
        RewriteRuleSubtreeStream stream_keyProperty=new RewriteRuleSubtreeStream(adaptor,"rule keyProperty");
         msgs.push("table properties list"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1549:5: ( keyValueProperty ( COMMA keyValueProperty )* -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ ) | keyProperty ( COMMA keyProperty )* -> ^( TOK_TABLEPROPLIST ( keyProperty )+ ) )
            int alt165=2;
            int LA165_0 = input.LA(1);

            if ( (LA165_0==StringLiteral) ) {
                int LA165_1 = input.LA(2);

                if ( (LA165_1==EQUAL) ) {
                    alt165=1;
                }
                else if ( (LA165_1==COMMA||LA165_1==RPAREN) ) {
                    alt165=2;
                }
                else {
                    NoViableAltException nvae =
                        new NoViableAltException("", 165, 1, input);

                    throw nvae;

                }
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 165, 0, input);

                throw nvae;

            }
            switch (alt165) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1550:7: keyValueProperty ( COMMA keyValueProperty )*
                    {
                    pushFollow(FOLLOW_keyValueProperty_in_tablePropertiesList9072);
                    keyValueProperty586=keyValueProperty();

                    state._fsp--;

                    stream_keyValueProperty.add(keyValueProperty586.getTree());

                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1550:24: ( COMMA keyValueProperty )*
                    loop163:
                    do {
                        int alt163=2;
                        int LA163_0 = input.LA(1);

                        if ( (LA163_0==COMMA) ) {
                            alt163=1;
                        }


                        switch (alt163) {
                    	case 1 :
                    	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1550:25: COMMA keyValueProperty
                    	    {
                    	    COMMA587=(Token)match(input,COMMA,FOLLOW_COMMA_in_tablePropertiesList9075);  
                    	    stream_COMMA.add(COMMA587);


                    	    pushFollow(FOLLOW_keyValueProperty_in_tablePropertiesList9077);
                    	    keyValueProperty588=keyValueProperty();

                    	    state._fsp--;

                    	    stream_keyValueProperty.add(keyValueProperty588.getTree());

                    	    }
                    	    break;

                    	default :
                    	    break loop163;
                        }
                    } while (true);


                    // AST REWRITE
                    // elements: keyValueProperty
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1550:50: -> ^( TOK_TABLEPROPLIST ( keyValueProperty )+ )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1550:53: ^( TOK_TABLEPROPLIST ( keyValueProperty )+ )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_TABLEPROPLIST, "TOK_TABLEPROPLIST")
                        , root_1);

                        if ( !(stream_keyValueProperty.hasNext()) ) {
                            throw new RewriteEarlyExitException();
                        }
                        while ( stream_keyValueProperty.hasNext() ) {
                            adaptor.addChild(root_1, stream_keyValueProperty.nextTree());

                        }
                        stream_keyValueProperty.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1552:7: keyProperty ( COMMA keyProperty )*
                    {
                    pushFollow(FOLLOW_keyProperty_in_tablePropertiesList9102);
                    keyProperty589=keyProperty();

                    state._fsp--;

                    stream_keyProperty.add(keyProperty589.getTree());

                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1552:19: ( COMMA keyProperty )*
                    loop164:
                    do {
                        int alt164=2;
                        int LA164_0 = input.LA(1);

                        if ( (LA164_0==COMMA) ) {
                            alt164=1;
                        }


                        switch (alt164) {
                    	case 1 :
                    	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1552:20: COMMA keyProperty
                    	    {
                    	    COMMA590=(Token)match(input,COMMA,FOLLOW_COMMA_in_tablePropertiesList9105);  
                    	    stream_COMMA.add(COMMA590);


                    	    pushFollow(FOLLOW_keyProperty_in_tablePropertiesList9107);
                    	    keyProperty591=keyProperty();

                    	    state._fsp--;

                    	    stream_keyProperty.add(keyProperty591.getTree());

                    	    }
                    	    break;

                    	default :
                    	    break loop164;
                        }
                    } while (true);


                    // AST REWRITE
                    // elements: keyProperty
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1552:40: -> ^( TOK_TABLEPROPLIST ( keyProperty )+ )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1552:43: ^( TOK_TABLEPROPLIST ( keyProperty )+ )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_TABLEPROPLIST, "TOK_TABLEPROPLIST")
                        , root_1);

                        if ( !(stream_keyProperty.hasNext()) ) {
                            throw new RewriteEarlyExitException();
                        }
                        while ( stream_keyProperty.hasNext() ) {
                            adaptor.addChild(root_1, stream_keyProperty.nextTree());

                        }
                        stream_keyProperty.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tablePropertiesList"


    public static class keyValueProperty_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "keyValueProperty"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1555:1: keyValueProperty : key= StringLiteral EQUAL value= StringLiteral -> ^( TOK_TABLEPROPERTY $key $value) ;
    public final HiveParser.keyValueProperty_return keyValueProperty() throws RecognitionException {
        HiveParser.keyValueProperty_return retval = new HiveParser.keyValueProperty_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token key=null;
        Token value=null;
        Token EQUAL592=null;

        CommonTree key_tree=null;
        CommonTree value_tree=null;
        CommonTree EQUAL592_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_EQUAL=new RewriteRuleTokenStream(adaptor,"token EQUAL");

         msgs.push("specifying key/value property"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1558:5: (key= StringLiteral EQUAL value= StringLiteral -> ^( TOK_TABLEPROPERTY $key $value) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1559:7: key= StringLiteral EQUAL value= StringLiteral
            {
            key=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_keyValueProperty9153);  
            stream_StringLiteral.add(key);


            EQUAL592=(Token)match(input,EQUAL,FOLLOW_EQUAL_in_keyValueProperty9155);  
            stream_EQUAL.add(EQUAL592);


            value=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_keyValueProperty9159);  
            stream_StringLiteral.add(value);


            // AST REWRITE
            // elements: value, key
            // token labels: value, key
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_value=new RewriteRuleTokenStream(adaptor,"token value",value);
            RewriteRuleTokenStream stream_key=new RewriteRuleTokenStream(adaptor,"token key",key);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1559:51: -> ^( TOK_TABLEPROPERTY $key $value)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1559:54: ^( TOK_TABLEPROPERTY $key $value)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABLEPROPERTY, "TOK_TABLEPROPERTY")
                , root_1);

                adaptor.addChild(root_1, stream_key.nextNode());

                adaptor.addChild(root_1, stream_value.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "keyValueProperty"


    public static class keyProperty_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "keyProperty"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1562:1: keyProperty : key= StringLiteral -> ^( TOK_TABLEPROPERTY $key TOK_NULL ) ;
    public final HiveParser.keyProperty_return keyProperty() throws RecognitionException {
        HiveParser.keyProperty_return retval = new HiveParser.keyProperty_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token key=null;

        CommonTree key_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");

         msgs.push("specifying key property"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1565:5: (key= StringLiteral -> ^( TOK_TABLEPROPERTY $key TOK_NULL ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1566:7: key= StringLiteral
            {
            key=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_keyProperty9206);  
            stream_StringLiteral.add(key);


            // AST REWRITE
            // elements: key
            // token labels: key
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_key=new RewriteRuleTokenStream(adaptor,"token key",key);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1566:25: -> ^( TOK_TABLEPROPERTY $key TOK_NULL )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1566:28: ^( TOK_TABLEPROPERTY $key TOK_NULL )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABLEPROPERTY, "TOK_TABLEPROPERTY")
                , root_1);

                adaptor.addChild(root_1, stream_key.nextNode());

                adaptor.addChild(root_1, 
                (CommonTree)adaptor.create(TOK_NULL, "TOK_NULL")
                );

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "keyProperty"


    public static class tableRowFormatFieldIdentifier_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableRowFormatFieldIdentifier"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1569:1: tableRowFormatFieldIdentifier : KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )? -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? ) ;
    public final HiveParser.tableRowFormatFieldIdentifier_return tableRowFormatFieldIdentifier() throws RecognitionException {
        HiveParser.tableRowFormatFieldIdentifier_return retval = new HiveParser.tableRowFormatFieldIdentifier_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token fldIdnt=null;
        Token fldEscape=null;
        Token KW_FIELDS593=null;
        Token KW_TERMINATED594=null;
        Token KW_BY595=null;
        Token KW_ESCAPED596=null;
        Token KW_BY597=null;

        CommonTree fldIdnt_tree=null;
        CommonTree fldEscape_tree=null;
        CommonTree KW_FIELDS593_tree=null;
        CommonTree KW_TERMINATED594_tree=null;
        CommonTree KW_BY595_tree=null;
        CommonTree KW_ESCAPED596_tree=null;
        CommonTree KW_BY597_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_ESCAPED=new RewriteRuleTokenStream(adaptor,"token KW_ESCAPED");
        RewriteRuleTokenStream stream_KW_FIELDS=new RewriteRuleTokenStream(adaptor,"token KW_FIELDS");
        RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
        RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");

         msgs.push("table row format's field separator"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1572:5: ( KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )? -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1573:7: KW_FIELDS KW_TERMINATED KW_BY fldIdnt= StringLiteral ( KW_ESCAPED KW_BY fldEscape= StringLiteral )?
            {
            KW_FIELDS593=(Token)match(input,KW_FIELDS,FOLLOW_KW_FIELDS_in_tableRowFormatFieldIdentifier9250);  
            stream_KW_FIELDS.add(KW_FIELDS593);


            KW_TERMINATED594=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatFieldIdentifier9252);  
            stream_KW_TERMINATED.add(KW_TERMINATED594);


            KW_BY595=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier9254);  
            stream_KW_BY.add(KW_BY595);


            fldIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier9258);  
            stream_StringLiteral.add(fldIdnt);


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1573:59: ( KW_ESCAPED KW_BY fldEscape= StringLiteral )?
            int alt166=2;
            int LA166_0 = input.LA(1);

            if ( (LA166_0==KW_ESCAPED) ) {
                alt166=1;
            }
            switch (alt166) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1573:60: KW_ESCAPED KW_BY fldEscape= StringLiteral
                    {
                    KW_ESCAPED596=(Token)match(input,KW_ESCAPED,FOLLOW_KW_ESCAPED_in_tableRowFormatFieldIdentifier9261);  
                    stream_KW_ESCAPED.add(KW_ESCAPED596);


                    KW_BY597=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier9263);  
                    stream_KW_BY.add(KW_BY597);


                    fldEscape=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier9267);  
                    stream_StringLiteral.add(fldEscape);


                    }
                    break;

            }


            // AST REWRITE
            // elements: fldEscape, fldIdnt
            // token labels: fldEscape, fldIdnt
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_fldEscape=new RewriteRuleTokenStream(adaptor,"token fldEscape",fldEscape);
            RewriteRuleTokenStream stream_fldIdnt=new RewriteRuleTokenStream(adaptor,"token fldIdnt",fldIdnt);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1574:5: -> ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1574:8: ^( TOK_TABLEROWFORMATFIELD $fldIdnt ( $fldEscape)? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABLEROWFORMATFIELD, "TOK_TABLEROWFORMATFIELD")
                , root_1);

                adaptor.addChild(root_1, stream_fldIdnt.nextNode());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1574:44: ( $fldEscape)?
                if ( stream_fldEscape.hasNext() ) {
                    adaptor.addChild(root_1, stream_fldEscape.nextNode());

                }
                stream_fldEscape.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableRowFormatFieldIdentifier"


    public static class tableRowFormatCollItemsIdentifier_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableRowFormatCollItemsIdentifier"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1577:1: tableRowFormatCollItemsIdentifier : KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt) ;
    public final HiveParser.tableRowFormatCollItemsIdentifier_return tableRowFormatCollItemsIdentifier() throws RecognitionException {
        HiveParser.tableRowFormatCollItemsIdentifier_return retval = new HiveParser.tableRowFormatCollItemsIdentifier_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token collIdnt=null;
        Token KW_COLLECTION598=null;
        Token KW_ITEMS599=null;
        Token KW_TERMINATED600=null;
        Token KW_BY601=null;

        CommonTree collIdnt_tree=null;
        CommonTree KW_COLLECTION598_tree=null;
        CommonTree KW_ITEMS599_tree=null;
        CommonTree KW_TERMINATED600_tree=null;
        CommonTree KW_BY601_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_ITEMS=new RewriteRuleTokenStream(adaptor,"token KW_ITEMS");
        RewriteRuleTokenStream stream_KW_COLLECTION=new RewriteRuleTokenStream(adaptor,"token KW_COLLECTION");
        RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
        RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");

         msgs.push("table row format's column separator"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1580:5: ( KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1581:7: KW_COLLECTION KW_ITEMS KW_TERMINATED KW_BY collIdnt= StringLiteral
            {
            KW_COLLECTION598=(Token)match(input,KW_COLLECTION,FOLLOW_KW_COLLECTION_in_tableRowFormatCollItemsIdentifier9319);  
            stream_KW_COLLECTION.add(KW_COLLECTION598);


            KW_ITEMS599=(Token)match(input,KW_ITEMS,FOLLOW_KW_ITEMS_in_tableRowFormatCollItemsIdentifier9321);  
            stream_KW_ITEMS.add(KW_ITEMS599);


            KW_TERMINATED600=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatCollItemsIdentifier9323);  
            stream_KW_TERMINATED.add(KW_TERMINATED600);


            KW_BY601=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatCollItemsIdentifier9325);  
            stream_KW_BY.add(KW_BY601);


            collIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatCollItemsIdentifier9329);  
            stream_StringLiteral.add(collIdnt);


            // AST REWRITE
            // elements: collIdnt
            // token labels: collIdnt
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_collIdnt=new RewriteRuleTokenStream(adaptor,"token collIdnt",collIdnt);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1582:5: -> ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1582:8: ^( TOK_TABLEROWFORMATCOLLITEMS $collIdnt)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABLEROWFORMATCOLLITEMS, "TOK_TABLEROWFORMATCOLLITEMS")
                , root_1);

                adaptor.addChild(root_1, stream_collIdnt.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableRowFormatCollItemsIdentifier"


    public static class tableRowFormatMapKeysIdentifier_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableRowFormatMapKeysIdentifier"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1585:1: tableRowFormatMapKeysIdentifier : KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt) ;
    public final HiveParser.tableRowFormatMapKeysIdentifier_return tableRowFormatMapKeysIdentifier() throws RecognitionException {
        HiveParser.tableRowFormatMapKeysIdentifier_return retval = new HiveParser.tableRowFormatMapKeysIdentifier_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token mapKeysIdnt=null;
        Token KW_MAP602=null;
        Token KW_KEYS603=null;
        Token KW_TERMINATED604=null;
        Token KW_BY605=null;

        CommonTree mapKeysIdnt_tree=null;
        CommonTree KW_MAP602_tree=null;
        CommonTree KW_KEYS603_tree=null;
        CommonTree KW_TERMINATED604_tree=null;
        CommonTree KW_BY605_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_KEYS=new RewriteRuleTokenStream(adaptor,"token KW_KEYS");
        RewriteRuleTokenStream stream_KW_MAP=new RewriteRuleTokenStream(adaptor,"token KW_MAP");
        RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
        RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");

         msgs.push("table row format's map key separator"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1588:5: ( KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1589:7: KW_MAP KW_KEYS KW_TERMINATED KW_BY mapKeysIdnt= StringLiteral
            {
            KW_MAP602=(Token)match(input,KW_MAP,FOLLOW_KW_MAP_in_tableRowFormatMapKeysIdentifier9375);  
            stream_KW_MAP.add(KW_MAP602);


            KW_KEYS603=(Token)match(input,KW_KEYS,FOLLOW_KW_KEYS_in_tableRowFormatMapKeysIdentifier9377);  
            stream_KW_KEYS.add(KW_KEYS603);


            KW_TERMINATED604=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatMapKeysIdentifier9379);  
            stream_KW_TERMINATED.add(KW_TERMINATED604);


            KW_BY605=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatMapKeysIdentifier9381);  
            stream_KW_BY.add(KW_BY605);


            mapKeysIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatMapKeysIdentifier9385);  
            stream_StringLiteral.add(mapKeysIdnt);


            // AST REWRITE
            // elements: mapKeysIdnt
            // token labels: mapKeysIdnt
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_mapKeysIdnt=new RewriteRuleTokenStream(adaptor,"token mapKeysIdnt",mapKeysIdnt);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1590:5: -> ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1590:8: ^( TOK_TABLEROWFORMATMAPKEYS $mapKeysIdnt)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABLEROWFORMATMAPKEYS, "TOK_TABLEROWFORMATMAPKEYS")
                , root_1);

                adaptor.addChild(root_1, stream_mapKeysIdnt.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableRowFormatMapKeysIdentifier"


    public static class tableRowFormatLinesIdentifier_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableRowFormatLinesIdentifier"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1593:1: tableRowFormatLinesIdentifier : KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATLINES $linesIdnt) ;
    public final HiveParser.tableRowFormatLinesIdentifier_return tableRowFormatLinesIdentifier() throws RecognitionException {
        HiveParser.tableRowFormatLinesIdentifier_return retval = new HiveParser.tableRowFormatLinesIdentifier_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token linesIdnt=null;
        Token KW_LINES606=null;
        Token KW_TERMINATED607=null;
        Token KW_BY608=null;

        CommonTree linesIdnt_tree=null;
        CommonTree KW_LINES606_tree=null;
        CommonTree KW_TERMINATED607_tree=null;
        CommonTree KW_BY608_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_LINES=new RewriteRuleTokenStream(adaptor,"token KW_LINES");
        RewriteRuleTokenStream stream_KW_TERMINATED=new RewriteRuleTokenStream(adaptor,"token KW_TERMINATED");
        RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");

         msgs.push("table row format's line separator"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1596:5: ( KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral -> ^( TOK_TABLEROWFORMATLINES $linesIdnt) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1597:7: KW_LINES KW_TERMINATED KW_BY linesIdnt= StringLiteral
            {
            KW_LINES606=(Token)match(input,KW_LINES,FOLLOW_KW_LINES_in_tableRowFormatLinesIdentifier9431);  
            stream_KW_LINES.add(KW_LINES606);


            KW_TERMINATED607=(Token)match(input,KW_TERMINATED,FOLLOW_KW_TERMINATED_in_tableRowFormatLinesIdentifier9433);  
            stream_KW_TERMINATED.add(KW_TERMINATED607);


            KW_BY608=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableRowFormatLinesIdentifier9435);  
            stream_KW_BY.add(KW_BY608);


            linesIdnt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableRowFormatLinesIdentifier9439);  
            stream_StringLiteral.add(linesIdnt);


            // AST REWRITE
            // elements: linesIdnt
            // token labels: linesIdnt
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_linesIdnt=new RewriteRuleTokenStream(adaptor,"token linesIdnt",linesIdnt);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1598:5: -> ^( TOK_TABLEROWFORMATLINES $linesIdnt)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1598:8: ^( TOK_TABLEROWFORMATLINES $linesIdnt)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABLEROWFORMATLINES, "TOK_TABLEROWFORMATLINES")
                , root_1);

                adaptor.addChild(root_1, stream_linesIdnt.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableRowFormatLinesIdentifier"


    public static class tableFileFormat_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableFileFormat"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1601:1: tableFileFormat : ( KW_STORED KW_AS KW_SEQUENCEFILE -> TOK_TBLSEQUENCEFILE | KW_STORED KW_AS KW_TEXTFILE -> TOK_TBLTEXTFILE | KW_STORED KW_AS KW_RCFILE -> TOK_TBLRCFILE | KW_STORED KW_AS KW_ORCFILE -> TOK_TBLORCFILE | KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? ) | KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? ) | KW_STORED KW_AS genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) );
    public final HiveParser.tableFileFormat_return tableFileFormat() throws RecognitionException {
        HiveParser.tableFileFormat_return retval = new HiveParser.tableFileFormat_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token inFmt=null;
        Token outFmt=null;
        Token inDriver=null;
        Token outDriver=null;
        Token storageHandler=null;
        Token KW_STORED609=null;
        Token KW_AS610=null;
        Token KW_SEQUENCEFILE611=null;
        Token KW_STORED612=null;
        Token KW_AS613=null;
        Token KW_TEXTFILE614=null;
        Token KW_STORED615=null;
        Token KW_AS616=null;
        Token KW_RCFILE617=null;
        Token KW_STORED618=null;
        Token KW_AS619=null;
        Token KW_ORCFILE620=null;
        Token KW_STORED621=null;
        Token KW_AS622=null;
        Token KW_INPUTFORMAT623=null;
        Token KW_OUTPUTFORMAT624=null;
        Token KW_INPUTDRIVER625=null;
        Token KW_OUTPUTDRIVER626=null;
        Token KW_STORED627=null;
        Token KW_BY628=null;
        Token KW_WITH629=null;
        Token KW_SERDEPROPERTIES630=null;
        Token KW_STORED631=null;
        Token KW_AS632=null;
        HiveParser.tableProperties_return serdeprops =null;

        HiveParser_IdentifiersParser.identifier_return genericSpec =null;


        CommonTree inFmt_tree=null;
        CommonTree outFmt_tree=null;
        CommonTree inDriver_tree=null;
        CommonTree outDriver_tree=null;
        CommonTree storageHandler_tree=null;
        CommonTree KW_STORED609_tree=null;
        CommonTree KW_AS610_tree=null;
        CommonTree KW_SEQUENCEFILE611_tree=null;
        CommonTree KW_STORED612_tree=null;
        CommonTree KW_AS613_tree=null;
        CommonTree KW_TEXTFILE614_tree=null;
        CommonTree KW_STORED615_tree=null;
        CommonTree KW_AS616_tree=null;
        CommonTree KW_RCFILE617_tree=null;
        CommonTree KW_STORED618_tree=null;
        CommonTree KW_AS619_tree=null;
        CommonTree KW_ORCFILE620_tree=null;
        CommonTree KW_STORED621_tree=null;
        CommonTree KW_AS622_tree=null;
        CommonTree KW_INPUTFORMAT623_tree=null;
        CommonTree KW_OUTPUTFORMAT624_tree=null;
        CommonTree KW_INPUTDRIVER625_tree=null;
        CommonTree KW_OUTPUTDRIVER626_tree=null;
        CommonTree KW_STORED627_tree=null;
        CommonTree KW_BY628_tree=null;
        CommonTree KW_WITH629_tree=null;
        CommonTree KW_SERDEPROPERTIES630_tree=null;
        CommonTree KW_STORED631_tree=null;
        CommonTree KW_AS632_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_INPUTDRIVER=new RewriteRuleTokenStream(adaptor,"token KW_INPUTDRIVER");
        RewriteRuleTokenStream stream_KW_OUTPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_OUTPUTFORMAT");
        RewriteRuleTokenStream stream_KW_ORCFILE=new RewriteRuleTokenStream(adaptor,"token KW_ORCFILE");
        RewriteRuleTokenStream stream_KW_TEXTFILE=new RewriteRuleTokenStream(adaptor,"token KW_TEXTFILE");
        RewriteRuleTokenStream stream_KW_BY=new RewriteRuleTokenStream(adaptor,"token KW_BY");
        RewriteRuleTokenStream stream_KW_AS=new RewriteRuleTokenStream(adaptor,"token KW_AS");
        RewriteRuleTokenStream stream_KW_RCFILE=new RewriteRuleTokenStream(adaptor,"token KW_RCFILE");
        RewriteRuleTokenStream stream_KW_INPUTFORMAT=new RewriteRuleTokenStream(adaptor,"token KW_INPUTFORMAT");
        RewriteRuleTokenStream stream_KW_STORED=new RewriteRuleTokenStream(adaptor,"token KW_STORED");
        RewriteRuleTokenStream stream_KW_OUTPUTDRIVER=new RewriteRuleTokenStream(adaptor,"token KW_OUTPUTDRIVER");
        RewriteRuleTokenStream stream_KW_SEQUENCEFILE=new RewriteRuleTokenStream(adaptor,"token KW_SEQUENCEFILE");
        RewriteRuleTokenStream stream_KW_WITH=new RewriteRuleTokenStream(adaptor,"token KW_WITH");
        RewriteRuleTokenStream stream_KW_SERDEPROPERTIES=new RewriteRuleTokenStream(adaptor,"token KW_SERDEPROPERTIES");
        RewriteRuleSubtreeStream stream_tableProperties=new RewriteRuleSubtreeStream(adaptor,"rule tableProperties");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("table file format specification"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1604:5: ( KW_STORED KW_AS KW_SEQUENCEFILE -> TOK_TBLSEQUENCEFILE | KW_STORED KW_AS KW_TEXTFILE -> TOK_TBLTEXTFILE | KW_STORED KW_AS KW_RCFILE -> TOK_TBLRCFILE | KW_STORED KW_AS KW_ORCFILE -> TOK_TBLORCFILE | KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )? -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? ) | KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )? -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? ) | KW_STORED KW_AS genericSpec= identifier -> ^( TOK_FILEFORMAT_GENERIC $genericSpec) )
            int alt169=7;
            int LA169_0 = input.LA(1);

            if ( (LA169_0==KW_STORED) ) {
                int LA169_1 = input.LA(2);

                if ( (LA169_1==KW_AS) ) {
                    switch ( input.LA(3) ) {
                    case KW_SEQUENCEFILE:
                        {
                        alt169=1;
                        }
                        break;
                    case KW_TEXTFILE:
                        {
                        alt169=2;
                        }
                        break;
                    case KW_RCFILE:
                        {
                        alt169=3;
                        }
                        break;
                    case KW_ORCFILE:
                        {
                        alt169=4;
                        }
                        break;
                    case KW_INPUTFORMAT:
                        {
                        alt169=5;
                        }
                        break;
                    case Identifier:
                    case KW_ADD:
                    case KW_AFTER:
                    case KW_ALTER:
                    case KW_ANALYZE:
                    case KW_ARCHIVE:
                    case KW_ARRAY:
                    case KW_AS:
                    case KW_ASC:
                    case KW_BEFORE:
                    case KW_BETWEEN:
                    case KW_BIGINT:
                    case KW_BINARY:
                    case KW_BOOLEAN:
                    case KW_BOTH:
                    case KW_BUCKET:
                    case KW_BUCKETS:
                    case KW_BY:
                    case KW_CASCADE:
                    case KW_CHANGE:
                    case KW_CLUSTER:
                    case KW_CLUSTERED:
                    case KW_CLUSTERSTATUS:
                    case KW_COLLECTION:
                    case KW_COLUMNS:
                    case KW_COMMENT:
                    case KW_COMPUTE:
                    case KW_CONCATENATE:
                    case KW_CONTINUE:
                    case KW_CREATE:
                    case KW_CUBE:
                    case KW_CURSOR:
                    case KW_DATA:
                    case KW_DATABASES:
                    case KW_DATE:
                    case KW_DATETIME:
                    case KW_DBPROPERTIES:
                    case KW_DECIMAL:
                    case KW_DEFERRED:
                    case KW_DELETE:
                    case KW_DELIMITED:
                    case KW_DEPENDENCY:
                    case KW_DESC:
                    case KW_DESCRIBE:
                    case KW_DIRECTORIES:
                    case KW_DIRECTORY:
                    case KW_DISABLE:
                    case KW_DISTRIBUTE:
                    case KW_DOUBLE:
                    case KW_DROP:
                    case KW_ELEM_TYPE:
                    case KW_ENABLE:
                    case KW_ESCAPED:
                    case KW_EXCLUSIVE:
                    case KW_EXISTS:
                    case KW_EXPLAIN:
                    case KW_EXPORT:
                    case KW_EXTERNAL:
                    case KW_FALSE:
                    case KW_FETCH:
                    case KW_FIELDS:
                    case KW_FILEFORMAT:
                    case KW_FIRST:
                    case KW_FLOAT:
                    case KW_FOR:
                    case KW_FORMAT:
                    case KW_FORMATTED:
                    case KW_FULL:
                    case KW_FUNCTIONS:
                    case KW_GRANT:
                    case KW_GROUP:
                    case KW_GROUPING:
                    case KW_HOLD_DDLTIME:
                    case KW_IDXPROPERTIES:
                    case KW_IGNORE:
                    case KW_IMPORT:
                    case KW_IN:
                    case KW_INDEX:
                    case KW_INDEXES:
                    case KW_INNER:
                    case KW_INPATH:
                    case KW_INPUTDRIVER:
                    case KW_INSERT:
                    case KW_INT:
                    case KW_INTERSECT:
                    case KW_INTO:
                    case KW_IS:
                    case KW_ITEMS:
                    case KW_KEYS:
                    case KW_KEY_TYPE:
                    case KW_LATERAL:
                    case KW_LEFT:
                    case KW_LIKE:
                    case KW_LIMIT:
                    case KW_LINES:
                    case KW_LOAD:
                    case KW_LOCAL:
                    case KW_LOCATION:
                    case KW_LOCK:
                    case KW_LOCKS:
                    case KW_LOGICAL:
                    case KW_LONG:
                    case KW_MAPJOIN:
                    case KW_MATERIALIZED:
                    case KW_MINUS:
                    case KW_MSCK:
                    case KW_NOSCAN:
                    case KW_NO_DROP:
                    case KW_NULL:
                    case KW_OF:
                    case KW_OFFLINE:
                    case KW_OPTION:
                    case KW_ORDER:
                    case KW_OUT:
                    case KW_OUTER:
                    case KW_OUTPUTDRIVER:
                    case KW_OUTPUTFORMAT:
                    case KW_OVERWRITE:
                    case KW_PARTITION:
                    case KW_PARTITIONED:
                    case KW_PARTITIONS:
                    case KW_PERCENT:
                    case KW_PLUS:
                    case KW_PRETTY:
                    case KW_PROCEDURE:
                    case KW_PROTECTION:
                    case KW_PURGE:
                    case KW_RANGE:
                    case KW_READ:
                    case KW_READONLY:
                    case KW_READS:
                    case KW_REBUILD:
                    case KW_RECORDREADER:
                    case KW_RECORDWRITER:
                    case KW_REGEXP:
                    case KW_RENAME:
                    case KW_REPAIR:
                    case KW_REPLACE:
                    case KW_RESTRICT:
                    case KW_REVOKE:
                    case KW_RIGHT:
                    case KW_RLIKE:
                    case KW_ROLE:
                    case KW_ROLLUP:
                    case KW_ROW:
                    case KW_ROWS:
                    case KW_SCHEMA:
                    case KW_SCHEMAS:
                    case KW_SEMI:
                    case KW_SERDE:
                    case KW_SERDEPROPERTIES:
                    case KW_SET:
                    case KW_SETS:
                    case KW_SHARED:
                    case KW_SHOW:
                    case KW_SHOW_DATABASE:
                    case KW_SKEWED:
                    case KW_SMALLINT:
                    case KW_SORT:
                    case KW_SORTED:
                    case KW_SSL:
                    case KW_STATISTICS:
                    case KW_STORED:
                    case KW_STREAMTABLE:
                    case KW_STRING:
                    case KW_STRUCT:
                    case KW_TABLE:
                    case KW_TABLES:
                    case KW_TBLPROPERTIES:
                    case KW_TEMPORARY:
                    case KW_TERMINATED:
                    case KW_TIMESTAMP:
                    case KW_TINYINT:
                    case KW_TO:
                    case KW_TOUCH:
                    case KW_TRIGGER:
                    case KW_TRUE:
                    case KW_TRUNCATE:
                    case KW_UNARCHIVE:
                    case KW_UNDO:
                    case KW_UNION:
                    case KW_UNIONTYPE:
                    case KW_UNLOCK:
                    case KW_UNSET:
                    case KW_UNSIGNED:
                    case KW_UPDATE:
                    case KW_USE:
                    case KW_USER:
                    case KW_USING:
                    case KW_UTC:
                    case KW_UTCTIMESTAMP:
                    case KW_VALUE_TYPE:
                    case KW_VIEW:
                    case KW_WHILE:
                    case KW_WITH:
                        {
                        alt169=7;
                        }
                        break;
                    default:
                        NoViableAltException nvae =
                            new NoViableAltException("", 169, 2, input);

                        throw nvae;

                    }

                }
                else if ( (LA169_1==KW_BY) ) {
                    alt169=6;
                }
                else {
                    NoViableAltException nvae =
                        new NoViableAltException("", 169, 1, input);

                    throw nvae;

                }
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 169, 0, input);

                throw nvae;

            }
            switch (alt169) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1605:7: KW_STORED KW_AS KW_SEQUENCEFILE
                    {
                    KW_STORED609=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat9485);  
                    stream_KW_STORED.add(KW_STORED609);


                    KW_AS610=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableFileFormat9487);  
                    stream_KW_AS.add(KW_AS610);


                    KW_SEQUENCEFILE611=(Token)match(input,KW_SEQUENCEFILE,FOLLOW_KW_SEQUENCEFILE_in_tableFileFormat9489);  
                    stream_KW_SEQUENCEFILE.add(KW_SEQUENCEFILE611);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1605:40: -> TOK_TBLSEQUENCEFILE
                    {
                        adaptor.addChild(root_0, 
                        (CommonTree)adaptor.create(TOK_TBLSEQUENCEFILE, "TOK_TBLSEQUENCEFILE")
                        );

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1606:9: KW_STORED KW_AS KW_TEXTFILE
                    {
                    KW_STORED612=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat9504);  
                    stream_KW_STORED.add(KW_STORED612);


                    KW_AS613=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableFileFormat9506);  
                    stream_KW_AS.add(KW_AS613);


                    KW_TEXTFILE614=(Token)match(input,KW_TEXTFILE,FOLLOW_KW_TEXTFILE_in_tableFileFormat9508);  
                    stream_KW_TEXTFILE.add(KW_TEXTFILE614);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1606:38: -> TOK_TBLTEXTFILE
                    {
                        adaptor.addChild(root_0, 
                        (CommonTree)adaptor.create(TOK_TBLTEXTFILE, "TOK_TBLTEXTFILE")
                        );

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1607:9: KW_STORED KW_AS KW_RCFILE
                    {
                    KW_STORED615=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat9523);  
                    stream_KW_STORED.add(KW_STORED615);


                    KW_AS616=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableFileFormat9525);  
                    stream_KW_AS.add(KW_AS616);


                    KW_RCFILE617=(Token)match(input,KW_RCFILE,FOLLOW_KW_RCFILE_in_tableFileFormat9527);  
                    stream_KW_RCFILE.add(KW_RCFILE617);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1607:36: -> TOK_TBLRCFILE
                    {
                        adaptor.addChild(root_0, 
                        (CommonTree)adaptor.create(TOK_TBLRCFILE, "TOK_TBLRCFILE")
                        );

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 4 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1608:9: KW_STORED KW_AS KW_ORCFILE
                    {
                    KW_STORED618=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat9542);  
                    stream_KW_STORED.add(KW_STORED618);


                    KW_AS619=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableFileFormat9544);  
                    stream_KW_AS.add(KW_AS619);


                    KW_ORCFILE620=(Token)match(input,KW_ORCFILE,FOLLOW_KW_ORCFILE_in_tableFileFormat9546);  
                    stream_KW_ORCFILE.add(KW_ORCFILE620);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1608:36: -> TOK_TBLORCFILE
                    {
                        adaptor.addChild(root_0, 
                        (CommonTree)adaptor.create(TOK_TBLORCFILE, "TOK_TBLORCFILE")
                        );

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 5 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:9: KW_STORED KW_AS KW_INPUTFORMAT inFmt= StringLiteral KW_OUTPUTFORMAT outFmt= StringLiteral ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
                    {
                    KW_STORED621=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat9560);  
                    stream_KW_STORED.add(KW_STORED621);


                    KW_AS622=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableFileFormat9562);  
                    stream_KW_AS.add(KW_AS622);


                    KW_INPUTFORMAT623=(Token)match(input,KW_INPUTFORMAT,FOLLOW_KW_INPUTFORMAT_in_tableFileFormat9564);  
                    stream_KW_INPUTFORMAT.add(KW_INPUTFORMAT623);


                    inFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat9568);  
                    stream_StringLiteral.add(inFmt);


                    KW_OUTPUTFORMAT624=(Token)match(input,KW_OUTPUTFORMAT,FOLLOW_KW_OUTPUTFORMAT_in_tableFileFormat9570);  
                    stream_KW_OUTPUTFORMAT.add(KW_OUTPUTFORMAT624);


                    outFmt=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat9574);  
                    stream_StringLiteral.add(outFmt);


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:97: ( KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral )?
                    int alt167=2;
                    int LA167_0 = input.LA(1);

                    if ( (LA167_0==KW_INPUTDRIVER) ) {
                        alt167=1;
                    }
                    switch (alt167) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1609:98: KW_INPUTDRIVER inDriver= StringLiteral KW_OUTPUTDRIVER outDriver= StringLiteral
                            {
                            KW_INPUTDRIVER625=(Token)match(input,KW_INPUTDRIVER,FOLLOW_KW_INPUTDRIVER_in_tableFileFormat9577);  
                            stream_KW_INPUTDRIVER.add(KW_INPUTDRIVER625);


                            inDriver=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat9581);  
                            stream_StringLiteral.add(inDriver);


                            KW_OUTPUTDRIVER626=(Token)match(input,KW_OUTPUTDRIVER,FOLLOW_KW_OUTPUTDRIVER_in_tableFileFormat9583);  
                            stream_KW_OUTPUTDRIVER.add(KW_OUTPUTDRIVER626);


                            outDriver=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat9587);  
                            stream_StringLiteral.add(outDriver);


                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: inDriver, outDriver, outFmt, inFmt
                    // token labels: outDriver, outFmt, inDriver, inFmt
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_outDriver=new RewriteRuleTokenStream(adaptor,"token outDriver",outDriver);
                    RewriteRuleTokenStream stream_outFmt=new RewriteRuleTokenStream(adaptor,"token outFmt",outFmt);
                    RewriteRuleTokenStream stream_inDriver=new RewriteRuleTokenStream(adaptor,"token inDriver",inDriver);
                    RewriteRuleTokenStream stream_inFmt=new RewriteRuleTokenStream(adaptor,"token inFmt",inFmt);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1610:7: -> ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1610:10: ^( TOK_TABLEFILEFORMAT $inFmt $outFmt ( $inDriver)? ( $outDriver)? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_TABLEFILEFORMAT, "TOK_TABLEFILEFORMAT")
                        , root_1);

                        adaptor.addChild(root_1, stream_inFmt.nextNode());

                        adaptor.addChild(root_1, stream_outFmt.nextNode());

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1610:48: ( $inDriver)?
                        if ( stream_inDriver.hasNext() ) {
                            adaptor.addChild(root_1, stream_inDriver.nextNode());

                        }
                        stream_inDriver.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1610:59: ( $outDriver)?
                        if ( stream_outDriver.hasNext() ) {
                            adaptor.addChild(root_1, stream_outDriver.nextNode());

                        }
                        stream_outDriver.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 6 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1611:9: KW_STORED KW_BY storageHandler= StringLiteral ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
                    {
                    KW_STORED627=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat9625);  
                    stream_KW_STORED.add(KW_STORED627);


                    KW_BY628=(Token)match(input,KW_BY,FOLLOW_KW_BY_in_tableFileFormat9627);  
                    stream_KW_BY.add(KW_BY628);


                    storageHandler=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableFileFormat9631);  
                    stream_StringLiteral.add(storageHandler);


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1612:10: ( KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties )?
                    int alt168=2;
                    int LA168_0 = input.LA(1);

                    if ( (LA168_0==KW_WITH) ) {
                        alt168=1;
                    }
                    switch (alt168) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1612:11: KW_WITH KW_SERDEPROPERTIES serdeprops= tableProperties
                            {
                            KW_WITH629=(Token)match(input,KW_WITH,FOLLOW_KW_WITH_in_tableFileFormat9643);  
                            stream_KW_WITH.add(KW_WITH629);


                            KW_SERDEPROPERTIES630=(Token)match(input,KW_SERDEPROPERTIES,FOLLOW_KW_SERDEPROPERTIES_in_tableFileFormat9645);  
                            stream_KW_SERDEPROPERTIES.add(KW_SERDEPROPERTIES630);


                            pushFollow(FOLLOW_tableProperties_in_tableFileFormat9649);
                            serdeprops=tableProperties();

                            state._fsp--;

                            stream_tableProperties.add(serdeprops.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: serdeprops, storageHandler
                    // token labels: storageHandler
                    // rule labels: serdeprops, retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_storageHandler=new RewriteRuleTokenStream(adaptor,"token storageHandler",storageHandler);
                    RewriteRuleSubtreeStream stream_serdeprops=new RewriteRuleSubtreeStream(adaptor,"rule serdeprops",serdeprops!=null?serdeprops.tree:null);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1613:7: -> ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1613:10: ^( TOK_STORAGEHANDLER $storageHandler ( $serdeprops)? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_STORAGEHANDLER, "TOK_STORAGEHANDLER")
                        , root_1);

                        adaptor.addChild(root_1, stream_storageHandler.nextNode());

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1613:48: ( $serdeprops)?
                        if ( stream_serdeprops.hasNext() ) {
                            adaptor.addChild(root_1, stream_serdeprops.nextTree());

                        }
                        stream_serdeprops.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 7 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1614:9: KW_STORED KW_AS genericSpec= identifier
                    {
                    KW_STORED631=(Token)match(input,KW_STORED,FOLLOW_KW_STORED_in_tableFileFormat9680);  
                    stream_KW_STORED.add(KW_STORED631);


                    KW_AS632=(Token)match(input,KW_AS,FOLLOW_KW_AS_in_tableFileFormat9682);  
                    stream_KW_AS.add(KW_AS632);


                    pushFollow(FOLLOW_identifier_in_tableFileFormat9686);
                    genericSpec=identifier();

                    state._fsp--;

                    stream_identifier.add(genericSpec.getTree());

                    // AST REWRITE
                    // elements: genericSpec
                    // token labels: 
                    // rule labels: retval, genericSpec
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
                    RewriteRuleSubtreeStream stream_genericSpec=new RewriteRuleSubtreeStream(adaptor,"rule genericSpec",genericSpec!=null?genericSpec.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1615:7: -> ^( TOK_FILEFORMAT_GENERIC $genericSpec)
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1615:10: ^( TOK_FILEFORMAT_GENERIC $genericSpec)
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_FILEFORMAT_GENERIC, "TOK_FILEFORMAT_GENERIC")
                        , root_1);

                        adaptor.addChild(root_1, stream_genericSpec.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableFileFormat"


    public static class tableLocation_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "tableLocation"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1618:1: tableLocation : KW_LOCATION locn= StringLiteral -> ^( TOK_TABLELOCATION $locn) ;
    public final HiveParser.tableLocation_return tableLocation() throws RecognitionException {
        HiveParser.tableLocation_return retval = new HiveParser.tableLocation_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token locn=null;
        Token KW_LOCATION633=null;

        CommonTree locn_tree=null;
        CommonTree KW_LOCATION633_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_LOCATION=new RewriteRuleTokenStream(adaptor,"token KW_LOCATION");

         msgs.push("table location specification"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1621:5: ( KW_LOCATION locn= StringLiteral -> ^( TOK_TABLELOCATION $locn) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1622:7: KW_LOCATION locn= StringLiteral
            {
            KW_LOCATION633=(Token)match(input,KW_LOCATION,FOLLOW_KW_LOCATION_in_tableLocation9734);  
            stream_KW_LOCATION.add(KW_LOCATION633);


            locn=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_tableLocation9738);  
            stream_StringLiteral.add(locn);


            // AST REWRITE
            // elements: locn
            // token labels: locn
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_locn=new RewriteRuleTokenStream(adaptor,"token locn",locn);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1622:38: -> ^( TOK_TABLELOCATION $locn)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1622:41: ^( TOK_TABLELOCATION $locn)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABLELOCATION, "TOK_TABLELOCATION")
                , root_1);

                adaptor.addChild(root_1, stream_locn.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "tableLocation"


    public static class columnNameTypeList_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameTypeList"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1625:1: columnNameTypeList : columnNameType ( COMMA columnNameType )* -> ^( TOK_TABCOLLIST ( columnNameType )+ ) ;
    public final HiveParser.columnNameTypeList_return columnNameTypeList() throws RecognitionException {
        HiveParser.columnNameTypeList_return retval = new HiveParser.columnNameTypeList_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token COMMA635=null;
        HiveParser.columnNameType_return columnNameType634 =null;

        HiveParser.columnNameType_return columnNameType636 =null;


        CommonTree COMMA635_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_columnNameType=new RewriteRuleSubtreeStream(adaptor,"rule columnNameType");
         msgs.push("column name type list"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1628:5: ( columnNameType ( COMMA columnNameType )* -> ^( TOK_TABCOLLIST ( columnNameType )+ ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1628:7: columnNameType ( COMMA columnNameType )*
            {
            pushFollow(FOLLOW_columnNameType_in_columnNameTypeList9774);
            columnNameType634=columnNameType();

            state._fsp--;

            stream_columnNameType.add(columnNameType634.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1628:22: ( COMMA columnNameType )*
            loop170:
            do {
                int alt170=2;
                int LA170_0 = input.LA(1);

                if ( (LA170_0==COMMA) ) {
                    alt170=1;
                }


                switch (alt170) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1628:23: COMMA columnNameType
            	    {
            	    COMMA635=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameTypeList9777);  
            	    stream_COMMA.add(COMMA635);


            	    pushFollow(FOLLOW_columnNameType_in_columnNameTypeList9779);
            	    columnNameType636=columnNameType();

            	    state._fsp--;

            	    stream_columnNameType.add(columnNameType636.getTree());

            	    }
            	    break;

            	default :
            	    break loop170;
                }
            } while (true);


            // AST REWRITE
            // elements: columnNameType
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1628:46: -> ^( TOK_TABCOLLIST ( columnNameType )+ )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1628:49: ^( TOK_TABCOLLIST ( columnNameType )+ )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABCOLLIST, "TOK_TABCOLLIST")
                , root_1);

                if ( !(stream_columnNameType.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_columnNameType.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnNameType.nextTree());

                }
                stream_columnNameType.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameTypeList"


    public static class columnNameColonTypeList_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameColonTypeList"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1631:1: columnNameColonTypeList : columnNameColonType ( COMMA columnNameColonType )* -> ^( TOK_TABCOLLIST ( columnNameColonType )+ ) ;
    public final HiveParser.columnNameColonTypeList_return columnNameColonTypeList() throws RecognitionException {
        HiveParser.columnNameColonTypeList_return retval = new HiveParser.columnNameColonTypeList_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token COMMA638=null;
        HiveParser.columnNameColonType_return columnNameColonType637 =null;

        HiveParser.columnNameColonType_return columnNameColonType639 =null;


        CommonTree COMMA638_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_columnNameColonType=new RewriteRuleSubtreeStream(adaptor,"rule columnNameColonType");
         msgs.push("column name type list"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1634:5: ( columnNameColonType ( COMMA columnNameColonType )* -> ^( TOK_TABCOLLIST ( columnNameColonType )+ ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1634:7: columnNameColonType ( COMMA columnNameColonType )*
            {
            pushFollow(FOLLOW_columnNameColonType_in_columnNameColonTypeList9817);
            columnNameColonType637=columnNameColonType();

            state._fsp--;

            stream_columnNameColonType.add(columnNameColonType637.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1634:27: ( COMMA columnNameColonType )*
            loop171:
            do {
                int alt171=2;
                int LA171_0 = input.LA(1);

                if ( (LA171_0==COMMA) ) {
                    alt171=1;
                }


                switch (alt171) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1634:28: COMMA columnNameColonType
            	    {
            	    COMMA638=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameColonTypeList9820);  
            	    stream_COMMA.add(COMMA638);


            	    pushFollow(FOLLOW_columnNameColonType_in_columnNameColonTypeList9822);
            	    columnNameColonType639=columnNameColonType();

            	    state._fsp--;

            	    stream_columnNameColonType.add(columnNameColonType639.getTree());

            	    }
            	    break;

            	default :
            	    break loop171;
                }
            } while (true);


            // AST REWRITE
            // elements: columnNameColonType
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1634:56: -> ^( TOK_TABCOLLIST ( columnNameColonType )+ )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1634:59: ^( TOK_TABCOLLIST ( columnNameColonType )+ )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABCOLLIST, "TOK_TABCOLLIST")
                , root_1);

                if ( !(stream_columnNameColonType.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_columnNameColonType.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnNameColonType.nextTree());

                }
                stream_columnNameColonType.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameColonTypeList"


    public static class columnNameList_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameList"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1637:1: columnNameList : columnName ( COMMA columnName )* -> ^( TOK_TABCOLNAME ( columnName )+ ) ;
    public final HiveParser.columnNameList_return columnNameList() throws RecognitionException {
        HiveParser.columnNameList_return retval = new HiveParser.columnNameList_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token COMMA641=null;
        HiveParser.columnName_return columnName640 =null;

        HiveParser.columnName_return columnName642 =null;


        CommonTree COMMA641_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_columnName=new RewriteRuleSubtreeStream(adaptor,"rule columnName");
         msgs.push("column name list"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:5: ( columnName ( COMMA columnName )* -> ^( TOK_TABCOLNAME ( columnName )+ ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:7: columnName ( COMMA columnName )*
            {
            pushFollow(FOLLOW_columnName_in_columnNameList9860);
            columnName640=columnName();

            state._fsp--;

            stream_columnName.add(columnName640.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:18: ( COMMA columnName )*
            loop172:
            do {
                int alt172=2;
                int LA172_0 = input.LA(1);

                if ( (LA172_0==COMMA) ) {
                    alt172=1;
                }


                switch (alt172) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:19: COMMA columnName
            	    {
            	    COMMA641=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameList9863);  
            	    stream_COMMA.add(COMMA641);


            	    pushFollow(FOLLOW_columnName_in_columnNameList9865);
            	    columnName642=columnName();

            	    state._fsp--;

            	    stream_columnName.add(columnName642.getTree());

            	    }
            	    break;

            	default :
            	    break loop172;
                }
            } while (true);


            // AST REWRITE
            // elements: columnName
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1640:38: -> ^( TOK_TABCOLNAME ( columnName )+ )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1640:41: ^( TOK_TABCOLNAME ( columnName )+ )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME")
                , root_1);

                if ( !(stream_columnName.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_columnName.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnName.nextTree());

                }
                stream_columnName.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameList"


    public static class columnName_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnName"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1643:1: columnName : identifier ;
    public final HiveParser.columnName_return columnName() throws RecognitionException {
        HiveParser.columnName_return retval = new HiveParser.columnName_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser_IdentifiersParser.identifier_return identifier643 =null;



         msgs.push("column name"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1646:5: ( identifier )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1647:7: identifier
            {
            root_0 = (CommonTree)adaptor.nil();


            pushFollow(FOLLOW_identifier_in_columnName9909);
            identifier643=identifier();

            state._fsp--;

            adaptor.addChild(root_0, identifier643.getTree());

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnName"


    public static class columnNameOrderList_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameOrderList"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1650:1: columnNameOrderList : columnNameOrder ( COMMA columnNameOrder )* -> ^( TOK_TABCOLNAME ( columnNameOrder )+ ) ;
    public final HiveParser.columnNameOrderList_return columnNameOrderList() throws RecognitionException {
        HiveParser.columnNameOrderList_return retval = new HiveParser.columnNameOrderList_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token COMMA645=null;
        HiveParser.columnNameOrder_return columnNameOrder644 =null;

        HiveParser.columnNameOrder_return columnNameOrder646 =null;


        CommonTree COMMA645_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_columnNameOrder=new RewriteRuleSubtreeStream(adaptor,"rule columnNameOrder");
         msgs.push("column name order list"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1653:5: ( columnNameOrder ( COMMA columnNameOrder )* -> ^( TOK_TABCOLNAME ( columnNameOrder )+ ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1653:7: columnNameOrder ( COMMA columnNameOrder )*
            {
            pushFollow(FOLLOW_columnNameOrder_in_columnNameOrderList9936);
            columnNameOrder644=columnNameOrder();

            state._fsp--;

            stream_columnNameOrder.add(columnNameOrder644.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1653:23: ( COMMA columnNameOrder )*
            loop173:
            do {
                int alt173=2;
                int LA173_0 = input.LA(1);

                if ( (LA173_0==COMMA) ) {
                    alt173=1;
                }


                switch (alt173) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1653:24: COMMA columnNameOrder
            	    {
            	    COMMA645=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameOrderList9939);  
            	    stream_COMMA.add(COMMA645);


            	    pushFollow(FOLLOW_columnNameOrder_in_columnNameOrderList9941);
            	    columnNameOrder646=columnNameOrder();

            	    state._fsp--;

            	    stream_columnNameOrder.add(columnNameOrder646.getTree());

            	    }
            	    break;

            	default :
            	    break loop173;
                }
            } while (true);


            // AST REWRITE
            // elements: columnNameOrder
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1653:48: -> ^( TOK_TABCOLNAME ( columnNameOrder )+ )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1653:51: ^( TOK_TABCOLNAME ( columnNameOrder )+ )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME")
                , root_1);

                if ( !(stream_columnNameOrder.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_columnNameOrder.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnNameOrder.nextTree());

                }
                stream_columnNameOrder.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameOrderList"


    public static class skewedValueElement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "skewedValueElement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1656:1: skewedValueElement : ( skewedColumnValues | skewedColumnValuePairList );
    public final HiveParser.skewedValueElement_return skewedValueElement() throws RecognitionException {
        HiveParser.skewedValueElement_return retval = new HiveParser.skewedValueElement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser.skewedColumnValues_return skewedColumnValues647 =null;

        HiveParser.skewedColumnValuePairList_return skewedColumnValuePairList648 =null;



         msgs.push("skewed value element"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1659:5: ( skewedColumnValues | skewedColumnValuePairList )
            int alt174=2;
            int LA174_0 = input.LA(1);

            if ( (LA174_0==BigintLiteral||LA174_0==CharSetName||LA174_0==DecimalLiteral||LA174_0==KW_DATE||LA174_0==KW_FALSE||LA174_0==KW_TRUE||LA174_0==Number||(LA174_0 >= SmallintLiteral && LA174_0 <= StringLiteral)||LA174_0==TinyintLiteral) ) {
                alt174=1;
            }
            else if ( (LA174_0==LPAREN) ) {
                alt174=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 174, 0, input);

                throw nvae;

            }
            switch (alt174) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1660:7: skewedColumnValues
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_skewedColumnValues_in_skewedValueElement9986);
                    skewedColumnValues647=skewedColumnValues();

                    state._fsp--;

                    adaptor.addChild(root_0, skewedColumnValues647.getTree());

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1661:8: skewedColumnValuePairList
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_skewedColumnValuePairList_in_skewedValueElement9995);
                    skewedColumnValuePairList648=skewedColumnValuePairList();

                    state._fsp--;

                    adaptor.addChild(root_0, skewedColumnValuePairList648.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "skewedValueElement"


    public static class skewedColumnValuePairList_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "skewedColumnValuePairList"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1664:1: skewedColumnValuePairList : skewedColumnValuePair ( COMMA skewedColumnValuePair )* -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ ) ;
    public final HiveParser.skewedColumnValuePairList_return skewedColumnValuePairList() throws RecognitionException {
        HiveParser.skewedColumnValuePairList_return retval = new HiveParser.skewedColumnValuePairList_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token COMMA650=null;
        HiveParser.skewedColumnValuePair_return skewedColumnValuePair649 =null;

        HiveParser.skewedColumnValuePair_return skewedColumnValuePair651 =null;


        CommonTree COMMA650_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_skewedColumnValuePair=new RewriteRuleSubtreeStream(adaptor,"rule skewedColumnValuePair");
         msgs.push("column value pair list"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1667:5: ( skewedColumnValuePair ( COMMA skewedColumnValuePair )* -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1667:7: skewedColumnValuePair ( COMMA skewedColumnValuePair )*
            {
            pushFollow(FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList10022);
            skewedColumnValuePair649=skewedColumnValuePair();

            state._fsp--;

            stream_skewedColumnValuePair.add(skewedColumnValuePair649.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1667:29: ( COMMA skewedColumnValuePair )*
            loop175:
            do {
                int alt175=2;
                int LA175_0 = input.LA(1);

                if ( (LA175_0==COMMA) ) {
                    alt175=1;
                }


                switch (alt175) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1667:30: COMMA skewedColumnValuePair
            	    {
            	    COMMA650=(Token)match(input,COMMA,FOLLOW_COMMA_in_skewedColumnValuePairList10025);  
            	    stream_COMMA.add(COMMA650);


            	    pushFollow(FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList10027);
            	    skewedColumnValuePair651=skewedColumnValuePair();

            	    state._fsp--;

            	    stream_skewedColumnValuePair.add(skewedColumnValuePair651.getTree());

            	    }
            	    break;

            	default :
            	    break loop175;
                }
            } while (true);


            // AST REWRITE
            // elements: skewedColumnValuePair
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1667:60: -> ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1667:63: ^( TOK_TABCOLVALUE_PAIR ( skewedColumnValuePair )+ )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABCOLVALUE_PAIR, "TOK_TABCOLVALUE_PAIR")
                , root_1);

                if ( !(stream_skewedColumnValuePair.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_skewedColumnValuePair.hasNext() ) {
                    adaptor.addChild(root_1, stream_skewedColumnValuePair.nextTree());

                }
                stream_skewedColumnValuePair.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "skewedColumnValuePairList"


    public static class skewedColumnValuePair_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "skewedColumnValuePair"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1670:1: skewedColumnValuePair : LPAREN colValues= skewedColumnValues RPAREN -> ^( TOK_TABCOLVALUES $colValues) ;
    public final HiveParser.skewedColumnValuePair_return skewedColumnValuePair() throws RecognitionException {
        HiveParser.skewedColumnValuePair_return retval = new HiveParser.skewedColumnValuePair_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token LPAREN652=null;
        Token RPAREN653=null;
        HiveParser.skewedColumnValues_return colValues =null;


        CommonTree LPAREN652_tree=null;
        CommonTree RPAREN653_tree=null;
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleSubtreeStream stream_skewedColumnValues=new RewriteRuleSubtreeStream(adaptor,"rule skewedColumnValues");
         msgs.push("column value pair"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1673:5: ( LPAREN colValues= skewedColumnValues RPAREN -> ^( TOK_TABCOLVALUES $colValues) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1674:7: LPAREN colValues= skewedColumnValues RPAREN
            {
            LPAREN652=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_skewedColumnValuePair10072);  
            stream_LPAREN.add(LPAREN652);


            pushFollow(FOLLOW_skewedColumnValues_in_skewedColumnValuePair10076);
            colValues=skewedColumnValues();

            state._fsp--;

            stream_skewedColumnValues.add(colValues.getTree());

            RPAREN653=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_skewedColumnValuePair10078);  
            stream_RPAREN.add(RPAREN653);


            // AST REWRITE
            // elements: colValues
            // token labels: 
            // rule labels: retval, colValues
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_colValues=new RewriteRuleSubtreeStream(adaptor,"rule colValues",colValues!=null?colValues.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1675:7: -> ^( TOK_TABCOLVALUES $colValues)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1675:10: ^( TOK_TABCOLVALUES $colValues)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABCOLVALUES, "TOK_TABCOLVALUES")
                , root_1);

                adaptor.addChild(root_1, stream_colValues.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "skewedColumnValuePair"


    public static class skewedColumnValues_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "skewedColumnValues"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1678:1: skewedColumnValues : skewedColumnValue ( COMMA skewedColumnValue )* -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ ) ;
    public final HiveParser.skewedColumnValues_return skewedColumnValues() throws RecognitionException {
        HiveParser.skewedColumnValues_return retval = new HiveParser.skewedColumnValues_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token COMMA655=null;
        HiveParser.skewedColumnValue_return skewedColumnValue654 =null;

        HiveParser.skewedColumnValue_return skewedColumnValue656 =null;


        CommonTree COMMA655_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_skewedColumnValue=new RewriteRuleSubtreeStream(adaptor,"rule skewedColumnValue");
         msgs.push("column values"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:5: ( skewedColumnValue ( COMMA skewedColumnValue )* -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:7: skewedColumnValue ( COMMA skewedColumnValue )*
            {
            pushFollow(FOLLOW_skewedColumnValue_in_skewedColumnValues10121);
            skewedColumnValue654=skewedColumnValue();

            state._fsp--;

            stream_skewedColumnValue.add(skewedColumnValue654.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:25: ( COMMA skewedColumnValue )*
            loop176:
            do {
                int alt176=2;
                int LA176_0 = input.LA(1);

                if ( (LA176_0==COMMA) ) {
                    alt176=1;
                }


                switch (alt176) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:26: COMMA skewedColumnValue
            	    {
            	    COMMA655=(Token)match(input,COMMA,FOLLOW_COMMA_in_skewedColumnValues10124);  
            	    stream_COMMA.add(COMMA655);


            	    pushFollow(FOLLOW_skewedColumnValue_in_skewedColumnValues10126);
            	    skewedColumnValue656=skewedColumnValue();

            	    state._fsp--;

            	    stream_skewedColumnValue.add(skewedColumnValue656.getTree());

            	    }
            	    break;

            	default :
            	    break loop176;
                }
            } while (true);


            // AST REWRITE
            // elements: skewedColumnValue
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1681:52: -> ^( TOK_TABCOLVALUE ( skewedColumnValue )+ )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1681:55: ^( TOK_TABCOLVALUE ( skewedColumnValue )+ )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABCOLVALUE, "TOK_TABCOLVALUE")
                , root_1);

                if ( !(stream_skewedColumnValue.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_skewedColumnValue.hasNext() ) {
                    adaptor.addChild(root_1, stream_skewedColumnValue.nextTree());

                }
                stream_skewedColumnValue.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "skewedColumnValues"


    public static class skewedColumnValue_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "skewedColumnValue"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1684:1: skewedColumnValue : constant ;
    public final HiveParser.skewedColumnValue_return skewedColumnValue() throws RecognitionException {
        HiveParser.skewedColumnValue_return retval = new HiveParser.skewedColumnValue_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser_IdentifiersParser.constant_return constant657 =null;



         msgs.push("column value"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1687:5: ( constant )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1688:7: constant
            {
            root_0 = (CommonTree)adaptor.nil();


            pushFollow(FOLLOW_constant_in_skewedColumnValue10170);
            constant657=constant();

            state._fsp--;

            adaptor.addChild(root_0, constant657.getTree());

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "skewedColumnValue"


    public static class skewedValueLocationElement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "skewedValueLocationElement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1691:1: skewedValueLocationElement : ( skewedColumnValue | skewedColumnValuePair );
    public final HiveParser.skewedValueLocationElement_return skewedValueLocationElement() throws RecognitionException {
        HiveParser.skewedValueLocationElement_return retval = new HiveParser.skewedValueLocationElement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser.skewedColumnValue_return skewedColumnValue658 =null;

        HiveParser.skewedColumnValuePair_return skewedColumnValuePair659 =null;



         msgs.push("skewed value location element"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1694:5: ( skewedColumnValue | skewedColumnValuePair )
            int alt177=2;
            int LA177_0 = input.LA(1);

            if ( (LA177_0==BigintLiteral||LA177_0==CharSetName||LA177_0==DecimalLiteral||LA177_0==KW_DATE||LA177_0==KW_FALSE||LA177_0==KW_TRUE||LA177_0==Number||(LA177_0 >= SmallintLiteral && LA177_0 <= StringLiteral)||LA177_0==TinyintLiteral) ) {
                alt177=1;
            }
            else if ( (LA177_0==LPAREN) ) {
                alt177=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 177, 0, input);

                throw nvae;

            }
            switch (alt177) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1695:7: skewedColumnValue
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_skewedColumnValue_in_skewedValueLocationElement10204);
                    skewedColumnValue658=skewedColumnValue();

                    state._fsp--;

                    adaptor.addChild(root_0, skewedColumnValue658.getTree());

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1696:8: skewedColumnValuePair
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_skewedColumnValuePair_in_skewedValueLocationElement10213);
                    skewedColumnValuePair659=skewedColumnValuePair();

                    state._fsp--;

                    adaptor.addChild(root_0, skewedColumnValuePair659.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "skewedValueLocationElement"


    public static class columnNameOrder_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameOrder"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1699:1: columnNameOrder : identifier (asc= KW_ASC |desc= KW_DESC )? -> {$desc == null}? ^( TOK_TABSORTCOLNAMEASC identifier ) -> ^( TOK_TABSORTCOLNAMEDESC identifier ) ;
    public final HiveParser.columnNameOrder_return columnNameOrder() throws RecognitionException {
        HiveParser.columnNameOrder_return retval = new HiveParser.columnNameOrder_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token asc=null;
        Token desc=null;
        HiveParser_IdentifiersParser.identifier_return identifier660 =null;


        CommonTree asc_tree=null;
        CommonTree desc_tree=null;
        RewriteRuleTokenStream stream_KW_DESC=new RewriteRuleTokenStream(adaptor,"token KW_DESC");
        RewriteRuleTokenStream stream_KW_ASC=new RewriteRuleTokenStream(adaptor,"token KW_ASC");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("column name order"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1702:5: ( identifier (asc= KW_ASC |desc= KW_DESC )? -> {$desc == null}? ^( TOK_TABSORTCOLNAMEASC identifier ) -> ^( TOK_TABSORTCOLNAMEDESC identifier ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1702:7: identifier (asc= KW_ASC |desc= KW_DESC )?
            {
            pushFollow(FOLLOW_identifier_in_columnNameOrder10244);
            identifier660=identifier();

            state._fsp--;

            stream_identifier.add(identifier660.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1702:18: (asc= KW_ASC |desc= KW_DESC )?
            int alt178=3;
            int LA178_0 = input.LA(1);

            if ( (LA178_0==KW_ASC) ) {
                alt178=1;
            }
            else if ( (LA178_0==KW_DESC) ) {
                alt178=2;
            }
            switch (alt178) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1702:19: asc= KW_ASC
                    {
                    asc=(Token)match(input,KW_ASC,FOLLOW_KW_ASC_in_columnNameOrder10249);  
                    stream_KW_ASC.add(asc);


                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1702:32: desc= KW_DESC
                    {
                    desc=(Token)match(input,KW_DESC,FOLLOW_KW_DESC_in_columnNameOrder10255);  
                    stream_KW_DESC.add(desc);


                    }
                    break;

            }


            // AST REWRITE
            // elements: identifier, identifier
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1703:5: -> {$desc == null}? ^( TOK_TABSORTCOLNAMEASC identifier )
            if (desc == null) {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1703:25: ^( TOK_TABSORTCOLNAMEASC identifier )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC")
                , root_1);

                adaptor.addChild(root_1, stream_identifier.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 1704:5: -> ^( TOK_TABSORTCOLNAMEDESC identifier )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1704:25: ^( TOK_TABSORTCOLNAMEDESC identifier )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABSORTCOLNAMEDESC, "TOK_TABSORTCOLNAMEDESC")
                , root_1);

                adaptor.addChild(root_1, stream_identifier.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameOrder"


    public static class columnNameCommentList_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameCommentList"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1707:1: columnNameCommentList : columnNameComment ( COMMA columnNameComment )* -> ^( TOK_TABCOLNAME ( columnNameComment )+ ) ;
    public final HiveParser.columnNameCommentList_return columnNameCommentList() throws RecognitionException {
        HiveParser.columnNameCommentList_return retval = new HiveParser.columnNameCommentList_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token COMMA662=null;
        HiveParser.columnNameComment_return columnNameComment661 =null;

        HiveParser.columnNameComment_return columnNameComment663 =null;


        CommonTree COMMA662_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_columnNameComment=new RewriteRuleSubtreeStream(adaptor,"rule columnNameComment");
         msgs.push("column name comment list"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1710:5: ( columnNameComment ( COMMA columnNameComment )* -> ^( TOK_TABCOLNAME ( columnNameComment )+ ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1710:7: columnNameComment ( COMMA columnNameComment )*
            {
            pushFollow(FOLLOW_columnNameComment_in_columnNameCommentList10327);
            columnNameComment661=columnNameComment();

            state._fsp--;

            stream_columnNameComment.add(columnNameComment661.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1710:25: ( COMMA columnNameComment )*
            loop179:
            do {
                int alt179=2;
                int LA179_0 = input.LA(1);

                if ( (LA179_0==COMMA) ) {
                    alt179=1;
                }


                switch (alt179) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1710:26: COMMA columnNameComment
            	    {
            	    COMMA662=(Token)match(input,COMMA,FOLLOW_COMMA_in_columnNameCommentList10330);  
            	    stream_COMMA.add(COMMA662);


            	    pushFollow(FOLLOW_columnNameComment_in_columnNameCommentList10332);
            	    columnNameComment663=columnNameComment();

            	    state._fsp--;

            	    stream_columnNameComment.add(columnNameComment663.getTree());

            	    }
            	    break;

            	default :
            	    break loop179;
                }
            } while (true);


            // AST REWRITE
            // elements: columnNameComment
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1710:52: -> ^( TOK_TABCOLNAME ( columnNameComment )+ )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1710:55: ^( TOK_TABCOLNAME ( columnNameComment )+ )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABCOLNAME, "TOK_TABCOLNAME")
                , root_1);

                if ( !(stream_columnNameComment.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_columnNameComment.hasNext() ) {
                    adaptor.addChild(root_1, stream_columnNameComment.nextTree());

                }
                stream_columnNameComment.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameCommentList"


    public static class columnNameComment_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameComment"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1713:1: columnNameComment : colName= identifier ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? ) ;
    public final HiveParser.columnNameComment_return columnNameComment() throws RecognitionException {
        HiveParser.columnNameComment_return retval = new HiveParser.columnNameComment_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token comment=null;
        Token KW_COMMENT664=null;
        HiveParser_IdentifiersParser.identifier_return colName =null;


        CommonTree comment_tree=null;
        CommonTree KW_COMMENT664_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("column name comment"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1716:5: (colName= identifier ( KW_COMMENT comment= StringLiteral )? -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1716:7: colName= identifier ( KW_COMMENT comment= StringLiteral )?
            {
            pushFollow(FOLLOW_identifier_in_columnNameComment10372);
            colName=identifier();

            state._fsp--;

            stream_identifier.add(colName.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1716:26: ( KW_COMMENT comment= StringLiteral )?
            int alt180=2;
            int LA180_0 = input.LA(1);

            if ( (LA180_0==KW_COMMENT) ) {
                alt180=1;
            }
            switch (alt180) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1716:27: KW_COMMENT comment= StringLiteral
                    {
                    KW_COMMENT664=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_columnNameComment10375);  
                    stream_KW_COMMENT.add(KW_COMMENT664);


                    comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_columnNameComment10379);  
                    stream_StringLiteral.add(comment);


                    }
                    break;

            }


            // AST REWRITE
            // elements: colName, comment
            // token labels: comment
            // rule labels: retval, colName
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1717:5: -> ^( TOK_TABCOL $colName TOK_NULL ( $comment)? )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1717:8: ^( TOK_TABCOL $colName TOK_NULL ( $comment)? )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABCOL, "TOK_TABCOL")
                , root_1);

                adaptor.addChild(root_1, stream_colName.nextTree());

                adaptor.addChild(root_1, 
                (CommonTree)adaptor.create(TOK_NULL, "TOK_NULL")
                );

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1717:40: ( $comment)?
                if ( stream_comment.hasNext() ) {
                    adaptor.addChild(root_1, stream_comment.nextNode());

                }
                stream_comment.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameComment"


    public static class columnRefOrder_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnRefOrder"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1720:1: columnRefOrder : expression (asc= KW_ASC |desc= KW_DESC )? -> {$desc == null}? ^( TOK_TABSORTCOLNAMEASC expression ) -> ^( TOK_TABSORTCOLNAMEDESC expression ) ;
    public final HiveParser.columnRefOrder_return columnRefOrder() throws RecognitionException {
        HiveParser.columnRefOrder_return retval = new HiveParser.columnRefOrder_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token asc=null;
        Token desc=null;
        HiveParser_IdentifiersParser.expression_return expression665 =null;


        CommonTree asc_tree=null;
        CommonTree desc_tree=null;
        RewriteRuleTokenStream stream_KW_DESC=new RewriteRuleTokenStream(adaptor,"token KW_DESC");
        RewriteRuleTokenStream stream_KW_ASC=new RewriteRuleTokenStream(adaptor,"token KW_ASC");
        RewriteRuleSubtreeStream stream_expression=new RewriteRuleSubtreeStream(adaptor,"rule expression");
         msgs.push("column order"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1723:5: ( expression (asc= KW_ASC |desc= KW_DESC )? -> {$desc == null}? ^( TOK_TABSORTCOLNAMEASC expression ) -> ^( TOK_TABSORTCOLNAMEDESC expression ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1723:7: expression (asc= KW_ASC |desc= KW_DESC )?
            {
            pushFollow(FOLLOW_expression_in_columnRefOrder10427);
            expression665=expression();

            state._fsp--;

            stream_expression.add(expression665.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1723:18: (asc= KW_ASC |desc= KW_DESC )?
            int alt181=3;
            int LA181_0 = input.LA(1);

            if ( (LA181_0==KW_ASC) ) {
                alt181=1;
            }
            else if ( (LA181_0==KW_DESC) ) {
                alt181=2;
            }
            switch (alt181) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1723:19: asc= KW_ASC
                    {
                    asc=(Token)match(input,KW_ASC,FOLLOW_KW_ASC_in_columnRefOrder10432);  
                    stream_KW_ASC.add(asc);


                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1723:32: desc= KW_DESC
                    {
                    desc=(Token)match(input,KW_DESC,FOLLOW_KW_DESC_in_columnRefOrder10438);  
                    stream_KW_DESC.add(desc);


                    }
                    break;

            }


            // AST REWRITE
            // elements: expression, expression
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1724:5: -> {$desc == null}? ^( TOK_TABSORTCOLNAMEASC expression )
            if (desc == null) {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1724:25: ^( TOK_TABSORTCOLNAMEASC expression )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABSORTCOLNAMEASC, "TOK_TABSORTCOLNAMEASC")
                , root_1);

                adaptor.addChild(root_1, stream_expression.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 1725:5: -> ^( TOK_TABSORTCOLNAMEDESC expression )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1725:25: ^( TOK_TABSORTCOLNAMEDESC expression )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABSORTCOLNAMEDESC, "TOK_TABSORTCOLNAMEDESC")
                , root_1);

                adaptor.addChild(root_1, stream_expression.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnRefOrder"


    public static class columnNameType_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameType"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1728:1: columnNameType : colName= identifier colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) ;
    public final HiveParser.columnNameType_return columnNameType() throws RecognitionException {
        HiveParser.columnNameType_return retval = new HiveParser.columnNameType_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token comment=null;
        Token KW_COMMENT667=null;
        HiveParser_IdentifiersParser.identifier_return colName =null;

        HiveParser.colType_return colType666 =null;


        CommonTree comment_tree=null;
        CommonTree KW_COMMENT667_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
        RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("column specification"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1731:5: (colName= identifier colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1731:7: colName= identifier colType ( KW_COMMENT comment= StringLiteral )?
            {
            pushFollow(FOLLOW_identifier_in_columnNameType10512);
            colName=identifier();

            state._fsp--;

            stream_identifier.add(colName.getTree());

            pushFollow(FOLLOW_colType_in_columnNameType10514);
            colType666=colType();

            state._fsp--;

            stream_colType.add(colType666.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1731:34: ( KW_COMMENT comment= StringLiteral )?
            int alt182=2;
            int LA182_0 = input.LA(1);

            if ( (LA182_0==KW_COMMENT) ) {
                alt182=1;
            }
            switch (alt182) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1731:35: KW_COMMENT comment= StringLiteral
                    {
                    KW_COMMENT667=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_columnNameType10517);  
                    stream_KW_COMMENT.add(KW_COMMENT667);


                    comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_columnNameType10521);  
                    stream_StringLiteral.add(comment);


                    }
                    break;

            }


            // AST REWRITE
            // elements: comment, colType, colName, colType, colName
            // token labels: comment
            // rule labels: retval, colName
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1732:5: -> {$comment == null}? ^( TOK_TABCOL $colName colType )
            if (comment == null) {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1732:28: ^( TOK_TABCOL $colName colType )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABCOL, "TOK_TABCOL")
                , root_1);

                adaptor.addChild(root_1, stream_colName.nextTree());

                adaptor.addChild(root_1, stream_colType.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 1733:5: -> ^( TOK_TABCOL $colName colType $comment)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1733:28: ^( TOK_TABCOL $colName colType $comment)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABCOL, "TOK_TABCOL")
                , root_1);

                adaptor.addChild(root_1, stream_colName.nextTree());

                adaptor.addChild(root_1, stream_colType.nextTree());

                adaptor.addChild(root_1, stream_comment.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameType"


    public static class columnNameColonType_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "columnNameColonType"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1736:1: columnNameColonType : colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) ;
    public final HiveParser.columnNameColonType_return columnNameColonType() throws RecognitionException {
        HiveParser.columnNameColonType_return retval = new HiveParser.columnNameColonType_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token comment=null;
        Token COLON668=null;
        Token KW_COMMENT670=null;
        HiveParser_IdentifiersParser.identifier_return colName =null;

        HiveParser.colType_return colType669 =null;


        CommonTree comment_tree=null;
        CommonTree COLON668_tree=null;
        CommonTree KW_COMMENT670_tree=null;
        RewriteRuleTokenStream stream_COLON=new RewriteRuleTokenStream(adaptor,"token COLON");
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_COMMENT=new RewriteRuleTokenStream(adaptor,"token KW_COMMENT");
        RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");
        RewriteRuleSubtreeStream stream_identifier=new RewriteRuleSubtreeStream(adaptor,"rule identifier");
         msgs.push("column specification"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1739:5: (colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )? -> {$comment == null}? ^( TOK_TABCOL $colName colType ) -> ^( TOK_TABCOL $colName colType $comment) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1739:7: colName= identifier COLON colType ( KW_COMMENT comment= StringLiteral )?
            {
            pushFollow(FOLLOW_identifier_in_columnNameColonType10607);
            colName=identifier();

            state._fsp--;

            stream_identifier.add(colName.getTree());

            COLON668=(Token)match(input,COLON,FOLLOW_COLON_in_columnNameColonType10609);  
            stream_COLON.add(COLON668);


            pushFollow(FOLLOW_colType_in_columnNameColonType10611);
            colType669=colType();

            state._fsp--;

            stream_colType.add(colType669.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1739:40: ( KW_COMMENT comment= StringLiteral )?
            int alt183=2;
            int LA183_0 = input.LA(1);

            if ( (LA183_0==KW_COMMENT) ) {
                alt183=1;
            }
            switch (alt183) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1739:41: KW_COMMENT comment= StringLiteral
                    {
                    KW_COMMENT670=(Token)match(input,KW_COMMENT,FOLLOW_KW_COMMENT_in_columnNameColonType10614);  
                    stream_KW_COMMENT.add(KW_COMMENT670);


                    comment=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_columnNameColonType10618);  
                    stream_StringLiteral.add(comment);


                    }
                    break;

            }


            // AST REWRITE
            // elements: colName, colName, comment, colType, colType
            // token labels: comment
            // rule labels: retval, colName
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_comment=new RewriteRuleTokenStream(adaptor,"token comment",comment);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_colName=new RewriteRuleSubtreeStream(adaptor,"rule colName",colName!=null?colName.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1740:5: -> {$comment == null}? ^( TOK_TABCOL $colName colType )
            if (comment == null) {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1740:28: ^( TOK_TABCOL $colName colType )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABCOL, "TOK_TABCOL")
                , root_1);

                adaptor.addChild(root_1, stream_colName.nextTree());

                adaptor.addChild(root_1, stream_colType.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }

            else // 1741:5: -> ^( TOK_TABCOL $colName colType $comment)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1741:28: ^( TOK_TABCOL $colName colType $comment)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_TABCOL, "TOK_TABCOL")
                , root_1);

                adaptor.addChild(root_1, stream_colName.nextTree());

                adaptor.addChild(root_1, stream_colType.nextTree());

                adaptor.addChild(root_1, stream_comment.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "columnNameColonType"


    public static class colType_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "colType"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1744:1: colType : type ;
    public final HiveParser.colType_return colType() throws RecognitionException {
        HiveParser.colType_return retval = new HiveParser.colType_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser.type_return type671 =null;



         msgs.push("column type"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1747:5: ( type )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1747:7: type
            {
            root_0 = (CommonTree)adaptor.nil();


            pushFollow(FOLLOW_type_in_colType10702);
            type671=type();

            state._fsp--;

            adaptor.addChild(root_0, type671.getTree());

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "colType"


    public static class colTypeList_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "colTypeList"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1750:1: colTypeList : colType ( COMMA colType )* -> ^( TOK_COLTYPELIST ( colType )+ ) ;
    public final HiveParser.colTypeList_return colTypeList() throws RecognitionException {
        HiveParser.colTypeList_return retval = new HiveParser.colTypeList_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token COMMA673=null;
        HiveParser.colType_return colType672 =null;

        HiveParser.colType_return colType674 =null;


        CommonTree COMMA673_tree=null;
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleSubtreeStream stream_colType=new RewriteRuleSubtreeStream(adaptor,"rule colType");
         msgs.push("column type list"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1753:5: ( colType ( COMMA colType )* -> ^( TOK_COLTYPELIST ( colType )+ ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1753:7: colType ( COMMA colType )*
            {
            pushFollow(FOLLOW_colType_in_colTypeList10729);
            colType672=colType();

            state._fsp--;

            stream_colType.add(colType672.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1753:15: ( COMMA colType )*
            loop184:
            do {
                int alt184=2;
                int LA184_0 = input.LA(1);

                if ( (LA184_0==COMMA) ) {
                    alt184=1;
                }


                switch (alt184) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1753:16: COMMA colType
            	    {
            	    COMMA673=(Token)match(input,COMMA,FOLLOW_COMMA_in_colTypeList10732);  
            	    stream_COMMA.add(COMMA673);


            	    pushFollow(FOLLOW_colType_in_colTypeList10734);
            	    colType674=colType();

            	    state._fsp--;

            	    stream_colType.add(colType674.getTree());

            	    }
            	    break;

            	default :
            	    break loop184;
                }
            } while (true);


            // AST REWRITE
            // elements: colType
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1753:32: -> ^( TOK_COLTYPELIST ( colType )+ )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1753:35: ^( TOK_COLTYPELIST ( colType )+ )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_COLTYPELIST, "TOK_COLTYPELIST")
                , root_1);

                if ( !(stream_colType.hasNext()) ) {
                    throw new RewriteEarlyExitException();
                }
                while ( stream_colType.hasNext() ) {
                    adaptor.addChild(root_1, stream_colType.nextTree());

                }
                stream_colType.reset();

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "colTypeList"


    public static class type_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "type"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1756:1: type : ( primitiveType | listType | structType | mapType | unionType );
    public final HiveParser.type_return type() throws RecognitionException {
        HiveParser.type_return retval = new HiveParser.type_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser.primitiveType_return primitiveType675 =null;

        HiveParser.listType_return listType676 =null;

        HiveParser.structType_return structType677 =null;

        HiveParser.mapType_return mapType678 =null;

        HiveParser.unionType_return unionType679 =null;



        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1757:5: ( primitiveType | listType | structType | mapType | unionType )
            int alt185=5;
            switch ( input.LA(1) ) {
            case KW_BIGINT:
            case KW_BINARY:
            case KW_BOOLEAN:
            case KW_DATE:
            case KW_DATETIME:
            case KW_DECIMAL:
            case KW_DOUBLE:
            case KW_FLOAT:
            case KW_INT:
            case KW_SMALLINT:
            case KW_STRING:
            case KW_TIMESTAMP:
            case KW_TINYINT:
            case KW_VARCHAR:
                {
                alt185=1;
                }
                break;
            case KW_ARRAY:
                {
                alt185=2;
                }
                break;
            case KW_STRUCT:
                {
                alt185=3;
                }
                break;
            case KW_MAP:
                {
                alt185=4;
                }
                break;
            case KW_UNIONTYPE:
                {
                alt185=5;
                }
                break;
            default:
                NoViableAltException nvae =
                    new NoViableAltException("", 185, 0, input);

                throw nvae;

            }

            switch (alt185) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1757:7: primitiveType
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_primitiveType_in_type10762);
                    primitiveType675=primitiveType();

                    state._fsp--;

                    adaptor.addChild(root_0, primitiveType675.getTree());

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1758:7: listType
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_listType_in_type10770);
                    listType676=listType();

                    state._fsp--;

                    adaptor.addChild(root_0, listType676.getTree());

                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1759:7: structType
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_structType_in_type10778);
                    structType677=structType();

                    state._fsp--;

                    adaptor.addChild(root_0, structType677.getTree());

                    }
                    break;
                case 4 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1760:7: mapType
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_mapType_in_type10786);
                    mapType678=mapType();

                    state._fsp--;

                    adaptor.addChild(root_0, mapType678.getTree());

                    }
                    break;
                case 5 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1761:7: unionType
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_unionType_in_type10794);
                    unionType679=unionType();

                    state._fsp--;

                    adaptor.addChild(root_0, unionType679.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "type"


    public static class primitiveType_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "primitiveType"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1763:1: primitiveType : ( KW_TINYINT -> TOK_TINYINT | KW_SMALLINT -> TOK_SMALLINT | KW_INT -> TOK_INT | KW_BIGINT -> TOK_BIGINT | KW_BOOLEAN -> TOK_BOOLEAN | KW_FLOAT -> TOK_FLOAT | KW_DOUBLE -> TOK_DOUBLE | KW_DATE -> TOK_DATE | KW_DATETIME -> TOK_DATETIME | KW_TIMESTAMP -> TOK_TIMESTAMP | KW_STRING -> TOK_STRING | KW_BINARY -> TOK_BINARY | KW_DECIMAL -> TOK_DECIMAL | KW_VARCHAR LPAREN length= Number RPAREN -> ^( TOK_VARCHAR $length) );
    public final HiveParser.primitiveType_return primitiveType() throws RecognitionException {
        HiveParser.primitiveType_return retval = new HiveParser.primitiveType_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token length=null;
        Token KW_TINYINT680=null;
        Token KW_SMALLINT681=null;
        Token KW_INT682=null;
        Token KW_BIGINT683=null;
        Token KW_BOOLEAN684=null;
        Token KW_FLOAT685=null;
        Token KW_DOUBLE686=null;
        Token KW_DATE687=null;
        Token KW_DATETIME688=null;
        Token KW_TIMESTAMP689=null;
        Token KW_STRING690=null;
        Token KW_BINARY691=null;
        Token KW_DECIMAL692=null;
        Token KW_VARCHAR693=null;
        Token LPAREN694=null;
        Token RPAREN695=null;

        CommonTree length_tree=null;
        CommonTree KW_TINYINT680_tree=null;
        CommonTree KW_SMALLINT681_tree=null;
        CommonTree KW_INT682_tree=null;
        CommonTree KW_BIGINT683_tree=null;
        CommonTree KW_BOOLEAN684_tree=null;
        CommonTree KW_FLOAT685_tree=null;
        CommonTree KW_DOUBLE686_tree=null;
        CommonTree KW_DATE687_tree=null;
        CommonTree KW_DATETIME688_tree=null;
        CommonTree KW_TIMESTAMP689_tree=null;
        CommonTree KW_STRING690_tree=null;
        CommonTree KW_BINARY691_tree=null;
        CommonTree KW_DECIMAL692_tree=null;
        CommonTree KW_VARCHAR693_tree=null;
        CommonTree LPAREN694_tree=null;
        CommonTree RPAREN695_tree=null;
        RewriteRuleTokenStream stream_KW_DATETIME=new RewriteRuleTokenStream(adaptor,"token KW_DATETIME");
        RewriteRuleTokenStream stream_KW_VARCHAR=new RewriteRuleTokenStream(adaptor,"token KW_VARCHAR");
        RewriteRuleTokenStream stream_RPAREN=new RewriteRuleTokenStream(adaptor,"token RPAREN");
        RewriteRuleTokenStream stream_KW_DATE=new RewriteRuleTokenStream(adaptor,"token KW_DATE");
        RewriteRuleTokenStream stream_KW_TIMESTAMP=new RewriteRuleTokenStream(adaptor,"token KW_TIMESTAMP");
        RewriteRuleTokenStream stream_KW_STRING=new RewriteRuleTokenStream(adaptor,"token KW_STRING");
        RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
        RewriteRuleTokenStream stream_KW_SMALLINT=new RewriteRuleTokenStream(adaptor,"token KW_SMALLINT");
        RewriteRuleTokenStream stream_KW_INT=new RewriteRuleTokenStream(adaptor,"token KW_INT");
        RewriteRuleTokenStream stream_KW_BINARY=new RewriteRuleTokenStream(adaptor,"token KW_BINARY");
        RewriteRuleTokenStream stream_KW_DECIMAL=new RewriteRuleTokenStream(adaptor,"token KW_DECIMAL");
        RewriteRuleTokenStream stream_KW_BOOLEAN=new RewriteRuleTokenStream(adaptor,"token KW_BOOLEAN");
        RewriteRuleTokenStream stream_KW_FLOAT=new RewriteRuleTokenStream(adaptor,"token KW_FLOAT");
        RewriteRuleTokenStream stream_KW_DOUBLE=new RewriteRuleTokenStream(adaptor,"token KW_DOUBLE");
        RewriteRuleTokenStream stream_LPAREN=new RewriteRuleTokenStream(adaptor,"token LPAREN");
        RewriteRuleTokenStream stream_KW_BIGINT=new RewriteRuleTokenStream(adaptor,"token KW_BIGINT");
        RewriteRuleTokenStream stream_KW_TINYINT=new RewriteRuleTokenStream(adaptor,"token KW_TINYINT");

         msgs.push("primitive type specification"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1766:5: ( KW_TINYINT -> TOK_TINYINT | KW_SMALLINT -> TOK_SMALLINT | KW_INT -> TOK_INT | KW_BIGINT -> TOK_BIGINT | KW_BOOLEAN -> TOK_BOOLEAN | KW_FLOAT -> TOK_FLOAT | KW_DOUBLE -> TOK_DOUBLE | KW_DATE -> TOK_DATE | KW_DATETIME -> TOK_DATETIME | KW_TIMESTAMP -> TOK_TIMESTAMP | KW_STRING -> TOK_STRING | KW_BINARY -> TOK_BINARY | KW_DECIMAL -> TOK_DECIMAL | KW_VARCHAR LPAREN length= Number RPAREN -> ^( TOK_VARCHAR $length) )
            int alt186=14;
            switch ( input.LA(1) ) {
            case KW_TINYINT:
                {
                alt186=1;
                }
                break;
            case KW_SMALLINT:
                {
                alt186=2;
                }
                break;
            case KW_INT:
                {
                alt186=3;
                }
                break;
            case KW_BIGINT:
                {
                alt186=4;
                }
                break;
            case KW_BOOLEAN:
                {
                alt186=5;
                }
                break;
            case KW_FLOAT:
                {
                alt186=6;
                }
                break;
            case KW_DOUBLE:
                {
                alt186=7;
                }
                break;
            case KW_DATE:
                {
                alt186=8;
                }
                break;
            case KW_DATETIME:
                {
                alt186=9;
                }
                break;
            case KW_TIMESTAMP:
                {
                alt186=10;
                }
                break;
            case KW_STRING:
                {
                alt186=11;
                }
                break;
            case KW_BINARY:
                {
                alt186=12;
                }
                break;
            case KW_DECIMAL:
                {
                alt186=13;
                }
                break;
            case KW_VARCHAR:
                {
                alt186=14;
                }
                break;
            default:
                NoViableAltException nvae =
                    new NoViableAltException("", 186, 0, input);

                throw nvae;

            }

            switch (alt186) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1766:7: KW_TINYINT
                    {
                    KW_TINYINT680=(Token)match(input,KW_TINYINT,FOLLOW_KW_TINYINT_in_primitiveType10816);  
                    stream_KW_TINYINT.add(KW_TINYINT680);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1766:24: -> TOK_TINYINT
                    {
                        adaptor.addChild(root_0, 
                        (CommonTree)adaptor.create(TOK_TINYINT, "TOK_TINYINT")
                        );

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1767:7: KW_SMALLINT
                    {
                    KW_SMALLINT681=(Token)match(input,KW_SMALLINT,FOLLOW_KW_SMALLINT_in_primitiveType10837);  
                    stream_KW_SMALLINT.add(KW_SMALLINT681);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1767:24: -> TOK_SMALLINT
                    {
                        adaptor.addChild(root_0, 
                        (CommonTree)adaptor.create(TOK_SMALLINT, "TOK_SMALLINT")
                        );

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1768:7: KW_INT
                    {
                    KW_INT682=(Token)match(input,KW_INT,FOLLOW_KW_INT_in_primitiveType10857);  
                    stream_KW_INT.add(KW_INT682);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1768:24: -> TOK_INT
                    {
                        adaptor.addChild(root_0, 
                        (CommonTree)adaptor.create(TOK_INT, "TOK_INT")
                        );

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 4 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1769:7: KW_BIGINT
                    {
                    KW_BIGINT683=(Token)match(input,KW_BIGINT,FOLLOW_KW_BIGINT_in_primitiveType10882);  
                    stream_KW_BIGINT.add(KW_BIGINT683);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1769:24: -> TOK_BIGINT
                    {
                        adaptor.addChild(root_0, 
                        (CommonTree)adaptor.create(TOK_BIGINT, "TOK_BIGINT")
                        );

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 5 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1770:7: KW_BOOLEAN
                    {
                    KW_BOOLEAN684=(Token)match(input,KW_BOOLEAN,FOLLOW_KW_BOOLEAN_in_primitiveType10904);  
                    stream_KW_BOOLEAN.add(KW_BOOLEAN684);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1770:24: -> TOK_BOOLEAN
                    {
                        adaptor.addChild(root_0, 
                        (CommonTree)adaptor.create(TOK_BOOLEAN, "TOK_BOOLEAN")
                        );

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 6 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1771:7: KW_FLOAT
                    {
                    KW_FLOAT685=(Token)match(input,KW_FLOAT,FOLLOW_KW_FLOAT_in_primitiveType10925);  
                    stream_KW_FLOAT.add(KW_FLOAT685);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1771:24: -> TOK_FLOAT
                    {
                        adaptor.addChild(root_0, 
                        (CommonTree)adaptor.create(TOK_FLOAT, "TOK_FLOAT")
                        );

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 7 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1772:7: KW_DOUBLE
                    {
                    KW_DOUBLE686=(Token)match(input,KW_DOUBLE,FOLLOW_KW_DOUBLE_in_primitiveType10948);  
                    stream_KW_DOUBLE.add(KW_DOUBLE686);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1772:24: -> TOK_DOUBLE
                    {
                        adaptor.addChild(root_0, 
                        (CommonTree)adaptor.create(TOK_DOUBLE, "TOK_DOUBLE")
                        );

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 8 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1773:7: KW_DATE
                    {
                    KW_DATE687=(Token)match(input,KW_DATE,FOLLOW_KW_DATE_in_primitiveType10970);  
                    stream_KW_DATE.add(KW_DATE687);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1773:24: -> TOK_DATE
                    {
                        adaptor.addChild(root_0, 
                        (CommonTree)adaptor.create(TOK_DATE, "TOK_DATE")
                        );

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 9 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1774:7: KW_DATETIME
                    {
                    KW_DATETIME688=(Token)match(input,KW_DATETIME,FOLLOW_KW_DATETIME_in_primitiveType10994);  
                    stream_KW_DATETIME.add(KW_DATETIME688);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1774:24: -> TOK_DATETIME
                    {
                        adaptor.addChild(root_0, 
                        (CommonTree)adaptor.create(TOK_DATETIME, "TOK_DATETIME")
                        );

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 10 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1775:7: KW_TIMESTAMP
                    {
                    KW_TIMESTAMP689=(Token)match(input,KW_TIMESTAMP,FOLLOW_KW_TIMESTAMP_in_primitiveType11014);  
                    stream_KW_TIMESTAMP.add(KW_TIMESTAMP689);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1775:24: -> TOK_TIMESTAMP
                    {
                        adaptor.addChild(root_0, 
                        (CommonTree)adaptor.create(TOK_TIMESTAMP, "TOK_TIMESTAMP")
                        );

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 11 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1776:7: KW_STRING
                    {
                    KW_STRING690=(Token)match(input,KW_STRING,FOLLOW_KW_STRING_in_primitiveType11033);  
                    stream_KW_STRING.add(KW_STRING690);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1776:24: -> TOK_STRING
                    {
                        adaptor.addChild(root_0, 
                        (CommonTree)adaptor.create(TOK_STRING, "TOK_STRING")
                        );

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 12 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1777:7: KW_BINARY
                    {
                    KW_BINARY691=(Token)match(input,KW_BINARY,FOLLOW_KW_BINARY_in_primitiveType11055);  
                    stream_KW_BINARY.add(KW_BINARY691);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1777:24: -> TOK_BINARY
                    {
                        adaptor.addChild(root_0, 
                        (CommonTree)adaptor.create(TOK_BINARY, "TOK_BINARY")
                        );

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 13 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1778:7: KW_DECIMAL
                    {
                    KW_DECIMAL692=(Token)match(input,KW_DECIMAL,FOLLOW_KW_DECIMAL_in_primitiveType11077);  
                    stream_KW_DECIMAL.add(KW_DECIMAL692);


                    // AST REWRITE
                    // elements: 
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1778:24: -> TOK_DECIMAL
                    {
                        adaptor.addChild(root_0, 
                        (CommonTree)adaptor.create(TOK_DECIMAL, "TOK_DECIMAL")
                        );

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 14 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1779:7: KW_VARCHAR LPAREN length= Number RPAREN
                    {
                    KW_VARCHAR693=(Token)match(input,KW_VARCHAR,FOLLOW_KW_VARCHAR_in_primitiveType11098);  
                    stream_KW_VARCHAR.add(KW_VARCHAR693);


                    LPAREN694=(Token)match(input,LPAREN,FOLLOW_LPAREN_in_primitiveType11100);  
                    stream_LPAREN.add(LPAREN694);


                    length=(Token)match(input,Number,FOLLOW_Number_in_primitiveType11104);  
                    stream_Number.add(length);


                    RPAREN695=(Token)match(input,RPAREN,FOLLOW_RPAREN_in_primitiveType11106);  
                    stream_RPAREN.add(RPAREN695);


                    // AST REWRITE
                    // elements: length
                    // token labels: length
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleTokenStream stream_length=new RewriteRuleTokenStream(adaptor,"token length",length);
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1779:51: -> ^( TOK_VARCHAR $length)
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1779:57: ^( TOK_VARCHAR $length)
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_VARCHAR, "TOK_VARCHAR")
                        , root_1);

                        adaptor.addChild(root_1, stream_length.nextNode());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "primitiveType"


    public static class listType_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "listType"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1782:1: listType : KW_ARRAY LESSTHAN type GREATERTHAN -> ^( TOK_LIST type ) ;
    public final HiveParser.listType_return listType() throws RecognitionException {
        HiveParser.listType_return retval = new HiveParser.listType_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_ARRAY696=null;
        Token LESSTHAN697=null;
        Token GREATERTHAN699=null;
        HiveParser.type_return type698 =null;


        CommonTree KW_ARRAY696_tree=null;
        CommonTree LESSTHAN697_tree=null;
        CommonTree GREATERTHAN699_tree=null;
        RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
        RewriteRuleTokenStream stream_KW_ARRAY=new RewriteRuleTokenStream(adaptor,"token KW_ARRAY");
        RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
        RewriteRuleSubtreeStream stream_type=new RewriteRuleSubtreeStream(adaptor,"rule type");
         msgs.push("list type"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1785:5: ( KW_ARRAY LESSTHAN type GREATERTHAN -> ^( TOK_LIST type ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1785:7: KW_ARRAY LESSTHAN type GREATERTHAN
            {
            KW_ARRAY696=(Token)match(input,KW_ARRAY,FOLLOW_KW_ARRAY_in_listType11150);  
            stream_KW_ARRAY.add(KW_ARRAY696);


            LESSTHAN697=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_listType11152);  
            stream_LESSTHAN.add(LESSTHAN697);


            pushFollow(FOLLOW_type_in_listType11154);
            type698=type();

            state._fsp--;

            stream_type.add(type698.getTree());

            GREATERTHAN699=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_listType11156);  
            stream_GREATERTHAN.add(GREATERTHAN699);


            // AST REWRITE
            // elements: type
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1785:44: -> ^( TOK_LIST type )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1785:47: ^( TOK_LIST type )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_LIST, "TOK_LIST")
                , root_1);

                adaptor.addChild(root_1, stream_type.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "listType"


    public static class structType_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "structType"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1788:1: structType : KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN -> ^( TOK_STRUCT columnNameColonTypeList ) ;
    public final HiveParser.structType_return structType() throws RecognitionException {
        HiveParser.structType_return retval = new HiveParser.structType_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_STRUCT700=null;
        Token LESSTHAN701=null;
        Token GREATERTHAN703=null;
        HiveParser.columnNameColonTypeList_return columnNameColonTypeList702 =null;


        CommonTree KW_STRUCT700_tree=null;
        CommonTree LESSTHAN701_tree=null;
        CommonTree GREATERTHAN703_tree=null;
        RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
        RewriteRuleTokenStream stream_KW_STRUCT=new RewriteRuleTokenStream(adaptor,"token KW_STRUCT");
        RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
        RewriteRuleSubtreeStream stream_columnNameColonTypeList=new RewriteRuleSubtreeStream(adaptor,"rule columnNameColonTypeList");
         msgs.push("struct type"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1791:5: ( KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN -> ^( TOK_STRUCT columnNameColonTypeList ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1791:7: KW_STRUCT LESSTHAN columnNameColonTypeList GREATERTHAN
            {
            KW_STRUCT700=(Token)match(input,KW_STRUCT,FOLLOW_KW_STRUCT_in_structType11193);  
            stream_KW_STRUCT.add(KW_STRUCT700);


            LESSTHAN701=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_structType11195);  
            stream_LESSTHAN.add(LESSTHAN701);


            pushFollow(FOLLOW_columnNameColonTypeList_in_structType11197);
            columnNameColonTypeList702=columnNameColonTypeList();

            state._fsp--;

            stream_columnNameColonTypeList.add(columnNameColonTypeList702.getTree());

            GREATERTHAN703=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_structType11199);  
            stream_GREATERTHAN.add(GREATERTHAN703);


            // AST REWRITE
            // elements: columnNameColonTypeList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1791:62: -> ^( TOK_STRUCT columnNameColonTypeList )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1791:65: ^( TOK_STRUCT columnNameColonTypeList )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_STRUCT, "TOK_STRUCT")
                , root_1);

                adaptor.addChild(root_1, stream_columnNameColonTypeList.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "structType"


    public static class mapType_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "mapType"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1794:1: mapType : KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN -> ^( TOK_MAP $left $right) ;
    public final HiveParser.mapType_return mapType() throws RecognitionException {
        HiveParser.mapType_return retval = new HiveParser.mapType_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_MAP704=null;
        Token LESSTHAN705=null;
        Token COMMA706=null;
        Token GREATERTHAN707=null;
        HiveParser.primitiveType_return left =null;

        HiveParser.type_return right =null;


        CommonTree KW_MAP704_tree=null;
        CommonTree LESSTHAN705_tree=null;
        CommonTree COMMA706_tree=null;
        CommonTree GREATERTHAN707_tree=null;
        RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
        RewriteRuleTokenStream stream_KW_MAP=new RewriteRuleTokenStream(adaptor,"token KW_MAP");
        RewriteRuleTokenStream stream_COMMA=new RewriteRuleTokenStream(adaptor,"token COMMA");
        RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
        RewriteRuleSubtreeStream stream_primitiveType=new RewriteRuleSubtreeStream(adaptor,"rule primitiveType");
        RewriteRuleSubtreeStream stream_type=new RewriteRuleSubtreeStream(adaptor,"rule type");
         msgs.push("map type"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1797:5: ( KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN -> ^( TOK_MAP $left $right) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1797:7: KW_MAP LESSTHAN left= primitiveType COMMA right= type GREATERTHAN
            {
            KW_MAP704=(Token)match(input,KW_MAP,FOLLOW_KW_MAP_in_mapType11234);  
            stream_KW_MAP.add(KW_MAP704);


            LESSTHAN705=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_mapType11236);  
            stream_LESSTHAN.add(LESSTHAN705);


            pushFollow(FOLLOW_primitiveType_in_mapType11240);
            left=primitiveType();

            state._fsp--;

            stream_primitiveType.add(left.getTree());

            COMMA706=(Token)match(input,COMMA,FOLLOW_COMMA_in_mapType11242);  
            stream_COMMA.add(COMMA706);


            pushFollow(FOLLOW_type_in_mapType11246);
            right=type();

            state._fsp--;

            stream_type.add(right.getTree());

            GREATERTHAN707=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_mapType11248);  
            stream_GREATERTHAN.add(GREATERTHAN707);


            // AST REWRITE
            // elements: left, right
            // token labels: 
            // rule labels: retval, left, right
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);
            RewriteRuleSubtreeStream stream_left=new RewriteRuleSubtreeStream(adaptor,"rule left",left!=null?left.tree:null);
            RewriteRuleSubtreeStream stream_right=new RewriteRuleSubtreeStream(adaptor,"rule right",right!=null?right.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1798:5: -> ^( TOK_MAP $left $right)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1798:8: ^( TOK_MAP $left $right)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_MAP, "TOK_MAP")
                , root_1);

                adaptor.addChild(root_1, stream_left.nextTree());

                adaptor.addChild(root_1, stream_right.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "mapType"


    public static class unionType_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "unionType"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1801:1: unionType : KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN -> ^( TOK_UNIONTYPE colTypeList ) ;
    public final HiveParser.unionType_return unionType() throws RecognitionException {
        HiveParser.unionType_return retval = new HiveParser.unionType_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_UNIONTYPE708=null;
        Token LESSTHAN709=null;
        Token GREATERTHAN711=null;
        HiveParser.colTypeList_return colTypeList710 =null;


        CommonTree KW_UNIONTYPE708_tree=null;
        CommonTree LESSTHAN709_tree=null;
        CommonTree GREATERTHAN711_tree=null;
        RewriteRuleTokenStream stream_LESSTHAN=new RewriteRuleTokenStream(adaptor,"token LESSTHAN");
        RewriteRuleTokenStream stream_KW_UNIONTYPE=new RewriteRuleTokenStream(adaptor,"token KW_UNIONTYPE");
        RewriteRuleTokenStream stream_GREATERTHAN=new RewriteRuleTokenStream(adaptor,"token GREATERTHAN");
        RewriteRuleSubtreeStream stream_colTypeList=new RewriteRuleSubtreeStream(adaptor,"rule colTypeList");
         msgs.push("uniontype type"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1804:5: ( KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN -> ^( TOK_UNIONTYPE colTypeList ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1804:7: KW_UNIONTYPE LESSTHAN colTypeList GREATERTHAN
            {
            KW_UNIONTYPE708=(Token)match(input,KW_UNIONTYPE,FOLLOW_KW_UNIONTYPE_in_unionType11291);  
            stream_KW_UNIONTYPE.add(KW_UNIONTYPE708);


            LESSTHAN709=(Token)match(input,LESSTHAN,FOLLOW_LESSTHAN_in_unionType11293);  
            stream_LESSTHAN.add(LESSTHAN709);


            pushFollow(FOLLOW_colTypeList_in_unionType11295);
            colTypeList710=colTypeList();

            state._fsp--;

            stream_colTypeList.add(colTypeList710.getTree());

            GREATERTHAN711=(Token)match(input,GREATERTHAN,FOLLOW_GREATERTHAN_in_unionType11297);  
            stream_GREATERTHAN.add(GREATERTHAN711);


            // AST REWRITE
            // elements: colTypeList
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1804:53: -> ^( TOK_UNIONTYPE colTypeList )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1804:56: ^( TOK_UNIONTYPE colTypeList )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_UNIONTYPE, "TOK_UNIONTYPE")
                , root_1);

                adaptor.addChild(root_1, stream_colTypeList.nextTree());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "unionType"


    public static class queryOperator_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "queryOperator"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1807:1: queryOperator : KW_UNION KW_ALL -> ^( TOK_UNION ) ;
    public final HiveParser.queryOperator_return queryOperator() throws RecognitionException {
        HiveParser.queryOperator_return retval = new HiveParser.queryOperator_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_UNION712=null;
        Token KW_ALL713=null;

        CommonTree KW_UNION712_tree=null;
        CommonTree KW_ALL713_tree=null;
        RewriteRuleTokenStream stream_KW_ALL=new RewriteRuleTokenStream(adaptor,"token KW_ALL");
        RewriteRuleTokenStream stream_KW_UNION=new RewriteRuleTokenStream(adaptor,"token KW_UNION");

         msgs.push("query operator"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1810:5: ( KW_UNION KW_ALL -> ^( TOK_UNION ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1810:7: KW_UNION KW_ALL
            {
            KW_UNION712=(Token)match(input,KW_UNION,FOLLOW_KW_UNION_in_queryOperator11332);  
            stream_KW_UNION.add(KW_UNION712);


            KW_ALL713=(Token)match(input,KW_ALL,FOLLOW_KW_ALL_in_queryOperator11334);  
            stream_KW_ALL.add(KW_ALL713);


            // AST REWRITE
            // elements: 
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1810:23: -> ^( TOK_UNION )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1810:26: ^( TOK_UNION )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_UNION, "TOK_UNION")
                , root_1);

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "queryOperator"


    public static class queryStatementExpression_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "queryStatementExpression"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1814:1: queryStatementExpression : queryStatement ( queryOperator ^ queryStatement )* ;
    public final HiveParser.queryStatementExpression_return queryStatementExpression() throws RecognitionException {
        HiveParser.queryStatementExpression_return retval = new HiveParser.queryStatementExpression_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser.queryStatement_return queryStatement714 =null;

        HiveParser.queryOperator_return queryOperator715 =null;

        HiveParser.queryStatement_return queryStatement716 =null;



        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1815:5: ( queryStatement ( queryOperator ^ queryStatement )* )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1815:7: queryStatement ( queryOperator ^ queryStatement )*
            {
            root_0 = (CommonTree)adaptor.nil();


            pushFollow(FOLLOW_queryStatement_in_queryStatementExpression11358);
            queryStatement714=queryStatement();

            state._fsp--;

            adaptor.addChild(root_0, queryStatement714.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1815:22: ( queryOperator ^ queryStatement )*
            loop187:
            do {
                int alt187=2;
                int LA187_0 = input.LA(1);

                if ( (LA187_0==KW_UNION) ) {
                    alt187=1;
                }


                switch (alt187) {
            	case 1 :
            	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1815:23: queryOperator ^ queryStatement
            	    {
            	    pushFollow(FOLLOW_queryOperator_in_queryStatementExpression11361);
            	    queryOperator715=queryOperator();

            	    state._fsp--;

            	    root_0 = (CommonTree)adaptor.becomeRoot(queryOperator715.getTree(), root_0);

            	    pushFollow(FOLLOW_queryStatement_in_queryStatementExpression11364);
            	    queryStatement716=queryStatement();

            	    state._fsp--;

            	    adaptor.addChild(root_0, queryStatement716.getTree());

            	    }
            	    break;

            	default :
            	    break loop187;
                }
            } while (true);


            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "queryStatementExpression"


    public static class queryStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "queryStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1818:1: queryStatement : ( fromClause (b+= body )+ -> ^( TOK_QUERY fromClause ( body )+ ) | regular_body );
    public final HiveParser.queryStatement_return queryStatement() throws RecognitionException {
        HiveParser.queryStatement_return retval = new HiveParser.queryStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        List list_b=null;
        HiveParser_FromClauseParser.fromClause_return fromClause717 =null;

        HiveParser.regular_body_return regular_body718 =null;

        RuleReturnScope b = null;
        RewriteRuleSubtreeStream stream_body=new RewriteRuleSubtreeStream(adaptor,"rule body");
        RewriteRuleSubtreeStream stream_fromClause=new RewriteRuleSubtreeStream(adaptor,"rule fromClause");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1819:5: ( fromClause (b+= body )+ -> ^( TOK_QUERY fromClause ( body )+ ) | regular_body )
            int alt189=2;
            int LA189_0 = input.LA(1);

            if ( (LA189_0==KW_FROM) ) {
                alt189=1;
            }
            else if ( (LA189_0==KW_INSERT||LA189_0==KW_MAP||LA189_0==KW_REDUCE||LA189_0==KW_SELECT) ) {
                alt189=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 189, 0, input);

                throw nvae;

            }
            switch (alt189) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1820:5: fromClause (b+= body )+
                    {
                    pushFollow(FOLLOW_fromClause_in_queryStatement11387);
                    fromClause717=fromClause();

                    state._fsp--;

                    stream_fromClause.add(fromClause717.getTree());

                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1821:5: (b+= body )+
                    int cnt188=0;
                    loop188:
                    do {
                        int alt188=2;
                        int LA188_0 = input.LA(1);

                        if ( (LA188_0==KW_INSERT||LA188_0==KW_MAP||LA188_0==KW_REDUCE||LA188_0==KW_SELECT) ) {
                            alt188=1;
                        }


                        switch (alt188) {
                    	case 1 :
                    	    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1821:7: b+= body
                    	    {
                    	    pushFollow(FOLLOW_body_in_queryStatement11397);
                    	    b=body();

                    	    state._fsp--;

                    	    stream_body.add(b.getTree());
                    	    if (list_b==null) list_b=new ArrayList();
                    	    list_b.add(b.getTree());


                    	    }
                    	    break;

                    	default :
                    	    if ( cnt188 >= 1 ) break loop188;
                                EarlyExitException eee =
                                    new EarlyExitException(188, input);
                                throw eee;
                        }
                        cnt188++;
                    } while (true);


                    // AST REWRITE
                    // elements: fromClause, body
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1821:18: -> ^( TOK_QUERY fromClause ( body )+ )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1821:21: ^( TOK_QUERY fromClause ( body )+ )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_QUERY, "TOK_QUERY")
                        , root_1);

                        adaptor.addChild(root_1, stream_fromClause.nextTree());

                        if ( !(stream_body.hasNext()) ) {
                            throw new RewriteEarlyExitException();
                        }
                        while ( stream_body.hasNext() ) {
                            adaptor.addChild(root_1, stream_body.nextTree());

                        }
                        stream_body.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1822:7: regular_body
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_regular_body_in_queryStatement11419);
                    regular_body718=regular_body();

                    state._fsp--;

                    adaptor.addChild(root_0, regular_body718.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "queryStatement"


    public static class regular_body_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "regular_body"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1825:1: regular_body : ( insertClause selectClause fromClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_QUERY fromClause ^( TOK_INSERT insertClause selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) ) | selectStatement );
    public final HiveParser.regular_body_return regular_body() throws RecognitionException {
        HiveParser.regular_body_return retval = new HiveParser.regular_body_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser.insertClause_return insertClause719 =null;

        HiveParser_SelectClauseParser.selectClause_return selectClause720 =null;

        HiveParser_FromClauseParser.fromClause_return fromClause721 =null;

        HiveParser_FromClauseParser.whereClause_return whereClause722 =null;

        HiveParser_IdentifiersParser.groupByClause_return groupByClause723 =null;

        HiveParser_IdentifiersParser.havingClause_return havingClause724 =null;

        HiveParser_IdentifiersParser.orderByClause_return orderByClause725 =null;

        HiveParser_IdentifiersParser.clusterByClause_return clusterByClause726 =null;

        HiveParser_IdentifiersParser.distributeByClause_return distributeByClause727 =null;

        HiveParser_IdentifiersParser.sortByClause_return sortByClause728 =null;

        HiveParser_SelectClauseParser.window_clause_return window_clause729 =null;

        HiveParser.limitClause_return limitClause730 =null;

        HiveParser.selectStatement_return selectStatement731 =null;


        RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
        RewriteRuleSubtreeStream stream_window_clause=new RewriteRuleSubtreeStream(adaptor,"rule window_clause");
        RewriteRuleSubtreeStream stream_clusterByClause=new RewriteRuleSubtreeStream(adaptor,"rule clusterByClause");
        RewriteRuleSubtreeStream stream_distributeByClause=new RewriteRuleSubtreeStream(adaptor,"rule distributeByClause");
        RewriteRuleSubtreeStream stream_limitClause=new RewriteRuleSubtreeStream(adaptor,"rule limitClause");
        RewriteRuleSubtreeStream stream_orderByClause=new RewriteRuleSubtreeStream(adaptor,"rule orderByClause");
        RewriteRuleSubtreeStream stream_sortByClause=new RewriteRuleSubtreeStream(adaptor,"rule sortByClause");
        RewriteRuleSubtreeStream stream_insertClause=new RewriteRuleSubtreeStream(adaptor,"rule insertClause");
        RewriteRuleSubtreeStream stream_groupByClause=new RewriteRuleSubtreeStream(adaptor,"rule groupByClause");
        RewriteRuleSubtreeStream stream_havingClause=new RewriteRuleSubtreeStream(adaptor,"rule havingClause");
        RewriteRuleSubtreeStream stream_selectClause=new RewriteRuleSubtreeStream(adaptor,"rule selectClause");
        RewriteRuleSubtreeStream stream_fromClause=new RewriteRuleSubtreeStream(adaptor,"rule fromClause");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1826:4: ( insertClause selectClause fromClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_QUERY fromClause ^( TOK_INSERT insertClause selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) ) | selectStatement )
            int alt199=2;
            int LA199_0 = input.LA(1);

            if ( (LA199_0==KW_INSERT) ) {
                alt199=1;
            }
            else if ( (LA199_0==KW_MAP||LA199_0==KW_REDUCE||LA199_0==KW_SELECT) ) {
                alt199=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 199, 0, input);

                throw nvae;

            }
            switch (alt199) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1827:4: insertClause selectClause fromClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )?
                    {
                    pushFollow(FOLLOW_insertClause_in_regular_body11438);
                    insertClause719=insertClause();

                    state._fsp--;

                    stream_insertClause.add(insertClause719.getTree());

                    pushFollow(FOLLOW_selectClause_in_regular_body11443);
                    selectClause720=selectClause();

                    state._fsp--;

                    stream_selectClause.add(selectClause720.getTree());

                    pushFollow(FOLLOW_fromClause_in_regular_body11448);
                    fromClause721=fromClause();

                    state._fsp--;

                    stream_fromClause.add(fromClause721.getTree());

                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1830:4: ( whereClause )?
                    int alt190=2;
                    int LA190_0 = input.LA(1);

                    if ( (LA190_0==KW_WHERE) ) {
                        alt190=1;
                    }
                    switch (alt190) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1830:4: whereClause
                            {
                            pushFollow(FOLLOW_whereClause_in_regular_body11453);
                            whereClause722=whereClause();

                            state._fsp--;

                            stream_whereClause.add(whereClause722.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1831:4: ( groupByClause )?
                    int alt191=2;
                    int LA191_0 = input.LA(1);

                    if ( (LA191_0==KW_GROUP) ) {
                        alt191=1;
                    }
                    switch (alt191) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1831:4: groupByClause
                            {
                            pushFollow(FOLLOW_groupByClause_in_regular_body11459);
                            groupByClause723=groupByClause();

                            state._fsp--;

                            stream_groupByClause.add(groupByClause723.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1832:4: ( havingClause )?
                    int alt192=2;
                    int LA192_0 = input.LA(1);

                    if ( (LA192_0==KW_HAVING) ) {
                        alt192=1;
                    }
                    switch (alt192) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1832:4: havingClause
                            {
                            pushFollow(FOLLOW_havingClause_in_regular_body11465);
                            havingClause724=havingClause();

                            state._fsp--;

                            stream_havingClause.add(havingClause724.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1833:4: ( orderByClause )?
                    int alt193=2;
                    int LA193_0 = input.LA(1);

                    if ( (LA193_0==KW_ORDER) ) {
                        alt193=1;
                    }
                    switch (alt193) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1833:4: orderByClause
                            {
                            pushFollow(FOLLOW_orderByClause_in_regular_body11471);
                            orderByClause725=orderByClause();

                            state._fsp--;

                            stream_orderByClause.add(orderByClause725.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1834:4: ( clusterByClause )?
                    int alt194=2;
                    int LA194_0 = input.LA(1);

                    if ( (LA194_0==KW_CLUSTER) ) {
                        alt194=1;
                    }
                    switch (alt194) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1834:4: clusterByClause
                            {
                            pushFollow(FOLLOW_clusterByClause_in_regular_body11477);
                            clusterByClause726=clusterByClause();

                            state._fsp--;

                            stream_clusterByClause.add(clusterByClause726.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1835:4: ( distributeByClause )?
                    int alt195=2;
                    int LA195_0 = input.LA(1);

                    if ( (LA195_0==KW_DISTRIBUTE) ) {
                        alt195=1;
                    }
                    switch (alt195) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1835:4: distributeByClause
                            {
                            pushFollow(FOLLOW_distributeByClause_in_regular_body11483);
                            distributeByClause727=distributeByClause();

                            state._fsp--;

                            stream_distributeByClause.add(distributeByClause727.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1836:4: ( sortByClause )?
                    int alt196=2;
                    int LA196_0 = input.LA(1);

                    if ( (LA196_0==KW_SORT) ) {
                        alt196=1;
                    }
                    switch (alt196) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1836:4: sortByClause
                            {
                            pushFollow(FOLLOW_sortByClause_in_regular_body11489);
                            sortByClause728=sortByClause();

                            state._fsp--;

                            stream_sortByClause.add(sortByClause728.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1837:4: ( window_clause )?
                    int alt197=2;
                    int LA197_0 = input.LA(1);

                    if ( (LA197_0==KW_WINDOW) ) {
                        alt197=1;
                    }
                    switch (alt197) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1837:4: window_clause
                            {
                            pushFollow(FOLLOW_window_clause_in_regular_body11495);
                            window_clause729=window_clause();

                            state._fsp--;

                            stream_window_clause.add(window_clause729.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1838:4: ( limitClause )?
                    int alt198=2;
                    int LA198_0 = input.LA(1);

                    if ( (LA198_0==KW_LIMIT) ) {
                        alt198=1;
                    }
                    switch (alt198) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1838:4: limitClause
                            {
                            pushFollow(FOLLOW_limitClause_in_regular_body11501);
                            limitClause730=limitClause();

                            state._fsp--;

                            stream_limitClause.add(limitClause730.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: limitClause, window_clause, sortByClause, havingClause, whereClause, insertClause, fromClause, orderByClause, distributeByClause, clusterByClause, groupByClause, selectClause
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1838:17: -> ^( TOK_QUERY fromClause ^( TOK_INSERT insertClause selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1838:20: ^( TOK_QUERY fromClause ^( TOK_INSERT insertClause selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_QUERY, "TOK_QUERY")
                        , root_1);

                        adaptor.addChild(root_1, stream_fromClause.nextTree());

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1838:43: ^( TOK_INSERT insertClause selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
                        {
                        CommonTree root_2 = (CommonTree)adaptor.nil();
                        root_2 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_INSERT, "TOK_INSERT")
                        , root_2);

                        adaptor.addChild(root_2, stream_insertClause.nextTree());

                        adaptor.addChild(root_2, stream_selectClause.nextTree());

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1839:35: ( whereClause )?
                        if ( stream_whereClause.hasNext() ) {
                            adaptor.addChild(root_2, stream_whereClause.nextTree());

                        }
                        stream_whereClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1839:48: ( groupByClause )?
                        if ( stream_groupByClause.hasNext() ) {
                            adaptor.addChild(root_2, stream_groupByClause.nextTree());

                        }
                        stream_groupByClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1839:63: ( havingClause )?
                        if ( stream_havingClause.hasNext() ) {
                            adaptor.addChild(root_2, stream_havingClause.nextTree());

                        }
                        stream_havingClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1839:77: ( orderByClause )?
                        if ( stream_orderByClause.hasNext() ) {
                            adaptor.addChild(root_2, stream_orderByClause.nextTree());

                        }
                        stream_orderByClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1839:92: ( clusterByClause )?
                        if ( stream_clusterByClause.hasNext() ) {
                            adaptor.addChild(root_2, stream_clusterByClause.nextTree());

                        }
                        stream_clusterByClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1840:22: ( distributeByClause )?
                        if ( stream_distributeByClause.hasNext() ) {
                            adaptor.addChild(root_2, stream_distributeByClause.nextTree());

                        }
                        stream_distributeByClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1840:42: ( sortByClause )?
                        if ( stream_sortByClause.hasNext() ) {
                            adaptor.addChild(root_2, stream_sortByClause.nextTree());

                        }
                        stream_sortByClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1840:56: ( window_clause )?
                        if ( stream_window_clause.hasNext() ) {
                            adaptor.addChild(root_2, stream_window_clause.nextTree());

                        }
                        stream_window_clause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1840:71: ( limitClause )?
                        if ( stream_limitClause.hasNext() ) {
                            adaptor.addChild(root_2, stream_limitClause.nextTree());

                        }
                        stream_limitClause.reset();

                        adaptor.addChild(root_1, root_2);
                        }

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1842:4: selectStatement
                    {
                    root_0 = (CommonTree)adaptor.nil();


                    pushFollow(FOLLOW_selectStatement_in_regular_body11597);
                    selectStatement731=selectStatement();

                    state._fsp--;

                    adaptor.addChild(root_0, selectStatement731.getTree());

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "regular_body"


    public static class selectStatement_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "selectStatement"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1845:1: selectStatement : selectClause fromClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_QUERY fromClause ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) ) ;
    public final HiveParser.selectStatement_return selectStatement() throws RecognitionException {
        HiveParser.selectStatement_return retval = new HiveParser.selectStatement_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser_SelectClauseParser.selectClause_return selectClause732 =null;

        HiveParser_FromClauseParser.fromClause_return fromClause733 =null;

        HiveParser_FromClauseParser.whereClause_return whereClause734 =null;

        HiveParser_IdentifiersParser.groupByClause_return groupByClause735 =null;

        HiveParser_IdentifiersParser.havingClause_return havingClause736 =null;

        HiveParser_IdentifiersParser.orderByClause_return orderByClause737 =null;

        HiveParser_IdentifiersParser.clusterByClause_return clusterByClause738 =null;

        HiveParser_IdentifiersParser.distributeByClause_return distributeByClause739 =null;

        HiveParser_IdentifiersParser.sortByClause_return sortByClause740 =null;

        HiveParser_SelectClauseParser.window_clause_return window_clause741 =null;

        HiveParser.limitClause_return limitClause742 =null;


        RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
        RewriteRuleSubtreeStream stream_window_clause=new RewriteRuleSubtreeStream(adaptor,"rule window_clause");
        RewriteRuleSubtreeStream stream_clusterByClause=new RewriteRuleSubtreeStream(adaptor,"rule clusterByClause");
        RewriteRuleSubtreeStream stream_distributeByClause=new RewriteRuleSubtreeStream(adaptor,"rule distributeByClause");
        RewriteRuleSubtreeStream stream_limitClause=new RewriteRuleSubtreeStream(adaptor,"rule limitClause");
        RewriteRuleSubtreeStream stream_orderByClause=new RewriteRuleSubtreeStream(adaptor,"rule orderByClause");
        RewriteRuleSubtreeStream stream_sortByClause=new RewriteRuleSubtreeStream(adaptor,"rule sortByClause");
        RewriteRuleSubtreeStream stream_groupByClause=new RewriteRuleSubtreeStream(adaptor,"rule groupByClause");
        RewriteRuleSubtreeStream stream_havingClause=new RewriteRuleSubtreeStream(adaptor,"rule havingClause");
        RewriteRuleSubtreeStream stream_selectClause=new RewriteRuleSubtreeStream(adaptor,"rule selectClause");
        RewriteRuleSubtreeStream stream_fromClause=new RewriteRuleSubtreeStream(adaptor,"rule fromClause");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1846:4: ( selectClause fromClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_QUERY fromClause ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) ) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1847:4: selectClause fromClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )?
            {
            pushFollow(FOLLOW_selectClause_in_selectStatement11615);
            selectClause732=selectClause();

            state._fsp--;

            stream_selectClause.add(selectClause732.getTree());

            pushFollow(FOLLOW_fromClause_in_selectStatement11620);
            fromClause733=fromClause();

            state._fsp--;

            stream_fromClause.add(fromClause733.getTree());

            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1849:4: ( whereClause )?
            int alt200=2;
            int LA200_0 = input.LA(1);

            if ( (LA200_0==KW_WHERE) ) {
                alt200=1;
            }
            switch (alt200) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1849:4: whereClause
                    {
                    pushFollow(FOLLOW_whereClause_in_selectStatement11625);
                    whereClause734=whereClause();

                    state._fsp--;

                    stream_whereClause.add(whereClause734.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1850:4: ( groupByClause )?
            int alt201=2;
            int LA201_0 = input.LA(1);

            if ( (LA201_0==KW_GROUP) ) {
                alt201=1;
            }
            switch (alt201) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1850:4: groupByClause
                    {
                    pushFollow(FOLLOW_groupByClause_in_selectStatement11631);
                    groupByClause735=groupByClause();

                    state._fsp--;

                    stream_groupByClause.add(groupByClause735.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1851:4: ( havingClause )?
            int alt202=2;
            int LA202_0 = input.LA(1);

            if ( (LA202_0==KW_HAVING) ) {
                alt202=1;
            }
            switch (alt202) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1851:4: havingClause
                    {
                    pushFollow(FOLLOW_havingClause_in_selectStatement11637);
                    havingClause736=havingClause();

                    state._fsp--;

                    stream_havingClause.add(havingClause736.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1852:4: ( orderByClause )?
            int alt203=2;
            int LA203_0 = input.LA(1);

            if ( (LA203_0==KW_ORDER) ) {
                alt203=1;
            }
            switch (alt203) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1852:4: orderByClause
                    {
                    pushFollow(FOLLOW_orderByClause_in_selectStatement11643);
                    orderByClause737=orderByClause();

                    state._fsp--;

                    stream_orderByClause.add(orderByClause737.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1853:4: ( clusterByClause )?
            int alt204=2;
            int LA204_0 = input.LA(1);

            if ( (LA204_0==KW_CLUSTER) ) {
                alt204=1;
            }
            switch (alt204) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1853:4: clusterByClause
                    {
                    pushFollow(FOLLOW_clusterByClause_in_selectStatement11649);
                    clusterByClause738=clusterByClause();

                    state._fsp--;

                    stream_clusterByClause.add(clusterByClause738.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1854:4: ( distributeByClause )?
            int alt205=2;
            int LA205_0 = input.LA(1);

            if ( (LA205_0==KW_DISTRIBUTE) ) {
                alt205=1;
            }
            switch (alt205) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1854:4: distributeByClause
                    {
                    pushFollow(FOLLOW_distributeByClause_in_selectStatement11655);
                    distributeByClause739=distributeByClause();

                    state._fsp--;

                    stream_distributeByClause.add(distributeByClause739.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1855:4: ( sortByClause )?
            int alt206=2;
            int LA206_0 = input.LA(1);

            if ( (LA206_0==KW_SORT) ) {
                alt206=1;
            }
            switch (alt206) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1855:4: sortByClause
                    {
                    pushFollow(FOLLOW_sortByClause_in_selectStatement11661);
                    sortByClause740=sortByClause();

                    state._fsp--;

                    stream_sortByClause.add(sortByClause740.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1856:4: ( window_clause )?
            int alt207=2;
            int LA207_0 = input.LA(1);

            if ( (LA207_0==KW_WINDOW) ) {
                alt207=1;
            }
            switch (alt207) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1856:4: window_clause
                    {
                    pushFollow(FOLLOW_window_clause_in_selectStatement11667);
                    window_clause741=window_clause();

                    state._fsp--;

                    stream_window_clause.add(window_clause741.getTree());

                    }
                    break;

            }


            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:4: ( limitClause )?
            int alt208=2;
            int LA208_0 = input.LA(1);

            if ( (LA208_0==KW_LIMIT) ) {
                alt208=1;
            }
            switch (alt208) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:4: limitClause
                    {
                    pushFollow(FOLLOW_limitClause_in_selectStatement11673);
                    limitClause742=limitClause();

                    state._fsp--;

                    stream_limitClause.add(limitClause742.getTree());

                    }
                    break;

            }


            // AST REWRITE
            // elements: havingClause, fromClause, orderByClause, selectClause, groupByClause, whereClause, distributeByClause, sortByClause, window_clause, clusterByClause, limitClause
            // token labels: 
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1857:17: -> ^( TOK_QUERY fromClause ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) )
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:20: ^( TOK_QUERY fromClause ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) )
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_QUERY, "TOK_QUERY")
                , root_1);

                adaptor.addChild(root_1, stream_fromClause.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:43: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
                {
                CommonTree root_2 = (CommonTree)adaptor.nil();
                root_2 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_INSERT, "TOK_INSERT")
                , root_2);

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:56: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
                {
                CommonTree root_3 = (CommonTree)adaptor.nil();
                root_3 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION")
                , root_3);

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1857:74: ^( TOK_DIR TOK_TMP_FILE )
                {
                CommonTree root_4 = (CommonTree)adaptor.nil();
                root_4 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_DIR, "TOK_DIR")
                , root_4);

                adaptor.addChild(root_4, 
                (CommonTree)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE")
                );

                adaptor.addChild(root_3, root_4);
                }

                adaptor.addChild(root_2, root_3);
                }

                adaptor.addChild(root_2, stream_selectClause.nextTree());

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1858:35: ( whereClause )?
                if ( stream_whereClause.hasNext() ) {
                    adaptor.addChild(root_2, stream_whereClause.nextTree());

                }
                stream_whereClause.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1858:48: ( groupByClause )?
                if ( stream_groupByClause.hasNext() ) {
                    adaptor.addChild(root_2, stream_groupByClause.nextTree());

                }
                stream_groupByClause.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1858:63: ( havingClause )?
                if ( stream_havingClause.hasNext() ) {
                    adaptor.addChild(root_2, stream_havingClause.nextTree());

                }
                stream_havingClause.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1858:77: ( orderByClause )?
                if ( stream_orderByClause.hasNext() ) {
                    adaptor.addChild(root_2, stream_orderByClause.nextTree());

                }
                stream_orderByClause.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1858:92: ( clusterByClause )?
                if ( stream_clusterByClause.hasNext() ) {
                    adaptor.addChild(root_2, stream_clusterByClause.nextTree());

                }
                stream_clusterByClause.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1859:22: ( distributeByClause )?
                if ( stream_distributeByClause.hasNext() ) {
                    adaptor.addChild(root_2, stream_distributeByClause.nextTree());

                }
                stream_distributeByClause.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1859:42: ( sortByClause )?
                if ( stream_sortByClause.hasNext() ) {
                    adaptor.addChild(root_2, stream_sortByClause.nextTree());

                }
                stream_sortByClause.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1859:56: ( window_clause )?
                if ( stream_window_clause.hasNext() ) {
                    adaptor.addChild(root_2, stream_window_clause.nextTree());

                }
                stream_window_clause.reset();

                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1859:71: ( limitClause )?
                if ( stream_limitClause.hasNext() ) {
                    adaptor.addChild(root_2, stream_limitClause.nextTree());

                }
                stream_limitClause.reset();

                adaptor.addChild(root_1, root_2);
                }

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "selectStatement"


    public static class body_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "body"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1863:1: body : ( insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) | selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) );
    public final HiveParser.body_return body() throws RecognitionException {
        HiveParser.body_return retval = new HiveParser.body_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        HiveParser.insertClause_return insertClause743 =null;

        HiveParser_SelectClauseParser.selectClause_return selectClause744 =null;

        HiveParser_FromClauseParser.lateralView_return lateralView745 =null;

        HiveParser_FromClauseParser.whereClause_return whereClause746 =null;

        HiveParser_IdentifiersParser.groupByClause_return groupByClause747 =null;

        HiveParser_IdentifiersParser.havingClause_return havingClause748 =null;

        HiveParser_IdentifiersParser.orderByClause_return orderByClause749 =null;

        HiveParser_IdentifiersParser.clusterByClause_return clusterByClause750 =null;

        HiveParser_IdentifiersParser.distributeByClause_return distributeByClause751 =null;

        HiveParser_IdentifiersParser.sortByClause_return sortByClause752 =null;

        HiveParser_SelectClauseParser.window_clause_return window_clause753 =null;

        HiveParser.limitClause_return limitClause754 =null;

        HiveParser_SelectClauseParser.selectClause_return selectClause755 =null;

        HiveParser_FromClauseParser.lateralView_return lateralView756 =null;

        HiveParser_FromClauseParser.whereClause_return whereClause757 =null;

        HiveParser_IdentifiersParser.groupByClause_return groupByClause758 =null;

        HiveParser_IdentifiersParser.havingClause_return havingClause759 =null;

        HiveParser_IdentifiersParser.orderByClause_return orderByClause760 =null;

        HiveParser_IdentifiersParser.clusterByClause_return clusterByClause761 =null;

        HiveParser_IdentifiersParser.distributeByClause_return distributeByClause762 =null;

        HiveParser_IdentifiersParser.sortByClause_return sortByClause763 =null;

        HiveParser_SelectClauseParser.window_clause_return window_clause764 =null;

        HiveParser.limitClause_return limitClause765 =null;


        RewriteRuleSubtreeStream stream_whereClause=new RewriteRuleSubtreeStream(adaptor,"rule whereClause");
        RewriteRuleSubtreeStream stream_window_clause=new RewriteRuleSubtreeStream(adaptor,"rule window_clause");
        RewriteRuleSubtreeStream stream_clusterByClause=new RewriteRuleSubtreeStream(adaptor,"rule clusterByClause");
        RewriteRuleSubtreeStream stream_distributeByClause=new RewriteRuleSubtreeStream(adaptor,"rule distributeByClause");
        RewriteRuleSubtreeStream stream_lateralView=new RewriteRuleSubtreeStream(adaptor,"rule lateralView");
        RewriteRuleSubtreeStream stream_limitClause=new RewriteRuleSubtreeStream(adaptor,"rule limitClause");
        RewriteRuleSubtreeStream stream_orderByClause=new RewriteRuleSubtreeStream(adaptor,"rule orderByClause");
        RewriteRuleSubtreeStream stream_sortByClause=new RewriteRuleSubtreeStream(adaptor,"rule sortByClause");
        RewriteRuleSubtreeStream stream_insertClause=new RewriteRuleSubtreeStream(adaptor,"rule insertClause");
        RewriteRuleSubtreeStream stream_groupByClause=new RewriteRuleSubtreeStream(adaptor,"rule groupByClause");
        RewriteRuleSubtreeStream stream_havingClause=new RewriteRuleSubtreeStream(adaptor,"rule havingClause");
        RewriteRuleSubtreeStream stream_selectClause=new RewriteRuleSubtreeStream(adaptor,"rule selectClause");
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1864:4: ( insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) | selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? ) )
            int alt229=2;
            int LA229_0 = input.LA(1);

            if ( (LA229_0==KW_INSERT) ) {
                alt229=1;
            }
            else if ( (LA229_0==KW_MAP||LA229_0==KW_REDUCE||LA229_0==KW_SELECT) ) {
                alt229=2;
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 229, 0, input);

                throw nvae;

            }
            switch (alt229) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1865:4: insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )?
                    {
                    pushFollow(FOLLOW_insertClause_in_body11786);
                    insertClause743=insertClause();

                    state._fsp--;

                    stream_insertClause.add(insertClause743.getTree());

                    pushFollow(FOLLOW_selectClause_in_body11791);
                    selectClause744=selectClause();

                    state._fsp--;

                    stream_selectClause.add(selectClause744.getTree());

                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1867:4: ( lateralView )?
                    int alt209=2;
                    int LA209_0 = input.LA(1);

                    if ( (LA209_0==KW_LATERAL) ) {
                        alt209=1;
                    }
                    switch (alt209) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1867:4: lateralView
                            {
                            pushFollow(FOLLOW_lateralView_in_body11796);
                            lateralView745=lateralView();

                            state._fsp--;

                            stream_lateralView.add(lateralView745.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1868:4: ( whereClause )?
                    int alt210=2;
                    int LA210_0 = input.LA(1);

                    if ( (LA210_0==KW_WHERE) ) {
                        alt210=1;
                    }
                    switch (alt210) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1868:4: whereClause
                            {
                            pushFollow(FOLLOW_whereClause_in_body11802);
                            whereClause746=whereClause();

                            state._fsp--;

                            stream_whereClause.add(whereClause746.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1869:4: ( groupByClause )?
                    int alt211=2;
                    int LA211_0 = input.LA(1);

                    if ( (LA211_0==KW_GROUP) ) {
                        alt211=1;
                    }
                    switch (alt211) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1869:4: groupByClause
                            {
                            pushFollow(FOLLOW_groupByClause_in_body11808);
                            groupByClause747=groupByClause();

                            state._fsp--;

                            stream_groupByClause.add(groupByClause747.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1870:4: ( havingClause )?
                    int alt212=2;
                    int LA212_0 = input.LA(1);

                    if ( (LA212_0==KW_HAVING) ) {
                        alt212=1;
                    }
                    switch (alt212) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1870:4: havingClause
                            {
                            pushFollow(FOLLOW_havingClause_in_body11814);
                            havingClause748=havingClause();

                            state._fsp--;

                            stream_havingClause.add(havingClause748.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1871:4: ( orderByClause )?
                    int alt213=2;
                    int LA213_0 = input.LA(1);

                    if ( (LA213_0==KW_ORDER) ) {
                        alt213=1;
                    }
                    switch (alt213) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1871:4: orderByClause
                            {
                            pushFollow(FOLLOW_orderByClause_in_body11820);
                            orderByClause749=orderByClause();

                            state._fsp--;

                            stream_orderByClause.add(orderByClause749.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1872:4: ( clusterByClause )?
                    int alt214=2;
                    int LA214_0 = input.LA(1);

                    if ( (LA214_0==KW_CLUSTER) ) {
                        alt214=1;
                    }
                    switch (alt214) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1872:4: clusterByClause
                            {
                            pushFollow(FOLLOW_clusterByClause_in_body11826);
                            clusterByClause750=clusterByClause();

                            state._fsp--;

                            stream_clusterByClause.add(clusterByClause750.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1873:4: ( distributeByClause )?
                    int alt215=2;
                    int LA215_0 = input.LA(1);

                    if ( (LA215_0==KW_DISTRIBUTE) ) {
                        alt215=1;
                    }
                    switch (alt215) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1873:4: distributeByClause
                            {
                            pushFollow(FOLLOW_distributeByClause_in_body11832);
                            distributeByClause751=distributeByClause();

                            state._fsp--;

                            stream_distributeByClause.add(distributeByClause751.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1874:4: ( sortByClause )?
                    int alt216=2;
                    int LA216_0 = input.LA(1);

                    if ( (LA216_0==KW_SORT) ) {
                        alt216=1;
                    }
                    switch (alt216) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1874:4: sortByClause
                            {
                            pushFollow(FOLLOW_sortByClause_in_body11838);
                            sortByClause752=sortByClause();

                            state._fsp--;

                            stream_sortByClause.add(sortByClause752.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1875:4: ( window_clause )?
                    int alt217=2;
                    int LA217_0 = input.LA(1);

                    if ( (LA217_0==KW_WINDOW) ) {
                        alt217=1;
                    }
                    switch (alt217) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1875:4: window_clause
                            {
                            pushFollow(FOLLOW_window_clause_in_body11844);
                            window_clause753=window_clause();

                            state._fsp--;

                            stream_window_clause.add(window_clause753.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1876:4: ( limitClause )?
                    int alt218=2;
                    int LA218_0 = input.LA(1);

                    if ( (LA218_0==KW_LIMIT) ) {
                        alt218=1;
                    }
                    switch (alt218) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1876:4: limitClause
                            {
                            pushFollow(FOLLOW_limitClause_in_body11850);
                            limitClause754=limitClause();

                            state._fsp--;

                            stream_limitClause.add(limitClause754.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: sortByClause, clusterByClause, window_clause, orderByClause, distributeByClause, groupByClause, insertClause, lateralView, limitClause, whereClause, selectClause, havingClause
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1876:17: -> ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1876:20: ^( TOK_INSERT insertClause selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_INSERT, "TOK_INSERT")
                        , root_1);

                        adaptor.addChild(root_1, stream_insertClause.nextTree());

                        adaptor.addChild(root_1, stream_selectClause.nextTree());

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1877:35: ( lateralView )?
                        if ( stream_lateralView.hasNext() ) {
                            adaptor.addChild(root_1, stream_lateralView.nextTree());

                        }
                        stream_lateralView.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1877:48: ( whereClause )?
                        if ( stream_whereClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_whereClause.nextTree());

                        }
                        stream_whereClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1877:61: ( groupByClause )?
                        if ( stream_groupByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_groupByClause.nextTree());

                        }
                        stream_groupByClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1877:76: ( havingClause )?
                        if ( stream_havingClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_havingClause.nextTree());

                        }
                        stream_havingClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1877:90: ( orderByClause )?
                        if ( stream_orderByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_orderByClause.nextTree());

                        }
                        stream_orderByClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1877:105: ( clusterByClause )?
                        if ( stream_clusterByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_clusterByClause.nextTree());

                        }
                        stream_clusterByClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1878:22: ( distributeByClause )?
                        if ( stream_distributeByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_distributeByClause.nextTree());

                        }
                        stream_distributeByClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1878:42: ( sortByClause )?
                        if ( stream_sortByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_sortByClause.nextTree());

                        }
                        stream_sortByClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1878:56: ( window_clause )?
                        if ( stream_window_clause.hasNext() ) {
                            adaptor.addChild(root_1, stream_window_clause.nextTree());

                        }
                        stream_window_clause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1878:71: ( limitClause )?
                        if ( stream_limitClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_limitClause.nextTree());

                        }
                        stream_limitClause.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1880:4: selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )?
                    {
                    pushFollow(FOLLOW_selectClause_in_body11943);
                    selectClause755=selectClause();

                    state._fsp--;

                    stream_selectClause.add(selectClause755.getTree());

                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:4: ( lateralView )?
                    int alt219=2;
                    int LA219_0 = input.LA(1);

                    if ( (LA219_0==KW_LATERAL) ) {
                        alt219=1;
                    }
                    switch (alt219) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1881:4: lateralView
                            {
                            pushFollow(FOLLOW_lateralView_in_body11948);
                            lateralView756=lateralView();

                            state._fsp--;

                            stream_lateralView.add(lateralView756.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1882:4: ( whereClause )?
                    int alt220=2;
                    int LA220_0 = input.LA(1);

                    if ( (LA220_0==KW_WHERE) ) {
                        alt220=1;
                    }
                    switch (alt220) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1882:4: whereClause
                            {
                            pushFollow(FOLLOW_whereClause_in_body11954);
                            whereClause757=whereClause();

                            state._fsp--;

                            stream_whereClause.add(whereClause757.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1883:4: ( groupByClause )?
                    int alt221=2;
                    int LA221_0 = input.LA(1);

                    if ( (LA221_0==KW_GROUP) ) {
                        alt221=1;
                    }
                    switch (alt221) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1883:4: groupByClause
                            {
                            pushFollow(FOLLOW_groupByClause_in_body11960);
                            groupByClause758=groupByClause();

                            state._fsp--;

                            stream_groupByClause.add(groupByClause758.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1884:4: ( havingClause )?
                    int alt222=2;
                    int LA222_0 = input.LA(1);

                    if ( (LA222_0==KW_HAVING) ) {
                        alt222=1;
                    }
                    switch (alt222) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1884:4: havingClause
                            {
                            pushFollow(FOLLOW_havingClause_in_body11966);
                            havingClause759=havingClause();

                            state._fsp--;

                            stream_havingClause.add(havingClause759.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1885:4: ( orderByClause )?
                    int alt223=2;
                    int LA223_0 = input.LA(1);

                    if ( (LA223_0==KW_ORDER) ) {
                        alt223=1;
                    }
                    switch (alt223) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1885:4: orderByClause
                            {
                            pushFollow(FOLLOW_orderByClause_in_body11972);
                            orderByClause760=orderByClause();

                            state._fsp--;

                            stream_orderByClause.add(orderByClause760.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1886:4: ( clusterByClause )?
                    int alt224=2;
                    int LA224_0 = input.LA(1);

                    if ( (LA224_0==KW_CLUSTER) ) {
                        alt224=1;
                    }
                    switch (alt224) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1886:4: clusterByClause
                            {
                            pushFollow(FOLLOW_clusterByClause_in_body11978);
                            clusterByClause761=clusterByClause();

                            state._fsp--;

                            stream_clusterByClause.add(clusterByClause761.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1887:4: ( distributeByClause )?
                    int alt225=2;
                    int LA225_0 = input.LA(1);

                    if ( (LA225_0==KW_DISTRIBUTE) ) {
                        alt225=1;
                    }
                    switch (alt225) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1887:4: distributeByClause
                            {
                            pushFollow(FOLLOW_distributeByClause_in_body11984);
                            distributeByClause762=distributeByClause();

                            state._fsp--;

                            stream_distributeByClause.add(distributeByClause762.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1888:4: ( sortByClause )?
                    int alt226=2;
                    int LA226_0 = input.LA(1);

                    if ( (LA226_0==KW_SORT) ) {
                        alt226=1;
                    }
                    switch (alt226) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1888:4: sortByClause
                            {
                            pushFollow(FOLLOW_sortByClause_in_body11990);
                            sortByClause763=sortByClause();

                            state._fsp--;

                            stream_sortByClause.add(sortByClause763.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1889:4: ( window_clause )?
                    int alt227=2;
                    int LA227_0 = input.LA(1);

                    if ( (LA227_0==KW_WINDOW) ) {
                        alt227=1;
                    }
                    switch (alt227) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1889:4: window_clause
                            {
                            pushFollow(FOLLOW_window_clause_in_body11996);
                            window_clause764=window_clause();

                            state._fsp--;

                            stream_window_clause.add(window_clause764.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1890:4: ( limitClause )?
                    int alt228=2;
                    int LA228_0 = input.LA(1);

                    if ( (LA228_0==KW_LIMIT) ) {
                        alt228=1;
                    }
                    switch (alt228) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1890:4: limitClause
                            {
                            pushFollow(FOLLOW_limitClause_in_body12002);
                            limitClause765=limitClause();

                            state._fsp--;

                            stream_limitClause.add(limitClause765.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: havingClause, orderByClause, selectClause, distributeByClause, whereClause, lateralView, window_clause, sortByClause, limitClause, groupByClause, clusterByClause
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1890:17: -> ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1890:20: ^( TOK_INSERT ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) ) selectClause ( lateralView )? ( whereClause )? ( groupByClause )? ( havingClause )? ( orderByClause )? ( clusterByClause )? ( distributeByClause )? ( sortByClause )? ( window_clause )? ( limitClause )? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_INSERT, "TOK_INSERT")
                        , root_1);

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1890:33: ^( TOK_DESTINATION ^( TOK_DIR TOK_TMP_FILE ) )
                        {
                        CommonTree root_2 = (CommonTree)adaptor.nil();
                        root_2 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION")
                        , root_2);

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1890:51: ^( TOK_DIR TOK_TMP_FILE )
                        {
                        CommonTree root_3 = (CommonTree)adaptor.nil();
                        root_3 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_DIR, "TOK_DIR")
                        , root_3);

                        adaptor.addChild(root_3, 
                        (CommonTree)adaptor.create(TOK_TMP_FILE, "TOK_TMP_FILE")
                        );

                        adaptor.addChild(root_2, root_3);
                        }

                        adaptor.addChild(root_1, root_2);
                        }

                        adaptor.addChild(root_1, stream_selectClause.nextTree());

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1891:35: ( lateralView )?
                        if ( stream_lateralView.hasNext() ) {
                            adaptor.addChild(root_1, stream_lateralView.nextTree());

                        }
                        stream_lateralView.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1891:48: ( whereClause )?
                        if ( stream_whereClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_whereClause.nextTree());

                        }
                        stream_whereClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1891:61: ( groupByClause )?
                        if ( stream_groupByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_groupByClause.nextTree());

                        }
                        stream_groupByClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1891:76: ( havingClause )?
                        if ( stream_havingClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_havingClause.nextTree());

                        }
                        stream_havingClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1891:90: ( orderByClause )?
                        if ( stream_orderByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_orderByClause.nextTree());

                        }
                        stream_orderByClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1891:105: ( clusterByClause )?
                        if ( stream_clusterByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_clusterByClause.nextTree());

                        }
                        stream_clusterByClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1892:22: ( distributeByClause )?
                        if ( stream_distributeByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_distributeByClause.nextTree());

                        }
                        stream_distributeByClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1892:42: ( sortByClause )?
                        if ( stream_sortByClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_sortByClause.nextTree());

                        }
                        stream_sortByClause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1892:56: ( window_clause )?
                        if ( stream_window_clause.hasNext() ) {
                            adaptor.addChild(root_1, stream_window_clause.nextTree());

                        }
                        stream_window_clause.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1892:71: ( limitClause )?
                        if ( stream_limitClause.hasNext() ) {
                            adaptor.addChild(root_1, stream_limitClause.nextTree());

                        }
                        stream_limitClause.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "body"


    public static class insertClause_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "insertClause"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1895:1: insertClause : ( KW_INSERT KW_OVERWRITE destination ( ifNotExists )? -> ^( TOK_DESTINATION destination ( ifNotExists )? ) | KW_INSERT KW_INTO KW_TABLE tableOrPartition -> ^( TOK_INSERT_INTO tableOrPartition ) );
    public final HiveParser.insertClause_return insertClause() throws RecognitionException {
        HiveParser.insertClause_return retval = new HiveParser.insertClause_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_INSERT766=null;
        Token KW_OVERWRITE767=null;
        Token KW_INSERT770=null;
        Token KW_INTO771=null;
        Token KW_TABLE772=null;
        HiveParser.destination_return destination768 =null;

        HiveParser.ifNotExists_return ifNotExists769 =null;

        HiveParser_IdentifiersParser.tableOrPartition_return tableOrPartition773 =null;


        CommonTree KW_INSERT766_tree=null;
        CommonTree KW_OVERWRITE767_tree=null;
        CommonTree KW_INSERT770_tree=null;
        CommonTree KW_INTO771_tree=null;
        CommonTree KW_TABLE772_tree=null;
        RewriteRuleTokenStream stream_KW_INTO=new RewriteRuleTokenStream(adaptor,"token KW_INTO");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleTokenStream stream_KW_OVERWRITE=new RewriteRuleTokenStream(adaptor,"token KW_OVERWRITE");
        RewriteRuleTokenStream stream_KW_INSERT=new RewriteRuleTokenStream(adaptor,"token KW_INSERT");
        RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
        RewriteRuleSubtreeStream stream_ifNotExists=new RewriteRuleSubtreeStream(adaptor,"rule ifNotExists");
        RewriteRuleSubtreeStream stream_destination=new RewriteRuleSubtreeStream(adaptor,"rule destination");
         msgs.push("insert clause"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1898:4: ( KW_INSERT KW_OVERWRITE destination ( ifNotExists )? -> ^( TOK_DESTINATION destination ( ifNotExists )? ) | KW_INSERT KW_INTO KW_TABLE tableOrPartition -> ^( TOK_INSERT_INTO tableOrPartition ) )
            int alt231=2;
            int LA231_0 = input.LA(1);

            if ( (LA231_0==KW_INSERT) ) {
                int LA231_1 = input.LA(2);

                if ( (LA231_1==KW_OVERWRITE) ) {
                    alt231=1;
                }
                else if ( (LA231_1==KW_INTO) ) {
                    alt231=2;
                }
                else {
                    NoViableAltException nvae =
                        new NoViableAltException("", 231, 1, input);

                    throw nvae;

                }
            }
            else {
                NoViableAltException nvae =
                    new NoViableAltException("", 231, 0, input);

                throw nvae;

            }
            switch (alt231) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1899:6: KW_INSERT KW_OVERWRITE destination ( ifNotExists )?
                    {
                    KW_INSERT766=(Token)match(input,KW_INSERT,FOLLOW_KW_INSERT_in_insertClause12123);  
                    stream_KW_INSERT.add(KW_INSERT766);


                    KW_OVERWRITE767=(Token)match(input,KW_OVERWRITE,FOLLOW_KW_OVERWRITE_in_insertClause12125);  
                    stream_KW_OVERWRITE.add(KW_OVERWRITE767);


                    pushFollow(FOLLOW_destination_in_insertClause12127);
                    destination768=destination();

                    state._fsp--;

                    stream_destination.add(destination768.getTree());

                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1899:41: ( ifNotExists )?
                    int alt230=2;
                    int LA230_0 = input.LA(1);

                    if ( (LA230_0==KW_IF) ) {
                        alt230=1;
                    }
                    switch (alt230) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1899:41: ifNotExists
                            {
                            pushFollow(FOLLOW_ifNotExists_in_insertClause12129);
                            ifNotExists769=ifNotExists();

                            state._fsp--;

                            stream_ifNotExists.add(ifNotExists769.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: ifNotExists, destination
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1899:54: -> ^( TOK_DESTINATION destination ( ifNotExists )? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1899:57: ^( TOK_DESTINATION destination ( ifNotExists )? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_DESTINATION, "TOK_DESTINATION")
                        , root_1);

                        adaptor.addChild(root_1, stream_destination.nextTree());

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1899:87: ( ifNotExists )?
                        if ( stream_ifNotExists.hasNext() ) {
                            adaptor.addChild(root_1, stream_ifNotExists.nextTree());

                        }
                        stream_ifNotExists.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1900:6: KW_INSERT KW_INTO KW_TABLE tableOrPartition
                    {
                    KW_INSERT770=(Token)match(input,KW_INSERT,FOLLOW_KW_INSERT_in_insertClause12148);  
                    stream_KW_INSERT.add(KW_INSERT770);


                    KW_INTO771=(Token)match(input,KW_INTO,FOLLOW_KW_INTO_in_insertClause12150);  
                    stream_KW_INTO.add(KW_INTO771);


                    KW_TABLE772=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_insertClause12152);  
                    stream_KW_TABLE.add(KW_TABLE772);


                    pushFollow(FOLLOW_tableOrPartition_in_insertClause12154);
                    tableOrPartition773=tableOrPartition();

                    state._fsp--;

                    stream_tableOrPartition.add(tableOrPartition773.getTree());

                    // AST REWRITE
                    // elements: tableOrPartition
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1901:8: -> ^( TOK_INSERT_INTO tableOrPartition )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1901:11: ^( TOK_INSERT_INTO tableOrPartition )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_INSERT_INTO, "TOK_INSERT_INTO")
                        , root_1);

                        adaptor.addChild(root_1, stream_tableOrPartition.nextTree());

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "insertClause"


    public static class destination_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "destination"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1904:1: destination : ( KW_LOCAL KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )? -> ^( TOK_LOCAL_DIR StringLiteral ( tableRowFormat )? ( tableFileFormat )? ) | KW_DIRECTORY StringLiteral -> ^( TOK_DIR StringLiteral ) | KW_TABLE tableOrPartition -> tableOrPartition );
    public final HiveParser.destination_return destination() throws RecognitionException {
        HiveParser.destination_return retval = new HiveParser.destination_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token KW_LOCAL774=null;
        Token KW_DIRECTORY775=null;
        Token StringLiteral776=null;
        Token KW_DIRECTORY779=null;
        Token StringLiteral780=null;
        Token KW_TABLE781=null;
        HiveParser.tableRowFormat_return tableRowFormat777 =null;

        HiveParser.tableFileFormat_return tableFileFormat778 =null;

        HiveParser_IdentifiersParser.tableOrPartition_return tableOrPartition782 =null;


        CommonTree KW_LOCAL774_tree=null;
        CommonTree KW_DIRECTORY775_tree=null;
        CommonTree StringLiteral776_tree=null;
        CommonTree KW_DIRECTORY779_tree=null;
        CommonTree StringLiteral780_tree=null;
        CommonTree KW_TABLE781_tree=null;
        RewriteRuleTokenStream stream_StringLiteral=new RewriteRuleTokenStream(adaptor,"token StringLiteral");
        RewriteRuleTokenStream stream_KW_DIRECTORY=new RewriteRuleTokenStream(adaptor,"token KW_DIRECTORY");
        RewriteRuleTokenStream stream_KW_LOCAL=new RewriteRuleTokenStream(adaptor,"token KW_LOCAL");
        RewriteRuleTokenStream stream_KW_TABLE=new RewriteRuleTokenStream(adaptor,"token KW_TABLE");
        RewriteRuleSubtreeStream stream_tableOrPartition=new RewriteRuleSubtreeStream(adaptor,"rule tableOrPartition");
        RewriteRuleSubtreeStream stream_tableRowFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableRowFormat");
        RewriteRuleSubtreeStream stream_tableFileFormat=new RewriteRuleSubtreeStream(adaptor,"rule tableFileFormat");
         msgs.push("destination specification"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1907:4: ( KW_LOCAL KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )? -> ^( TOK_LOCAL_DIR StringLiteral ( tableRowFormat )? ( tableFileFormat )? ) | KW_DIRECTORY StringLiteral -> ^( TOK_DIR StringLiteral ) | KW_TABLE tableOrPartition -> tableOrPartition )
            int alt234=3;
            switch ( input.LA(1) ) {
            case KW_LOCAL:
                {
                alt234=1;
                }
                break;
            case KW_DIRECTORY:
                {
                alt234=2;
                }
                break;
            case KW_TABLE:
                {
                alt234=3;
                }
                break;
            default:
                NoViableAltException nvae =
                    new NoViableAltException("", 234, 0, input);

                throw nvae;

            }

            switch (alt234) {
                case 1 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1908:6: KW_LOCAL KW_DIRECTORY StringLiteral ( tableRowFormat )? ( tableFileFormat )?
                    {
                    KW_LOCAL774=(Token)match(input,KW_LOCAL,FOLLOW_KW_LOCAL_in_destination12199);  
                    stream_KW_LOCAL.add(KW_LOCAL774);


                    KW_DIRECTORY775=(Token)match(input,KW_DIRECTORY,FOLLOW_KW_DIRECTORY_in_destination12201);  
                    stream_KW_DIRECTORY.add(KW_DIRECTORY775);


                    StringLiteral776=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_destination12203);  
                    stream_StringLiteral.add(StringLiteral776);


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1908:42: ( tableRowFormat )?
                    int alt232=2;
                    int LA232_0 = input.LA(1);

                    if ( (LA232_0==KW_ROW) ) {
                        alt232=1;
                    }
                    switch (alt232) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1908:42: tableRowFormat
                            {
                            pushFollow(FOLLOW_tableRowFormat_in_destination12205);
                            tableRowFormat777=tableRowFormat();

                            state._fsp--;

                            stream_tableRowFormat.add(tableRowFormat777.getTree());

                            }
                            break;

                    }


                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1908:58: ( tableFileFormat )?
                    int alt233=2;
                    int LA233_0 = input.LA(1);

                    if ( (LA233_0==KW_STORED) ) {
                        alt233=1;
                    }
                    switch (alt233) {
                        case 1 :
                            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1908:58: tableFileFormat
                            {
                            pushFollow(FOLLOW_tableFileFormat_in_destination12208);
                            tableFileFormat778=tableFileFormat();

                            state._fsp--;

                            stream_tableFileFormat.add(tableFileFormat778.getTree());

                            }
                            break;

                    }


                    // AST REWRITE
                    // elements: tableRowFormat, tableFileFormat, StringLiteral
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1908:75: -> ^( TOK_LOCAL_DIR StringLiteral ( tableRowFormat )? ( tableFileFormat )? )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1908:78: ^( TOK_LOCAL_DIR StringLiteral ( tableRowFormat )? ( tableFileFormat )? )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_LOCAL_DIR, "TOK_LOCAL_DIR")
                        , root_1);

                        adaptor.addChild(root_1, 
                        stream_StringLiteral.nextNode()
                        );

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1908:108: ( tableRowFormat )?
                        if ( stream_tableRowFormat.hasNext() ) {
                            adaptor.addChild(root_1, stream_tableRowFormat.nextTree());

                        }
                        stream_tableRowFormat.reset();

                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1908:124: ( tableFileFormat )?
                        if ( stream_tableFileFormat.hasNext() ) {
                            adaptor.addChild(root_1, stream_tableFileFormat.nextTree());

                        }
                        stream_tableFileFormat.reset();

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 2 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1909:6: KW_DIRECTORY StringLiteral
                    {
                    KW_DIRECTORY779=(Token)match(input,KW_DIRECTORY,FOLLOW_KW_DIRECTORY_in_destination12230);  
                    stream_KW_DIRECTORY.add(KW_DIRECTORY779);


                    StringLiteral780=(Token)match(input,StringLiteral,FOLLOW_StringLiteral_in_destination12232);  
                    stream_StringLiteral.add(StringLiteral780);


                    // AST REWRITE
                    // elements: StringLiteral
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1909:33: -> ^( TOK_DIR StringLiteral )
                    {
                        // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1909:36: ^( TOK_DIR StringLiteral )
                        {
                        CommonTree root_1 = (CommonTree)adaptor.nil();
                        root_1 = (CommonTree)adaptor.becomeRoot(
                        (CommonTree)adaptor.create(TOK_DIR, "TOK_DIR")
                        , root_1);

                        adaptor.addChild(root_1, 
                        stream_StringLiteral.nextNode()
                        );

                        adaptor.addChild(root_0, root_1);
                        }

                    }


                    retval.tree = root_0;

                    }
                    break;
                case 3 :
                    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1910:6: KW_TABLE tableOrPartition
                    {
                    KW_TABLE781=(Token)match(input,KW_TABLE,FOLLOW_KW_TABLE_in_destination12247);  
                    stream_KW_TABLE.add(KW_TABLE781);


                    pushFollow(FOLLOW_tableOrPartition_in_destination12249);
                    tableOrPartition782=tableOrPartition();

                    state._fsp--;

                    stream_tableOrPartition.add(tableOrPartition782.getTree());

                    // AST REWRITE
                    // elements: tableOrPartition
                    // token labels: 
                    // rule labels: retval
                    // token list labels: 
                    // rule list labels: 
                    // wildcard labels: 
                    retval.tree = root_0;
                    RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

                    root_0 = (CommonTree)adaptor.nil();
                    // 1910:32: -> tableOrPartition
                    {
                        adaptor.addChild(root_0, stream_tableOrPartition.nextTree());

                    }


                    retval.tree = root_0;

                    }
                    break;

            }
            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "destination"


    public static class limitClause_return extends ParserRuleReturnScope {
        CommonTree tree;
        public Object getTree() { return tree; }
    };


    // $ANTLR start "limitClause"
    // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1913:1: limitClause : KW_LIMIT num= Number -> ^( TOK_LIMIT $num) ;
    public final HiveParser.limitClause_return limitClause() throws RecognitionException {
        HiveParser.limitClause_return retval = new HiveParser.limitClause_return();
        retval.start = input.LT(1);


        CommonTree root_0 = null;

        Token num=null;
        Token KW_LIMIT783=null;

        CommonTree num_tree=null;
        CommonTree KW_LIMIT783_tree=null;
        RewriteRuleTokenStream stream_Number=new RewriteRuleTokenStream(adaptor,"token Number");
        RewriteRuleTokenStream stream_KW_LIMIT=new RewriteRuleTokenStream(adaptor,"token KW_LIMIT");

         msgs.push("limit clause"); 
        try {
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1916:4: ( KW_LIMIT num= Number -> ^( TOK_LIMIT $num) )
            // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1917:4: KW_LIMIT num= Number
            {
            KW_LIMIT783=(Token)match(input,KW_LIMIT,FOLLOW_KW_LIMIT_in_limitClause12281);  
            stream_KW_LIMIT.add(KW_LIMIT783);


            num=(Token)match(input,Number,FOLLOW_Number_in_limitClause12285);  
            stream_Number.add(num);


            // AST REWRITE
            // elements: num
            // token labels: num
            // rule labels: retval
            // token list labels: 
            // rule list labels: 
            // wildcard labels: 
            retval.tree = root_0;
            RewriteRuleTokenStream stream_num=new RewriteRuleTokenStream(adaptor,"token num",num);
            RewriteRuleSubtreeStream stream_retval=new RewriteRuleSubtreeStream(adaptor,"rule retval",retval!=null?retval.tree:null);

            root_0 = (CommonTree)adaptor.nil();
            // 1917:24: -> ^( TOK_LIMIT $num)
            {
                // /root/workspace/disk2/opensource/hive-release-0.12.0/ql/src/java/org/apache/hadoop/hive/ql/parse/HiveParser.g:1917:27: ^( TOK_LIMIT $num)
                {
                CommonTree root_1 = (CommonTree)adaptor.nil();
                root_1 = (CommonTree)adaptor.becomeRoot(
                (CommonTree)adaptor.create(TOK_LIMIT, "TOK_LIMIT")
                , root_1);

                adaptor.addChild(root_1, stream_num.nextNode());

                adaptor.addChild(root_0, root_1);
                }

            }


            retval.tree = root_0;

            }

            retval.stop = input.LT(-1);


            retval.tree = (CommonTree)adaptor.rulePostProcessing(root_0);
            adaptor.setTokenBoundaries(retval.tree, retval.start, retval.stop);

             msgs.pop(); 
        }

        catch (RecognitionException e) {
         reportError(e);
          throw e;
        }

        finally {
        	// do for sure before leaving
        }
        return retval;
    }
    // $ANTLR end "limitClause"

    // Delegated rules
    public HiveParser_IdentifiersParser.descFuncNames_return descFuncNames() throws RecognitionException { return gIdentifiersParser.descFuncNames(); }
    public HiveParser_FromClauseParser.expressionList_return expressionList() throws RecognitionException { return gFromClauseParser.expressionList(); }
    public HiveParser_IdentifiersParser.constant_return constant() throws RecognitionException { return gIdentifiersParser.constant(); }
    public HiveParser_IdentifiersParser.nullCondition_return nullCondition() throws RecognitionException { return gIdentifiersParser.nullCondition(); }
    public HiveParser_IdentifiersParser.caseExpression_return caseExpression() throws RecognitionException { return gIdentifiersParser.caseExpression(); }
    public HiveParser_SelectClauseParser.hintItem_return hintItem() throws RecognitionException { return gSelectClauseParser.hintItem(); }
    public HiveParser_IdentifiersParser.function_return function() throws RecognitionException { return gIdentifiersParser.function(); }
    public HiveParser_FromClauseParser.fromClause_return fromClause() throws RecognitionException { return gFromClauseParser.fromClause(); }
    public HiveParser_IdentifiersParser.charSetStringLiteral_return charSetStringLiteral() throws RecognitionException { return gIdentifiersParser.charSetStringLiteral(); }
    public HiveParser_FromClauseParser.tableAlias_return tableAlias() throws RecognitionException { return gFromClauseParser.tableAlias(); }
    public HiveParser_SelectClauseParser.window_clause_return window_clause() throws RecognitionException { return gSelectClauseParser.window_clause(); }
    public HiveParser_IdentifiersParser.precedenceOrOperator_return precedenceOrOperator() throws RecognitionException { return gIdentifiersParser.precedenceOrOperator(); }
    public HiveParser_IdentifiersParser.precedenceEqualOperator_return precedenceEqualOperator() throws RecognitionException { return gIdentifiersParser.precedenceEqualOperator(); }
    public HiveParser_FromClauseParser.subQuerySource_return subQuerySource() throws RecognitionException { return gFromClauseParser.subQuerySource(); }
    public HiveParser_IdentifiersParser.groupingSetExpression_return groupingSetExpression() throws RecognitionException { return gIdentifiersParser.groupingSetExpression(); }
    public HiveParser_IdentifiersParser.stringLiteralSequence_return stringLiteralSequence() throws RecognitionException { return gIdentifiersParser.stringLiteralSequence(); }
    public HiveParser_FromClauseParser.splitSample_return splitSample() throws RecognitionException { return gFromClauseParser.splitSample(); }
    public HiveParser_IdentifiersParser.precedenceUnarySuffixExpression_return precedenceUnarySuffixExpression() throws RecognitionException { return gIdentifiersParser.precedenceUnarySuffixExpression(); }
    public HiveParser_SelectClauseParser.selectList_return selectList() throws RecognitionException { return gSelectClauseParser.selectList(); }
    public HiveParser_FromClauseParser.joinToken_return joinToken() throws RecognitionException { return gFromClauseParser.joinToken(); }
    public HiveParser_IdentifiersParser.groupByClause_return groupByClause() throws RecognitionException { return gIdentifiersParser.groupByClause(); }
    public HiveParser_IdentifiersParser.atomExpression_return atomExpression() throws RecognitionException { return gIdentifiersParser.atomExpression(); }
    public HiveParser_FromClauseParser.tableSource_return tableSource() throws RecognitionException { return gFromClauseParser.tableSource(); }
    public HiveParser_IdentifiersParser.identifier_return identifier() throws RecognitionException { return gIdentifiersParser.identifier(); }
    public HiveParser_IdentifiersParser.precedenceEqualExpression_return precedenceEqualExpression() throws RecognitionException { return gIdentifiersParser.precedenceEqualExpression(); }
    public HiveParser_IdentifiersParser.dropPartitionOperator_return dropPartitionOperator() throws RecognitionException { return gIdentifiersParser.dropPartitionOperator(); }
    public HiveParser_SelectClauseParser.selectItem_return selectItem() throws RecognitionException { return gSelectClauseParser.selectItem(); }
    public HiveParser_IdentifiersParser.expressions_return expressions() throws RecognitionException { return gIdentifiersParser.expressions(); }
    public HiveParser_IdentifiersParser.distributeByClause_return distributeByClause() throws RecognitionException { return gIdentifiersParser.distributeByClause(); }
    public HiveParser_IdentifiersParser.precedenceAndOperator_return precedenceAndOperator() throws RecognitionException { return gIdentifiersParser.precedenceAndOperator(); }
    public HiveParser_FromClauseParser.viewName_return viewName() throws RecognitionException { return gFromClauseParser.viewName(); }
    public HiveParser_IdentifiersParser.precedenceOrExpression_return precedenceOrExpression() throws RecognitionException { return gIdentifiersParser.precedenceOrExpression(); }
    public HiveParser_IdentifiersParser.precedencePlusExpression_return precedencePlusExpression() throws RecognitionException { return gIdentifiersParser.precedencePlusExpression(); }
    public HiveParser_FromClauseParser.tableBucketSample_return tableBucketSample() throws RecognitionException { return gFromClauseParser.tableBucketSample(); }
    public HiveParser_FromClauseParser.tableOrColumn_return tableOrColumn() throws RecognitionException { return gFromClauseParser.tableOrColumn(); }
    public HiveParser_IdentifiersParser.havingClause_return havingClause() throws RecognitionException { return gIdentifiersParser.havingClause(); }
    public HiveParser_FromClauseParser.searchCondition_return searchCondition() throws RecognitionException { return gFromClauseParser.searchCondition(); }
    public HiveParser_FromClauseParser.tableName_return tableName() throws RecognitionException { return gFromClauseParser.tableName(); }
    public HiveParser_IdentifiersParser.nonReserved_return nonReserved() throws RecognitionException { return gIdentifiersParser.nonReserved(); }
    public HiveParser_IdentifiersParser.partitionByClause_return partitionByClause() throws RecognitionException { return gIdentifiersParser.partitionByClause(); }
    public HiveParser_IdentifiersParser.precedenceNotOperator_return precedenceNotOperator() throws RecognitionException { return gIdentifiersParser.precedenceNotOperator(); }
    public HiveParser_FromClauseParser.tableSample_return tableSample() throws RecognitionException { return gFromClauseParser.tableSample(); }
    public HiveParser_IdentifiersParser.precedenceNotExpression_return precedenceNotExpression() throws RecognitionException { return gIdentifiersParser.precedenceNotExpression(); }
    public HiveParser_SelectClauseParser.window_specification_return window_specification() throws RecognitionException { return gSelectClauseParser.window_specification(); }
    public HiveParser_SelectClauseParser.selectExpression_return selectExpression() throws RecognitionException { return gSelectClauseParser.selectExpression(); }
    public HiveParser_FromClauseParser.aliasList_return aliasList() throws RecognitionException { return gFromClauseParser.aliasList(); }
    public HiveParser_IdentifiersParser.precedenceEqualNegatableOperator_return precedenceEqualNegatableOperator() throws RecognitionException { return gIdentifiersParser.precedenceEqualNegatableOperator(); }
    public HiveParser_IdentifiersParser.precedenceBitwiseOrOperator_return precedenceBitwiseOrOperator() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseOrOperator(); }
    public HiveParser_FromClauseParser.uniqueJoinExpr_return uniqueJoinExpr() throws RecognitionException { return gFromClauseParser.uniqueJoinExpr(); }
    public HiveParser_IdentifiersParser.precedenceUnaryPrefixExpression_return precedenceUnaryPrefixExpression() throws RecognitionException { return gIdentifiersParser.precedenceUnaryPrefixExpression(); }
    public HiveParser_IdentifiersParser.clusterByClause_return clusterByClause() throws RecognitionException { return gIdentifiersParser.clusterByClause(); }
    public HiveParser_IdentifiersParser.functionName_return functionName() throws RecognitionException { return gIdentifiersParser.functionName(); }
    public HiveParser_FromClauseParser.uniqueJoinSource_return uniqueJoinSource() throws RecognitionException { return gFromClauseParser.uniqueJoinSource(); }
    public HiveParser_SelectClauseParser.hintClause_return hintClause() throws RecognitionException { return gSelectClauseParser.hintClause(); }
    public HiveParser_SelectClauseParser.hintArgs_return hintArgs() throws RecognitionException { return gSelectClauseParser.hintArgs(); }
    public HiveParser_IdentifiersParser.expression_return expression() throws RecognitionException { return gIdentifiersParser.expression(); }
    public HiveParser_IdentifiersParser.dateLiteral_return dateLiteral() throws RecognitionException { return gIdentifiersParser.dateLiteral(); }
    public HiveParser_IdentifiersParser.precedenceAmpersandOperator_return precedenceAmpersandOperator() throws RecognitionException { return gIdentifiersParser.precedenceAmpersandOperator(); }
    public HiveParser_SelectClauseParser.hintName_return hintName() throws RecognitionException { return gSelectClauseParser.hintName(); }
    public HiveParser_FromClauseParser.joinSource_return joinSource() throws RecognitionException { return gFromClauseParser.joinSource(); }
    public HiveParser_IdentifiersParser.precedencePlusOperator_return precedencePlusOperator() throws RecognitionException { return gIdentifiersParser.precedencePlusOperator(); }
    public HiveParser_IdentifiersParser.havingCondition_return havingCondition() throws RecognitionException { return gIdentifiersParser.havingCondition(); }
    public HiveParser_IdentifiersParser.precedenceStarExpression_return precedenceStarExpression() throws RecognitionException { return gIdentifiersParser.precedenceStarExpression(); }
    public HiveParser_FromClauseParser.partitionedTableFunction_return partitionedTableFunction() throws RecognitionException { return gFromClauseParser.partitionedTableFunction(); }
    public HiveParser_FromClauseParser.partitioningSpec_return partitioningSpec() throws RecognitionException { return gFromClauseParser.partitioningSpec(); }
    public HiveParser_IdentifiersParser.castExpression_return castExpression() throws RecognitionException { return gIdentifiersParser.castExpression(); }
    public HiveParser_SelectClauseParser.trfmClause_return trfmClause() throws RecognitionException { return gSelectClauseParser.trfmClause(); }
    public HiveParser_IdentifiersParser.precedenceAndExpression_return precedenceAndExpression() throws RecognitionException { return gIdentifiersParser.precedenceAndExpression(); }
    public HiveParser_IdentifiersParser.precedenceAmpersandExpression_return precedenceAmpersandExpression() throws RecognitionException { return gIdentifiersParser.precedenceAmpersandExpression(); }
    public HiveParser_IdentifiersParser.tableOrPartition_return tableOrPartition() throws RecognitionException { return gIdentifiersParser.tableOrPartition(); }
    public HiveParser_IdentifiersParser.precedenceBitwiseOrExpression_return precedenceBitwiseOrExpression() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseOrExpression(); }
    public HiveParser_FromClauseParser.fromSource_return fromSource() throws RecognitionException { return gFromClauseParser.fromSource(); }
    public HiveParser_SelectClauseParser.window_frame_start_boundary_return window_frame_start_boundary() throws RecognitionException { return gSelectClauseParser.window_frame_start_boundary(); }
    public HiveParser_FromClauseParser.lateralView_return lateralView() throws RecognitionException { return gFromClauseParser.lateralView(); }
    public HiveParser_IdentifiersParser.whenExpression_return whenExpression() throws RecognitionException { return gIdentifiersParser.whenExpression(); }
    public HiveParser_IdentifiersParser.sortByClause_return sortByClause() throws RecognitionException { return gIdentifiersParser.sortByClause(); }
    public HiveParser_IdentifiersParser.dropPartitionVal_return dropPartitionVal() throws RecognitionException { return gIdentifiersParser.dropPartitionVal(); }
    public HiveParser_IdentifiersParser.dropPartitionSpec_return dropPartitionSpec() throws RecognitionException { return gIdentifiersParser.dropPartitionSpec(); }
    public HiveParser_SelectClauseParser.hintArgName_return hintArgName() throws RecognitionException { return gSelectClauseParser.hintArgName(); }
    public HiveParser_IdentifiersParser.precedenceBitwiseXorOperator_return precedenceBitwiseXorOperator() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseXorOperator(); }
    public HiveParser_SelectClauseParser.window_frame_boundary_return window_frame_boundary() throws RecognitionException { return gSelectClauseParser.window_frame_boundary(); }
    public HiveParser_IdentifiersParser.precedenceUnaryOperator_return precedenceUnaryOperator() throws RecognitionException { return gIdentifiersParser.precedenceUnaryOperator(); }
    public HiveParser_IdentifiersParser.booleanValue_return booleanValue() throws RecognitionException { return gIdentifiersParser.booleanValue(); }
    public HiveParser_SelectClauseParser.selectTrfmClause_return selectTrfmClause() throws RecognitionException { return gSelectClauseParser.selectTrfmClause(); }
    public HiveParser_SelectClauseParser.selectExpressionList_return selectExpressionList() throws RecognitionException { return gSelectClauseParser.selectExpressionList(); }
    public HiveParser_IdentifiersParser.orderByClause_return orderByClause() throws RecognitionException { return gIdentifiersParser.orderByClause(); }
    public HiveParser_FromClauseParser.tableAllColumns_return tableAllColumns() throws RecognitionException { return gFromClauseParser.tableAllColumns(); }
    public HiveParser_IdentifiersParser.partitionVal_return partitionVal() throws RecognitionException { return gIdentifiersParser.partitionVal(); }
    public HiveParser_FromClauseParser.whereClause_return whereClause() throws RecognitionException { return gFromClauseParser.whereClause(); }
    public HiveParser_SelectClauseParser.window_value_expression_return window_value_expression() throws RecognitionException { return gSelectClauseParser.window_value_expression(); }
    public HiveParser_IdentifiersParser.precedenceBitwiseXorExpression_return precedenceBitwiseXorExpression() throws RecognitionException { return gIdentifiersParser.precedenceBitwiseXorExpression(); }
    public HiveParser_FromClauseParser.uniqueJoinToken_return uniqueJoinToken() throws RecognitionException { return gFromClauseParser.uniqueJoinToken(); }
    public HiveParser_IdentifiersParser.partitionSpec_return partitionSpec() throws RecognitionException { return gIdentifiersParser.partitionSpec(); }
    public HiveParser_IdentifiersParser.precedenceStarOperator_return precedenceStarOperator() throws RecognitionException { return gIdentifiersParser.precedenceStarOperator(); }
    public HiveParser_SelectClauseParser.hintList_return hintList() throws RecognitionException { return gSelectClauseParser.hintList(); }
    public HiveParser_SelectClauseParser.selectClause_return selectClause() throws RecognitionException { return gSelectClauseParser.selectClause(); }
    public HiveParser_IdentifiersParser.groupByExpression_return groupByExpression() throws RecognitionException { return gIdentifiersParser.groupByExpression(); }
    public HiveParser_SelectClauseParser.window_frame_return window_frame() throws RecognitionException { return gSelectClauseParser.window_frame(); }
    public HiveParser_FromClauseParser.partitionTableFunctionSource_return partitionTableFunctionSource() throws RecognitionException { return gFromClauseParser.partitionTableFunctionSource(); }
    public HiveParser_IdentifiersParser.precedenceFieldExpression_return precedenceFieldExpression() throws RecognitionException { return gIdentifiersParser.precedenceFieldExpression(); }
    public HiveParser_SelectClauseParser.window_defn_return window_defn() throws RecognitionException { return gSelectClauseParser.window_defn(); }
    public HiveParser_IdentifiersParser.sysFuncNames_return sysFuncNames() throws RecognitionException { return gIdentifiersParser.sysFuncNames(); }
    public HiveParser_SelectClauseParser.window_range_expression_return window_range_expression() throws RecognitionException { return gSelectClauseParser.window_range_expression(); }


    protected DFA9 dfa9 = new DFA9(this);
    protected DFA48 dfa48 = new DFA48(this);
    protected DFA160 dfa160 = new DFA160(this);
    static final String DFA9_eotS =
        "\106\uffff";
    static final String DFA9_eofS =
        "\106\uffff";
    static final String DFA9_minS =
        "\1\36\1\102\1\uffff\1\102\4\uffff\1\67\4\uffff\2\35\1\155\13\uffff"+
        "\1\155\52\uffff";
    static final String DFA9_maxS =
        "\1\u00fe\1\u0105\1\uffff\1\u0105\4\uffff\1\u00e7\4\uffff\2\u00fd"+
        "\1\u0095\13\uffff\1\u0095\52\uffff";
    static final String DFA9_acceptS =
        "\2\uffff\1\2\1\uffff\1\6\1\7\1\10\2\uffff\1\12\1\23\1\24\1\25\3"+
        "\uffff\1\17\1\26\1\1\1\uffff\1\4\1\uffff\1\13\1\uffff\1\5\1\14\1"+
        "\20\1\uffff\1\27\1\3\1\uffff\1\11\7\uffff\1\32\1\33\5\uffff\1\34"+
        "\1\30\10\uffff\1\35\1\31\10\uffff\1\15\1\16\1\21\1\22";
    static final String DFA9_specialS =
        "\106\uffff}>";
    static final String[] DFA9_transitionS = {
            "\1\5\1\12\34\uffff\1\1\17\uffff\2\6\6\uffff\1\3\32\uffff\1\15"+
            "\41\uffff\1\13\11\uffff\1\11\53\uffff\1\16\20\uffff\1\10\32"+
            "\uffff\1\4\6\uffff\1\14\3\uffff\1\2",
            "\1\22\35\uffff\1\24\30\uffff\1\20\52\uffff\1\26\45\uffff\1"+
            "\21\3\uffff\1\22\25\uffff\1\24\3\uffff\1\17\34\uffff\1\26",
            "",
            "\1\35\66\uffff\1\32\120\uffff\1\34\3\uffff\1\35\25\uffff\1"+
            "\30\3\uffff\1\33\34\uffff\1\31",
            "",
            "",
            "",
            "",
            "\1\37\4\uffff\1\37\6\uffff\1\37\46\uffff\1\37\3\uffff\1\37"+
            "\1\47\11\uffff\2\37\27\uffff\1\37\35\uffff\1\37\31\uffff\1\50"+
            "\4\uffff\1\37\24\uffff\2\37\1\uffff\1\37",
            "",
            "",
            "",
            "",
            "\2\57\35\uffff\1\57\27\uffff\1\57\44\uffff\1\57\27\uffff\1"+
            "\57\70\uffff\1\56\5\uffff\1\57\10\uffff\1\57\43\uffff\1\57",
            "\2\71\35\uffff\1\71\27\uffff\1\71\44\uffff\1\71\27\uffff\1"+
            "\71\70\uffff\1\70\5\uffff\1\71\10\uffff\1\71\43\uffff\1\71",
            "\1\102\47\uffff\1\103",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "\1\104\47\uffff\1\105",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
    };

    static final short[] DFA9_eot = DFA.unpackEncodedString(DFA9_eotS);
    static final short[] DFA9_eof = DFA.unpackEncodedString(DFA9_eofS);
    static final char[] DFA9_min = DFA.unpackEncodedStringToUnsignedChars(DFA9_minS);
    static final char[] DFA9_max = DFA.unpackEncodedStringToUnsignedChars(DFA9_maxS);
    static final short[] DFA9_accept = DFA.unpackEncodedString(DFA9_acceptS);
    static final short[] DFA9_special = DFA.unpackEncodedString(DFA9_specialS);
    static final short[][] DFA9_transition;

    static {
        int numStates = DFA9_transitionS.length;
        DFA9_transition = new short[numStates][];
        for (int i=0; i<numStates; i++) {
            DFA9_transition[i] = DFA.unpackEncodedString(DFA9_transitionS[i]);
        }
    }

    class DFA9 extends DFA {

        public DFA9(BaseRecognizer recognizer) {
            this.recognizer = recognizer;
            this.decisionNumber = 9;
            this.eot = DFA9_eot;
            this.eof = DFA9_eof;
            this.min = DFA9_min;
            this.max = DFA9_max;
            this.accept = DFA9_accept;
            this.special = DFA9_special;
            this.transition = DFA9_transition;
        }
        public String getDescription() {
            return "598:1: ddlStatement : ( createDatabaseStatement | switchDatabaseStatement | dropDatabaseStatement | createTableStatement | dropTableStatement | truncateTableStatement | alterStatement | descStatement | showStatement | metastoreCheck | createViewStatement | dropViewStatement | createFunctionStatement | createMacroStatement | createIndexStatement | dropIndexStatement | dropFunctionStatement | dropMacroStatement | analyzeStatement | lockStatement | unlockStatement | createRoleStatement | dropRoleStatement | grantPrivileges | revokePrivileges | showGrants | showRoleGrants | grantRole | revokeRole );";
        }
    }
    static final String DFA48_eotS =
        "\107\uffff";
    static final String DFA48_eofS =
        "\107\uffff";
    static final String DFA48_minS =
        "\1\32\2\21\1\uffff\1\u00ee\1\67\6\uffff\1\144\5\uffff\1\63\4\uffff"+
        "\1\u00ee\1\67\6\uffff\1\144\6\uffff\1\63\40\uffff";
    static final String DFA48_maxS =
        "\1\u010a\2\u00fb\1\uffff\1\u00ee\1\u00ae\6\uffff\1\u00e7\5\uffff"+
        "\1\u00e0\4\uffff\1\u00ee\1\u00ae\6\uffff\1\u00e7\6\uffff\1\u00e0"+
        "\40\uffff";
    static final String DFA48_acceptS =
        "\3\uffff\1\12\2\uffff\1\2\1\3\1\4\1\6\1\7\1\10\1\uffff\1\11\6\uffff"+
        "\1\13\1\14\25\uffff\1\1\1\uffff\1\5\13\uffff\1\1\15\uffff";
    static final String DFA48_specialS =
        "\107\uffff}>";
    static final String[] DFA48_transitionS = {
            "\1\1\2\2\1\uffff\2\2\1\uffff\16\2\2\uffff\5\2\1\uffff\6\2\1"+
            "\uffff\1\2\1\uffff\2\2\1\uffff\16\2\1\uffff\4\2\1\uffff\1\2"+
            "\1\uffff\1\2\1\uffff\4\2\1\uffff\7\2\1\uffff\3\2\1\uffff\1\2"+
            "\1\uffff\4\2\1\uffff\2\2\1\uffff\17\2\1\uffff\4\2\1\uffff\12"+
            "\2\2\uffff\3\2\1\uffff\2\2\1\uffff\4\2\1\uffff\1\2\1\uffff\6"+
            "\2\1\uffff\1\2\1\uffff\5\2\2\uffff\14\2\1\uffff\16\2\1\uffff"+
            "\25\2\1\uffff\4\2\1\uffff\4\2\1\uffff\4\2\1\uffff\3\2\1\uffff"+
            "\12\2\1\uffff\1\2\2\uffff\1\2\1\uffff\1\2",
            "\1\25\11\uffff\1\5\5\uffff\1\12\17\uffff\1\7\1\uffff\1\3\6"+
            "\uffff\1\3\25\uffff\1\3\3\uffff\1\10\2\uffff\1\3\2\uffff\1\25"+
            "\47\uffff\1\3\32\uffff\1\22\20\uffff\1\3\24\uffff\1\4\1\uffff"+
            "\1\6\17\uffff\1\14\4\uffff\1\24\24\uffff\1\11\4\uffff\1\13\6"+
            "\uffff\1\15",
            "\1\25\11\uffff\1\30\5\uffff\1\12\17\uffff\1\7\1\uffff\1\3\6"+
            "\uffff\1\3\25\uffff\1\3\3\uffff\1\10\2\uffff\1\3\2\uffff\1\25"+
            "\47\uffff\1\3\32\uffff\1\46\20\uffff\1\3\24\uffff\1\27\1\uffff"+
            "\1\6\17\uffff\1\37\4\uffff\1\24\24\uffff\1\11\4\uffff\1\13\6"+
            "\uffff\1\15",
            "",
            "\1\53",
            "\1\6\75\uffff\1\55\70\uffff\1\55",
            "",
            "",
            "",
            "",
            "",
            "",
            "\1\3\53\uffff\1\3\102\uffff\2\3\5\uffff\1\3\14\uffff\1\15",
            "",
            "",
            "",
            "",
            "",
            "\1\3\u00a6\uffff\1\24\2\uffff\1\3\2\uffff\1\24",
            "",
            "",
            "",
            "",
            "\1\71",
            "\1\6\75\uffff\1\55\70\uffff\1\55",
            "",
            "",
            "",
            "",
            "",
            "",
            "\1\3\53\uffff\1\3\102\uffff\2\3\5\uffff\1\3\14\uffff\1\15",
            "",
            "",
            "",
            "",
            "",
            "",
            "\1\3\u00a6\uffff\1\24\2\uffff\1\3\2\uffff\1\24",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
    };

    static final short[] DFA48_eot = DFA.unpackEncodedString(DFA48_eotS);
    static final short[] DFA48_eof = DFA.unpackEncodedString(DFA48_eofS);
    static final char[] DFA48_min = DFA.unpackEncodedStringToUnsignedChars(DFA48_minS);
    static final char[] DFA48_max = DFA.unpackEncodedStringToUnsignedChars(DFA48_maxS);
    static final short[] DFA48_accept = DFA.unpackEncodedString(DFA48_acceptS);
    static final short[] DFA48_special = DFA.unpackEncodedString(DFA48_specialS);
    static final short[][] DFA48_transition;

    static {
        int numStates = DFA48_transitionS.length;
        DFA48_transition = new short[numStates][];
        for (int i=0; i<numStates; i++) {
            DFA48_transition[i] = DFA.unpackEncodedString(DFA48_transitionS[i]);
        }
    }

    class DFA48 extends DFA {

        public DFA48(BaseRecognizer recognizer) {
            this.recognizer = recognizer;
            this.decisionNumber = 48;
            this.eot = DFA48_eot;
            this.eof = DFA48_eof;
            this.min = DFA48_min;
            this.max = DFA48_max;
            this.accept = DFA48_accept;
            this.special = DFA48_special;
            this.transition = DFA48_transition;
        }
        public String getDescription() {
            return "864:1: alterTableStatementSuffix : ( alterStatementSuffixRename | alterStatementSuffixAddCol | alterStatementSuffixRenameCol | alterStatementSuffixDropPartitions | alterStatementSuffixAddPartitions | alterStatementSuffixTouch | alterStatementSuffixArchive | alterStatementSuffixUnArchive | alterStatementSuffixProperties | alterTblPartitionStatement | alterStatementSuffixSkewedby | alterStatementSuffixExchangePartition );";
        }
    }
    static final String DFA160_eotS =
        "\122\uffff";
    static final String DFA160_eofS =
        "\1\2\121\uffff";
    static final String DFA160_minS =
        "\1\43\1\7\33\uffff\1\4\64\uffff";
    static final String DFA160_maxS =
        "\1\u0118\1\u0120\33\uffff\1\u011c\64\uffff";
    static final String DFA160_acceptS =
        "\2\uffff\1\2\63\uffff\1\1\33\uffff";
    static final String DFA160_specialS =
        "\122\uffff}>";
    static final String[] DFA160_transitionS = {
            "\1\2\16\uffff\1\2\5\uffff\1\2\31\uffff\1\2\30\uffff\1\2\4\uffff"+
            "\1\2\1\uffff\1\2\2\uffff\1\2\11\uffff\1\2\10\uffff\1\2\3\uffff"+
            "\2\2\2\uffff\1\2\5\uffff\1\1\17\uffff\1\2\30\uffff\3\2\16\uffff"+
            "\1\2\13\uffff\1\2\3\uffff\1\2\6\uffff\1\2\17\uffff\1\2\10\uffff"+
            "\1\2\6\uffff\1\2\1\uffff\1\2\16\uffff\1\2",
            "\1\2\5\uffff\1\2\4\uffff\1\2\7\uffff\3\2\1\uffff\2\2\1\uffff"+
            "\25\2\1\uffff\6\2\1\uffff\1\2\1\uffff\2\2\1\uffff\16\2\1\uffff"+
            "\4\2\1\uffff\1\2\1\uffff\1\2\1\uffff\4\2\1\uffff\7\2\1\uffff"+
            "\3\2\1\uffff\1\2\1\uffff\4\2\1\uffff\22\2\1\uffff\1\35\3\2\1"+
            "\uffff\12\2\1\uffff\4\2\1\uffff\7\2\1\uffff\1\2\1\uffff\6\2"+
            "\1\uffff\1\2\1\uffff\5\2\2\uffff\14\2\1\uffff\16\2\1\uffff\25"+
            "\2\1\uffff\4\2\1\uffff\4\2\1\uffff\4\2\1\uffff\3\2\1\uffff\12"+
            "\2\1\uffff\1\2\2\uffff\1\2\1\uffff\1\2\3\uffff\1\2\2\uffff\1"+
            "\2\2\uffff\2\2\6\uffff\5\2",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "\3\2\3\uffff\1\2\3\uffff\2\2\1\uffff\1\2\2\uffff\2\2\1\uffff"+
            "\2\2\7\uffff\1\2\5\uffff\1\2\121\uffff\1\2\12\uffff\1\2\7\uffff"+
            "\1\2\21\uffff\1\2\6\uffff\1\2\33\uffff\1\2\1\uffff\1\2\6\uffff"+
            "\1\2\2\uffff\1\2\34\uffff\1\66\26\uffff\1\2\13\uffff\4\2\1\uffff"+
            "\3\2\1\uffff\1\2\6\uffff\1\2",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            "",
            ""
    };

    static final short[] DFA160_eot = DFA.unpackEncodedString(DFA160_eotS);
    static final short[] DFA160_eof = DFA.unpackEncodedString(DFA160_eofS);
    static final char[] DFA160_min = DFA.unpackEncodedStringToUnsignedChars(DFA160_minS);
    static final char[] DFA160_max = DFA.unpackEncodedStringToUnsignedChars(DFA160_maxS);
    static final short[] DFA160_accept = DFA.unpackEncodedString(DFA160_acceptS);
    static final short[] DFA160_special = DFA.unpackEncodedString(DFA160_specialS);
    static final short[][] DFA160_transition;

    static {
        int numStates = DFA160_transitionS.length;
        DFA160_transition = new short[numStates][];
        for (int i=0; i<numStates; i++) {
            DFA160_transition[i] = DFA.unpackEncodedString(DFA160_transitionS[i]);
        }
    }

    class DFA160 extends DFA {

        public DFA160(BaseRecognizer recognizer) {
            this.recognizer = recognizer;
            this.decisionNumber = 160;
            this.eot = DFA160_eot;
            this.eof = DFA160_eof;
            this.min = DFA160_min;
            this.max = DFA160_max;
            this.accept = DFA160_accept;
            this.special = DFA160_special;
            this.transition = DFA160_transition;
        }
        public String getDescription() {
            return "1518:103: ( tableRowFormatMapKeysIdentifier )?";
        }
    }
 

    public static final BitSet FOLLOW_explainStatement_in_statement905 = new BitSet(new long[]{0x0000000000000000L});
    public static final BitSet FOLLOW_EOF_in_statement907 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_execStatement_in_statement912 = new BitSet(new long[]{0x0000000000000000L});
    public static final BitSet FOLLOW_EOF_in_statement914 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_EXPLAIN_in_explainStatement935 = new BitSet(new long[]{0x10000000C0000000L,0x80808C00C0103800L,0x00000000084A4000L,0x4408000001010082L});
    public static final BitSet FOLLOW_KW_EXTENDED_in_explainStatement940 = new BitSet(new long[]{0x10000000C0000000L,0x8080880040103000L,0x0000000008424000L,0x4408000001010082L});
    public static final BitSet FOLLOW_KW_FORMATTED_in_explainStatement944 = new BitSet(new long[]{0x10000000C0000000L,0x8080880040103000L,0x0000000008424000L,0x4408000001010082L});
    public static final BitSet FOLLOW_KW_DEPENDENCY_in_explainStatement948 = new BitSet(new long[]{0x10000000C0000000L,0x8080880040103000L,0x0000000008424000L,0x4408000001010082L});
    public static final BitSet FOLLOW_KW_LOGICAL_in_explainStatement952 = new BitSet(new long[]{0x10000000C0000000L,0x8080880040103000L,0x0000000008424000L,0x4408000001010082L});
    public static final BitSet FOLLOW_execStatement_in_explainStatement956 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_queryStatementExpression_in_execStatement998 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_loadStatement_in_execStatement1006 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_exportStatement_in_execStatement1014 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_importStatement_in_execStatement1022 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_ddlStatement_in_execStatement1030 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_LOAD_in_loadStatement1057 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DATA_in_loadStatement1059 = new BitSet(new long[]{0x0000000000000000L,0x1000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_KW_LOCAL_in_loadStatement1064 = new BitSet(new long[]{0x0000000000000000L,0x1000000000000000L});
    public static final BitSet FOLLOW_KW_INPATH_in_loadStatement1068 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_loadStatement1073 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000100000000004L});
    public static final BitSet FOLLOW_KW_OVERWRITE_in_loadStatement1079 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_INTO_in_loadStatement1083 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_TABLE_in_loadStatement1085 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_tableOrPartition_in_loadStatement1090 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_EXPORT_in_exportStatement1142 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_TABLE_in_exportStatement1144 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_tableOrPartition_in_exportStatement1149 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_KW_TO_in_exportStatement1152 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_exportStatement1157 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_IMPORT_in_importStatement1198 = new BitSet(new long[]{0x0000000000000000L,0x0000080100000000L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_EXTERNAL_in_importStatement1204 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_TABLE_in_importStatement1208 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_tableOrPartition_in_importStatement1213 = new BitSet(new long[]{0x0000000000000000L,0x0000080000000000L});
    public static final BitSet FOLLOW_KW_FROM_in_importStatement1218 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_importStatement1223 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000010000L});
    public static final BitSet FOLLOW_tableLocation_in_importStatement1226 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_createDatabaseStatement_in_ddlStatement1278 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_switchDatabaseStatement_in_ddlStatement1286 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_dropDatabaseStatement_in_ddlStatement1294 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_createTableStatement_in_ddlStatement1302 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_dropTableStatement_in_ddlStatement1310 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_truncateTableStatement_in_ddlStatement1318 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatement_in_ddlStatement1326 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_descStatement_in_ddlStatement1334 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_showStatement_in_ddlStatement1342 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_metastoreCheck_in_ddlStatement1350 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_createViewStatement_in_ddlStatement1358 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_dropViewStatement_in_ddlStatement1366 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_createFunctionStatement_in_ddlStatement1374 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_createMacroStatement_in_ddlStatement1382 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_createIndexStatement_in_ddlStatement1390 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_dropIndexStatement_in_ddlStatement1398 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_dropFunctionStatement_in_ddlStatement1406 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_dropMacroStatement_in_ddlStatement1414 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_analyzeStatement_in_ddlStatement1422 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_lockStatement_in_ddlStatement1430 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_unlockStatement_in_ddlStatement1438 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_createRoleStatement_in_ddlStatement1446 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_dropRoleStatement_in_ddlStatement1454 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_grantPrivileges_in_ddlStatement1462 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_revokePrivileges_in_ddlStatement1470 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_showGrants_in_ddlStatement1478 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_showRoleGrants_in_ddlStatement1486 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_grantRole_in_ddlStatement1494 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_revokeRole_in_ddlStatement1502 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_IF_in_ifExists1529 = new BitSet(new long[]{0x0000000000000000L,0x0000000010000000L});
    public static final BitSet FOLLOW_KW_EXISTS_in_ifExists1531 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_RESTRICT_in_restrictOrCascade1568 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CASCADE_in_restrictOrCascade1586 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_IF_in_ifNotExists1623 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000020000000L});
    public static final BitSet FOLLOW_KW_NOT_in_ifNotExists1625 = new BitSet(new long[]{0x0000000000000000L,0x0000000010000000L});
    public static final BitSet FOLLOW_KW_EXISTS_in_ifNotExists1627 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_STORED_in_storedAsDirs1664 = new BitSet(new long[]{0x0000000800000000L});
    public static final BitSet FOLLOW_KW_AS_in_storedAsDirs1666 = new BitSet(new long[]{0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_KW_DIRECTORIES_in_storedAsDirs1668 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_OR_in_orReplace1705 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
    public static final BitSet FOLLOW_KW_REPLACE_in_orReplace1707 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_IGNORE_in_ignoreProtection1748 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
    public static final BitSet FOLLOW_KW_PROTECTION_in_ignoreProtection1750 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CREATE_in_createDatabaseStatement1795 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_KW_DATABASE_in_createDatabaseStatement1798 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFFBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_KW_SCHEMA_in_createDatabaseStatement1800 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFFBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_ifNotExists_in_createDatabaseStatement1811 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_createDatabaseStatement1824 = new BitSet(new long[]{0x0100000000000002L,0x0000000000000000L,0x0000000000010000L,0x0000000000000000L,0x0000000000000400L});
    public static final BitSet FOLLOW_databaseComment_in_createDatabaseStatement1834 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000010000L,0x0000000000000000L,0x0000000000000400L});
    public static final BitSet FOLLOW_dbLocation_in_createDatabaseStatement1845 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L});
    public static final BitSet FOLLOW_KW_WITH_in_createDatabaseStatement1857 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_KW_DBPROPERTIES_in_createDatabaseStatement1859 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_dbProperties_in_createDatabaseStatement1863 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_LOCATION_in_dbLocation1924 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_dbLocation1928 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_LPAREN_in_dbProperties1970 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_dbPropertiesList_in_dbProperties1972 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_dbProperties1974 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_keyValueProperty_in_dbPropertiesList2015 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_dbPropertiesList2018 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_keyValueProperty_in_dbPropertiesList2020 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_KW_USE_in_switchDatabaseStatement2059 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_switchDatabaseStatement2061 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DROP_in_dropDatabaseStatement2100 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_KW_DATABASE_in_dropDatabaseStatement2103 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFFBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_KW_SCHEMA_in_dropDatabaseStatement2105 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFFBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_ifExists_in_dropDatabaseStatement2108 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_dropDatabaseStatement2111 = new BitSet(new long[]{0x0000400000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_restrictOrCascade_in_dropDatabaseStatement2113 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_COMMENT_in_databaseComment2159 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_databaseComment2163 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CREATE_in_createTableStatement2203 = new BitSet(new long[]{0x0000000000000000L,0x0000000100000000L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_EXTERNAL_in_createTableStatement2208 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_TABLE_in_createTableStatement2212 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFFBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_ifNotExists_in_createTableStatement2214 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_tableName_in_createTableStatement2219 = new BitSet(new long[]{0x0108000800000002L,0x0000000000000000L,0x0000800000010800L,0x0000008104001000L,0x0000000000004000L});
    public static final BitSet FOLLOW_KW_LIKE_in_createTableStatement2232 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_tableName_in_createTableStatement2236 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000010000L,0x0000008000000000L});
    public static final BitSet FOLLOW_tableLocation_in_createTableStatement2247 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
    public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createTableStatement2259 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_LPAREN_in_createTableStatement2272 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnNameTypeList_in_createTableStatement2274 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_createTableStatement2276 = new BitSet(new long[]{0x0108000800000002L,0x0000000000000000L,0x0000800000010000L,0x0000008104001000L});
    public static final BitSet FOLLOW_tableComment_in_createTableStatement2289 = new BitSet(new long[]{0x0008000800000002L,0x0000000000000000L,0x0000800000010000L,0x0000008104001000L});
    public static final BitSet FOLLOW_tablePartition_in_createTableStatement2301 = new BitSet(new long[]{0x0008000800000002L,0x0000000000000000L,0x0000000000010000L,0x0000008104001000L});
    public static final BitSet FOLLOW_tableBuckets_in_createTableStatement2313 = new BitSet(new long[]{0x0000000800000002L,0x0000000000000000L,0x0000000000010000L,0x0000008104001000L});
    public static final BitSet FOLLOW_tableSkewed_in_createTableStatement2325 = new BitSet(new long[]{0x0000000800000002L,0x0000000000000000L,0x0000000000010000L,0x0000008100001000L});
    public static final BitSet FOLLOW_tableRowFormat_in_createTableStatement2337 = new BitSet(new long[]{0x0000000800000002L,0x0000000000000000L,0x0000000000010000L,0x0000008100000000L});
    public static final BitSet FOLLOW_tableFileFormat_in_createTableStatement2349 = new BitSet(new long[]{0x0000000800000002L,0x0000000000000000L,0x0000000000010000L,0x0000008000000000L});
    public static final BitSet FOLLOW_tableLocation_in_createTableStatement2361 = new BitSet(new long[]{0x0000000800000002L,0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
    public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createTableStatement2373 = new BitSet(new long[]{0x0000000800000002L});
    public static final BitSet FOLLOW_KW_AS_in_createTableStatement2386 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000400000L,0x0000000000010002L});
    public static final BitSet FOLLOW_selectStatement_in_createTableStatement2388 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_TRUNCATE_in_truncateTableStatement2591 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_TABLE_in_truncateTableStatement2593 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_tablePartitionPrefix_in_truncateTableStatement2595 = new BitSet(new long[]{0x0080000000000002L});
    public static final BitSet FOLLOW_KW_COLUMNS_in_truncateTableStatement2598 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_LPAREN_in_truncateTableStatement2600 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnNameList_in_truncateTableStatement2602 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_truncateTableStatement2604 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CREATE_in_createIndexStatement2639 = new BitSet(new long[]{0x0000000000000000L,0x0200000000000000L});
    public static final BitSet FOLLOW_KW_INDEX_in_createIndexStatement2641 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_createIndexStatement2645 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
    public static final BitSet FOLLOW_KW_ON_in_createIndexStatement2653 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_TABLE_in_createIndexStatement2655 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_tableName_in_createIndexStatement2659 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_LPAREN_in_createIndexStatement2661 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnNameList_in_createIndexStatement2665 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_createIndexStatement2667 = new BitSet(new long[]{0x0000000800000000L});
    public static final BitSet FOLLOW_KW_AS_in_createIndexStatement2675 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_createIndexStatement2679 = new BitSet(new long[]{0x0100000000000002L,0x0110000000000000L,0x0000000000010000L,0x0000008100001000L,0x0000000000000400L});
    public static final BitSet FOLLOW_autoRebuild_in_createIndexStatement2687 = new BitSet(new long[]{0x0100000000000002L,0x0110000000000000L,0x0000000000010000L,0x0000008100001000L});
    public static final BitSet FOLLOW_indexPropertiesPrefixed_in_createIndexStatement2696 = new BitSet(new long[]{0x0100000000000002L,0x0100000000000000L,0x0000000000010000L,0x0000008100001000L});
    public static final BitSet FOLLOW_indexTblName_in_createIndexStatement2705 = new BitSet(new long[]{0x0100000000000002L,0x0000000000000000L,0x0000000000010000L,0x0000008100001000L});
    public static final BitSet FOLLOW_tableRowFormat_in_createIndexStatement2714 = new BitSet(new long[]{0x0100000000000002L,0x0000000000000000L,0x0000000000010000L,0x0000008100000000L});
    public static final BitSet FOLLOW_tableFileFormat_in_createIndexStatement2723 = new BitSet(new long[]{0x0100000000000002L,0x0000000000000000L,0x0000000000010000L,0x0000008000000000L});
    public static final BitSet FOLLOW_tableLocation_in_createIndexStatement2732 = new BitSet(new long[]{0x0100000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
    public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createIndexStatement2741 = new BitSet(new long[]{0x0100000000000002L});
    public static final BitSet FOLLOW_indexComment_in_createIndexStatement2750 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_COMMENT_in_indexComment2907 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_indexComment2911 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_WITH_in_autoRebuild2952 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000100L});
    public static final BitSet FOLLOW_KW_DEFERRED_in_autoRebuild2954 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x4000000000000000L});
    public static final BitSet FOLLOW_KW_REBUILD_in_autoRebuild2956 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_IN_in_indexTblName2992 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_TABLE_in_indexTblName2994 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_tableName_in_indexTblName2998 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_IDXPROPERTIES_in_indexPropertiesPrefixed3045 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_indexProperties_in_indexPropertiesPrefixed3048 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_LPAREN_in_indexProperties3081 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_indexPropertiesList_in_indexProperties3083 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_indexProperties3085 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_keyValueProperty_in_indexPropertiesList3126 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_indexPropertiesList3129 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_keyValueProperty_in_indexPropertiesList3131 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_KW_DROP_in_dropIndexStatement3169 = new BitSet(new long[]{0x0000000000000000L,0x0200000000000000L});
    public static final BitSet FOLLOW_KW_INDEX_in_dropIndexStatement3171 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFFBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_ifExists_in_dropIndexStatement3173 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_dropIndexStatement3178 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
    public static final BitSet FOLLOW_KW_ON_in_dropIndexStatement3180 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_tableName_in_dropIndexStatement3184 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DROP_in_dropTableStatement3229 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_TABLE_in_dropTableStatement3231 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFFBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_ifExists_in_dropTableStatement3233 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_tableName_in_dropTableStatement3236 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ALTER_in_alterStatement3274 = new BitSet(new long[]{0x0000000000000000L,0x0200000000000004L,0x0000000000000000L,0x0000001000000000L,0x0000000000000020L});
    public static final BitSet FOLLOW_KW_TABLE_in_alterStatement3299 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_alterTableStatementSuffix_in_alterStatement3302 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_VIEW_in_alterStatement3326 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_alterViewStatementSuffix_in_alterStatement3329 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_INDEX_in_alterStatement3353 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_alterIndexStatementSuffix_in_alterStatement3356 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DATABASE_in_alterStatement3380 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_alterDatabaseStatementSuffix_in_alterStatement3383 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixRename_in_alterTableStatementSuffix3420 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixAddCol_in_alterTableStatementSuffix3428 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixRenameCol_in_alterTableStatementSuffix3436 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixDropPartitions_in_alterTableStatementSuffix3444 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixAddPartitions_in_alterTableStatementSuffix3452 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixTouch_in_alterTableStatementSuffix3460 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixArchive_in_alterTableStatementSuffix3468 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixUnArchive_in_alterTableStatementSuffix3476 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixProperties_in_alterTableStatementSuffix3484 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterTblPartitionStatement_in_alterTableStatementSuffix3492 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixSkewedby_in_alterTableStatementSuffix3500 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixExchangePartition_in_alterTableStatementSuffix3508 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterViewSuffixProperties_in_alterViewStatementSuffix3535 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixRename_in_alterViewStatementSuffix3543 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixAddPartitions_in_alterViewStatementSuffix3567 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixDropPartitions_in_alterViewStatementSuffix3591 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_tableName_in_alterViewStatementSuffix3617 = new BitSet(new long[]{0x0000000800000000L});
    public static final BitSet FOLLOW_KW_AS_in_alterViewStatementSuffix3619 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000400000L,0x0000000000010002L});
    public static final BitSet FOLLOW_selectStatement_in_alterViewStatementSuffix3621 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_alterIndexStatementSuffix3669 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
    public static final BitSet FOLLOW_KW_ON_in_alterIndexStatementSuffix3678 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_alterIndexStatementSuffix3682 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x4000400000000000L,0x0000000000200000L});
    public static final BitSet FOLLOW_partitionSpec_in_alterIndexStatementSuffix3691 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x4000000000000000L,0x0000000000200000L});
    public static final BitSet FOLLOW_KW_REBUILD_in_alterIndexStatementSuffix3706 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SET_in_alterIndexStatementSuffix3740 = new BitSet(new long[]{0x0000000000000000L,0x0010000000000000L});
    public static final BitSet FOLLOW_KW_IDXPROPERTIES_in_alterIndexStatementSuffix3742 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_indexProperties_in_alterIndexStatementSuffix3750 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterDatabaseSuffixProperties_in_alterDatabaseStatementSuffix3802 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_alterDatabaseSuffixProperties3831 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000200000L});
    public static final BitSet FOLLOW_KW_SET_in_alterDatabaseSuffixProperties3833 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_KW_DBPROPERTIES_in_alterDatabaseSuffixProperties3835 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_dbProperties_in_alterDatabaseSuffixProperties3837 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixRename3881 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000008L});
    public static final BitSet FOLLOW_KW_RENAME_in_alterStatementSuffixRename3883 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_KW_TO_in_alterStatementSuffixRename3885 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixRename3889 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixAddCol3932 = new BitSet(new long[]{0x0000000008000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
    public static final BitSet FOLLOW_KW_ADD_in_alterStatementSuffixAddCol3937 = new BitSet(new long[]{0x0080000000000000L});
    public static final BitSet FOLLOW_KW_REPLACE_in_alterStatementSuffixAddCol3943 = new BitSet(new long[]{0x0080000000000000L});
    public static final BitSet FOLLOW_KW_COLUMNS_in_alterStatementSuffixAddCol3946 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_LPAREN_in_alterStatementSuffixAddCol3948 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnNameTypeList_in_alterStatementSuffixAddCol3950 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_alterStatementSuffixAddCol3952 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixRenameCol4025 = new BitSet(new long[]{0x0002000000000000L});
    public static final BitSet FOLLOW_KW_CHANGE_in_alterStatementSuffixRenameCol4027 = new BitSet(new long[]{0x5FFE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_KW_COLUMN_in_alterStatementSuffixRenameCol4029 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixRenameCol4034 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixRenameCol4038 = new BitSet(new long[]{0x0000038400000000L,0x00000040000800B0L,0x0000000000400001L,0x0100300C08000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_colType_in_alterStatementSuffixRenameCol4040 = new BitSet(new long[]{0x0100000010000002L,0x0000002000000000L});
    public static final BitSet FOLLOW_KW_COMMENT_in_alterStatementSuffixRenameCol4043 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixRenameCol4047 = new BitSet(new long[]{0x0000000010000002L,0x0000002000000000L});
    public static final BitSet FOLLOW_alterStatementChangeColPosition_in_alterStatementSuffixRenameCol4051 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_FIRST_in_alterStatementChangeColPosition4097 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_AFTER_in_alterStatementChangeColPosition4099 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_alterStatementChangeColPosition4103 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixAddPartitions4155 = new BitSet(new long[]{0x0000000008000000L});
    public static final BitSet FOLLOW_KW_ADD_in_alterStatementSuffixAddPartitions4157 = new BitSet(new long[]{0x0000000000000000L,0x0020000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_ifNotExists_in_alterStatementSuffixAddPartitions4159 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_alterStatementSuffixAddPartitionsElement_in_alterStatementSuffixAddPartitions4162 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixAddPartitionsElement4198 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000010000L});
    public static final BitSet FOLLOW_partitionLocation_in_alterStatementSuffixAddPartitionsElement4200 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixTouch4228 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000800000000000L});
    public static final BitSet FOLLOW_KW_TOUCH_in_alterStatementSuffixTouch4230 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixTouch4233 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixArchive4279 = new BitSet(new long[]{0x0000000200000000L});
    public static final BitSet FOLLOW_KW_ARCHIVE_in_alterStatementSuffixArchive4281 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixArchive4284 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixUnArchive4330 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0010000000000000L});
    public static final BitSet FOLLOW_KW_UNARCHIVE_in_alterStatementSuffixUnArchive4332 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixUnArchive4335 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_KW_LOCATION_in_partitionLocation4387 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_partitionLocation4391 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixDropPartitions4427 = new BitSet(new long[]{0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_KW_DROP_in_alterStatementSuffixDropPartitions4429 = new BitSet(new long[]{0x0000000000000000L,0x0020000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_ifExists_in_alterStatementSuffixDropPartitions4431 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions4434 = new BitSet(new long[]{0x0000000000000402L,0x0040000000000000L});
    public static final BitSet FOLLOW_COMMA_in_alterStatementSuffixDropPartitions4437 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_dropPartitionSpec_in_alterStatementSuffixDropPartitions4439 = new BitSet(new long[]{0x0000000000000402L,0x0040000000000000L});
    public static final BitSet FOLLOW_ignoreProtection_in_alterStatementSuffixDropPartitions4443 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixProperties4494 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000200000L});
    public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixProperties4496 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
    public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties4498 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixProperties4500 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixProperties4525 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0800000000000000L});
    public static final BitSet FOLLOW_KW_UNSET_in_alterStatementSuffixProperties4527 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
    public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterStatementSuffixProperties4529 = new BitSet(new long[]{0x0000000000000000L,0x0020000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_ifExists_in_alterStatementSuffixProperties4531 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixProperties4534 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_alterViewSuffixProperties4581 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000200000L});
    public static final BitSet FOLLOW_KW_SET_in_alterViewSuffixProperties4583 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
    public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties4585 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_tableProperties_in_alterViewSuffixProperties4587 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_alterViewSuffixProperties4612 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0800000000000000L});
    public static final BitSet FOLLOW_KW_UNSET_in_alterViewSuffixProperties4614 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
    public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_alterViewSuffixProperties4616 = new BitSet(new long[]{0x0000000000000000L,0x0020000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_ifExists_in_alterViewSuffixProperties4618 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_tableProperties_in_alterViewSuffixProperties4621 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties4666 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_KW_SERDE_in_alterStatementSuffixSerdeProperties4668 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixSerdeProperties4672 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L});
    public static final BitSet FOLLOW_KW_WITH_in_alterStatementSuffixSerdeProperties4675 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties4677 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties4679 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixSerdeProperties4705 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_alterStatementSuffixSerdeProperties4707 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_tableProperties_in_alterStatementSuffixSerdeProperties4709 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_tablePartitionPrefix4747 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_partitionSpec_in_tablePartitionPrefix4749 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_tablePartitionPrefix_in_alterTblPartitionStatement4786 = new BitSet(new long[]{0x0408000000000000L,0x0000000000810000L,0x0000000020000004L,0x0000000000200008L});
    public static final BitSet FOLLOW_alterTblPartitionStatementSuffix_in_alterTblPartitionStatement4788 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_Identifier_in_alterTblPartitionStatement4805 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_KW_PARTITION_in_alterTblPartitionStatement4807 = new BitSet(new long[]{0x0040000000000000L});
    public static final BitSet FOLLOW_KW_COLUMN_in_alterTblPartitionStatement4809 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_LPAREN_in_alterTblPartitionStatement4811 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnNameType_in_alterTblPartitionStatement4813 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_alterTblPartitionStatement4815 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixFileFormat_in_alterTblPartitionStatementSuffix4850 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixLocation_in_alterTblPartitionStatementSuffix4856 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixProtectMode_in_alterTblPartitionStatementSuffix4862 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixMergeFiles_in_alterTblPartitionStatementSuffix4868 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixSerdeProperties_in_alterTblPartitionStatementSuffix4874 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixRenamePart_in_alterTblPartitionStatementSuffix4880 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixBucketNum_in_alterTblPartitionStatementSuffix4886 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterTblPartitionStatementSuffixSkewedLocation_in_alterTblPartitionStatementSuffix4892 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterStatementSuffixClusterbySortby_in_alterTblPartitionStatementSuffix4898 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixFileFormat4920 = new BitSet(new long[]{0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_FILEFORMAT_in_alterStatementSuffixFileFormat4922 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_fileFormat_in_alterStatementSuffixFileFormat4924 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby4955 = new BitSet(new long[]{0x0008000000000000L});
    public static final BitSet FOLLOW_KW_CLUSTERED_in_alterStatementSuffixClusterbySortby4957 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixClusterbySortby4971 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000020000000L});
    public static final BitSet FOLLOW_KW_SORTED_in_alterStatementSuffixClusterbySortby4973 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_tableBuckets_in_alterStatementSuffixClusterbySortby4987 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SET_in_alterTblPartitionStatementSuffixSkewedLocation5018 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_KW_SKEWED_in_alterTblPartitionStatementSuffixSkewedLocation5020 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
    public static final BitSet FOLLOW_KW_LOCATION_in_alterTblPartitionStatementSuffixSkewedLocation5022 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_skewedLocations_in_alterTblPartitionStatementSuffixSkewedLocation5024 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_LPAREN_in_skewedLocations5067 = new BitSet(new long[]{0x0000000000042080L,0x0000000200000010L,0x0000000000000000L,0x0004000000000000L,0x0000000160104000L});
    public static final BitSet FOLLOW_skewedLocationsList_in_skewedLocations5069 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_skewedLocations5071 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_skewedLocationMap_in_skewedLocationsList5112 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_skewedLocationsList5115 = new BitSet(new long[]{0x0000000000042080L,0x0000000200000010L,0x0000000000000000L,0x0004000000000000L,0x0000000160104000L});
    public static final BitSet FOLLOW_skewedLocationMap_in_skewedLocationsList5117 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_skewedValueLocationElement_in_skewedLocationMap5163 = new BitSet(new long[]{0x0000000000100000L});
    public static final BitSet FOLLOW_EQUAL_in_skewedLocationMap5165 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_skewedLocationMap5169 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SET_in_alterStatementSuffixLocation5206 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000010000L});
    public static final BitSet FOLLOW_KW_LOCATION_in_alterStatementSuffixLocation5208 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_alterStatementSuffixLocation5212 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixSkewedby5247 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_tableSkewed_in_alterStatementSuffixSkewedby5249 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixSkewedby5268 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000020000000L});
    public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby5270 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_KW_SKEWED_in_alterStatementSuffixSkewedby5272 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_alterStatementSuffixSkewedby5289 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000020000000L});
    public static final BitSet FOLLOW_KW_NOT_in_alterStatementSuffixSkewedby5291 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000100000000L});
    public static final BitSet FOLLOW_storedAsDirs_in_alterStatementSuffixSkewedby5293 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_tableName_in_alterStatementSuffixExchangePartition5329 = new BitSet(new long[]{0x0000000000000000L,0x0000000004000000L});
    public static final BitSet FOLLOW_KW_EXCHANGE_in_alterStatementSuffixExchangePartition5331 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixExchangePartition5333 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L});
    public static final BitSet FOLLOW_KW_WITH_in_alterStatementSuffixExchangePartition5335 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_TABLE_in_alterStatementSuffixExchangePartition5337 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_tableName_in_alterStatementSuffixExchangePartition5341 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_alterProtectMode_in_alterStatementSuffixProtectMode5386 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_RENAME_in_alterStatementSuffixRenamePart5425 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_KW_TO_in_alterStatementSuffixRenamePart5427 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_partitionSpec_in_alterStatementSuffixRenamePart5429 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CONCATENATE_in_alterStatementSuffixMergeFiles5467 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ENABLE_in_alterProtectMode5504 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x1000000240000000L});
    public static final BitSet FOLLOW_alterProtectModeMode_in_alterProtectMode5506 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DISABLE_in_alterProtectMode5523 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x1000000240000000L});
    public static final BitSet FOLLOW_alterProtectModeMode_in_alterProtectMode5525 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_OFFLINE_in_alterProtectModeMode5561 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_NO_DROP_in_alterProtectModeMode5576 = new BitSet(new long[]{0x0000400000000002L});
    public static final BitSet FOLLOW_KW_CASCADE_in_alterProtectModeMode5578 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_READONLY_in_alterProtectModeMode5596 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_INTO_in_alterStatementSuffixBucketNum5630 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_Number_in_alterStatementSuffixBucketNum5634 = new BitSet(new long[]{0x0000100000000000L});
    public static final BitSet FOLLOW_KW_BUCKETS_in_alterStatementSuffixBucketNum5636 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SEQUENCEFILE_in_fileFormat5676 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_TEXTFILE_in_fileFormat5691 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_RCFILE_in_fileFormat5706 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ORCFILE_in_fileFormat5721 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_INPUTFORMAT_in_fileFormat5735 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_fileFormat5739 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000040000000000L});
    public static final BitSet FOLLOW_KW_OUTPUTFORMAT_in_fileFormat5741 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_fileFormat5745 = new BitSet(new long[]{0x0000000000000002L,0x2000000000000000L});
    public static final BitSet FOLLOW_KW_INPUTDRIVER_in_fileFormat5748 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_fileFormat5752 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000020000000000L});
    public static final BitSet FOLLOW_KW_OUTPUTDRIVER_in_fileFormat5754 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_fileFormat5758 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_fileFormat5796 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_tabTypeExpr5832 = new BitSet(new long[]{0x0000000000020002L});
    public static final BitSet FOLLOW_DOT_in_tabTypeExpr5835 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_KW_ELEM_TYPE_in_tabTypeExpr5839 = new BitSet(new long[]{0x0000000000020002L});
    public static final BitSet FOLLOW_KW_KEY_TYPE_in_tabTypeExpr5843 = new BitSet(new long[]{0x0000000000020002L});
    public static final BitSet FOLLOW_KW_VALUE_TYPE_in_tabTypeExpr5847 = new BitSet(new long[]{0x0000000000020002L});
    public static final BitSet FOLLOW_identifier_in_tabTypeExpr5851 = new BitSet(new long[]{0x0000000000020002L});
    public static final BitSet FOLLOW_identifier_in_descTabTypeExpr5880 = new BitSet(new long[]{0x5FBE7FFEDC020002L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_DOT_in_descTabTypeExpr5883 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_KW_ELEM_TYPE_in_descTabTypeExpr5887 = new BitSet(new long[]{0x5FBE7FFEDC020002L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_KW_KEY_TYPE_in_descTabTypeExpr5891 = new BitSet(new long[]{0x5FBE7FFEDC020002L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_KW_VALUE_TYPE_in_descTabTypeExpr5895 = new BitSet(new long[]{0x5FBE7FFEDC020002L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_descTabTypeExpr5899 = new BitSet(new long[]{0x5FBE7FFEDC020002L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_descTabTypeExpr5904 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_tabTypeExpr_in_partTypeExpr5932 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_partitionSpec_in_partTypeExpr5934 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_descTabTypeExpr_in_descPartTypeExpr5974 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_partitionSpec_in_descPartTypeExpr5976 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DESCRIBE_in_descStatement6016 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77FFABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_KW_DESC_in_descStatement6018 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77FFABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_KW_FORMATTED_in_descStatement6024 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_KW_EXTENDED_in_descStatement6028 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_KW_PRETTY_in_descStatement6032 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_descPartTypeExpr_in_descStatement6039 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DESCRIBE_in_descStatement6062 = new BitSet(new long[]{0x0000000000000000L,0x0000200000000000L});
    public static final BitSet FOLLOW_KW_DESC_in_descStatement6064 = new BitSet(new long[]{0x0000000000000000L,0x0000200000000000L});
    public static final BitSet FOLLOW_KW_FUNCTION_in_descStatement6067 = new BitSet(new long[]{0x5FBEFFFFDDB0C070L,0xFFFBD77FFABDFFFBL,0xFFE7D7FBFBDFFBDFL,0xFDDEF7BFFFFEFFFDL,0x00000000D02E356FL});
    public static final BitSet FOLLOW_KW_EXTENDED_in_descStatement6069 = new BitSet(new long[]{0x5FBEFFFFDDB0C070L,0xFFFBD77F7ABDFFFBL,0xFFE7D7FBFBDFFBDFL,0xFDDEF7BFFFFEFFFDL,0x00000000D02E356FL});
    public static final BitSet FOLLOW_descFuncNames_in_descStatement6075 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DESCRIBE_in_descStatement6097 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_DESC_in_descStatement6099 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_DATABASE_in_descStatement6102 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77FFABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_KW_EXTENDED_in_descStatement6104 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_descStatement6110 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ANALYZE_in_analyzeStatement6150 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_TABLE_in_analyzeStatement6152 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_tableOrPartition_in_analyzeStatement6157 = new BitSet(new long[]{0x0200000000000000L});
    public static final BitSet FOLLOW_KW_COMPUTE_in_analyzeStatement6160 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000080000000L});
    public static final BitSet FOLLOW_KW_STATISTICS_in_analyzeStatement6162 = new BitSet(new long[]{0x0000000000000002L,0x0000010000000000L,0x0000200010000000L});
    public static final BitSet FOLLOW_KW_NOSCAN_in_analyzeStatement6168 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_PARTIALSCAN_in_analyzeStatement6176 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_FOR_in_analyzeStatement6182 = new BitSet(new long[]{0x0080000000000000L});
    public static final BitSet FOLLOW_KW_COLUMNS_in_analyzeStatement6184 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnNameList_in_analyzeStatement6188 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement6239 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000008L,0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_KW_DATABASES_in_showStatement6242 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000800L});
    public static final BitSet FOLLOW_KW_SCHEMAS_in_showStatement6244 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000800L});
    public static final BitSet FOLLOW_KW_LIKE_in_showStatement6248 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000004000052FL});
    public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement6250 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement6269 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000002000000000L});
    public static final BitSet FOLLOW_KW_TABLES_in_showStatement6271 = new BitSet(new long[]{0x5FBE7FFEDC000002L,0xFFDBDF7F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000004000052FL});
    public static final BitSet FOLLOW_KW_FROM_in_showStatement6275 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_KW_IN_in_showStatement6277 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_showStatement6282 = new BitSet(new long[]{0x5FBE7FFEDC000002L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000004000052FL});
    public static final BitSet FOLLOW_KW_LIKE_in_showStatement6287 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000004000052FL});
    public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement6289 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement6291 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement6319 = new BitSet(new long[]{0x0080000000000000L});
    public static final BitSet FOLLOW_KW_COLUMNS_in_showStatement6321 = new BitSet(new long[]{0x0000000000000000L,0x0100080000000000L});
    public static final BitSet FOLLOW_KW_FROM_in_showStatement6324 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_KW_IN_in_showStatement6326 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_tableName_in_showStatement6331 = new BitSet(new long[]{0x0000000000000002L,0x0100080000000000L});
    public static final BitSet FOLLOW_KW_FROM_in_showStatement6335 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_KW_IN_in_showStatement6337 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_showStatement6342 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement6370 = new BitSet(new long[]{0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_KW_FUNCTIONS_in_showStatement6372 = new BitSet(new long[]{0x5FBE7FFEDC000002L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000004000052FL});
    public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement6374 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement6393 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0001000000000000L});
    public static final BitSet FOLLOW_KW_PARTITIONS_in_showStatement6395 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_showStatement6397 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_partitionSpec_in_showStatement6399 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement6419 = new BitSet(new long[]{0x1000000000000000L});
    public static final BitSet FOLLOW_KW_CREATE_in_showStatement6421 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_TABLE_in_showStatement6423 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_tableName_in_showStatement6427 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement6444 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_TABLE_in_showStatement6446 = new BitSet(new long[]{0x0000000000000000L,0x0000000080000000L});
    public static final BitSet FOLLOW_KW_EXTENDED_in_showStatement6448 = new BitSet(new long[]{0x0000000000000000L,0x0100080000000000L,0x0000000000000800L});
    public static final BitSet FOLLOW_KW_FROM_in_showStatement6452 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_KW_IN_in_showStatement6454 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_showStatement6459 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000800L});
    public static final BitSet FOLLOW_KW_LIKE_in_showStatement6463 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000004000052FL});
    public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement6465 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_partitionSpec_in_showStatement6467 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement6495 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
    public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_showStatement6497 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_showStatement6501 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_LPAREN_in_showStatement6504 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_showStatement6508 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_showStatement6510 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement6533 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000040000L});
    public static final BitSet FOLLOW_KW_LOCKS_in_showStatement6535 = new BitSet(new long[]{0x5FBE7FFEDC000002L,0xFFDBD77FFABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_partTypeExpr_in_showStatement6540 = new BitSet(new long[]{0x0000000000000002L,0x0000000080000000L});
    public static final BitSet FOLLOW_KW_EXTENDED_in_showStatement6547 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showStatement6571 = new BitSet(new long[]{0x0000000000000000L,0x0600040000000000L});
    public static final BitSet FOLLOW_KW_FORMATTED_in_showStatement6576 = new BitSet(new long[]{0x0000000000000000L,0x0600000000000000L});
    public static final BitSet FOLLOW_KW_INDEX_in_showStatement6581 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
    public static final BitSet FOLLOW_KW_INDEXES_in_showStatement6583 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
    public static final BitSet FOLLOW_KW_ON_in_showStatement6586 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000004000052FL});
    public static final BitSet FOLLOW_showStmtIdentifier_in_showStatement6588 = new BitSet(new long[]{0x0000000000000002L,0x0100080000000000L});
    public static final BitSet FOLLOW_KW_FROM_in_showStatement6592 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_KW_IN_in_showStatement6594 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_showStatement6599 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_LOCK_in_lockStatement6648 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_TABLE_in_lockStatement6650 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_tableName_in_lockStatement6652 = new BitSet(new long[]{0x0000000000000000L,0x0000000008000000L,0x0000400000000000L,0x0000000000800000L});
    public static final BitSet FOLLOW_partitionSpec_in_lockStatement6654 = new BitSet(new long[]{0x0000000000000000L,0x0000000008000000L,0x0000000000000000L,0x0000000000800000L});
    public static final BitSet FOLLOW_lockMode_in_lockStatement6657 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_UNLOCK_in_unlockStatement6728 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_TABLE_in_unlockStatement6730 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_tableName_in_unlockStatement6732 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_partitionSpec_in_unlockStatement6734 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CREATE_in_createRoleStatement6774 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L});
    public static final BitSet FOLLOW_KW_ROLE_in_createRoleStatement6776 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_createRoleStatement6780 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DROP_in_dropRoleStatement6820 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L});
    public static final BitSet FOLLOW_KW_ROLE_in_dropRoleStatement6822 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_dropRoleStatement6826 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_GRANT_in_grantPrivileges6866 = new BitSet(new long[]{0x1000000060000000L,0x0200000000100000L,0x0000000000020000L,0x2000000002010000L});
    public static final BitSet FOLLOW_privilegeList_in_grantPrivileges6870 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000400000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_privilegeObject_in_grantPrivileges6878 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_KW_TO_in_grantPrivileges6887 = new BitSet(new long[]{0x0000000000000000L,0x0001000000000000L,0x0000000000000000L,0x8000000000000400L});
    public static final BitSet FOLLOW_principalSpecification_in_grantPrivileges6889 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L});
    public static final BitSet FOLLOW_KW_WITH_in_grantPrivileges6898 = new BitSet(new long[]{0x0000000000000000L,0x0000800000000000L});
    public static final BitSet FOLLOW_withOption_in_grantPrivileges6900 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_REVOKE_in_revokePrivileges6950 = new BitSet(new long[]{0x1000000060000000L,0x0200000000100000L,0x0000000000020000L,0x2000000002010000L});
    public static final BitSet FOLLOW_privilegeList_in_revokePrivileges6952 = new BitSet(new long[]{0x0000000000000000L,0x0000080000000000L,0x0000000400000000L});
    public static final BitSet FOLLOW_privilegeObject_in_revokePrivileges6954 = new BitSet(new long[]{0x0000000000000000L,0x0000080000000000L});
    public static final BitSet FOLLOW_KW_FROM_in_revokePrivileges6957 = new BitSet(new long[]{0x0000000000000000L,0x0001000000000000L,0x0000000000000000L,0x8000000000000400L});
    public static final BitSet FOLLOW_principalSpecification_in_revokePrivileges6959 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_GRANT_in_grantRole7003 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L});
    public static final BitSet FOLLOW_KW_ROLE_in_grantRole7005 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_grantRole7007 = new BitSet(new long[]{0x0000000000000400L,0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_COMMA_in_grantRole7010 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_grantRole7012 = new BitSet(new long[]{0x0000000000000400L,0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_KW_TO_in_grantRole7016 = new BitSet(new long[]{0x0000000000000000L,0x0001000000000000L,0x0000000000000000L,0x8000000000000400L});
    public static final BitSet FOLLOW_principalSpecification_in_grantRole7018 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_REVOKE_in_revokeRole7060 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L});
    public static final BitSet FOLLOW_KW_ROLE_in_revokeRole7062 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_revokeRole7064 = new BitSet(new long[]{0x0000000000000400L,0x0000080000000000L});
    public static final BitSet FOLLOW_COMMA_in_revokeRole7067 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_revokeRole7069 = new BitSet(new long[]{0x0000000000000400L,0x0000080000000000L});
    public static final BitSet FOLLOW_KW_FROM_in_revokeRole7073 = new BitSet(new long[]{0x0000000000000000L,0x0001000000000000L,0x0000000000000000L,0x8000000000000400L});
    public static final BitSet FOLLOW_principalSpecification_in_revokeRole7075 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showRoleGrants7117 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L});
    public static final BitSet FOLLOW_KW_ROLE_in_showRoleGrants7119 = new BitSet(new long[]{0x0000000000000000L,0x0000800000000000L});
    public static final BitSet FOLLOW_KW_GRANT_in_showRoleGrants7121 = new BitSet(new long[]{0x0000000000000000L,0x0001000000000000L,0x0000000000000000L,0x8000000000000400L});
    public static final BitSet FOLLOW_principalName_in_showRoleGrants7123 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_in_showGrants7162 = new BitSet(new long[]{0x0000000000000000L,0x0000800000000000L});
    public static final BitSet FOLLOW_KW_GRANT_in_showGrants7164 = new BitSet(new long[]{0x0000000000000000L,0x0001000000000000L,0x0000000000000000L,0x8000000000000400L});
    public static final BitSet FOLLOW_principalName_in_showGrants7166 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000400000000L});
    public static final BitSet FOLLOW_privilegeIncludeColObject_in_showGrants7168 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ON_in_privilegeIncludeColObject7211 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_TABLE_in_privilegeIncludeColObject7216 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_KW_DATABASE_in_privilegeIncludeColObject7218 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_privilegeIncludeColObject7221 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000400000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_LPAREN_in_privilegeIncludeColObject7224 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnNameList_in_privilegeIncludeColObject7228 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_privilegeIncludeColObject7230 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_partitionSpec_in_privilegeIncludeColObject7234 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ON_in_privilegeObject7285 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000004L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_TABLE_in_privilegeObject7290 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_KW_DATABASE_in_privilegeObject7292 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_privilegeObject7295 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_partitionSpec_in_privilegeObject7297 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_privlegeDef_in_privilegeList7344 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_privilegeList7347 = new BitSet(new long[]{0x1000000060000000L,0x0200000000100000L,0x0000000000020000L,0x2000000002010000L});
    public static final BitSet FOLLOW_privlegeDef_in_privilegeList7349 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_privilegeType_in_privlegeDef7391 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_LPAREN_in_privlegeDef7394 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnNameList_in_privlegeDef7398 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_privlegeDef7400 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ALL_in_privilegeType7445 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ALTER_in_privilegeType7459 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_UPDATE_in_privilegeType7473 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CREATE_in_privilegeType7487 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DROP_in_privilegeType7501 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_INDEX_in_privilegeType7515 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_LOCK_in_privilegeType7529 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SELECT_in_privilegeType7543 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SHOW_DATABASE_in_privilegeType7557 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_principalName_in_principalSpecification7590 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_principalSpecification7593 = new BitSet(new long[]{0x0000000000000000L,0x0001000000000000L,0x0000000000000000L,0x8000000000000400L});
    public static final BitSet FOLLOW_principalName_in_principalSpecification7595 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_KW_USER_in_principalName7633 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_principalName7635 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_GROUP_in_principalName7651 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_principalName7653 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ROLE_in_principalName7669 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_principalName7671 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_GRANT_in_withOption7706 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000800000000L});
    public static final BitSet FOLLOW_KW_OPTION_in_withOption7708 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_MSCK_in_metastoreCheck7745 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000001000000010L});
    public static final BitSet FOLLOW_KW_REPAIR_in_metastoreCheck7750 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_TABLE_in_metastoreCheck7755 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_metastoreCheck7759 = new BitSet(new long[]{0x0000000000000402L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_partitionSpec_in_metastoreCheck7761 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_metastoreCheck7765 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000400000000000L});
    public static final BitSet FOLLOW_partitionSpec_in_metastoreCheck7767 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_KW_CREATE_in_createFunctionStatement7821 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000010000000000L});
    public static final BitSet FOLLOW_KW_TEMPORARY_in_createFunctionStatement7823 = new BitSet(new long[]{0x0000000000000000L,0x0000200000000000L});
    public static final BitSet FOLLOW_KW_FUNCTION_in_createFunctionStatement7825 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_createFunctionStatement7827 = new BitSet(new long[]{0x0000000800000000L});
    public static final BitSet FOLLOW_KW_AS_in_createFunctionStatement7829 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_createFunctionStatement7831 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DROP_in_dropFunctionStatement7872 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000010000000000L});
    public static final BitSet FOLLOW_KW_TEMPORARY_in_dropFunctionStatement7874 = new BitSet(new long[]{0x0000000000000000L,0x0000200000000000L});
    public static final BitSet FOLLOW_KW_FUNCTION_in_dropFunctionStatement7876 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFFBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_ifExists_in_dropFunctionStatement7878 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_dropFunctionStatement7881 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CREATE_in_createMacroStatement7923 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000010000000000L});
    public static final BitSet FOLLOW_KW_TEMPORARY_in_createMacroStatement7925 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000200000L});
    public static final BitSet FOLLOW_KW_MACRO_in_createMacroStatement7927 = new BitSet(new long[]{0x0000000004000000L});
    public static final BitSet FOLLOW_Identifier_in_createMacroStatement7929 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_LPAREN_in_createMacroStatement7937 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000100052FL});
    public static final BitSet FOLLOW_columnNameTypeList_in_createMacroStatement7939 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_createMacroStatement7942 = new BitSet(new long[]{0x5FBFFFFEDC042080L,0xFFFBD77F7ABDFFFBL,0xFFE7D7EBFBDFFBDFL,0xFDDEF7BFFFFEFFFDL,0x00000001E032452FL});
    public static final BitSet FOLLOW_expression_in_createMacroStatement7944 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DROP_in_dropMacroStatement7988 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000010000000000L});
    public static final BitSet FOLLOW_KW_TEMPORARY_in_dropMacroStatement7990 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000200000L});
    public static final BitSet FOLLOW_KW_MACRO_in_dropMacroStatement7992 = new BitSet(new long[]{0x0000000004000000L,0x0020000000000000L});
    public static final BitSet FOLLOW_ifExists_in_dropMacroStatement7994 = new BitSet(new long[]{0x0000000004000000L});
    public static final BitSet FOLLOW_Identifier_in_dropMacroStatement7997 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CREATE_in_createViewStatement8039 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000001000000000L,0x0000000000000000L,0x0000000000000020L});
    public static final BitSet FOLLOW_orReplace_in_createViewStatement8042 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
    public static final BitSet FOLLOW_KW_VIEW_in_createViewStatement8046 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFFBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_ifNotExists_in_createViewStatement8049 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_tableName_in_createViewStatement8055 = new BitSet(new long[]{0x0100000800000000L,0x0000000000000000L,0x0000800000000000L,0x0000008000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_LPAREN_in_createViewStatement8066 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnNameCommentList_in_createViewStatement8068 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_createViewStatement8070 = new BitSet(new long[]{0x0100000800000000L,0x0000000000000000L,0x0000800000000000L,0x0000008000000000L});
    public static final BitSet FOLLOW_tableComment_in_createViewStatement8074 = new BitSet(new long[]{0x0000000800000000L,0x0000000000000000L,0x0000800000000000L,0x0000008000000000L});
    public static final BitSet FOLLOW_viewPartition_in_createViewStatement8077 = new BitSet(new long[]{0x0000000800000000L,0x0000000000000000L,0x0000000000000000L,0x0000008000000000L});
    public static final BitSet FOLLOW_tablePropertiesPrefixed_in_createViewStatement8088 = new BitSet(new long[]{0x0000000800000000L});
    public static final BitSet FOLLOW_KW_AS_in_createViewStatement8099 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000400000L,0x0000000000010002L});
    public static final BitSet FOLLOW_selectStatement_in_createViewStatement8109 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_PARTITIONED_in_viewPartition8232 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
    public static final BitSet FOLLOW_KW_ON_in_viewPartition8234 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_LPAREN_in_viewPartition8236 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnNameList_in_viewPartition8238 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_viewPartition8240 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DROP_in_dropViewStatement8279 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000020L});
    public static final BitSet FOLLOW_KW_VIEW_in_dropViewStatement8281 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFFBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_ifExists_in_dropViewStatement8283 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_viewName_in_dropViewStatement8286 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_showStmtIdentifier8324 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_StringLiteral_in_showStmtIdentifier8332 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_COMMENT_in_tableComment8365 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableComment8369 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_PARTITIONED_in_tablePartition8406 = new BitSet(new long[]{0x0000200000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tablePartition8408 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_LPAREN_in_tablePartition8410 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnNameTypeList_in_tablePartition8412 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_tablePartition8414 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_CLUSTERED_in_tableBuckets8459 = new BitSet(new long[]{0x0000200000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tableBuckets8461 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_LPAREN_in_tableBuckets8463 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnNameList_in_tableBuckets8467 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_tableBuckets8469 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000004L,0x0000000020000000L});
    public static final BitSet FOLLOW_KW_SORTED_in_tableBuckets8472 = new BitSet(new long[]{0x0000200000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tableBuckets8474 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_LPAREN_in_tableBuckets8476 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnNameOrderList_in_tableBuckets8480 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_tableBuckets8482 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_INTO_in_tableBuckets8486 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_Number_in_tableBuckets8490 = new BitSet(new long[]{0x0000100000000000L});
    public static final BitSet FOLLOW_KW_BUCKETS_in_tableBuckets8492 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SKEWED_in_tableSkewed8544 = new BitSet(new long[]{0x0000200000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tableSkewed8546 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_LPAREN_in_tableSkewed8548 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnNameList_in_tableSkewed8552 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_tableSkewed8554 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000400000000L});
    public static final BitSet FOLLOW_KW_ON_in_tableSkewed8556 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_LPAREN_in_tableSkewed8558 = new BitSet(new long[]{0x0000000000042080L,0x0000000200000010L,0x0000000000000000L,0x0004000000000000L,0x0000000160104000L});
    public static final BitSet FOLLOW_skewedValueElement_in_tableSkewed8563 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_tableSkewed8566 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000100000000L});
    public static final BitSet FOLLOW_storedAsDirs_in_tableSkewed8569 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_rowFormatSerde_in_rowFormat8617 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_rowFormatDelimited_in_rowFormat8633 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_RECORDREADER_in_recordReader8682 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_recordReader8684 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_RECORDWRITER_in_recordWriter8733 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_recordWriter8735 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ROW_in_rowFormatSerde8784 = new BitSet(new long[]{0x0000000000000000L,0x0000020000000000L});
    public static final BitSet FOLLOW_KW_FORMAT_in_rowFormatSerde8786 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000080000L});
    public static final BitSet FOLLOW_KW_SERDE_in_rowFormatSerde8788 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_rowFormatSerde8792 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L});
    public static final BitSet FOLLOW_KW_WITH_in_rowFormatSerde8795 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_rowFormatSerde8797 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_tableProperties_in_rowFormatSerde8801 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ROW_in_rowFormatDelimited8853 = new BitSet(new long[]{0x0000000000000000L,0x0000020000000000L});
    public static final BitSet FOLLOW_KW_FORMAT_in_rowFormatDelimited8855 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000400L});
    public static final BitSet FOLLOW_KW_DELIMITED_in_rowFormatDelimited8857 = new BitSet(new long[]{0x0020000000000002L,0x0000000800000000L,0x0000000000402000L});
    public static final BitSet FOLLOW_tableRowFormatFieldIdentifier_in_rowFormatDelimited8859 = new BitSet(new long[]{0x0020000000000002L,0x0000000000000000L,0x0000000000402000L});
    public static final BitSet FOLLOW_tableRowFormatCollItemsIdentifier_in_rowFormatDelimited8862 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000402000L});
    public static final BitSet FOLLOW_tableRowFormatMapKeysIdentifier_in_rowFormatDelimited8865 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000002000L});
    public static final BitSet FOLLOW_tableRowFormatLinesIdentifier_in_rowFormatDelimited8868 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_rowFormatDelimited_in_tableRowFormat8924 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_rowFormatSerde_in_tableRowFormat8944 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_TBLPROPERTIES_in_tablePropertiesPrefixed8991 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_tableProperties_in_tablePropertiesPrefixed8994 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_LPAREN_in_tableProperties9027 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_tablePropertiesList_in_tableProperties9029 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_tableProperties9031 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_keyValueProperty_in_tablePropertiesList9072 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_tablePropertiesList9075 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_keyValueProperty_in_tablePropertiesList9077 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_keyProperty_in_tablePropertiesList9102 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_tablePropertiesList9105 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_keyProperty_in_tablePropertiesList9107 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_StringLiteral_in_keyValueProperty9153 = new BitSet(new long[]{0x0000000000100000L});
    public static final BitSet FOLLOW_EQUAL_in_keyValueProperty9155 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_keyValueProperty9159 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_StringLiteral_in_keyProperty9206 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_FIELDS_in_tableRowFormatFieldIdentifier9250 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000020000000000L});
    public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatFieldIdentifier9252 = new BitSet(new long[]{0x0000200000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier9254 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier9258 = new BitSet(new long[]{0x0000000000000002L,0x0000000002000000L});
    public static final BitSet FOLLOW_KW_ESCAPED_in_tableRowFormatFieldIdentifier9261 = new BitSet(new long[]{0x0000200000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tableRowFormatFieldIdentifier9263 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatFieldIdentifier9267 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_COLLECTION_in_tableRowFormatCollItemsIdentifier9319 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_KW_ITEMS_in_tableRowFormatCollItemsIdentifier9321 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000020000000000L});
    public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatCollItemsIdentifier9323 = new BitSet(new long[]{0x0000200000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tableRowFormatCollItemsIdentifier9325 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatCollItemsIdentifier9329 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_MAP_in_tableRowFormatMapKeysIdentifier9375 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000040L});
    public static final BitSet FOLLOW_KW_KEYS_in_tableRowFormatMapKeysIdentifier9377 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000020000000000L});
    public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatMapKeysIdentifier9379 = new BitSet(new long[]{0x0000200000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tableRowFormatMapKeysIdentifier9381 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatMapKeysIdentifier9385 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_LINES_in_tableRowFormatLinesIdentifier9431 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000020000000000L});
    public static final BitSet FOLLOW_KW_TERMINATED_in_tableRowFormatLinesIdentifier9433 = new BitSet(new long[]{0x0000200000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tableRowFormatLinesIdentifier9435 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableRowFormatLinesIdentifier9439 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat9485 = new BitSet(new long[]{0x0000000800000000L});
    public static final BitSet FOLLOW_KW_AS_in_tableFileFormat9487 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000040000L});
    public static final BitSet FOLLOW_KW_SEQUENCEFILE_in_tableFileFormat9489 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat9504 = new BitSet(new long[]{0x0000000800000000L});
    public static final BitSet FOLLOW_KW_AS_in_tableFileFormat9506 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000040000000000L});
    public static final BitSet FOLLOW_KW_TEXTFILE_in_tableFileFormat9508 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat9523 = new BitSet(new long[]{0x0000000800000000L});
    public static final BitSet FOLLOW_KW_AS_in_tableFileFormat9525 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0400000000000000L});
    public static final BitSet FOLLOW_KW_RCFILE_in_tableFileFormat9527 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat9542 = new BitSet(new long[]{0x0000000800000000L});
    public static final BitSet FOLLOW_KW_AS_in_tableFileFormat9544 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000002000000000L});
    public static final BitSet FOLLOW_KW_ORCFILE_in_tableFileFormat9546 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat9560 = new BitSet(new long[]{0x0000000800000000L});
    public static final BitSet FOLLOW_KW_AS_in_tableFileFormat9562 = new BitSet(new long[]{0x0000000000000000L,0x4000000000000000L});
    public static final BitSet FOLLOW_KW_INPUTFORMAT_in_tableFileFormat9564 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat9568 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000040000000000L});
    public static final BitSet FOLLOW_KW_OUTPUTFORMAT_in_tableFileFormat9570 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat9574 = new BitSet(new long[]{0x0000000000000002L,0x2000000000000000L});
    public static final BitSet FOLLOW_KW_INPUTDRIVER_in_tableFileFormat9577 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat9581 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000020000000000L});
    public static final BitSet FOLLOW_KW_OUTPUTDRIVER_in_tableFileFormat9583 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat9587 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat9625 = new BitSet(new long[]{0x0000200000000000L});
    public static final BitSet FOLLOW_KW_BY_in_tableFileFormat9627 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableFileFormat9631 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000400L});
    public static final BitSet FOLLOW_KW_WITH_in_tableFileFormat9643 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_KW_SERDEPROPERTIES_in_tableFileFormat9645 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_tableProperties_in_tableFileFormat9649 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_STORED_in_tableFileFormat9680 = new BitSet(new long[]{0x0000000800000000L});
    public static final BitSet FOLLOW_KW_AS_in_tableFileFormat9682 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_identifier_in_tableFileFormat9686 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_LOCATION_in_tableLocation9734 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_tableLocation9738 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_columnNameType_in_columnNameTypeList9774 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_columnNameTypeList9777 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnNameType_in_columnNameTypeList9779 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_columnNameColonType_in_columnNameColonTypeList9817 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_columnNameColonTypeList9820 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnNameColonType_in_columnNameColonTypeList9822 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_columnName_in_columnNameList9860 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_columnNameList9863 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnName_in_columnNameList9865 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_identifier_in_columnName9909 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_columnNameOrder_in_columnNameOrderList9936 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_columnNameOrderList9939 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnNameOrder_in_columnNameOrderList9941 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_skewedColumnValues_in_skewedValueElement9986 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_skewedColumnValuePairList_in_skewedValueElement9995 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList10022 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_skewedColumnValuePairList10025 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_skewedColumnValuePair_in_skewedColumnValuePairList10027 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_LPAREN_in_skewedColumnValuePair10072 = new BitSet(new long[]{0x0000000000042080L,0x0000000200000010L,0x0000000000000000L,0x0004000000000000L,0x0000000160100000L});
    public static final BitSet FOLLOW_skewedColumnValues_in_skewedColumnValuePair10076 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_skewedColumnValuePair10078 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_skewedColumnValue_in_skewedColumnValues10121 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_skewedColumnValues10124 = new BitSet(new long[]{0x0000000000042080L,0x0000000200000010L,0x0000000000000000L,0x0004000000000000L,0x0000000160100000L});
    public static final BitSet FOLLOW_skewedColumnValue_in_skewedColumnValues10126 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_constant_in_skewedColumnValue10170 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_skewedColumnValue_in_skewedValueLocationElement10204 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_skewedColumnValuePair_in_skewedValueLocationElement10213 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_columnNameOrder10244 = new BitSet(new long[]{0x0000001000000002L,0x0000000000001000L});
    public static final BitSet FOLLOW_KW_ASC_in_columnNameOrder10249 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DESC_in_columnNameOrder10255 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_columnNameComment_in_columnNameCommentList10327 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_columnNameCommentList10330 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnNameComment_in_columnNameCommentList10332 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_identifier_in_columnNameComment10372 = new BitSet(new long[]{0x0100000000000002L});
    public static final BitSet FOLLOW_KW_COMMENT_in_columnNameComment10375 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_columnNameComment10379 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_expression_in_columnRefOrder10427 = new BitSet(new long[]{0x0000001000000002L,0x0000000000001000L});
    public static final BitSet FOLLOW_KW_ASC_in_columnRefOrder10432 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DESC_in_columnRefOrder10438 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_columnNameType10512 = new BitSet(new long[]{0x0000038400000000L,0x00000040000800B0L,0x0000000000400001L,0x0100300C08000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_colType_in_columnNameType10514 = new BitSet(new long[]{0x0100000000000002L});
    public static final BitSet FOLLOW_KW_COMMENT_in_columnNameType10517 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_columnNameType10521 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_identifier_in_columnNameColonType10607 = new BitSet(new long[]{0x0000000000000200L});
    public static final BitSet FOLLOW_COLON_in_columnNameColonType10609 = new BitSet(new long[]{0x0000038400000000L,0x00000040000800B0L,0x0000000000400001L,0x0100300C08000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_colType_in_columnNameColonType10611 = new BitSet(new long[]{0x0100000000000002L});
    public static final BitSet FOLLOW_KW_COMMENT_in_columnNameColonType10614 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_columnNameColonType10618 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_type_in_colType10702 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_colType_in_colTypeList10729 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_COMMA_in_colTypeList10732 = new BitSet(new long[]{0x0000038400000000L,0x00000040000800B0L,0x0000000000400001L,0x0100300C08000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_colType_in_colTypeList10734 = new BitSet(new long[]{0x0000000000000402L});
    public static final BitSet FOLLOW_primitiveType_in_type10762 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_listType_in_type10770 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_structType_in_type10778 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_mapType_in_type10786 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_unionType_in_type10794 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_TINYINT_in_primitiveType10816 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_SMALLINT_in_primitiveType10837 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_INT_in_primitiveType10857 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_BIGINT_in_primitiveType10882 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_BOOLEAN_in_primitiveType10904 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_FLOAT_in_primitiveType10925 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DOUBLE_in_primitiveType10948 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DATE_in_primitiveType10970 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DATETIME_in_primitiveType10994 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_TIMESTAMP_in_primitiveType11014 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_STRING_in_primitiveType11033 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_BINARY_in_primitiveType11055 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DECIMAL_in_primitiveType11077 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_VARCHAR_in_primitiveType11098 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000004000L});
    public static final BitSet FOLLOW_LPAREN_in_primitiveType11100 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_Number_in_primitiveType11104 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000001000000L});
    public static final BitSet FOLLOW_RPAREN_in_primitiveType11106 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_ARRAY_in_listType11150 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000001000L});
    public static final BitSet FOLLOW_LESSTHAN_in_listType11152 = new BitSet(new long[]{0x0000038400000000L,0x00000040000800B0L,0x0000000000400001L,0x0100300C08000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_type_in_listType11154 = new BitSet(new long[]{0x0000000000800000L});
    public static final BitSet FOLLOW_GREATERTHAN_in_listType11156 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_STRUCT_in_structType11193 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000001000L});
    public static final BitSet FOLLOW_LESSTHAN_in_structType11195 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_columnNameColonTypeList_in_structType11197 = new BitSet(new long[]{0x0000000000800000L});
    public static final BitSet FOLLOW_GREATERTHAN_in_structType11199 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_MAP_in_mapType11234 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000001000L});
    public static final BitSet FOLLOW_LESSTHAN_in_mapType11236 = new BitSet(new long[]{0x0000038000000000L,0x00000040000800B0L,0x0000000000000001L,0x0000300408000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_primitiveType_in_mapType11240 = new BitSet(new long[]{0x0000000000000400L});
    public static final BitSet FOLLOW_COMMA_in_mapType11242 = new BitSet(new long[]{0x0000038400000000L,0x00000040000800B0L,0x0000000000400001L,0x0100300C08000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_type_in_mapType11246 = new BitSet(new long[]{0x0000000000800000L});
    public static final BitSet FOLLOW_GREATERTHAN_in_mapType11248 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_UNIONTYPE_in_unionType11291 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000001000L});
    public static final BitSet FOLLOW_LESSTHAN_in_unionType11293 = new BitSet(new long[]{0x0000038400000000L,0x00000040000800B0L,0x0000000000400001L,0x0100300C08000000L,0x0000000000000010L});
    public static final BitSet FOLLOW_colTypeList_in_unionType11295 = new BitSet(new long[]{0x0000000000800000L});
    public static final BitSet FOLLOW_GREATERTHAN_in_unionType11297 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_UNION_in_queryOperator11332 = new BitSet(new long[]{0x0000000020000000L});
    public static final BitSet FOLLOW_KW_ALL_in_queryOperator11334 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_queryStatement_in_queryStatementExpression11358 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
    public static final BitSet FOLLOW_queryOperator_in_queryStatementExpression11361 = new BitSet(new long[]{0x0000000000000000L,0x8000080000000000L,0x0000000000400000L,0x0000000000010002L});
    public static final BitSet FOLLOW_queryStatement_in_queryStatementExpression11364 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0080000000000000L});
    public static final BitSet FOLLOW_fromClause_in_queryStatement11387 = new BitSet(new long[]{0x0000000000000000L,0x8000000000000000L,0x0000000000400000L,0x0000000000010002L});
    public static final BitSet FOLLOW_body_in_queryStatement11397 = new BitSet(new long[]{0x0000000000000002L,0x8000000000000000L,0x0000000000400000L,0x0000000000010002L});
    public static final BitSet FOLLOW_regular_body_in_queryStatement11419 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_insertClause_in_regular_body11438 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000400000L,0x0000000000010002L});
    public static final BitSet FOLLOW_selectClause_in_regular_body11443 = new BitSet(new long[]{0x0000000000000000L,0x0000080000000000L});
    public static final BitSet FOLLOW_fromClause_in_regular_body11448 = new BitSet(new long[]{0x0004000000000002L,0x0005000000040000L,0x0000004000001000L,0x0000000010000000L,0x0000000000000280L});
    public static final BitSet FOLLOW_whereClause_in_regular_body11453 = new BitSet(new long[]{0x0004000000000002L,0x0005000000040000L,0x0000004000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_groupByClause_in_regular_body11459 = new BitSet(new long[]{0x0004000000000002L,0x0004000000040000L,0x0000004000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_havingClause_in_regular_body11465 = new BitSet(new long[]{0x0004000000000002L,0x0000000000040000L,0x0000004000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_orderByClause_in_regular_body11471 = new BitSet(new long[]{0x0004000000000002L,0x0000000000040000L,0x0000000000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_clusterByClause_in_regular_body11477 = new BitSet(new long[]{0x0000000000000002L,0x0000000000040000L,0x0000000000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_distributeByClause_in_regular_body11483 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_sortByClause_in_regular_body11489 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000001000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_window_clause_in_regular_body11495 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000001000L});
    public static final BitSet FOLLOW_limitClause_in_regular_body11501 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_selectStatement_in_regular_body11597 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_selectClause_in_selectStatement11615 = new BitSet(new long[]{0x0000000000000000L,0x0000080000000000L});
    public static final BitSet FOLLOW_fromClause_in_selectStatement11620 = new BitSet(new long[]{0x0004000000000002L,0x0005000000040000L,0x0000004000001000L,0x0000000010000000L,0x0000000000000280L});
    public static final BitSet FOLLOW_whereClause_in_selectStatement11625 = new BitSet(new long[]{0x0004000000000002L,0x0005000000040000L,0x0000004000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_groupByClause_in_selectStatement11631 = new BitSet(new long[]{0x0004000000000002L,0x0004000000040000L,0x0000004000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_havingClause_in_selectStatement11637 = new BitSet(new long[]{0x0004000000000002L,0x0000000000040000L,0x0000004000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_orderByClause_in_selectStatement11643 = new BitSet(new long[]{0x0004000000000002L,0x0000000000040000L,0x0000000000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_clusterByClause_in_selectStatement11649 = new BitSet(new long[]{0x0000000000000002L,0x0000000000040000L,0x0000000000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_distributeByClause_in_selectStatement11655 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_sortByClause_in_selectStatement11661 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000001000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_window_clause_in_selectStatement11667 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000001000L});
    public static final BitSet FOLLOW_limitClause_in_selectStatement11673 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_insertClause_in_body11786 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000400000L,0x0000000000010002L});
    public static final BitSet FOLLOW_selectClause_in_body11791 = new BitSet(new long[]{0x0004000000000002L,0x0005000000040000L,0x0000004000001100L,0x0000000010000000L,0x0000000000000280L});
    public static final BitSet FOLLOW_lateralView_in_body11796 = new BitSet(new long[]{0x0004000000000002L,0x0005000000040000L,0x0000004000001000L,0x0000000010000000L,0x0000000000000280L});
    public static final BitSet FOLLOW_whereClause_in_body11802 = new BitSet(new long[]{0x0004000000000002L,0x0005000000040000L,0x0000004000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_groupByClause_in_body11808 = new BitSet(new long[]{0x0004000000000002L,0x0004000000040000L,0x0000004000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_havingClause_in_body11814 = new BitSet(new long[]{0x0004000000000002L,0x0000000000040000L,0x0000004000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_orderByClause_in_body11820 = new BitSet(new long[]{0x0004000000000002L,0x0000000000040000L,0x0000000000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_clusterByClause_in_body11826 = new BitSet(new long[]{0x0000000000000002L,0x0000000000040000L,0x0000000000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_distributeByClause_in_body11832 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_sortByClause_in_body11838 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000001000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_window_clause_in_body11844 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000001000L});
    public static final BitSet FOLLOW_limitClause_in_body11850 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_selectClause_in_body11943 = new BitSet(new long[]{0x0004000000000002L,0x0005000000040000L,0x0000004000001100L,0x0000000010000000L,0x0000000000000280L});
    public static final BitSet FOLLOW_lateralView_in_body11948 = new BitSet(new long[]{0x0004000000000002L,0x0005000000040000L,0x0000004000001000L,0x0000000010000000L,0x0000000000000280L});
    public static final BitSet FOLLOW_whereClause_in_body11954 = new BitSet(new long[]{0x0004000000000002L,0x0005000000040000L,0x0000004000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_groupByClause_in_body11960 = new BitSet(new long[]{0x0004000000000002L,0x0004000000040000L,0x0000004000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_havingClause_in_body11966 = new BitSet(new long[]{0x0004000000000002L,0x0000000000040000L,0x0000004000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_orderByClause_in_body11972 = new BitSet(new long[]{0x0004000000000002L,0x0000000000040000L,0x0000000000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_clusterByClause_in_body11978 = new BitSet(new long[]{0x0000000000000002L,0x0000000000040000L,0x0000000000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_distributeByClause_in_body11984 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000001000L,0x0000000010000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_sortByClause_in_body11990 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000001000L,0x0000000000000000L,0x0000000000000200L});
    public static final BitSet FOLLOW_window_clause_in_body11996 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000001000L});
    public static final BitSet FOLLOW_limitClause_in_body12002 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_INSERT_in_insertClause12123 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000100000000000L});
    public static final BitSet FOLLOW_KW_OVERWRITE_in_insertClause12125 = new BitSet(new long[]{0x0000000000000000L,0x0000000000008000L,0x0000000000008000L,0x0000001000000000L});
    public static final BitSet FOLLOW_destination_in_insertClause12127 = new BitSet(new long[]{0x0000000000000002L,0x0020000000000000L});
    public static final BitSet FOLLOW_ifNotExists_in_insertClause12129 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_INSERT_in_insertClause12148 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000004L});
    public static final BitSet FOLLOW_KW_INTO_in_insertClause12150 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000001000000000L});
    public static final BitSet FOLLOW_KW_TABLE_in_insertClause12152 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_tableOrPartition_in_insertClause12154 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_LOCAL_in_destination12199 = new BitSet(new long[]{0x0000000000000000L,0x0000000000008000L});
    public static final BitSet FOLLOW_KW_DIRECTORY_in_destination12201 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_destination12203 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000100001000L});
    public static final BitSet FOLLOW_tableRowFormat_in_destination12205 = new BitSet(new long[]{0x0000000000000002L,0x0000000000000000L,0x0000000000000000L,0x0000000100000000L});
    public static final BitSet FOLLOW_tableFileFormat_in_destination12208 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_DIRECTORY_in_destination12230 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000040000000L});
    public static final BitSet FOLLOW_StringLiteral_in_destination12232 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_TABLE_in_destination12247 = new BitSet(new long[]{0x5FBE7FFEDC000000L,0xFFDBD77F7ABDFFFBL,0xFFE7D7EBDB9FFBDFL,0xFDDEF7BFFFFEFFFDL,0x000000000000052FL});
    public static final BitSet FOLLOW_tableOrPartition_in_destination12249 = new BitSet(new long[]{0x0000000000000002L});
    public static final BitSet FOLLOW_KW_LIMIT_in_limitClause12281 = new BitSet(new long[]{0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000000000L,0x0000000000100000L});
    public static final BitSet FOLLOW_Number_in_limitClause12285 = new BitSet(new long[]{0x0000000000000002L});

}